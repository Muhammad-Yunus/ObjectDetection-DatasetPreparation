{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert video to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_video = True # rotate saved image 90* clockwise\n",
    "frame_delta = 10 # save image for each 10 frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing 99 images...\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for name in os.listdir(\"videos\"):\n",
    "    video_name,  video_extension = name.split(\".\")\n",
    "    labels.append(video_name)\n",
    "    \n",
    "    cap = cv2.VideoCapture('videos/' + video_name + video_extension)\n",
    "\n",
    "    counter = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % frame_delta == 0 :\n",
    "            if rotate_video :\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            cv2.imwrite(\"dataset/images/%s_%d.jpg\" % (video_name, counter), frame)\n",
    "            counter += 1\n",
    "\n",
    "    print(\"finish processing %d images %s...\" % (counter, video_name))\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download & Install `Git` :\n",
    "    - https://git-scm.com/downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clone `labelImg` repository using git\n",
    "    - or just download repo as zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/tzutalin/labelImg.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- change dir to labelImg cloned repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunus\\Desktop\\dataset_from_video\\images\n"
     ]
    }
   ],
   "source": [
    "%cd labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install pyqt=5\n",
    "! conda install -c anaconda lxml\n",
    "! pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run `lableImg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open dir `images/` in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- annotate image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 0.2 # 20% for test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train/` and `test/` dir already exist!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "try :\n",
    "    os.mkdir(\"dataset/images/train\")\n",
    "    os.mkdir(\"dataset/images/test\")\n",
    "except :\n",
    "    print(\"`train/` and `test/` dir already exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames = []\n",
    "for file in os.listdir(\"dataset/images\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        all_filenames.append(file.replace(\".jpg\", \"\"))\n",
    "\n",
    "file_counter = {}\n",
    "file_group = {}\n",
    "for name in all_filenames:\n",
    "    label = name.split(\"_\")[0]\n",
    "    try :\n",
    "        file_counter[label] += 1\n",
    "        file_group[label].append(name)\n",
    "    except :\n",
    "        file_counter[label] = 0\n",
    "        file_group[label] = []\n",
    "        \n",
    "print(file_counter)\n",
    "        \n",
    "for label in file_counter:\n",
    "    n_split = int(file_counter[label]*split_size)\n",
    "    for i, name in enumerate(file_group[label]) :\n",
    "        if i < n_split :\n",
    "            shutil.move(\"dataset/images/\" + name + \".jpg\", \"dataset/images/test\")\n",
    "            shutil.move(\"dataset/images/\" + name + \".xml\", \"dataset/images/test\")\n",
    "        else :\n",
    "            shutil.move(\"dataset/images/\" + name + \".jpg\", \"dataset/images/train\")\n",
    "            shutil.move(\"dataset/images/\" + name + \".xml\", \"dataset/images/train\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lambel Map data\n",
    "- label map structure :\n",
    "```\n",
    "item {\n",
    "\tid : 1\n",
    "\tname : \"batman\"\n",
    "}\n",
    "item {\n",
    "\tid : 2\n",
    "\tname : \"ironman\"\n",
    "}\n",
    "item {\n",
    "\tid : 3\n",
    "\tname : \"xxxxxx\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dataset/data/object-detection.pbtxt\"\n",
    "\n",
    "with open(filename, \"w\") as fw:\n",
    "    for i, name in enumerate(file_counter, start=1) :\n",
    "        fw.write('item {\\n')\n",
    "        fw.write('\\tid : %d\\n' % i)\n",
    "        fw.write('\\tname : \"%s\"\\n' % name)\n",
    "        fw.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipdir(path, ziph):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(path, '..')))\n",
    "\n",
    "zipf = zipfile.ZipFile('dataset.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('dataset/', zipf)\n",
    "zipf.close()\n",
    "\n",
    "print(\"`dataset.zip` created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Faster R-CNN Training in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open Google Colab : https://colab.research.google.com/notebooks/intro.ipynb#recent=true\n",
    "- Click tab **Upload**,\n",
    "- Upload `Faster_R_CNN_Training_using_Custom_Dataset.ipynb` to google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CVDL]",
   "language": "python",
   "name": "conda-env-CVDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
