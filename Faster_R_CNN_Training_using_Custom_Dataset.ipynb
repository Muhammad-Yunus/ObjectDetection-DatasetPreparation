{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster R-CNN Training using Custom Dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6baQ8wWMPkfO"
      },
      "source": [
        "# Faster R-CNN Training using Tensorflow\r\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOpn4IebMl6p"
      },
      "source": [
        "# 1. Install Library\n",
        "### 1.A. Install Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvLlklwNhg_"
      },
      "source": [
        "pip install tensorflow_gpu==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLBq4481GWAD"
      },
      "source": [
        "### 1.B. Install Other Library & Clone Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGqlSTLuxld"
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython tf_slim\n",
        "!pip install -q pycocotools\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_drTO_gGeYP"
      },
      "source": [
        "### 1.C. Build Tensorflow Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdUXiMQ-OBX"
      },
      "source": [
        "%cd /content/models/research\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += \":/content/models\"\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append(\"/content/models\")\r\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiXiLQumY-nz"
      },
      "source": [
        "# 2. Prepare Dataset\r\n",
        "### 2.A Upload and extract dataset.\r\n",
        "- upload `dataset.zip` using this script,\r\n",
        "- `dataset.zip` is created by running `dataset_builder.ipynb` from this repository ([ObjectDetection-DatasetPreparation](http://github.com/Muhammad-Yunus/ObjectDetection-DatasetPreparation)) in your local computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THhnes1ckVA5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "5f090762-2516-4ddd-b68a-c4832586c792"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files\n",
        "from os import path\n",
        "\n",
        "print(\"Upload `dataset.zip` to colab :\")\n",
        "uploaded = files.upload()\n",
        "  \n",
        "for fileName, data in uploaded.items():\n",
        "  with open('dataset.zip', 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved dataset (.zip) file ' + fileName)\n",
        "\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Upload `dataset.zip` to colab :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ef325ffe-0cd3-4005-a1f3-2283be455f5e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ef325ffe-0cd3-4005-a1f3-2283be455f5e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataset.zip to dataset.zip\n",
            "saved dataset (.zip) file dataset.zip\n",
            "Extracted zip file dataset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKqIKqOc7bzs"
      },
      "source": [
        "### 2.B. Prepare Dataset \r\n",
        "- Convert XML PASCAL VOC to CSV\r\n",
        "- Create TF_Record from generated CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yre-rvSJ83bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68ad20c-dc57-4a38-f589-14855aad1b8d"
      },
      "source": [
        "%cd /content/dataset\n",
        "\n",
        "!python xml_to_csv.py"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHhmA2KNNUGl"
      },
      "source": [
        "- edit `class_text_to_int()` function in `generated_tfrecord.py` with label and index label we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeqgzNhluaC"
      },
      "source": [
        "%cd /content/dataset\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=data/train.record --image_dir=images/train\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=data/test.record --image_dir=images/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyO_oSKdhsG"
      },
      "source": [
        "# 3. Download pretrained model\n",
        "\n",
        "- Pretrained model (Tensorflow 1 Model Zoo) : [[tensorflow github](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZJly9QBTS1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135a1cfe-6f29-4b58-cd92-3419a6c3b3a4"
      },
      "source": [
        "%cd /content/dataset\n",
        "%rm -rf models\n",
        "\n",
        "%mkdir models\n",
        "%mkdir models/inference_graph"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUDk1gLQsWOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d08105a-c314-4832-9773-f9f867488fa4"
      },
      "source": [
        "%cd /content/dataset/models\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "MODEL = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'faster_rcnn_inception_v2'\n",
        "\n",
        "with urllib.request.urlopen(DOWNLOAD_BASE+MODEL_FILE) as response, open(MODEL_FILE, 'wb') as out_file:\n",
        "  shutil.copyfileobj(response, out_file)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QydCLoLFIWLN"
      },
      "source": [
        "# 4. Edit Config File\r\n",
        "- copy config model to `data/` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UVdm_SRi-SwV",
        "outputId": "a80c1acf-c4f1-4357-be90-1b0c7e461046"
      },
      "source": [
        "CONFIG_NAME = \"faster_rcnn_inception_v2_coco.config\"\r\n",
        "shutil.copy(\r\n",
        "    \"/content/models/research/object_detection/samples/configs/\" + CONFIG_NAME, \r\n",
        "    \"/content/dataset/data/\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/dataset/data/faster_rcnn_inception_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSdT5sLCMyeI"
      },
      "source": [
        "- open & edit config file, \r\n",
        "- \r\n",
        "```\r\n",
        "fine_tune_checkpoint: \"/Path to the pre-trained models/model.ckpt\"\r\n",
        "```\r\n",
        "- \r\n",
        "```\r\n",
        "train_input_reader: {\r\n",
        "  tf_record_input_reader {\r\n",
        "  input_path: \"/Path to the tfrecord/train.record\"\r\n",
        "  }\r\n",
        "  label_map_path: \"/Path to label map/object-detection.pbtxt\"\r\n",
        "}\r\n",
        "```\r\n",
        "- \r\n",
        "```\r\n",
        "eval_input_reader: {\r\n",
        "tf_record_input_reader {\r\n",
        "input_path: \"/Path to the tfrecord/test.record\"\r\n",
        "}\r\n",
        "label_map_path: \"/Path to label map/object-detection.pbtxt\"\r\n",
        "}\r\n",
        "```\r\n",
        "- change  `model`>`faster_rcnn`>`num_classes` to number of class on uploaded dataset.\r\n",
        "- change `train_config`>`num_steps` to 20000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAYXLhS2uZ9X"
      },
      "source": [
        "# 5. Train model\n",
        "Make and set train directory num_train_steps and num_eval_steps values to change train and eval steps in training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF7VAuMY_9aK"
      },
      "source": [
        "!cp /content/models/research/object_detection/legacy/train.py /content/models/research/object_detection"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aFmHc6wcR0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e2512e-cd73-41a2-d8a4-e5d7badec111"
      },
      "source": [
        "%cd /content/models/research/object_detection/\n",
        "%rm -rf training/*\n",
        "\n",
        "!python train.py \\\n",
        "  --logtostderr \\\n",
        "  --train_dir=training/ \\\n",
        "  --pipeline_config_path=/content/dataset/data/faster_rcnn_inception_v2_coco.config"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:global step 7508: loss = 0.0210 (0.156 sec/step)\n",
            "I0213 16:55:00.775731 139806407255936 learning.py:512] global step 7508: loss = 0.0210 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7509: loss = 0.0291 (0.173 sec/step)\n",
            "I0213 16:55:00.950285 139806407255936 learning.py:512] global step 7509: loss = 0.0291 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7510: loss = 0.0228 (0.175 sec/step)\n",
            "I0213 16:55:01.126521 139806407255936 learning.py:512] global step 7510: loss = 0.0228 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7511: loss = 0.0567 (0.156 sec/step)\n",
            "I0213 16:55:01.284325 139806407255936 learning.py:512] global step 7511: loss = 0.0567 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7512: loss = 0.0400 (0.171 sec/step)\n",
            "I0213 16:55:01.456530 139806407255936 learning.py:512] global step 7512: loss = 0.0400 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7513: loss = 0.0150 (0.169 sec/step)\n",
            "I0213 16:55:01.627006 139806407255936 learning.py:512] global step 7513: loss = 0.0150 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7514: loss = 0.0646 (0.172 sec/step)\n",
            "I0213 16:55:01.800349 139806407255936 learning.py:512] global step 7514: loss = 0.0646 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7515: loss = 0.0171 (0.172 sec/step)\n",
            "I0213 16:55:01.974307 139806407255936 learning.py:512] global step 7515: loss = 0.0171 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7516: loss = 0.0277 (0.167 sec/step)\n",
            "I0213 16:55:02.142817 139806407255936 learning.py:512] global step 7516: loss = 0.0277 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7517: loss = 0.0303 (0.168 sec/step)\n",
            "I0213 16:55:02.312740 139806407255936 learning.py:512] global step 7517: loss = 0.0303 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7518: loss = 0.0340 (0.165 sec/step)\n",
            "I0213 16:55:02.479453 139806407255936 learning.py:512] global step 7518: loss = 0.0340 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7519: loss = 0.0367 (0.176 sec/step)\n",
            "I0213 16:55:02.657147 139806407255936 learning.py:512] global step 7519: loss = 0.0367 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7520: loss = 0.0446 (0.163 sec/step)\n",
            "I0213 16:55:02.821244 139806407255936 learning.py:512] global step 7520: loss = 0.0446 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7521: loss = 0.0180 (0.166 sec/step)\n",
            "I0213 16:55:02.988603 139806407255936 learning.py:512] global step 7521: loss = 0.0180 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7522: loss = 0.0173 (0.161 sec/step)\n",
            "I0213 16:55:03.150938 139806407255936 learning.py:512] global step 7522: loss = 0.0173 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7523: loss = 0.0332 (0.169 sec/step)\n",
            "I0213 16:55:03.321393 139806407255936 learning.py:512] global step 7523: loss = 0.0332 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7524: loss = 0.0151 (0.166 sec/step)\n",
            "I0213 16:55:03.488804 139806407255936 learning.py:512] global step 7524: loss = 0.0151 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7525: loss = 0.0386 (0.187 sec/step)\n",
            "I0213 16:55:03.676781 139806407255936 learning.py:512] global step 7525: loss = 0.0386 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7526: loss = 0.0187 (0.165 sec/step)\n",
            "I0213 16:55:03.843496 139806407255936 learning.py:512] global step 7526: loss = 0.0187 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7527: loss = 0.0266 (0.194 sec/step)\n",
            "I0213 16:55:04.038493 139806407255936 learning.py:512] global step 7527: loss = 0.0266 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 7528: loss = 0.0271 (0.169 sec/step)\n",
            "I0213 16:55:04.209142 139806407255936 learning.py:512] global step 7528: loss = 0.0271 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7529: loss = 0.0376 (0.160 sec/step)\n",
            "I0213 16:55:04.370398 139806407255936 learning.py:512] global step 7529: loss = 0.0376 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7530: loss = 0.0387 (0.167 sec/step)\n",
            "I0213 16:55:04.538927 139806407255936 learning.py:512] global step 7530: loss = 0.0387 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7531: loss = 0.0172 (0.172 sec/step)\n",
            "I0213 16:55:04.711992 139806407255936 learning.py:512] global step 7531: loss = 0.0172 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7532: loss = 0.0390 (0.182 sec/step)\n",
            "I0213 16:55:04.895938 139806407255936 learning.py:512] global step 7532: loss = 0.0390 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7533: loss = 0.0248 (0.177 sec/step)\n",
            "I0213 16:55:05.074114 139806407255936 learning.py:512] global step 7533: loss = 0.0248 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7534: loss = 0.0428 (0.178 sec/step)\n",
            "I0213 16:55:05.253728 139806407255936 learning.py:512] global step 7534: loss = 0.0428 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7535: loss = 0.0301 (0.173 sec/step)\n",
            "I0213 16:55:05.428188 139806407255936 learning.py:512] global step 7535: loss = 0.0301 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7536: loss = 0.0139 (0.178 sec/step)\n",
            "I0213 16:55:05.607793 139806407255936 learning.py:512] global step 7536: loss = 0.0139 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7537: loss = 0.0370 (0.157 sec/step)\n",
            "I0213 16:55:05.766220 139806407255936 learning.py:512] global step 7537: loss = 0.0370 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7538: loss = 0.0359 (0.165 sec/step)\n",
            "I0213 16:55:05.932282 139806407255936 learning.py:512] global step 7538: loss = 0.0359 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7539: loss = 0.0250 (0.173 sec/step)\n",
            "I0213 16:55:06.106526 139806407255936 learning.py:512] global step 7539: loss = 0.0250 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7540: loss = 0.0266 (0.166 sec/step)\n",
            "I0213 16:55:06.273374 139806407255936 learning.py:512] global step 7540: loss = 0.0266 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7541: loss = 0.0341 (0.187 sec/step)\n",
            "I0213 16:55:06.461798 139806407255936 learning.py:512] global step 7541: loss = 0.0341 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7542: loss = 0.0493 (0.165 sec/step)\n",
            "I0213 16:55:06.627976 139806407255936 learning.py:512] global step 7542: loss = 0.0493 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7543: loss = 0.0440 (0.168 sec/step)\n",
            "I0213 16:55:06.797473 139806407255936 learning.py:512] global step 7543: loss = 0.0440 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7544: loss = 0.0159 (0.158 sec/step)\n",
            "I0213 16:55:06.957782 139806407255936 learning.py:512] global step 7544: loss = 0.0159 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7545: loss = 0.0371 (0.160 sec/step)\n",
            "I0213 16:55:07.119935 139806407255936 learning.py:512] global step 7545: loss = 0.0371 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7546: loss = 0.0167 (0.177 sec/step)\n",
            "I0213 16:55:07.298028 139806407255936 learning.py:512] global step 7546: loss = 0.0167 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7547: loss = 0.0515 (0.161 sec/step)\n",
            "I0213 16:55:07.460112 139806407255936 learning.py:512] global step 7547: loss = 0.0515 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7548: loss = 0.0748 (0.169 sec/step)\n",
            "I0213 16:55:07.630542 139806407255936 learning.py:512] global step 7548: loss = 0.0748 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7549: loss = 0.0947 (0.179 sec/step)\n",
            "I0213 16:55:07.810642 139806407255936 learning.py:512] global step 7549: loss = 0.0947 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7550: loss = 0.0250 (0.168 sec/step)\n",
            "I0213 16:55:07.980549 139806407255936 learning.py:512] global step 7550: loss = 0.0250 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7551: loss = 0.0377 (0.176 sec/step)\n",
            "I0213 16:55:08.158296 139806407255936 learning.py:512] global step 7551: loss = 0.0377 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7552: loss = 0.0308 (0.168 sec/step)\n",
            "I0213 16:55:08.327910 139806407255936 learning.py:512] global step 7552: loss = 0.0308 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7553: loss = 0.0194 (0.167 sec/step)\n",
            "I0213 16:55:08.496121 139806407255936 learning.py:512] global step 7553: loss = 0.0194 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7554: loss = 0.0415 (0.177 sec/step)\n",
            "I0213 16:55:08.674774 139806407255936 learning.py:512] global step 7554: loss = 0.0415 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7555: loss = 0.0128 (0.176 sec/step)\n",
            "I0213 16:55:08.852200 139806407255936 learning.py:512] global step 7555: loss = 0.0128 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7556: loss = 0.0274 (0.158 sec/step)\n",
            "I0213 16:55:09.012827 139806407255936 learning.py:512] global step 7556: loss = 0.0274 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7557: loss = 0.0151 (0.163 sec/step)\n",
            "I0213 16:55:09.176985 139806407255936 learning.py:512] global step 7557: loss = 0.0151 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7558: loss = 0.0626 (0.161 sec/step)\n",
            "I0213 16:55:09.339286 139806407255936 learning.py:512] global step 7558: loss = 0.0626 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7559: loss = 0.0263 (0.164 sec/step)\n",
            "I0213 16:55:09.505008 139806407255936 learning.py:512] global step 7559: loss = 0.0263 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7560: loss = 0.0286 (0.184 sec/step)\n",
            "I0213 16:55:09.690289 139806407255936 learning.py:512] global step 7560: loss = 0.0286 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7561: loss = 0.0366 (0.174 sec/step)\n",
            "I0213 16:55:09.865327 139806407255936 learning.py:512] global step 7561: loss = 0.0366 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7562: loss = 0.0356 (0.185 sec/step)\n",
            "I0213 16:55:10.051318 139806407255936 learning.py:512] global step 7562: loss = 0.0356 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7563: loss = 0.0186 (0.179 sec/step)\n",
            "I0213 16:55:10.231952 139806407255936 learning.py:512] global step 7563: loss = 0.0186 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7564: loss = 0.0283 (0.158 sec/step)\n",
            "I0213 16:55:10.391321 139806407255936 learning.py:512] global step 7564: loss = 0.0283 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7565: loss = 0.0370 (0.167 sec/step)\n",
            "I0213 16:55:10.560128 139806407255936 learning.py:512] global step 7565: loss = 0.0370 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7566: loss = 0.0160 (0.155 sec/step)\n",
            "I0213 16:55:10.716386 139806407255936 learning.py:512] global step 7566: loss = 0.0160 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7567: loss = 0.0341 (0.164 sec/step)\n",
            "I0213 16:55:10.881594 139806407255936 learning.py:512] global step 7567: loss = 0.0341 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7568: loss = 0.0121 (0.151 sec/step)\n",
            "I0213 16:55:11.033651 139806407255936 learning.py:512] global step 7568: loss = 0.0121 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 7569: loss = 0.0219 (0.170 sec/step)\n",
            "I0213 16:55:11.205321 139806407255936 learning.py:512] global step 7569: loss = 0.0219 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7570: loss = 0.0118 (0.176 sec/step)\n",
            "I0213 16:55:11.383202 139806407255936 learning.py:512] global step 7570: loss = 0.0118 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7571: loss = 0.0147 (0.165 sec/step)\n",
            "I0213 16:55:11.549234 139806407255936 learning.py:512] global step 7571: loss = 0.0147 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7572: loss = 0.0145 (0.170 sec/step)\n",
            "I0213 16:55:11.720829 139806407255936 learning.py:512] global step 7572: loss = 0.0145 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7573: loss = 0.0168 (0.171 sec/step)\n",
            "I0213 16:55:11.893316 139806407255936 learning.py:512] global step 7573: loss = 0.0168 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7574: loss = 0.0230 (0.175 sec/step)\n",
            "I0213 16:55:12.069236 139806407255936 learning.py:512] global step 7574: loss = 0.0230 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7575: loss = 0.0366 (0.192 sec/step)\n",
            "I0213 16:55:12.262759 139806407255936 learning.py:512] global step 7575: loss = 0.0366 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7576: loss = 0.0263 (0.162 sec/step)\n",
            "I0213 16:55:12.426110 139806407255936 learning.py:512] global step 7576: loss = 0.0263 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7577: loss = 0.0163 (0.160 sec/step)\n",
            "I0213 16:55:12.587751 139806407255936 learning.py:512] global step 7577: loss = 0.0163 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7578: loss = 0.0464 (0.164 sec/step)\n",
            "I0213 16:55:12.753108 139806407255936 learning.py:512] global step 7578: loss = 0.0464 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7579: loss = 0.0203 (0.185 sec/step)\n",
            "I0213 16:55:12.940289 139806407255936 learning.py:512] global step 7579: loss = 0.0203 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7580: loss = 0.0205 (0.181 sec/step)\n",
            "I0213 16:55:13.123167 139806407255936 learning.py:512] global step 7580: loss = 0.0205 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7581: loss = 0.0847 (0.174 sec/step)\n",
            "I0213 16:55:13.298144 139806407255936 learning.py:512] global step 7581: loss = 0.0847 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7582: loss = 0.0283 (0.166 sec/step)\n",
            "I0213 16:55:13.465895 139806407255936 learning.py:512] global step 7582: loss = 0.0283 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7583: loss = 0.0480 (0.174 sec/step)\n",
            "I0213 16:55:13.640802 139806407255936 learning.py:512] global step 7583: loss = 0.0480 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7584: loss = 0.0476 (0.176 sec/step)\n",
            "I0213 16:55:13.818072 139806407255936 learning.py:512] global step 7584: loss = 0.0476 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7585: loss = 0.0364 (0.155 sec/step)\n",
            "I0213 16:55:13.974486 139806407255936 learning.py:512] global step 7585: loss = 0.0364 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7586: loss = 0.0791 (0.186 sec/step)\n",
            "I0213 16:55:14.162052 139806407255936 learning.py:512] global step 7586: loss = 0.0791 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7587: loss = 0.0203 (0.166 sec/step)\n",
            "I0213 16:55:14.329477 139806407255936 learning.py:512] global step 7587: loss = 0.0203 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7588: loss = 0.0338 (0.166 sec/step)\n",
            "I0213 16:55:14.496249 139806407255936 learning.py:512] global step 7588: loss = 0.0338 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7589: loss = 0.0297 (0.170 sec/step)\n",
            "I0213 16:55:14.667398 139806407255936 learning.py:512] global step 7589: loss = 0.0297 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7590: loss = 0.0508 (0.165 sec/step)\n",
            "I0213 16:55:14.833748 139806407255936 learning.py:512] global step 7590: loss = 0.0508 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7591: loss = 0.0224 (0.169 sec/step)\n",
            "I0213 16:55:15.003847 139806407255936 learning.py:512] global step 7591: loss = 0.0224 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7592: loss = 0.0241 (0.189 sec/step)\n",
            "I0213 16:55:15.194338 139806407255936 learning.py:512] global step 7592: loss = 0.0241 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7593: loss = 0.0352 (0.156 sec/step)\n",
            "I0213 16:55:15.351840 139806407255936 learning.py:512] global step 7593: loss = 0.0352 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7594: loss = 0.0260 (0.179 sec/step)\n",
            "I0213 16:55:15.532163 139806407255936 learning.py:512] global step 7594: loss = 0.0260 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7595: loss = 0.0431 (0.169 sec/step)\n",
            "I0213 16:55:15.702503 139806407255936 learning.py:512] global step 7595: loss = 0.0431 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7596: loss = 0.0188 (0.176 sec/step)\n",
            "I0213 16:55:15.879581 139806407255936 learning.py:512] global step 7596: loss = 0.0188 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7597: loss = 0.0620 (0.175 sec/step)\n",
            "I0213 16:55:16.056298 139806407255936 learning.py:512] global step 7597: loss = 0.0620 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7598: loss = 0.0562 (0.166 sec/step)\n",
            "I0213 16:55:16.224002 139806407255936 learning.py:512] global step 7598: loss = 0.0562 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7599: loss = 0.0316 (0.162 sec/step)\n",
            "I0213 16:55:16.387447 139806407255936 learning.py:512] global step 7599: loss = 0.0316 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7600: loss = 0.0252 (0.174 sec/step)\n",
            "I0213 16:55:16.562613 139806407255936 learning.py:512] global step 7600: loss = 0.0252 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7601: loss = 0.0412 (0.170 sec/step)\n",
            "I0213 16:55:16.734293 139806407255936 learning.py:512] global step 7601: loss = 0.0412 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7602: loss = 0.0218 (0.163 sec/step)\n",
            "I0213 16:55:16.899043 139806407255936 learning.py:512] global step 7602: loss = 0.0218 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7603: loss = 0.0314 (0.179 sec/step)\n",
            "I0213 16:55:17.079200 139806407255936 learning.py:512] global step 7603: loss = 0.0314 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7604: loss = 0.0224 (0.176 sec/step)\n",
            "I0213 16:55:17.256894 139806407255936 learning.py:512] global step 7604: loss = 0.0224 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7605: loss = 0.0460 (0.184 sec/step)\n",
            "I0213 16:55:17.441935 139806407255936 learning.py:512] global step 7605: loss = 0.0460 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7606: loss = 0.0383 (0.158 sec/step)\n",
            "I0213 16:55:17.601663 139806407255936 learning.py:512] global step 7606: loss = 0.0383 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7607: loss = 0.0145 (0.179 sec/step)\n",
            "I0213 16:55:17.782357 139806407255936 learning.py:512] global step 7607: loss = 0.0145 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7608: loss = 0.0220 (0.175 sec/step)\n",
            "I0213 16:55:17.958437 139806407255936 learning.py:512] global step 7608: loss = 0.0220 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7609: loss = 0.0133 (0.168 sec/step)\n",
            "I0213 16:55:18.127806 139806407255936 learning.py:512] global step 7609: loss = 0.0133 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7610: loss = 0.0268 (0.169 sec/step)\n",
            "I0213 16:55:18.298316 139806407255936 learning.py:512] global step 7610: loss = 0.0268 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7611: loss = 0.0488 (0.167 sec/step)\n",
            "I0213 16:55:18.466707 139806407255936 learning.py:512] global step 7611: loss = 0.0488 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7612: loss = 0.0126 (0.171 sec/step)\n",
            "I0213 16:55:18.638825 139806407255936 learning.py:512] global step 7612: loss = 0.0126 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7613: loss = 0.1247 (0.174 sec/step)\n",
            "I0213 16:55:18.814834 139806407255936 learning.py:512] global step 7613: loss = 0.1247 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7614: loss = 0.0210 (0.169 sec/step)\n",
            "I0213 16:55:18.985253 139806407255936 learning.py:512] global step 7614: loss = 0.0210 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7615: loss = 0.0814 (0.192 sec/step)\n",
            "I0213 16:55:19.178201 139806407255936 learning.py:512] global step 7615: loss = 0.0814 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7616: loss = 0.0205 (0.155 sec/step)\n",
            "I0213 16:55:19.334900 139806407255936 learning.py:512] global step 7616: loss = 0.0205 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7617: loss = 0.0805 (0.172 sec/step)\n",
            "I0213 16:55:19.507802 139806407255936 learning.py:512] global step 7617: loss = 0.0805 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7618: loss = 0.0327 (0.187 sec/step)\n",
            "I0213 16:55:19.696359 139806407255936 learning.py:512] global step 7618: loss = 0.0327 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7619: loss = 0.0438 (0.164 sec/step)\n",
            "I0213 16:55:19.861469 139806407255936 learning.py:512] global step 7619: loss = 0.0438 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7620: loss = 0.0379 (0.164 sec/step)\n",
            "I0213 16:55:20.026751 139806407255936 learning.py:512] global step 7620: loss = 0.0379 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7621: loss = 0.0160 (0.154 sec/step)\n",
            "I0213 16:55:20.182405 139806407255936 learning.py:512] global step 7621: loss = 0.0160 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 7622: loss = 0.0447 (0.164 sec/step)\n",
            "I0213 16:55:20.347426 139806407255936 learning.py:512] global step 7622: loss = 0.0447 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7623: loss = 0.0376 (0.171 sec/step)\n",
            "I0213 16:55:20.520151 139806407255936 learning.py:512] global step 7623: loss = 0.0376 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7624: loss = 0.0177 (0.180 sec/step)\n",
            "I0213 16:55:20.702116 139806407255936 learning.py:512] global step 7624: loss = 0.0177 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7625: loss = 0.0321 (0.173 sec/step)\n",
            "I0213 16:55:20.876340 139806407255936 learning.py:512] global step 7625: loss = 0.0321 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7626: loss = 0.0381 (0.292 sec/step)\n",
            "I0213 16:55:21.344815 139806407255936 learning.py:512] global step 7626: loss = 0.0381 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 7627: loss = 0.0425 (0.305 sec/step)\n",
            "I0213 16:55:21.659910 139806407255936 learning.py:512] global step 7627: loss = 0.0425 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 7628: loss = 0.0425 (0.226 sec/step)\n",
            "I0213 16:55:21.887952 139806407255936 learning.py:512] global step 7628: loss = 0.0425 (0.226 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7628.\n",
            "I0213 16:55:21.893917 139802720151296 supervisor.py:1050] Recording summary at step 7628.\n",
            "INFO:tensorflow:global step 7629: loss = 0.0240 (0.179 sec/step)\n",
            "I0213 16:55:22.068234 139806407255936 learning.py:512] global step 7629: loss = 0.0240 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7630: loss = 0.0177 (0.183 sec/step)\n",
            "I0213 16:55:22.252100 139806407255936 learning.py:512] global step 7630: loss = 0.0177 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7631: loss = 0.0317 (0.174 sec/step)\n",
            "I0213 16:55:22.427540 139806407255936 learning.py:512] global step 7631: loss = 0.0317 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7632: loss = 0.0530 (0.172 sec/step)\n",
            "I0213 16:55:22.601008 139806407255936 learning.py:512] global step 7632: loss = 0.0530 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7633: loss = 0.0353 (0.199 sec/step)\n",
            "I0213 16:55:22.801062 139806407255936 learning.py:512] global step 7633: loss = 0.0353 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 7634: loss = 0.0793 (0.168 sec/step)\n",
            "I0213 16:55:22.970943 139806407255936 learning.py:512] global step 7634: loss = 0.0793 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7635: loss = 0.0922 (0.173 sec/step)\n",
            "I0213 16:55:23.145573 139806407255936 learning.py:512] global step 7635: loss = 0.0922 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7636: loss = 0.0134 (0.158 sec/step)\n",
            "I0213 16:55:23.304544 139806407255936 learning.py:512] global step 7636: loss = 0.0134 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7637: loss = 0.0266 (0.161 sec/step)\n",
            "I0213 16:55:23.467331 139806407255936 learning.py:512] global step 7637: loss = 0.0266 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7638: loss = 0.0167 (0.168 sec/step)\n",
            "I0213 16:55:23.636174 139806407255936 learning.py:512] global step 7638: loss = 0.0167 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7639: loss = 0.0400 (0.172 sec/step)\n",
            "I0213 16:55:23.809255 139806407255936 learning.py:512] global step 7639: loss = 0.0400 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7640: loss = 0.0424 (0.179 sec/step)\n",
            "I0213 16:55:23.991446 139806407255936 learning.py:512] global step 7640: loss = 0.0424 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7641: loss = 0.0463 (0.168 sec/step)\n",
            "I0213 16:55:24.161098 139806407255936 learning.py:512] global step 7641: loss = 0.0463 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7642: loss = 0.0324 (0.179 sec/step)\n",
            "I0213 16:55:24.341276 139806407255936 learning.py:512] global step 7642: loss = 0.0324 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7643: loss = 0.0425 (0.173 sec/step)\n",
            "I0213 16:55:24.516165 139806407255936 learning.py:512] global step 7643: loss = 0.0425 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7644: loss = 0.0507 (0.163 sec/step)\n",
            "I0213 16:55:24.680514 139806407255936 learning.py:512] global step 7644: loss = 0.0507 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7645: loss = 0.0125 (0.172 sec/step)\n",
            "I0213 16:55:24.853556 139806407255936 learning.py:512] global step 7645: loss = 0.0125 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7646: loss = 0.0271 (0.179 sec/step)\n",
            "I0213 16:55:25.033562 139806407255936 learning.py:512] global step 7646: loss = 0.0271 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7647: loss = 0.0521 (0.169 sec/step)\n",
            "I0213 16:55:25.204735 139806407255936 learning.py:512] global step 7647: loss = 0.0521 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7648: loss = 0.0742 (0.160 sec/step)\n",
            "I0213 16:55:25.365980 139806407255936 learning.py:512] global step 7648: loss = 0.0742 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7649: loss = 0.0308 (0.159 sec/step)\n",
            "I0213 16:55:25.526392 139806407255936 learning.py:512] global step 7649: loss = 0.0308 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7650: loss = 0.0855 (0.167 sec/step)\n",
            "I0213 16:55:25.695144 139806407255936 learning.py:512] global step 7650: loss = 0.0855 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7651: loss = 0.0145 (0.170 sec/step)\n",
            "I0213 16:55:25.865959 139806407255936 learning.py:512] global step 7651: loss = 0.0145 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7652: loss = 0.0172 (0.165 sec/step)\n",
            "I0213 16:55:26.032398 139806407255936 learning.py:512] global step 7652: loss = 0.0172 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7653: loss = 0.0331 (0.155 sec/step)\n",
            "I0213 16:55:26.188449 139806407255936 learning.py:512] global step 7653: loss = 0.0331 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7654: loss = 0.0191 (0.169 sec/step)\n",
            "I0213 16:55:26.359447 139806407255936 learning.py:512] global step 7654: loss = 0.0191 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7655: loss = 0.0362 (0.163 sec/step)\n",
            "I0213 16:55:26.523523 139806407255936 learning.py:512] global step 7655: loss = 0.0362 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7656: loss = 0.0210 (0.165 sec/step)\n",
            "I0213 16:55:26.689496 139806407255936 learning.py:512] global step 7656: loss = 0.0210 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7657: loss = 0.0179 (0.159 sec/step)\n",
            "I0213 16:55:26.849360 139806407255936 learning.py:512] global step 7657: loss = 0.0179 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7658: loss = 0.0196 (0.166 sec/step)\n",
            "I0213 16:55:27.016695 139806407255936 learning.py:512] global step 7658: loss = 0.0196 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7659: loss = 0.0272 (0.167 sec/step)\n",
            "I0213 16:55:27.185280 139806407255936 learning.py:512] global step 7659: loss = 0.0272 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7660: loss = 0.0340 (0.172 sec/step)\n",
            "I0213 16:55:27.359098 139806407255936 learning.py:512] global step 7660: loss = 0.0340 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7661: loss = 0.0263 (0.176 sec/step)\n",
            "I0213 16:55:27.536443 139806407255936 learning.py:512] global step 7661: loss = 0.0263 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7662: loss = 0.0448 (0.172 sec/step)\n",
            "I0213 16:55:27.710167 139806407255936 learning.py:512] global step 7662: loss = 0.0448 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7663: loss = 0.0262 (0.156 sec/step)\n",
            "I0213 16:55:27.867280 139806407255936 learning.py:512] global step 7663: loss = 0.0262 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7664: loss = 0.0115 (0.159 sec/step)\n",
            "I0213 16:55:28.027275 139806407255936 learning.py:512] global step 7664: loss = 0.0115 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7665: loss = 0.0256 (0.180 sec/step)\n",
            "I0213 16:55:28.208734 139806407255936 learning.py:512] global step 7665: loss = 0.0256 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7666: loss = 0.0212 (0.159 sec/step)\n",
            "I0213 16:55:28.369367 139806407255936 learning.py:512] global step 7666: loss = 0.0212 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7667: loss = 0.0215 (0.185 sec/step)\n",
            "I0213 16:55:28.555879 139806407255936 learning.py:512] global step 7667: loss = 0.0215 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7668: loss = 0.0318 (0.164 sec/step)\n",
            "I0213 16:55:28.720897 139806407255936 learning.py:512] global step 7668: loss = 0.0318 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7669: loss = 0.0120 (0.161 sec/step)\n",
            "I0213 16:55:28.883276 139806407255936 learning.py:512] global step 7669: loss = 0.0120 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7670: loss = 0.0386 (0.170 sec/step)\n",
            "I0213 16:55:29.054171 139806407255936 learning.py:512] global step 7670: loss = 0.0386 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7671: loss = 0.0434 (0.164 sec/step)\n",
            "I0213 16:55:29.220209 139806407255936 learning.py:512] global step 7671: loss = 0.0434 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7672: loss = 0.0215 (0.161 sec/step)\n",
            "I0213 16:55:29.382965 139806407255936 learning.py:512] global step 7672: loss = 0.0215 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7673: loss = 0.0274 (0.170 sec/step)\n",
            "I0213 16:55:29.554453 139806407255936 learning.py:512] global step 7673: loss = 0.0274 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7674: loss = 0.0178 (0.146 sec/step)\n",
            "I0213 16:55:29.701973 139806407255936 learning.py:512] global step 7674: loss = 0.0178 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 7675: loss = 0.0319 (0.166 sec/step)\n",
            "I0213 16:55:29.870271 139806407255936 learning.py:512] global step 7675: loss = 0.0319 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7676: loss = 0.0389 (0.168 sec/step)\n",
            "I0213 16:55:30.039784 139806407255936 learning.py:512] global step 7676: loss = 0.0389 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7677: loss = 0.0505 (0.161 sec/step)\n",
            "I0213 16:55:30.201860 139806407255936 learning.py:512] global step 7677: loss = 0.0505 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7678: loss = 0.0301 (0.177 sec/step)\n",
            "I0213 16:55:30.379710 139806407255936 learning.py:512] global step 7678: loss = 0.0301 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7679: loss = 0.0243 (0.166 sec/step)\n",
            "I0213 16:55:30.546582 139806407255936 learning.py:512] global step 7679: loss = 0.0243 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7680: loss = 0.0163 (0.168 sec/step)\n",
            "I0213 16:55:30.716221 139806407255936 learning.py:512] global step 7680: loss = 0.0163 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7681: loss = 0.0105 (0.170 sec/step)\n",
            "I0213 16:55:30.887486 139806407255936 learning.py:512] global step 7681: loss = 0.0105 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7682: loss = 0.0321 (0.161 sec/step)\n",
            "I0213 16:55:31.050067 139806407255936 learning.py:512] global step 7682: loss = 0.0321 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7683: loss = 0.0353 (0.171 sec/step)\n",
            "I0213 16:55:31.222575 139806407255936 learning.py:512] global step 7683: loss = 0.0353 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7684: loss = 0.0251 (0.183 sec/step)\n",
            "I0213 16:55:31.406900 139806407255936 learning.py:512] global step 7684: loss = 0.0251 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7685: loss = 0.0352 (0.163 sec/step)\n",
            "I0213 16:55:31.571337 139806407255936 learning.py:512] global step 7685: loss = 0.0352 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7686: loss = 0.0492 (0.169 sec/step)\n",
            "I0213 16:55:31.741753 139806407255936 learning.py:512] global step 7686: loss = 0.0492 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7687: loss = 0.0220 (0.159 sec/step)\n",
            "I0213 16:55:31.902671 139806407255936 learning.py:512] global step 7687: loss = 0.0220 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7688: loss = 0.0562 (0.172 sec/step)\n",
            "I0213 16:55:32.076552 139806407255936 learning.py:512] global step 7688: loss = 0.0562 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7689: loss = 0.0637 (0.163 sec/step)\n",
            "I0213 16:55:32.241170 139806407255936 learning.py:512] global step 7689: loss = 0.0637 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7690: loss = 0.0146 (0.182 sec/step)\n",
            "I0213 16:55:32.424687 139806407255936 learning.py:512] global step 7690: loss = 0.0146 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7691: loss = 0.0364 (0.180 sec/step)\n",
            "I0213 16:55:32.605733 139806407255936 learning.py:512] global step 7691: loss = 0.0364 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7692: loss = 0.0292 (0.185 sec/step)\n",
            "I0213 16:55:32.792294 139806407255936 learning.py:512] global step 7692: loss = 0.0292 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7693: loss = 0.0180 (0.160 sec/step)\n",
            "I0213 16:55:32.953186 139806407255936 learning.py:512] global step 7693: loss = 0.0180 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7694: loss = 0.0642 (0.165 sec/step)\n",
            "I0213 16:55:33.119338 139806407255936 learning.py:512] global step 7694: loss = 0.0642 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7695: loss = 0.0227 (0.166 sec/step)\n",
            "I0213 16:55:33.286548 139806407255936 learning.py:512] global step 7695: loss = 0.0227 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7696: loss = 0.0156 (0.172 sec/step)\n",
            "I0213 16:55:33.460698 139806407255936 learning.py:512] global step 7696: loss = 0.0156 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7697: loss = 0.0509 (0.151 sec/step)\n",
            "I0213 16:55:33.613468 139806407255936 learning.py:512] global step 7697: loss = 0.0509 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 7698: loss = 0.0759 (0.179 sec/step)\n",
            "I0213 16:55:33.793353 139806407255936 learning.py:512] global step 7698: loss = 0.0759 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7699: loss = 0.0182 (0.170 sec/step)\n",
            "I0213 16:55:33.964819 139806407255936 learning.py:512] global step 7699: loss = 0.0182 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7700: loss = 0.0478 (0.178 sec/step)\n",
            "I0213 16:55:34.144081 139806407255936 learning.py:512] global step 7700: loss = 0.0478 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7701: loss = 0.0806 (0.173 sec/step)\n",
            "I0213 16:55:34.318986 139806407255936 learning.py:512] global step 7701: loss = 0.0806 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7702: loss = 0.0273 (0.176 sec/step)\n",
            "I0213 16:55:34.496491 139806407255936 learning.py:512] global step 7702: loss = 0.0273 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7703: loss = 0.0068 (0.176 sec/step)\n",
            "I0213 16:55:34.673541 139806407255936 learning.py:512] global step 7703: loss = 0.0068 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7704: loss = 0.0202 (0.163 sec/step)\n",
            "I0213 16:55:34.837944 139806407255936 learning.py:512] global step 7704: loss = 0.0202 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7705: loss = 0.0440 (0.164 sec/step)\n",
            "I0213 16:55:35.003422 139806407255936 learning.py:512] global step 7705: loss = 0.0440 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7706: loss = 0.0083 (0.166 sec/step)\n",
            "I0213 16:55:35.170328 139806407255936 learning.py:512] global step 7706: loss = 0.0083 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7707: loss = 0.0134 (0.166 sec/step)\n",
            "I0213 16:55:35.337595 139806407255936 learning.py:512] global step 7707: loss = 0.0134 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7708: loss = 0.0375 (0.169 sec/step)\n",
            "I0213 16:55:35.507692 139806407255936 learning.py:512] global step 7708: loss = 0.0375 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7709: loss = 0.0165 (0.167 sec/step)\n",
            "I0213 16:55:35.675843 139806407255936 learning.py:512] global step 7709: loss = 0.0165 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7710: loss = 0.0225 (0.160 sec/step)\n",
            "I0213 16:55:35.837303 139806407255936 learning.py:512] global step 7710: loss = 0.0225 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7711: loss = 0.0265 (0.160 sec/step)\n",
            "I0213 16:55:35.998384 139806407255936 learning.py:512] global step 7711: loss = 0.0265 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7712: loss = 0.0339 (0.155 sec/step)\n",
            "I0213 16:55:36.154721 139806407255936 learning.py:512] global step 7712: loss = 0.0339 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7713: loss = 0.0317 (0.155 sec/step)\n",
            "I0213 16:55:36.311678 139806407255936 learning.py:512] global step 7713: loss = 0.0317 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7714: loss = 0.0152 (0.181 sec/step)\n",
            "I0213 16:55:36.493672 139806407255936 learning.py:512] global step 7714: loss = 0.0152 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7715: loss = 0.0148 (0.193 sec/step)\n",
            "I0213 16:55:36.687692 139806407255936 learning.py:512] global step 7715: loss = 0.0148 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7716: loss = 0.0311 (0.174 sec/step)\n",
            "I0213 16:55:36.862728 139806407255936 learning.py:512] global step 7716: loss = 0.0311 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7717: loss = 0.0158 (0.173 sec/step)\n",
            "I0213 16:55:37.037518 139806407255936 learning.py:512] global step 7717: loss = 0.0158 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7718: loss = 0.0132 (0.178 sec/step)\n",
            "I0213 16:55:37.217212 139806407255936 learning.py:512] global step 7718: loss = 0.0132 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7719: loss = 0.0282 (0.184 sec/step)\n",
            "I0213 16:55:37.402402 139806407255936 learning.py:512] global step 7719: loss = 0.0282 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7720: loss = 0.0289 (0.181 sec/step)\n",
            "I0213 16:55:37.584987 139806407255936 learning.py:512] global step 7720: loss = 0.0289 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7721: loss = 0.0178 (0.176 sec/step)\n",
            "I0213 16:55:37.762012 139806407255936 learning.py:512] global step 7721: loss = 0.0178 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7722: loss = 0.0179 (0.186 sec/step)\n",
            "I0213 16:55:37.949162 139806407255936 learning.py:512] global step 7722: loss = 0.0179 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7723: loss = 0.0342 (0.182 sec/step)\n",
            "I0213 16:55:38.132172 139806407255936 learning.py:512] global step 7723: loss = 0.0342 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7724: loss = 0.0382 (0.172 sec/step)\n",
            "I0213 16:55:38.306212 139806407255936 learning.py:512] global step 7724: loss = 0.0382 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7725: loss = 0.0342 (0.180 sec/step)\n",
            "I0213 16:55:38.487501 139806407255936 learning.py:512] global step 7725: loss = 0.0342 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7726: loss = 0.0085 (0.168 sec/step)\n",
            "I0213 16:55:38.657300 139806407255936 learning.py:512] global step 7726: loss = 0.0085 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7727: loss = 0.0492 (0.159 sec/step)\n",
            "I0213 16:55:38.817772 139806407255936 learning.py:512] global step 7727: loss = 0.0492 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7728: loss = 0.0300 (0.164 sec/step)\n",
            "I0213 16:55:38.983433 139806407255936 learning.py:512] global step 7728: loss = 0.0300 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7729: loss = 0.0623 (0.161 sec/step)\n",
            "I0213 16:55:39.145454 139806407255936 learning.py:512] global step 7729: loss = 0.0623 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7730: loss = 0.0190 (0.173 sec/step)\n",
            "I0213 16:55:39.320270 139806407255936 learning.py:512] global step 7730: loss = 0.0190 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7731: loss = 0.0244 (0.188 sec/step)\n",
            "I0213 16:55:39.509667 139806407255936 learning.py:512] global step 7731: loss = 0.0244 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7732: loss = 0.0189 (0.168 sec/step)\n",
            "I0213 16:55:39.678812 139806407255936 learning.py:512] global step 7732: loss = 0.0189 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7733: loss = 0.0712 (0.161 sec/step)\n",
            "I0213 16:55:39.841343 139806407255936 learning.py:512] global step 7733: loss = 0.0712 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7734: loss = 0.0221 (0.186 sec/step)\n",
            "I0213 16:55:40.029445 139806407255936 learning.py:512] global step 7734: loss = 0.0221 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7735: loss = 0.0142 (0.169 sec/step)\n",
            "I0213 16:55:40.199617 139806407255936 learning.py:512] global step 7735: loss = 0.0142 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7736: loss = 0.0243 (0.174 sec/step)\n",
            "I0213 16:55:40.374478 139806407255936 learning.py:512] global step 7736: loss = 0.0243 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7737: loss = 0.0435 (0.177 sec/step)\n",
            "I0213 16:55:40.552719 139806407255936 learning.py:512] global step 7737: loss = 0.0435 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7738: loss = 0.0887 (0.186 sec/step)\n",
            "I0213 16:55:40.740938 139806407255936 learning.py:512] global step 7738: loss = 0.0887 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7739: loss = 0.0893 (0.169 sec/step)\n",
            "I0213 16:55:40.911791 139806407255936 learning.py:512] global step 7739: loss = 0.0893 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7740: loss = 0.0481 (0.177 sec/step)\n",
            "I0213 16:55:41.090341 139806407255936 learning.py:512] global step 7740: loss = 0.0481 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7741: loss = 0.0596 (0.166 sec/step)\n",
            "I0213 16:55:41.257904 139806407255936 learning.py:512] global step 7741: loss = 0.0596 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7742: loss = 0.0299 (0.168 sec/step)\n",
            "I0213 16:55:41.427298 139806407255936 learning.py:512] global step 7742: loss = 0.0299 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7743: loss = 0.0227 (0.172 sec/step)\n",
            "I0213 16:55:41.600340 139806407255936 learning.py:512] global step 7743: loss = 0.0227 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7744: loss = 0.0158 (0.173 sec/step)\n",
            "I0213 16:55:41.775176 139806407255936 learning.py:512] global step 7744: loss = 0.0158 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7745: loss = 0.0484 (0.184 sec/step)\n",
            "I0213 16:55:41.960639 139806407255936 learning.py:512] global step 7745: loss = 0.0484 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7746: loss = 0.0441 (0.179 sec/step)\n",
            "I0213 16:55:42.141501 139806407255936 learning.py:512] global step 7746: loss = 0.0441 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7747: loss = 0.0465 (0.175 sec/step)\n",
            "I0213 16:55:42.318358 139806407255936 learning.py:512] global step 7747: loss = 0.0465 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7748: loss = 0.0226 (0.162 sec/step)\n",
            "I0213 16:55:42.482373 139806407255936 learning.py:512] global step 7748: loss = 0.0226 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7749: loss = 0.0445 (0.179 sec/step)\n",
            "I0213 16:55:42.666896 139806407255936 learning.py:512] global step 7749: loss = 0.0445 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7750: loss = 0.0204 (0.168 sec/step)\n",
            "I0213 16:55:42.836392 139806407255936 learning.py:512] global step 7750: loss = 0.0204 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7751: loss = 0.0217 (0.173 sec/step)\n",
            "I0213 16:55:43.010765 139806407255936 learning.py:512] global step 7751: loss = 0.0217 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7752: loss = 0.0278 (0.165 sec/step)\n",
            "I0213 16:55:43.177011 139806407255936 learning.py:512] global step 7752: loss = 0.0278 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7753: loss = 0.0519 (0.167 sec/step)\n",
            "I0213 16:55:43.345609 139806407255936 learning.py:512] global step 7753: loss = 0.0519 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7754: loss = 0.0369 (0.178 sec/step)\n",
            "I0213 16:55:43.525209 139806407255936 learning.py:512] global step 7754: loss = 0.0369 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7755: loss = 0.0263 (0.160 sec/step)\n",
            "I0213 16:55:43.686181 139806407255936 learning.py:512] global step 7755: loss = 0.0263 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7756: loss = 0.0177 (0.164 sec/step)\n",
            "I0213 16:55:43.852028 139806407255936 learning.py:512] global step 7756: loss = 0.0177 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7757: loss = 0.0167 (0.158 sec/step)\n",
            "I0213 16:55:44.011547 139806407255936 learning.py:512] global step 7757: loss = 0.0167 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7758: loss = 0.0345 (0.161 sec/step)\n",
            "I0213 16:55:44.173273 139806407255936 learning.py:512] global step 7758: loss = 0.0345 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7759: loss = 0.0135 (0.182 sec/step)\n",
            "I0213 16:55:44.356694 139806407255936 learning.py:512] global step 7759: loss = 0.0135 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7760: loss = 0.0413 (0.150 sec/step)\n",
            "I0213 16:55:44.508077 139806407255936 learning.py:512] global step 7760: loss = 0.0413 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 7761: loss = 0.0326 (0.171 sec/step)\n",
            "I0213 16:55:44.680169 139806407255936 learning.py:512] global step 7761: loss = 0.0326 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7762: loss = 0.0347 (0.169 sec/step)\n",
            "I0213 16:55:44.850615 139806407255936 learning.py:512] global step 7762: loss = 0.0347 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7763: loss = 0.0244 (0.165 sec/step)\n",
            "I0213 16:55:45.017546 139806407255936 learning.py:512] global step 7763: loss = 0.0244 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7764: loss = 0.0711 (0.169 sec/step)\n",
            "I0213 16:55:45.187561 139806407255936 learning.py:512] global step 7764: loss = 0.0711 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7765: loss = 0.0109 (0.169 sec/step)\n",
            "I0213 16:55:45.357959 139806407255936 learning.py:512] global step 7765: loss = 0.0109 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7766: loss = 0.0407 (0.163 sec/step)\n",
            "I0213 16:55:45.522352 139806407255936 learning.py:512] global step 7766: loss = 0.0407 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7767: loss = 0.0121 (0.179 sec/step)\n",
            "I0213 16:55:45.703178 139806407255936 learning.py:512] global step 7767: loss = 0.0121 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7768: loss = 0.0432 (0.171 sec/step)\n",
            "I0213 16:55:45.875252 139806407255936 learning.py:512] global step 7768: loss = 0.0432 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7769: loss = 0.0117 (0.171 sec/step)\n",
            "I0213 16:55:46.047883 139806407255936 learning.py:512] global step 7769: loss = 0.0117 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7770: loss = 0.0162 (0.156 sec/step)\n",
            "I0213 16:55:46.205810 139806407255936 learning.py:512] global step 7770: loss = 0.0162 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7771: loss = 0.0298 (0.161 sec/step)\n",
            "I0213 16:55:46.368643 139806407255936 learning.py:512] global step 7771: loss = 0.0298 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7772: loss = 0.0209 (0.171 sec/step)\n",
            "I0213 16:55:46.541452 139806407255936 learning.py:512] global step 7772: loss = 0.0209 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7773: loss = 0.0198 (0.187 sec/step)\n",
            "I0213 16:55:46.729228 139806407255936 learning.py:512] global step 7773: loss = 0.0198 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7774: loss = 0.0428 (0.163 sec/step)\n",
            "I0213 16:55:46.893878 139806407255936 learning.py:512] global step 7774: loss = 0.0428 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7775: loss = 0.0226 (0.187 sec/step)\n",
            "I0213 16:55:47.082349 139806407255936 learning.py:512] global step 7775: loss = 0.0226 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7776: loss = 0.0167 (0.170 sec/step)\n",
            "I0213 16:55:47.254171 139806407255936 learning.py:512] global step 7776: loss = 0.0167 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7777: loss = 0.0206 (0.165 sec/step)\n",
            "I0213 16:55:47.420069 139806407255936 learning.py:512] global step 7777: loss = 0.0206 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7778: loss = 0.0533 (0.171 sec/step)\n",
            "I0213 16:55:47.592751 139806407255936 learning.py:512] global step 7778: loss = 0.0533 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7779: loss = 0.0139 (0.173 sec/step)\n",
            "I0213 16:55:47.767081 139806407255936 learning.py:512] global step 7779: loss = 0.0139 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7780: loss = 0.0122 (0.176 sec/step)\n",
            "I0213 16:55:47.944378 139806407255936 learning.py:512] global step 7780: loss = 0.0122 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7781: loss = 0.0234 (0.151 sec/step)\n",
            "I0213 16:55:48.097092 139806407255936 learning.py:512] global step 7781: loss = 0.0234 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 7782: loss = 0.0146 (0.172 sec/step)\n",
            "I0213 16:55:48.270203 139806407255936 learning.py:512] global step 7782: loss = 0.0146 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7783: loss = 0.0067 (0.161 sec/step)\n",
            "I0213 16:55:48.432194 139806407255936 learning.py:512] global step 7783: loss = 0.0067 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7784: loss = 0.0156 (0.168 sec/step)\n",
            "I0213 16:55:48.601930 139806407255936 learning.py:512] global step 7784: loss = 0.0156 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7785: loss = 0.0366 (0.169 sec/step)\n",
            "I0213 16:55:48.772110 139806407255936 learning.py:512] global step 7785: loss = 0.0366 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7786: loss = 0.0284 (0.173 sec/step)\n",
            "I0213 16:55:48.946058 139806407255936 learning.py:512] global step 7786: loss = 0.0284 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7787: loss = 0.0295 (0.167 sec/step)\n",
            "I0213 16:55:49.114439 139806407255936 learning.py:512] global step 7787: loss = 0.0295 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7788: loss = 0.0059 (0.169 sec/step)\n",
            "I0213 16:55:49.284303 139806407255936 learning.py:512] global step 7788: loss = 0.0059 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7789: loss = 0.0176 (0.163 sec/step)\n",
            "I0213 16:55:49.449082 139806407255936 learning.py:512] global step 7789: loss = 0.0176 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7790: loss = 0.0684 (0.176 sec/step)\n",
            "I0213 16:55:49.626376 139806407255936 learning.py:512] global step 7790: loss = 0.0684 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7791: loss = 0.0258 (0.178 sec/step)\n",
            "I0213 16:55:49.805681 139806407255936 learning.py:512] global step 7791: loss = 0.0258 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7792: loss = 0.0476 (0.173 sec/step)\n",
            "I0213 16:55:49.980452 139806407255936 learning.py:512] global step 7792: loss = 0.0476 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7793: loss = 0.0325 (0.175 sec/step)\n",
            "I0213 16:55:50.156460 139806407255936 learning.py:512] global step 7793: loss = 0.0325 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7794: loss = 0.0437 (0.169 sec/step)\n",
            "I0213 16:55:50.328289 139806407255936 learning.py:512] global step 7794: loss = 0.0437 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7795: loss = 0.0269 (0.170 sec/step)\n",
            "I0213 16:55:50.499316 139806407255936 learning.py:512] global step 7795: loss = 0.0269 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7796: loss = 0.0817 (0.179 sec/step)\n",
            "I0213 16:55:50.679206 139806407255936 learning.py:512] global step 7796: loss = 0.0817 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7797: loss = 0.0201 (0.149 sec/step)\n",
            "I0213 16:55:50.829766 139806407255936 learning.py:512] global step 7797: loss = 0.0201 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 7798: loss = 0.0517 (0.172 sec/step)\n",
            "I0213 16:55:51.003708 139806407255936 learning.py:512] global step 7798: loss = 0.0517 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7799: loss = 0.0540 (0.162 sec/step)\n",
            "I0213 16:55:51.167284 139806407255936 learning.py:512] global step 7799: loss = 0.0540 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7800: loss = 0.0111 (0.173 sec/step)\n",
            "I0213 16:55:51.341644 139806407255936 learning.py:512] global step 7800: loss = 0.0111 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7801: loss = 0.0266 (0.181 sec/step)\n",
            "I0213 16:55:51.524309 139806407255936 learning.py:512] global step 7801: loss = 0.0266 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7802: loss = 0.0367 (0.162 sec/step)\n",
            "I0213 16:55:51.687111 139806407255936 learning.py:512] global step 7802: loss = 0.0367 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7803: loss = 0.0397 (0.178 sec/step)\n",
            "I0213 16:55:51.866198 139806407255936 learning.py:512] global step 7803: loss = 0.0397 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7804: loss = 0.0170 (0.173 sec/step)\n",
            "I0213 16:55:52.040046 139806407255936 learning.py:512] global step 7804: loss = 0.0170 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7805: loss = 0.0214 (0.166 sec/step)\n",
            "I0213 16:55:52.207175 139806407255936 learning.py:512] global step 7805: loss = 0.0214 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7806: loss = 0.0248 (0.157 sec/step)\n",
            "I0213 16:55:52.365586 139806407255936 learning.py:512] global step 7806: loss = 0.0248 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7807: loss = 0.0787 (0.164 sec/step)\n",
            "I0213 16:55:52.531234 139806407255936 learning.py:512] global step 7807: loss = 0.0787 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7808: loss = 0.0269 (0.153 sec/step)\n",
            "I0213 16:55:52.685581 139806407255936 learning.py:512] global step 7808: loss = 0.0269 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7809: loss = 0.0082 (0.176 sec/step)\n",
            "I0213 16:55:52.862909 139806407255936 learning.py:512] global step 7809: loss = 0.0082 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7810: loss = 0.0253 (0.155 sec/step)\n",
            "I0213 16:55:53.019512 139806407255936 learning.py:512] global step 7810: loss = 0.0253 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7811: loss = 0.0212 (0.152 sec/step)\n",
            "I0213 16:55:53.172698 139806407255936 learning.py:512] global step 7811: loss = 0.0212 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 7812: loss = 0.0371 (0.168 sec/step)\n",
            "I0213 16:55:53.342696 139806407255936 learning.py:512] global step 7812: loss = 0.0371 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7813: loss = 0.0507 (0.174 sec/step)\n",
            "I0213 16:55:53.518481 139806407255936 learning.py:512] global step 7813: loss = 0.0507 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7814: loss = 0.0439 (0.171 sec/step)\n",
            "I0213 16:55:53.691383 139806407255936 learning.py:512] global step 7814: loss = 0.0439 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7815: loss = 0.0227 (0.170 sec/step)\n",
            "I0213 16:55:53.862868 139806407255936 learning.py:512] global step 7815: loss = 0.0227 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7816: loss = 0.0132 (0.171 sec/step)\n",
            "I0213 16:55:54.035199 139806407255936 learning.py:512] global step 7816: loss = 0.0132 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7817: loss = 0.0571 (0.170 sec/step)\n",
            "I0213 16:55:54.206962 139806407255936 learning.py:512] global step 7817: loss = 0.0571 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7818: loss = 0.0220 (0.169 sec/step)\n",
            "I0213 16:55:54.376813 139806407255936 learning.py:512] global step 7818: loss = 0.0220 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7819: loss = 0.0366 (0.161 sec/step)\n",
            "I0213 16:55:54.538565 139806407255936 learning.py:512] global step 7819: loss = 0.0366 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7820: loss = 0.0654 (0.169 sec/step)\n",
            "I0213 16:55:54.708746 139806407255936 learning.py:512] global step 7820: loss = 0.0654 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7821: loss = 0.0477 (0.163 sec/step)\n",
            "I0213 16:55:54.873292 139806407255936 learning.py:512] global step 7821: loss = 0.0477 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7822: loss = 0.0274 (0.187 sec/step)\n",
            "I0213 16:55:55.061636 139806407255936 learning.py:512] global step 7822: loss = 0.0274 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7823: loss = 0.0183 (0.179 sec/step)\n",
            "I0213 16:55:55.241912 139806407255936 learning.py:512] global step 7823: loss = 0.0183 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7824: loss = 0.0157 (0.155 sec/step)\n",
            "I0213 16:55:55.398673 139806407255936 learning.py:512] global step 7824: loss = 0.0157 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7825: loss = 0.0375 (0.155 sec/step)\n",
            "I0213 16:55:55.555478 139806407255936 learning.py:512] global step 7825: loss = 0.0375 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7826: loss = 0.0511 (0.168 sec/step)\n",
            "I0213 16:55:55.725398 139806407255936 learning.py:512] global step 7826: loss = 0.0511 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7827: loss = 0.0793 (0.179 sec/step)\n",
            "I0213 16:55:55.905973 139806407255936 learning.py:512] global step 7827: loss = 0.0793 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7828: loss = 0.0574 (0.162 sec/step)\n",
            "I0213 16:55:56.069751 139806407255936 learning.py:512] global step 7828: loss = 0.0574 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7829: loss = 0.0446 (0.175 sec/step)\n",
            "I0213 16:55:56.245602 139806407255936 learning.py:512] global step 7829: loss = 0.0446 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7830: loss = 0.0287 (0.159 sec/step)\n",
            "I0213 16:55:56.406204 139806407255936 learning.py:512] global step 7830: loss = 0.0287 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7831: loss = 0.0527 (0.171 sec/step)\n",
            "I0213 16:55:56.578627 139806407255936 learning.py:512] global step 7831: loss = 0.0527 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7832: loss = 0.0206 (0.181 sec/step)\n",
            "I0213 16:55:56.761085 139806407255936 learning.py:512] global step 7832: loss = 0.0206 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7833: loss = 0.0429 (0.158 sec/step)\n",
            "I0213 16:55:56.920375 139806407255936 learning.py:512] global step 7833: loss = 0.0429 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7834: loss = 0.0279 (0.160 sec/step)\n",
            "I0213 16:55:57.082270 139806407255936 learning.py:512] global step 7834: loss = 0.0279 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7835: loss = 0.0199 (0.174 sec/step)\n",
            "I0213 16:55:57.258470 139806407255936 learning.py:512] global step 7835: loss = 0.0199 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7836: loss = 0.0260 (0.167 sec/step)\n",
            "I0213 16:55:57.426499 139806407255936 learning.py:512] global step 7836: loss = 0.0260 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7837: loss = 0.0099 (0.174 sec/step)\n",
            "I0213 16:55:57.602167 139806407255936 learning.py:512] global step 7837: loss = 0.0099 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7838: loss = 0.0249 (0.167 sec/step)\n",
            "I0213 16:55:57.770314 139806407255936 learning.py:512] global step 7838: loss = 0.0249 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7839: loss = 0.0143 (0.169 sec/step)\n",
            "I0213 16:55:57.940744 139806407255936 learning.py:512] global step 7839: loss = 0.0143 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7840: loss = 0.0307 (0.157 sec/step)\n",
            "I0213 16:55:58.099289 139806407255936 learning.py:512] global step 7840: loss = 0.0307 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7841: loss = 0.0167 (0.164 sec/step)\n",
            "I0213 16:55:58.264502 139806407255936 learning.py:512] global step 7841: loss = 0.0167 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7842: loss = 0.0623 (0.172 sec/step)\n",
            "I0213 16:55:58.437796 139806407255936 learning.py:512] global step 7842: loss = 0.0623 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7843: loss = 0.0079 (0.166 sec/step)\n",
            "I0213 16:55:58.605626 139806407255936 learning.py:512] global step 7843: loss = 0.0079 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7844: loss = 0.0198 (0.167 sec/step)\n",
            "I0213 16:55:58.773513 139806407255936 learning.py:512] global step 7844: loss = 0.0198 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7845: loss = 0.0386 (0.153 sec/step)\n",
            "I0213 16:55:58.927946 139806407255936 learning.py:512] global step 7845: loss = 0.0386 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7846: loss = 0.0468 (0.158 sec/step)\n",
            "I0213 16:55:59.087134 139806407255936 learning.py:512] global step 7846: loss = 0.0468 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7847: loss = 0.0245 (0.175 sec/step)\n",
            "I0213 16:55:59.263330 139806407255936 learning.py:512] global step 7847: loss = 0.0245 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7848: loss = 0.0432 (0.171 sec/step)\n",
            "I0213 16:55:59.435557 139806407255936 learning.py:512] global step 7848: loss = 0.0432 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7849: loss = 0.0144 (0.164 sec/step)\n",
            "I0213 16:55:59.601283 139806407255936 learning.py:512] global step 7849: loss = 0.0144 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7850: loss = 0.0129 (0.166 sec/step)\n",
            "I0213 16:55:59.768295 139806407255936 learning.py:512] global step 7850: loss = 0.0129 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7851: loss = 0.0197 (0.160 sec/step)\n",
            "I0213 16:55:59.930391 139806407255936 learning.py:512] global step 7851: loss = 0.0197 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7852: loss = 0.0245 (0.175 sec/step)\n",
            "I0213 16:56:00.106723 139806407255936 learning.py:512] global step 7852: loss = 0.0245 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7853: loss = 0.0161 (0.166 sec/step)\n",
            "I0213 16:56:00.273911 139806407255936 learning.py:512] global step 7853: loss = 0.0161 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7854: loss = 0.0451 (0.179 sec/step)\n",
            "I0213 16:56:00.453843 139806407255936 learning.py:512] global step 7854: loss = 0.0451 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7855: loss = 0.0142 (0.169 sec/step)\n",
            "I0213 16:56:00.624527 139806407255936 learning.py:512] global step 7855: loss = 0.0142 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7856: loss = 0.0269 (0.170 sec/step)\n",
            "I0213 16:56:00.795451 139806407255936 learning.py:512] global step 7856: loss = 0.0269 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7857: loss = 0.0183 (0.174 sec/step)\n",
            "I0213 16:56:00.970661 139806407255936 learning.py:512] global step 7857: loss = 0.0183 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7858: loss = 0.0441 (0.171 sec/step)\n",
            "I0213 16:56:01.143444 139806407255936 learning.py:512] global step 7858: loss = 0.0441 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7859: loss = 0.0269 (0.165 sec/step)\n",
            "I0213 16:56:01.309545 139806407255936 learning.py:512] global step 7859: loss = 0.0269 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7860: loss = 0.0566 (0.181 sec/step)\n",
            "I0213 16:56:01.491657 139806407255936 learning.py:512] global step 7860: loss = 0.0566 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7861: loss = 0.0281 (0.157 sec/step)\n",
            "I0213 16:56:01.650594 139806407255936 learning.py:512] global step 7861: loss = 0.0281 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7862: loss = 0.0519 (0.172 sec/step)\n",
            "I0213 16:56:01.823769 139806407255936 learning.py:512] global step 7862: loss = 0.0519 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7863: loss = 0.0249 (0.156 sec/step)\n",
            "I0213 16:56:01.981317 139806407255936 learning.py:512] global step 7863: loss = 0.0249 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7864: loss = 0.0198 (0.172 sec/step)\n",
            "I0213 16:56:02.155039 139806407255936 learning.py:512] global step 7864: loss = 0.0198 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7865: loss = 0.0185 (0.162 sec/step)\n",
            "I0213 16:56:02.318260 139806407255936 learning.py:512] global step 7865: loss = 0.0185 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7866: loss = 0.0230 (0.165 sec/step)\n",
            "I0213 16:56:02.484906 139806407255936 learning.py:512] global step 7866: loss = 0.0230 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7867: loss = 0.0179 (0.171 sec/step)\n",
            "I0213 16:56:02.657463 139806407255936 learning.py:512] global step 7867: loss = 0.0179 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7868: loss = 0.0175 (0.167 sec/step)\n",
            "I0213 16:56:02.825745 139806407255936 learning.py:512] global step 7868: loss = 0.0175 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7869: loss = 0.0284 (0.163 sec/step)\n",
            "I0213 16:56:02.990183 139806407255936 learning.py:512] global step 7869: loss = 0.0284 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7870: loss = 0.0754 (0.167 sec/step)\n",
            "I0213 16:56:03.159052 139806407255936 learning.py:512] global step 7870: loss = 0.0754 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7871: loss = 0.0948 (0.167 sec/step)\n",
            "I0213 16:56:03.327081 139806407255936 learning.py:512] global step 7871: loss = 0.0948 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7872: loss = 0.0189 (0.173 sec/step)\n",
            "I0213 16:56:03.501475 139806407255936 learning.py:512] global step 7872: loss = 0.0189 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7873: loss = 0.0283 (0.158 sec/step)\n",
            "I0213 16:56:03.661216 139806407255936 learning.py:512] global step 7873: loss = 0.0283 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7874: loss = 0.0878 (0.192 sec/step)\n",
            "I0213 16:56:03.854687 139806407255936 learning.py:512] global step 7874: loss = 0.0878 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7875: loss = 0.0575 (0.162 sec/step)\n",
            "I0213 16:56:04.017843 139806407255936 learning.py:512] global step 7875: loss = 0.0575 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7876: loss = 0.0173 (0.176 sec/step)\n",
            "I0213 16:56:04.195005 139806407255936 learning.py:512] global step 7876: loss = 0.0173 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7877: loss = 0.0265 (0.175 sec/step)\n",
            "I0213 16:56:04.371884 139806407255936 learning.py:512] global step 7877: loss = 0.0265 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7878: loss = 0.0281 (0.161 sec/step)\n",
            "I0213 16:56:04.534443 139806407255936 learning.py:512] global step 7878: loss = 0.0281 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7879: loss = 0.0408 (0.171 sec/step)\n",
            "I0213 16:56:04.706575 139806407255936 learning.py:512] global step 7879: loss = 0.0408 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7880: loss = 0.0218 (0.159 sec/step)\n",
            "I0213 16:56:04.867020 139806407255936 learning.py:512] global step 7880: loss = 0.0218 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7881: loss = 0.0347 (0.177 sec/step)\n",
            "I0213 16:56:05.045249 139806407255936 learning.py:512] global step 7881: loss = 0.0347 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7882: loss = 0.0311 (0.168 sec/step)\n",
            "I0213 16:56:05.214202 139806407255936 learning.py:512] global step 7882: loss = 0.0311 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7883: loss = 0.0246 (0.172 sec/step)\n",
            "I0213 16:56:05.387655 139806407255936 learning.py:512] global step 7883: loss = 0.0246 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7884: loss = 0.0137 (0.170 sec/step)\n",
            "I0213 16:56:05.558708 139806407255936 learning.py:512] global step 7884: loss = 0.0137 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7885: loss = 0.0393 (0.164 sec/step)\n",
            "I0213 16:56:05.724533 139806407255936 learning.py:512] global step 7885: loss = 0.0393 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7886: loss = 0.0202 (0.175 sec/step)\n",
            "I0213 16:56:05.901081 139806407255936 learning.py:512] global step 7886: loss = 0.0202 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7887: loss = 0.0368 (0.175 sec/step)\n",
            "I0213 16:56:06.077350 139806407255936 learning.py:512] global step 7887: loss = 0.0368 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7888: loss = 0.0225 (0.171 sec/step)\n",
            "I0213 16:56:06.249963 139806407255936 learning.py:512] global step 7888: loss = 0.0225 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7889: loss = 0.0097 (0.181 sec/step)\n",
            "I0213 16:56:06.432877 139806407255936 learning.py:512] global step 7889: loss = 0.0097 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7890: loss = 0.0538 (0.174 sec/step)\n",
            "I0213 16:56:06.608142 139806407255936 learning.py:512] global step 7890: loss = 0.0538 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7891: loss = 0.0215 (0.155 sec/step)\n",
            "I0213 16:56:06.764981 139806407255936 learning.py:512] global step 7891: loss = 0.0215 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7892: loss = 0.0175 (0.170 sec/step)\n",
            "I0213 16:56:06.936727 139806407255936 learning.py:512] global step 7892: loss = 0.0175 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7893: loss = 0.0080 (0.167 sec/step)\n",
            "I0213 16:56:07.105026 139806407255936 learning.py:512] global step 7893: loss = 0.0080 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7894: loss = 0.0303 (0.178 sec/step)\n",
            "I0213 16:56:07.284369 139806407255936 learning.py:512] global step 7894: loss = 0.0303 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7895: loss = 0.0584 (0.170 sec/step)\n",
            "I0213 16:56:07.455710 139806407255936 learning.py:512] global step 7895: loss = 0.0584 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7896: loss = 0.0638 (0.177 sec/step)\n",
            "I0213 16:56:07.634037 139806407255936 learning.py:512] global step 7896: loss = 0.0638 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7897: loss = 0.0369 (0.176 sec/step)\n",
            "I0213 16:56:07.811353 139806407255936 learning.py:512] global step 7897: loss = 0.0369 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7898: loss = 0.0365 (0.175 sec/step)\n",
            "I0213 16:56:07.987875 139806407255936 learning.py:512] global step 7898: loss = 0.0365 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7899: loss = 0.0224 (0.159 sec/step)\n",
            "I0213 16:56:08.148606 139806407255936 learning.py:512] global step 7899: loss = 0.0224 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7900: loss = 0.0205 (0.177 sec/step)\n",
            "I0213 16:56:08.326511 139806407255936 learning.py:512] global step 7900: loss = 0.0205 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7901: loss = 0.0581 (0.170 sec/step)\n",
            "I0213 16:56:08.497730 139806407255936 learning.py:512] global step 7901: loss = 0.0581 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7902: loss = 0.0151 (0.168 sec/step)\n",
            "I0213 16:56:08.667267 139806407255936 learning.py:512] global step 7902: loss = 0.0151 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7903: loss = 0.0416 (0.172 sec/step)\n",
            "I0213 16:56:08.840760 139806407255936 learning.py:512] global step 7903: loss = 0.0416 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7904: loss = 0.0171 (0.177 sec/step)\n",
            "I0213 16:56:09.019452 139806407255936 learning.py:512] global step 7904: loss = 0.0171 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7905: loss = 0.0196 (0.175 sec/step)\n",
            "I0213 16:56:09.195866 139806407255936 learning.py:512] global step 7905: loss = 0.0196 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7906: loss = 0.0159 (0.160 sec/step)\n",
            "I0213 16:56:09.357176 139806407255936 learning.py:512] global step 7906: loss = 0.0159 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7907: loss = 0.0182 (0.164 sec/step)\n",
            "I0213 16:56:09.522353 139806407255936 learning.py:512] global step 7907: loss = 0.0182 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7908: loss = 0.0519 (0.167 sec/step)\n",
            "I0213 16:56:09.690914 139806407255936 learning.py:512] global step 7908: loss = 0.0519 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7909: loss = 0.0375 (0.167 sec/step)\n",
            "I0213 16:56:09.859400 139806407255936 learning.py:512] global step 7909: loss = 0.0375 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7910: loss = 0.0189 (0.175 sec/step)\n",
            "I0213 16:56:10.035522 139806407255936 learning.py:512] global step 7910: loss = 0.0189 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7911: loss = 0.0554 (0.170 sec/step)\n",
            "I0213 16:56:10.206719 139806407255936 learning.py:512] global step 7911: loss = 0.0554 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7912: loss = 0.0305 (0.167 sec/step)\n",
            "I0213 16:56:10.375255 139806407255936 learning.py:512] global step 7912: loss = 0.0305 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7913: loss = 0.0345 (0.170 sec/step)\n",
            "I0213 16:56:10.546448 139806407255936 learning.py:512] global step 7913: loss = 0.0345 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7914: loss = 0.0203 (0.169 sec/step)\n",
            "I0213 16:56:10.717128 139806407255936 learning.py:512] global step 7914: loss = 0.0203 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7915: loss = 0.0147 (0.168 sec/step)\n",
            "I0213 16:56:10.886530 139806407255936 learning.py:512] global step 7915: loss = 0.0147 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7916: loss = 0.0511 (0.182 sec/step)\n",
            "I0213 16:56:11.069668 139806407255936 learning.py:512] global step 7916: loss = 0.0511 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7917: loss = 0.0205 (0.155 sec/step)\n",
            "I0213 16:56:11.225746 139806407255936 learning.py:512] global step 7917: loss = 0.0205 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7918: loss = 0.0213 (0.181 sec/step)\n",
            "I0213 16:56:11.408252 139806407255936 learning.py:512] global step 7918: loss = 0.0213 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7919: loss = 0.0889 (0.160 sec/step)\n",
            "I0213 16:56:11.570251 139806407255936 learning.py:512] global step 7919: loss = 0.0889 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7920: loss = 0.0221 (0.159 sec/step)\n",
            "I0213 16:56:11.730952 139806407255936 learning.py:512] global step 7920: loss = 0.0221 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7921: loss = 0.0232 (0.166 sec/step)\n",
            "I0213 16:56:11.898010 139806407255936 learning.py:512] global step 7921: loss = 0.0232 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7922: loss = 0.0296 (0.173 sec/step)\n",
            "I0213 16:56:12.072805 139806407255936 learning.py:512] global step 7922: loss = 0.0296 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7923: loss = 0.0277 (0.165 sec/step)\n",
            "I0213 16:56:12.239453 139806407255936 learning.py:512] global step 7923: loss = 0.0277 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7924: loss = 0.0227 (0.159 sec/step)\n",
            "I0213 16:56:12.400264 139806407255936 learning.py:512] global step 7924: loss = 0.0227 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7925: loss = 0.0189 (0.170 sec/step)\n",
            "I0213 16:56:12.571531 139806407255936 learning.py:512] global step 7925: loss = 0.0189 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7926: loss = 0.0438 (0.172 sec/step)\n",
            "I0213 16:56:12.745493 139806407255936 learning.py:512] global step 7926: loss = 0.0438 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7927: loss = 0.0151 (0.183 sec/step)\n",
            "I0213 16:56:12.929938 139806407255936 learning.py:512] global step 7927: loss = 0.0151 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7928: loss = 0.0110 (0.179 sec/step)\n",
            "I0213 16:56:13.110582 139806407255936 learning.py:512] global step 7928: loss = 0.0110 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7929: loss = 0.0358 (0.182 sec/step)\n",
            "I0213 16:56:13.293621 139806407255936 learning.py:512] global step 7929: loss = 0.0358 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7930: loss = 0.0143 (0.168 sec/step)\n",
            "I0213 16:56:13.462674 139806407255936 learning.py:512] global step 7930: loss = 0.0143 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7931: loss = 0.0235 (0.172 sec/step)\n",
            "I0213 16:56:13.635952 139806407255936 learning.py:512] global step 7931: loss = 0.0235 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7932: loss = 0.0493 (0.190 sec/step)\n",
            "I0213 16:56:13.827596 139806407255936 learning.py:512] global step 7932: loss = 0.0493 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7933: loss = 0.0123 (0.159 sec/step)\n",
            "I0213 16:56:13.988150 139806407255936 learning.py:512] global step 7933: loss = 0.0123 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7934: loss = 0.0214 (0.177 sec/step)\n",
            "I0213 16:56:14.167106 139806407255936 learning.py:512] global step 7934: loss = 0.0214 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7935: loss = 0.0199 (0.165 sec/step)\n",
            "I0213 16:56:14.333453 139806407255936 learning.py:512] global step 7935: loss = 0.0199 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7936: loss = 0.0194 (0.171 sec/step)\n",
            "I0213 16:56:14.506369 139806407255936 learning.py:512] global step 7936: loss = 0.0194 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7937: loss = 0.0120 (0.166 sec/step)\n",
            "I0213 16:56:14.673608 139806407255936 learning.py:512] global step 7937: loss = 0.0120 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7938: loss = 0.0214 (0.158 sec/step)\n",
            "I0213 16:56:14.833274 139806407255936 learning.py:512] global step 7938: loss = 0.0214 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7939: loss = 0.0397 (0.170 sec/step)\n",
            "I0213 16:56:15.004411 139806407255936 learning.py:512] global step 7939: loss = 0.0397 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7940: loss = 0.0209 (0.165 sec/step)\n",
            "I0213 16:56:15.171565 139806407255936 learning.py:512] global step 7940: loss = 0.0209 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7941: loss = 0.0124 (0.177 sec/step)\n",
            "I0213 16:56:15.349744 139806407255936 learning.py:512] global step 7941: loss = 0.0124 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7942: loss = 0.0274 (0.160 sec/step)\n",
            "I0213 16:56:15.511586 139806407255936 learning.py:512] global step 7942: loss = 0.0274 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7943: loss = 0.0211 (0.167 sec/step)\n",
            "I0213 16:56:15.679948 139806407255936 learning.py:512] global step 7943: loss = 0.0211 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7944: loss = 0.0283 (0.180 sec/step)\n",
            "I0213 16:56:15.861055 139806407255936 learning.py:512] global step 7944: loss = 0.0283 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7945: loss = 0.0421 (0.165 sec/step)\n",
            "I0213 16:56:16.027120 139806407255936 learning.py:512] global step 7945: loss = 0.0421 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7946: loss = 0.0196 (0.153 sec/step)\n",
            "I0213 16:56:16.181325 139806407255936 learning.py:512] global step 7946: loss = 0.0196 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7947: loss = 0.0264 (0.167 sec/step)\n",
            "I0213 16:56:16.349704 139806407255936 learning.py:512] global step 7947: loss = 0.0264 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7948: loss = 0.1178 (0.157 sec/step)\n",
            "I0213 16:56:16.507827 139806407255936 learning.py:512] global step 7948: loss = 0.1178 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7949: loss = 0.0515 (0.177 sec/step)\n",
            "I0213 16:56:16.686118 139806407255936 learning.py:512] global step 7949: loss = 0.0515 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7950: loss = 0.0148 (0.161 sec/step)\n",
            "I0213 16:56:16.848235 139806407255936 learning.py:512] global step 7950: loss = 0.0148 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7951: loss = 0.0370 (0.174 sec/step)\n",
            "I0213 16:56:17.023693 139806407255936 learning.py:512] global step 7951: loss = 0.0370 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7952: loss = 0.0251 (0.164 sec/step)\n",
            "I0213 16:56:17.189520 139806407255936 learning.py:512] global step 7952: loss = 0.0251 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7953: loss = 0.0573 (0.159 sec/step)\n",
            "I0213 16:56:17.349939 139806407255936 learning.py:512] global step 7953: loss = 0.0573 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7954: loss = 0.0506 (0.162 sec/step)\n",
            "I0213 16:56:17.513767 139806407255936 learning.py:512] global step 7954: loss = 0.0506 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7955: loss = 0.0376 (0.182 sec/step)\n",
            "I0213 16:56:17.697392 139806407255936 learning.py:512] global step 7955: loss = 0.0376 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7956: loss = 0.0085 (0.184 sec/step)\n",
            "I0213 16:56:17.882890 139806407255936 learning.py:512] global step 7956: loss = 0.0085 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7957: loss = 0.0172 (0.167 sec/step)\n",
            "I0213 16:56:18.051641 139806407255936 learning.py:512] global step 7957: loss = 0.0172 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7958: loss = 0.0232 (0.164 sec/step)\n",
            "I0213 16:56:18.217250 139806407255936 learning.py:512] global step 7958: loss = 0.0232 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7959: loss = 0.0337 (0.169 sec/step)\n",
            "I0213 16:56:18.387671 139806407255936 learning.py:512] global step 7959: loss = 0.0337 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7960: loss = 0.0337 (0.172 sec/step)\n",
            "I0213 16:56:18.561534 139806407255936 learning.py:512] global step 7960: loss = 0.0337 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7961: loss = 0.0550 (0.188 sec/step)\n",
            "I0213 16:56:18.751302 139806407255936 learning.py:512] global step 7961: loss = 0.0550 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7962: loss = 0.0365 (0.168 sec/step)\n",
            "I0213 16:56:18.921143 139806407255936 learning.py:512] global step 7962: loss = 0.0365 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7963: loss = 0.0285 (0.176 sec/step)\n",
            "I0213 16:56:19.099015 139806407255936 learning.py:512] global step 7963: loss = 0.0285 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7964: loss = 0.0234 (0.160 sec/step)\n",
            "I0213 16:56:19.259942 139806407255936 learning.py:512] global step 7964: loss = 0.0234 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7965: loss = 0.0145 (0.163 sec/step)\n",
            "I0213 16:56:19.424096 139806407255936 learning.py:512] global step 7965: loss = 0.0145 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7966: loss = 0.0492 (0.164 sec/step)\n",
            "I0213 16:56:19.589333 139806407255936 learning.py:512] global step 7966: loss = 0.0492 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7967: loss = 0.0207 (0.168 sec/step)\n",
            "I0213 16:56:19.758934 139806407255936 learning.py:512] global step 7967: loss = 0.0207 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7968: loss = 0.0159 (0.176 sec/step)\n",
            "I0213 16:56:19.936562 139806407255936 learning.py:512] global step 7968: loss = 0.0159 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7969: loss = 0.0420 (0.181 sec/step)\n",
            "I0213 16:56:20.118895 139806407255936 learning.py:512] global step 7969: loss = 0.0420 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7970: loss = 0.0463 (0.167 sec/step)\n",
            "I0213 16:56:20.287522 139806407255936 learning.py:512] global step 7970: loss = 0.0463 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7971: loss = 0.0240 (0.172 sec/step)\n",
            "I0213 16:56:20.461317 139806407255936 learning.py:512] global step 7971: loss = 0.0240 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7972: loss = 0.0253 (0.171 sec/step)\n",
            "I0213 16:56:20.634006 139806407255936 learning.py:512] global step 7972: loss = 0.0253 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7973: loss = 0.0268 (0.155 sec/step)\n",
            "I0213 16:56:20.790120 139806407255936 learning.py:512] global step 7973: loss = 0.0268 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7974: loss = 0.0172 (0.167 sec/step)\n",
            "I0213 16:56:20.958714 139806407255936 learning.py:512] global step 7974: loss = 0.0172 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7975: loss = 0.0221 (0.167 sec/step)\n",
            "I0213 16:56:21.126557 139806407255936 learning.py:512] global step 7975: loss = 0.0221 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7976: loss = 0.0217 (0.163 sec/step)\n",
            "I0213 16:56:21.291347 139806407255936 learning.py:512] global step 7976: loss = 0.0217 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7977: loss = 0.0214 (0.170 sec/step)\n",
            "I0213 16:56:21.463128 139806407255936 learning.py:512] global step 7977: loss = 0.0214 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7978: loss = 0.0548 (0.161 sec/step)\n",
            "I0213 16:56:21.625853 139806407255936 learning.py:512] global step 7978: loss = 0.0548 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7979: loss = 0.0247 (0.168 sec/step)\n",
            "I0213 16:56:21.795573 139806407255936 learning.py:512] global step 7979: loss = 0.0247 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7980: loss = 0.0164 (0.163 sec/step)\n",
            "I0213 16:56:21.959385 139806407255936 learning.py:512] global step 7980: loss = 0.0164 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7981: loss = 0.0278 (0.170 sec/step)\n",
            "I0213 16:56:22.131304 139806407255936 learning.py:512] global step 7981: loss = 0.0278 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7982: loss = 0.0156 (0.162 sec/step)\n",
            "I0213 16:56:22.294824 139806407255936 learning.py:512] global step 7982: loss = 0.0156 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7983: loss = 0.0361 (0.171 sec/step)\n",
            "I0213 16:56:22.466635 139806407255936 learning.py:512] global step 7983: loss = 0.0361 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7984: loss = 0.0594 (0.167 sec/step)\n",
            "I0213 16:56:22.636078 139806407255936 learning.py:512] global step 7984: loss = 0.0594 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7985: loss = 0.0175 (0.176 sec/step)\n",
            "I0213 16:56:22.813397 139806407255936 learning.py:512] global step 7985: loss = 0.0175 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7986: loss = 0.0529 (0.180 sec/step)\n",
            "I0213 16:56:22.995438 139806407255936 learning.py:512] global step 7986: loss = 0.0529 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7987: loss = 0.0243 (0.172 sec/step)\n",
            "I0213 16:56:23.168362 139806407255936 learning.py:512] global step 7987: loss = 0.0243 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7988: loss = 0.0380 (0.173 sec/step)\n",
            "I0213 16:56:23.342738 139806407255936 learning.py:512] global step 7988: loss = 0.0380 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7989: loss = 0.0087 (0.170 sec/step)\n",
            "I0213 16:56:23.514550 139806407255936 learning.py:512] global step 7989: loss = 0.0087 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7990: loss = 0.0278 (0.170 sec/step)\n",
            "I0213 16:56:23.686176 139806407255936 learning.py:512] global step 7990: loss = 0.0278 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7991: loss = 0.0175 (0.175 sec/step)\n",
            "I0213 16:56:23.862427 139806407255936 learning.py:512] global step 7991: loss = 0.0175 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7992: loss = 0.0105 (0.174 sec/step)\n",
            "I0213 16:56:24.038049 139806407255936 learning.py:512] global step 7992: loss = 0.0105 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7993: loss = 0.0208 (0.171 sec/step)\n",
            "I0213 16:56:24.210727 139806407255936 learning.py:512] global step 7993: loss = 0.0208 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7994: loss = 0.0349 (0.161 sec/step)\n",
            "I0213 16:56:24.373076 139806407255936 learning.py:512] global step 7994: loss = 0.0349 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7995: loss = 0.0532 (0.167 sec/step)\n",
            "I0213 16:56:24.541796 139806407255936 learning.py:512] global step 7995: loss = 0.0532 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7996: loss = 0.0176 (0.168 sec/step)\n",
            "I0213 16:56:24.711571 139806407255936 learning.py:512] global step 7996: loss = 0.0176 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7997: loss = 0.0306 (0.173 sec/step)\n",
            "I0213 16:56:24.885642 139806407255936 learning.py:512] global step 7997: loss = 0.0306 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7998: loss = 0.0144 (0.165 sec/step)\n",
            "I0213 16:56:25.051592 139806407255936 learning.py:512] global step 7998: loss = 0.0144 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7999: loss = 0.0154 (0.172 sec/step)\n",
            "I0213 16:56:25.224625 139806407255936 learning.py:512] global step 7999: loss = 0.0154 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8000: loss = 0.0247 (0.177 sec/step)\n",
            "I0213 16:56:25.403198 139806407255936 learning.py:512] global step 8000: loss = 0.0247 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8001: loss = 0.0115 (0.162 sec/step)\n",
            "I0213 16:56:25.566826 139806407255936 learning.py:512] global step 8001: loss = 0.0115 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8002: loss = 0.0149 (0.180 sec/step)\n",
            "I0213 16:56:25.748493 139806407255936 learning.py:512] global step 8002: loss = 0.0149 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8003: loss = 0.0231 (0.165 sec/step)\n",
            "I0213 16:56:25.914340 139806407255936 learning.py:512] global step 8003: loss = 0.0231 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8004: loss = 0.0073 (0.172 sec/step)\n",
            "I0213 16:56:26.088171 139806407255936 learning.py:512] global step 8004: loss = 0.0073 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8005: loss = 0.0512 (0.171 sec/step)\n",
            "I0213 16:56:26.260050 139806407255936 learning.py:512] global step 8005: loss = 0.0512 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8006: loss = 0.0116 (0.159 sec/step)\n",
            "I0213 16:56:26.420757 139806407255936 learning.py:512] global step 8006: loss = 0.0116 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8007: loss = 0.0105 (0.157 sec/step)\n",
            "I0213 16:56:26.579206 139806407255936 learning.py:512] global step 8007: loss = 0.0105 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8008: loss = 0.0075 (0.169 sec/step)\n",
            "I0213 16:56:26.749293 139806407255936 learning.py:512] global step 8008: loss = 0.0075 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8009: loss = 0.0260 (0.163 sec/step)\n",
            "I0213 16:56:26.913591 139806407255936 learning.py:512] global step 8009: loss = 0.0260 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8010: loss = 0.0156 (0.155 sec/step)\n",
            "I0213 16:56:27.070006 139806407255936 learning.py:512] global step 8010: loss = 0.0156 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8011: loss = 0.0279 (0.174 sec/step)\n",
            "I0213 16:56:27.245635 139806407255936 learning.py:512] global step 8011: loss = 0.0279 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8012: loss = 0.0250 (0.162 sec/step)\n",
            "I0213 16:56:27.408521 139806407255936 learning.py:512] global step 8012: loss = 0.0250 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8013: loss = 0.0393 (0.163 sec/step)\n",
            "I0213 16:56:27.572875 139806407255936 learning.py:512] global step 8013: loss = 0.0393 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8014: loss = 0.0187 (0.172 sec/step)\n",
            "I0213 16:56:27.746640 139806407255936 learning.py:512] global step 8014: loss = 0.0187 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8015: loss = 0.0326 (0.186 sec/step)\n",
            "I0213 16:56:27.933779 139806407255936 learning.py:512] global step 8015: loss = 0.0326 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8016: loss = 0.0206 (0.175 sec/step)\n",
            "I0213 16:56:28.110188 139806407255936 learning.py:512] global step 8016: loss = 0.0206 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8017: loss = 0.0392 (0.158 sec/step)\n",
            "I0213 16:56:28.269211 139806407255936 learning.py:512] global step 8017: loss = 0.0392 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8018: loss = 0.0263 (0.183 sec/step)\n",
            "I0213 16:56:28.453629 139806407255936 learning.py:512] global step 8018: loss = 0.0263 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8019: loss = 0.0249 (0.182 sec/step)\n",
            "I0213 16:56:28.638370 139806407255936 learning.py:512] global step 8019: loss = 0.0249 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8020: loss = 0.0500 (0.173 sec/step)\n",
            "I0213 16:56:28.812583 139806407255936 learning.py:512] global step 8020: loss = 0.0500 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8021: loss = 0.0303 (0.173 sec/step)\n",
            "I0213 16:56:28.986826 139806407255936 learning.py:512] global step 8021: loss = 0.0303 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8022: loss = 0.0367 (0.182 sec/step)\n",
            "I0213 16:56:29.170260 139806407255936 learning.py:512] global step 8022: loss = 0.0367 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8023: loss = 0.0484 (0.168 sec/step)\n",
            "I0213 16:56:29.339724 139806407255936 learning.py:512] global step 8023: loss = 0.0484 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8024: loss = 0.0726 (0.178 sec/step)\n",
            "I0213 16:56:29.518932 139806407255936 learning.py:512] global step 8024: loss = 0.0726 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8025: loss = 0.0239 (0.166 sec/step)\n",
            "I0213 16:56:29.686740 139806407255936 learning.py:512] global step 8025: loss = 0.0239 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8026: loss = 0.0321 (0.163 sec/step)\n",
            "I0213 16:56:29.851027 139806407255936 learning.py:512] global step 8026: loss = 0.0321 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8027: loss = 0.0555 (0.163 sec/step)\n",
            "I0213 16:56:30.015218 139806407255936 learning.py:512] global step 8027: loss = 0.0555 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8028: loss = 0.0359 (0.170 sec/step)\n",
            "I0213 16:56:30.186519 139806407255936 learning.py:512] global step 8028: loss = 0.0359 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8029: loss = 0.0328 (0.179 sec/step)\n",
            "I0213 16:56:30.366795 139806407255936 learning.py:512] global step 8029: loss = 0.0328 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8030: loss = 0.0503 (0.174 sec/step)\n",
            "I0213 16:56:30.541855 139806407255936 learning.py:512] global step 8030: loss = 0.0503 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8031: loss = 0.0197 (0.156 sec/step)\n",
            "I0213 16:56:30.699603 139806407255936 learning.py:512] global step 8031: loss = 0.0197 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8032: loss = 0.0515 (0.164 sec/step)\n",
            "I0213 16:56:30.865177 139806407255936 learning.py:512] global step 8032: loss = 0.0515 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8033: loss = 0.0217 (0.155 sec/step)\n",
            "I0213 16:56:31.021363 139806407255936 learning.py:512] global step 8033: loss = 0.0217 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8034: loss = 0.0669 (0.176 sec/step)\n",
            "I0213 16:56:31.198706 139806407255936 learning.py:512] global step 8034: loss = 0.0669 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8035: loss = 0.0577 (0.188 sec/step)\n",
            "I0213 16:56:31.388141 139806407255936 learning.py:512] global step 8035: loss = 0.0577 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8036: loss = 0.0175 (0.150 sec/step)\n",
            "I0213 16:56:31.539305 139806407255936 learning.py:512] global step 8036: loss = 0.0175 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8037: loss = 0.0258 (0.163 sec/step)\n",
            "I0213 16:56:31.704041 139806407255936 learning.py:512] global step 8037: loss = 0.0258 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8038: loss = 0.0122 (0.183 sec/step)\n",
            "I0213 16:56:31.889067 139806407255936 learning.py:512] global step 8038: loss = 0.0122 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8039: loss = 0.0168 (0.165 sec/step)\n",
            "I0213 16:56:32.055594 139806407255936 learning.py:512] global step 8039: loss = 0.0168 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8040: loss = 0.0142 (0.180 sec/step)\n",
            "I0213 16:56:32.236915 139806407255936 learning.py:512] global step 8040: loss = 0.0142 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8041: loss = 0.0591 (0.179 sec/step)\n",
            "I0213 16:56:32.416959 139806407255936 learning.py:512] global step 8041: loss = 0.0591 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8042: loss = 0.0247 (0.168 sec/step)\n",
            "I0213 16:56:32.588880 139806407255936 learning.py:512] global step 8042: loss = 0.0247 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8043: loss = 0.0179 (0.205 sec/step)\n",
            "I0213 16:56:32.795502 139806407255936 learning.py:512] global step 8043: loss = 0.0179 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 8044: loss = 0.0125 (0.172 sec/step)\n",
            "I0213 16:56:32.969117 139806407255936 learning.py:512] global step 8044: loss = 0.0125 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8045: loss = 0.0109 (0.178 sec/step)\n",
            "I0213 16:56:33.148901 139806407255936 learning.py:512] global step 8045: loss = 0.0109 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8046: loss = 0.0110 (0.162 sec/step)\n",
            "I0213 16:56:33.312138 139806407255936 learning.py:512] global step 8046: loss = 0.0110 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8047: loss = 0.0242 (0.178 sec/step)\n",
            "I0213 16:56:33.491239 139806407255936 learning.py:512] global step 8047: loss = 0.0242 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8048: loss = 0.0193 (0.162 sec/step)\n",
            "I0213 16:56:33.654440 139806407255936 learning.py:512] global step 8048: loss = 0.0193 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8049: loss = 0.0655 (0.175 sec/step)\n",
            "I0213 16:56:33.831475 139806407255936 learning.py:512] global step 8049: loss = 0.0655 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8050: loss = 0.0360 (0.157 sec/step)\n",
            "I0213 16:56:33.989935 139806407255936 learning.py:512] global step 8050: loss = 0.0360 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8051: loss = 0.0314 (0.169 sec/step)\n",
            "I0213 16:56:34.160227 139806407255936 learning.py:512] global step 8051: loss = 0.0314 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8052: loss = 0.0281 (0.163 sec/step)\n",
            "I0213 16:56:34.324102 139806407255936 learning.py:512] global step 8052: loss = 0.0281 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8053: loss = 0.0304 (0.185 sec/step)\n",
            "I0213 16:56:34.510467 139806407255936 learning.py:512] global step 8053: loss = 0.0304 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8054: loss = 0.0473 (0.174 sec/step)\n",
            "I0213 16:56:34.686086 139806407255936 learning.py:512] global step 8054: loss = 0.0473 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8055: loss = 0.0216 (0.162 sec/step)\n",
            "I0213 16:56:34.849178 139806407255936 learning.py:512] global step 8055: loss = 0.0216 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8056: loss = 0.0183 (0.160 sec/step)\n",
            "I0213 16:56:35.011088 139806407255936 learning.py:512] global step 8056: loss = 0.0183 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8057: loss = 0.0103 (0.174 sec/step)\n",
            "I0213 16:56:35.187476 139806407255936 learning.py:512] global step 8057: loss = 0.0103 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8058: loss = 0.0202 (0.190 sec/step)\n",
            "I0213 16:56:35.379554 139806407255936 learning.py:512] global step 8058: loss = 0.0202 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8059: loss = 0.0443 (0.187 sec/step)\n",
            "I0213 16:56:35.568081 139806407255936 learning.py:512] global step 8059: loss = 0.0443 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8060: loss = 0.0177 (0.172 sec/step)\n",
            "I0213 16:56:35.741384 139806407255936 learning.py:512] global step 8060: loss = 0.0177 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8061: loss = 0.0233 (0.174 sec/step)\n",
            "I0213 16:56:35.917249 139806407255936 learning.py:512] global step 8061: loss = 0.0233 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8062: loss = 0.0211 (0.166 sec/step)\n",
            "I0213 16:56:36.084651 139806407255936 learning.py:512] global step 8062: loss = 0.0211 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8063: loss = 0.0234 (0.169 sec/step)\n",
            "I0213 16:56:36.255529 139806407255936 learning.py:512] global step 8063: loss = 0.0234 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8064: loss = 0.0235 (0.173 sec/step)\n",
            "I0213 16:56:36.430058 139806407255936 learning.py:512] global step 8064: loss = 0.0235 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8065: loss = 0.0161 (0.176 sec/step)\n",
            "I0213 16:56:36.607668 139806407255936 learning.py:512] global step 8065: loss = 0.0161 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8066: loss = 0.0192 (0.181 sec/step)\n",
            "I0213 16:56:36.789646 139806407255936 learning.py:512] global step 8066: loss = 0.0192 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8067: loss = 0.0351 (0.180 sec/step)\n",
            "I0213 16:56:36.971563 139806407255936 learning.py:512] global step 8067: loss = 0.0351 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8068: loss = 0.0693 (0.171 sec/step)\n",
            "I0213 16:56:37.144338 139806407255936 learning.py:512] global step 8068: loss = 0.0693 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8069: loss = 0.0109 (0.165 sec/step)\n",
            "I0213 16:56:37.310727 139806407255936 learning.py:512] global step 8069: loss = 0.0109 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8070: loss = 0.0248 (0.202 sec/step)\n",
            "I0213 16:56:37.514551 139806407255936 learning.py:512] global step 8070: loss = 0.0248 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 8071: loss = 0.0099 (0.169 sec/step)\n",
            "I0213 16:56:37.685271 139806407255936 learning.py:512] global step 8071: loss = 0.0099 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8072: loss = 0.0085 (0.181 sec/step)\n",
            "I0213 16:56:37.867821 139806407255936 learning.py:512] global step 8072: loss = 0.0085 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8073: loss = 0.0850 (0.176 sec/step)\n",
            "I0213 16:56:38.045686 139806407255936 learning.py:512] global step 8073: loss = 0.0850 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8074: loss = 0.0394 (0.160 sec/step)\n",
            "I0213 16:56:38.207274 139806407255936 learning.py:512] global step 8074: loss = 0.0394 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8075: loss = 0.0156 (0.158 sec/step)\n",
            "I0213 16:56:38.367768 139806407255936 learning.py:512] global step 8075: loss = 0.0156 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8076: loss = 0.0570 (0.180 sec/step)\n",
            "I0213 16:56:38.548958 139806407255936 learning.py:512] global step 8076: loss = 0.0570 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8077: loss = 0.0102 (0.164 sec/step)\n",
            "I0213 16:56:38.713914 139806407255936 learning.py:512] global step 8077: loss = 0.0102 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8078: loss = 0.0279 (0.165 sec/step)\n",
            "I0213 16:56:38.880372 139806407255936 learning.py:512] global step 8078: loss = 0.0279 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8079: loss = 0.0198 (0.168 sec/step)\n",
            "I0213 16:56:39.050063 139806407255936 learning.py:512] global step 8079: loss = 0.0198 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8080: loss = 0.0121 (0.163 sec/step)\n",
            "I0213 16:56:39.214692 139806407255936 learning.py:512] global step 8080: loss = 0.0121 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8081: loss = 0.0448 (0.172 sec/step)\n",
            "I0213 16:56:39.388073 139806407255936 learning.py:512] global step 8081: loss = 0.0448 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8082: loss = 0.0234 (0.167 sec/step)\n",
            "I0213 16:56:39.556232 139806407255936 learning.py:512] global step 8082: loss = 0.0234 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8083: loss = 0.0113 (0.163 sec/step)\n",
            "I0213 16:56:39.721043 139806407255936 learning.py:512] global step 8083: loss = 0.0113 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8084: loss = 0.0126 (0.160 sec/step)\n",
            "I0213 16:56:39.882532 139806407255936 learning.py:512] global step 8084: loss = 0.0126 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8085: loss = 0.0397 (0.179 sec/step)\n",
            "I0213 16:56:40.063183 139806407255936 learning.py:512] global step 8085: loss = 0.0397 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8086: loss = 0.0142 (0.165 sec/step)\n",
            "I0213 16:56:40.229156 139806407255936 learning.py:512] global step 8086: loss = 0.0142 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8087: loss = 0.0469 (0.157 sec/step)\n",
            "I0213 16:56:40.387777 139806407255936 learning.py:512] global step 8087: loss = 0.0469 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8088: loss = 0.0557 (0.172 sec/step)\n",
            "I0213 16:56:40.561861 139806407255936 learning.py:512] global step 8088: loss = 0.0557 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8089: loss = 0.0370 (0.171 sec/step)\n",
            "I0213 16:56:40.734925 139806407255936 learning.py:512] global step 8089: loss = 0.0370 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8090: loss = 0.0618 (0.175 sec/step)\n",
            "I0213 16:56:40.911331 139806407255936 learning.py:512] global step 8090: loss = 0.0618 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8091: loss = 0.0254 (0.163 sec/step)\n",
            "I0213 16:56:41.076014 139806407255936 learning.py:512] global step 8091: loss = 0.0254 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8092: loss = 0.0337 (0.166 sec/step)\n",
            "I0213 16:56:41.243105 139806407255936 learning.py:512] global step 8092: loss = 0.0337 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8093: loss = 0.0302 (0.157 sec/step)\n",
            "I0213 16:56:41.401601 139806407255936 learning.py:512] global step 8093: loss = 0.0302 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8094: loss = 0.0230 (0.169 sec/step)\n",
            "I0213 16:56:41.572467 139806407255936 learning.py:512] global step 8094: loss = 0.0230 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8095: loss = 0.0119 (0.174 sec/step)\n",
            "I0213 16:56:41.747786 139806407255936 learning.py:512] global step 8095: loss = 0.0119 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8096: loss = 0.0117 (0.163 sec/step)\n",
            "I0213 16:56:41.912045 139806407255936 learning.py:512] global step 8096: loss = 0.0117 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8097: loss = 0.0111 (0.185 sec/step)\n",
            "I0213 16:56:42.098215 139806407255936 learning.py:512] global step 8097: loss = 0.0111 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8098: loss = 0.0159 (0.172 sec/step)\n",
            "I0213 16:56:42.271559 139806407255936 learning.py:512] global step 8098: loss = 0.0159 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8099: loss = 0.0216 (0.165 sec/step)\n",
            "I0213 16:56:42.438581 139806407255936 learning.py:512] global step 8099: loss = 0.0216 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8100: loss = 0.0216 (0.175 sec/step)\n",
            "I0213 16:56:42.615360 139806407255936 learning.py:512] global step 8100: loss = 0.0216 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8101: loss = 0.0320 (0.173 sec/step)\n",
            "I0213 16:56:42.789817 139806407255936 learning.py:512] global step 8101: loss = 0.0320 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8102: loss = 0.0223 (0.178 sec/step)\n",
            "I0213 16:56:42.968830 139806407255936 learning.py:512] global step 8102: loss = 0.0223 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8103: loss = 0.0395 (0.160 sec/step)\n",
            "I0213 16:56:43.130779 139806407255936 learning.py:512] global step 8103: loss = 0.0395 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8104: loss = 0.0123 (0.173 sec/step)\n",
            "I0213 16:56:43.304750 139806407255936 learning.py:512] global step 8104: loss = 0.0123 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8105: loss = 0.0397 (0.158 sec/step)\n",
            "I0213 16:56:43.464571 139806407255936 learning.py:512] global step 8105: loss = 0.0397 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8106: loss = 0.0234 (0.171 sec/step)\n",
            "I0213 16:56:43.636342 139806407255936 learning.py:512] global step 8106: loss = 0.0234 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8107: loss = 0.0312 (0.168 sec/step)\n",
            "I0213 16:56:43.805515 139806407255936 learning.py:512] global step 8107: loss = 0.0312 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8108: loss = 0.0095 (0.168 sec/step)\n",
            "I0213 16:56:43.974523 139806407255936 learning.py:512] global step 8108: loss = 0.0095 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8109: loss = 0.0246 (0.175 sec/step)\n",
            "I0213 16:56:44.150661 139806407255936 learning.py:512] global step 8109: loss = 0.0246 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8110: loss = 0.0364 (0.173 sec/step)\n",
            "I0213 16:56:44.325006 139806407255936 learning.py:512] global step 8110: loss = 0.0364 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8111: loss = 0.0110 (0.172 sec/step)\n",
            "I0213 16:56:44.498368 139806407255936 learning.py:512] global step 8111: loss = 0.0110 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8112: loss = 0.0288 (0.161 sec/step)\n",
            "I0213 16:56:44.661176 139806407255936 learning.py:512] global step 8112: loss = 0.0288 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8113: loss = 0.0226 (0.181 sec/step)\n",
            "I0213 16:56:44.843136 139806407255936 learning.py:512] global step 8113: loss = 0.0226 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8114: loss = 0.0152 (0.162 sec/step)\n",
            "I0213 16:56:45.006397 139806407255936 learning.py:512] global step 8114: loss = 0.0152 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8115: loss = 0.0219 (0.170 sec/step)\n",
            "I0213 16:56:45.178083 139806407255936 learning.py:512] global step 8115: loss = 0.0219 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8116: loss = 0.0130 (0.174 sec/step)\n",
            "I0213 16:56:45.353605 139806407255936 learning.py:512] global step 8116: loss = 0.0130 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8117: loss = 0.0187 (0.159 sec/step)\n",
            "I0213 16:56:45.514097 139806407255936 learning.py:512] global step 8117: loss = 0.0187 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8118: loss = 0.0189 (0.167 sec/step)\n",
            "I0213 16:56:45.682201 139806407255936 learning.py:512] global step 8118: loss = 0.0189 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8119: loss = 0.0218 (0.164 sec/step)\n",
            "I0213 16:56:45.848066 139806407255936 learning.py:512] global step 8119: loss = 0.0218 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8120: loss = 0.0086 (0.177 sec/step)\n",
            "I0213 16:56:46.026669 139806407255936 learning.py:512] global step 8120: loss = 0.0086 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8121: loss = 0.0281 (0.163 sec/step)\n",
            "I0213 16:56:46.190930 139806407255936 learning.py:512] global step 8121: loss = 0.0281 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8122: loss = 0.0363 (0.164 sec/step)\n",
            "I0213 16:56:46.356673 139806407255936 learning.py:512] global step 8122: loss = 0.0363 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8123: loss = 0.0358 (0.169 sec/step)\n",
            "I0213 16:56:46.526814 139806407255936 learning.py:512] global step 8123: loss = 0.0358 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8124: loss = 0.0382 (0.176 sec/step)\n",
            "I0213 16:56:46.704498 139806407255936 learning.py:512] global step 8124: loss = 0.0382 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8125: loss = 0.0093 (0.162 sec/step)\n",
            "I0213 16:56:46.868455 139806407255936 learning.py:512] global step 8125: loss = 0.0093 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8126: loss = 0.0572 (0.179 sec/step)\n",
            "I0213 16:56:47.048790 139806407255936 learning.py:512] global step 8126: loss = 0.0572 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8127: loss = 0.0521 (0.162 sec/step)\n",
            "I0213 16:56:47.213135 139806407255936 learning.py:512] global step 8127: loss = 0.0521 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8128: loss = 0.0303 (0.162 sec/step)\n",
            "I0213 16:56:47.376787 139806407255936 learning.py:512] global step 8128: loss = 0.0303 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8129: loss = 0.0387 (0.169 sec/step)\n",
            "I0213 16:56:47.546997 139806407255936 learning.py:512] global step 8129: loss = 0.0387 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8130: loss = 0.0305 (0.162 sec/step)\n",
            "I0213 16:56:47.710518 139806407255936 learning.py:512] global step 8130: loss = 0.0305 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8131: loss = 0.0234 (0.164 sec/step)\n",
            "I0213 16:56:47.875920 139806407255936 learning.py:512] global step 8131: loss = 0.0234 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8132: loss = 0.0151 (0.158 sec/step)\n",
            "I0213 16:56:48.034802 139806407255936 learning.py:512] global step 8132: loss = 0.0151 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8133: loss = 0.0398 (0.165 sec/step)\n",
            "I0213 16:56:48.201143 139806407255936 learning.py:512] global step 8133: loss = 0.0398 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8134: loss = 0.0633 (0.147 sec/step)\n",
            "I0213 16:56:48.349237 139806407255936 learning.py:512] global step 8134: loss = 0.0633 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8135: loss = 0.0197 (0.176 sec/step)\n",
            "I0213 16:56:48.527271 139806407255936 learning.py:512] global step 8135: loss = 0.0197 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8136: loss = 0.0388 (0.174 sec/step)\n",
            "I0213 16:56:48.703751 139806407255936 learning.py:512] global step 8136: loss = 0.0388 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8137: loss = 0.0163 (0.170 sec/step)\n",
            "I0213 16:56:48.875465 139806407255936 learning.py:512] global step 8137: loss = 0.0163 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8138: loss = 0.0377 (0.182 sec/step)\n",
            "I0213 16:56:49.058849 139806407255936 learning.py:512] global step 8138: loss = 0.0377 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8139: loss = 0.0150 (0.169 sec/step)\n",
            "I0213 16:56:49.229599 139806407255936 learning.py:512] global step 8139: loss = 0.0150 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8140: loss = 0.0255 (0.162 sec/step)\n",
            "I0213 16:56:49.393194 139806407255936 learning.py:512] global step 8140: loss = 0.0255 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8141: loss = 0.0229 (0.191 sec/step)\n",
            "I0213 16:56:49.585123 139806407255936 learning.py:512] global step 8141: loss = 0.0229 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8142: loss = 0.0153 (0.164 sec/step)\n",
            "I0213 16:56:49.750523 139806407255936 learning.py:512] global step 8142: loss = 0.0153 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8143: loss = 0.0273 (0.162 sec/step)\n",
            "I0213 16:56:49.913753 139806407255936 learning.py:512] global step 8143: loss = 0.0273 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8144: loss = 0.0146 (0.172 sec/step)\n",
            "I0213 16:56:50.087269 139806407255936 learning.py:512] global step 8144: loss = 0.0146 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8145: loss = 0.0070 (0.166 sec/step)\n",
            "I0213 16:56:50.254907 139806407255936 learning.py:512] global step 8145: loss = 0.0070 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8146: loss = 0.0358 (0.165 sec/step)\n",
            "I0213 16:56:50.421527 139806407255936 learning.py:512] global step 8146: loss = 0.0358 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8147: loss = 0.0224 (0.162 sec/step)\n",
            "I0213 16:56:50.584855 139806407255936 learning.py:512] global step 8147: loss = 0.0224 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8148: loss = 0.0207 (0.168 sec/step)\n",
            "I0213 16:56:50.754273 139806407255936 learning.py:512] global step 8148: loss = 0.0207 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8149: loss = 0.0238 (0.177 sec/step)\n",
            "I0213 16:56:50.932600 139806407255936 learning.py:512] global step 8149: loss = 0.0238 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8150: loss = 0.0429 (0.165 sec/step)\n",
            "I0213 16:56:51.098752 139806407255936 learning.py:512] global step 8150: loss = 0.0429 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8151: loss = 0.0222 (0.158 sec/step)\n",
            "I0213 16:56:51.258725 139806407255936 learning.py:512] global step 8151: loss = 0.0222 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8152: loss = 0.0155 (0.175 sec/step)\n",
            "I0213 16:56:51.435060 139806407255936 learning.py:512] global step 8152: loss = 0.0155 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8153: loss = 0.0174 (0.173 sec/step)\n",
            "I0213 16:56:51.609064 139806407255936 learning.py:512] global step 8153: loss = 0.0174 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8154: loss = 0.0147 (0.176 sec/step)\n",
            "I0213 16:56:51.786137 139806407255936 learning.py:512] global step 8154: loss = 0.0147 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8155: loss = 0.0343 (0.189 sec/step)\n",
            "I0213 16:56:51.976824 139806407255936 learning.py:512] global step 8155: loss = 0.0343 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8156: loss = 0.0167 (0.164 sec/step)\n",
            "I0213 16:56:52.142151 139806407255936 learning.py:512] global step 8156: loss = 0.0167 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8157: loss = 0.0257 (0.165 sec/step)\n",
            "I0213 16:56:52.308484 139806407255936 learning.py:512] global step 8157: loss = 0.0257 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8158: loss = 0.0322 (0.166 sec/step)\n",
            "I0213 16:56:52.475944 139806407255936 learning.py:512] global step 8158: loss = 0.0322 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8159: loss = 0.0246 (0.155 sec/step)\n",
            "I0213 16:56:52.631762 139806407255936 learning.py:512] global step 8159: loss = 0.0246 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8160: loss = 0.0109 (0.170 sec/step)\n",
            "I0213 16:56:52.803479 139806407255936 learning.py:512] global step 8160: loss = 0.0109 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8161: loss = 0.0437 (0.160 sec/step)\n",
            "I0213 16:56:52.964475 139806407255936 learning.py:512] global step 8161: loss = 0.0437 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8162: loss = 0.0224 (0.169 sec/step)\n",
            "I0213 16:56:53.135250 139806407255936 learning.py:512] global step 8162: loss = 0.0224 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8163: loss = 0.0113 (0.166 sec/step)\n",
            "I0213 16:56:53.302719 139806407255936 learning.py:512] global step 8163: loss = 0.0113 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8164: loss = 0.0347 (0.173 sec/step)\n",
            "I0213 16:56:53.476995 139806407255936 learning.py:512] global step 8164: loss = 0.0347 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8165: loss = 0.0370 (0.169 sec/step)\n",
            "I0213 16:56:53.647936 139806407255936 learning.py:512] global step 8165: loss = 0.0370 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8166: loss = 0.0195 (0.151 sec/step)\n",
            "I0213 16:56:53.800711 139806407255936 learning.py:512] global step 8166: loss = 0.0195 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8167: loss = 0.0172 (0.165 sec/step)\n",
            "I0213 16:56:53.967225 139806407255936 learning.py:512] global step 8167: loss = 0.0172 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8168: loss = 0.0222 (0.177 sec/step)\n",
            "I0213 16:56:54.145779 139806407255936 learning.py:512] global step 8168: loss = 0.0222 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8169: loss = 0.0340 (0.168 sec/step)\n",
            "I0213 16:56:54.316057 139806407255936 learning.py:512] global step 8169: loss = 0.0340 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8170: loss = 0.1044 (0.168 sec/step)\n",
            "I0213 16:56:54.485751 139806407255936 learning.py:512] global step 8170: loss = 0.1044 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8171: loss = 0.0373 (0.168 sec/step)\n",
            "I0213 16:56:54.654625 139806407255936 learning.py:512] global step 8171: loss = 0.0373 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8172: loss = 0.0538 (0.170 sec/step)\n",
            "I0213 16:56:54.826255 139806407255936 learning.py:512] global step 8172: loss = 0.0538 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8173: loss = 0.0104 (0.166 sec/step)\n",
            "I0213 16:56:54.993478 139806407255936 learning.py:512] global step 8173: loss = 0.0104 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8174: loss = 0.0237 (0.180 sec/step)\n",
            "I0213 16:56:55.175381 139806407255936 learning.py:512] global step 8174: loss = 0.0237 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8175: loss = 0.0223 (0.161 sec/step)\n",
            "I0213 16:56:55.337965 139806407255936 learning.py:512] global step 8175: loss = 0.0223 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8176: loss = 0.0449 (0.184 sec/step)\n",
            "I0213 16:56:55.523258 139806407255936 learning.py:512] global step 8176: loss = 0.0449 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8177: loss = 0.0254 (0.162 sec/step)\n",
            "I0213 16:56:55.686183 139806407255936 learning.py:512] global step 8177: loss = 0.0254 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8178: loss = 0.0457 (0.186 sec/step)\n",
            "I0213 16:56:55.873439 139806407255936 learning.py:512] global step 8178: loss = 0.0457 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8179: loss = 0.0363 (0.160 sec/step)\n",
            "I0213 16:56:56.035251 139806407255936 learning.py:512] global step 8179: loss = 0.0363 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8180: loss = 0.0245 (0.162 sec/step)\n",
            "I0213 16:56:56.198912 139806407255936 learning.py:512] global step 8180: loss = 0.0245 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8181: loss = 0.0276 (0.168 sec/step)\n",
            "I0213 16:56:56.368149 139806407255936 learning.py:512] global step 8181: loss = 0.0276 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8182: loss = 0.0188 (0.175 sec/step)\n",
            "I0213 16:56:56.544570 139806407255936 learning.py:512] global step 8182: loss = 0.0188 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8183: loss = 0.0307 (0.178 sec/step)\n",
            "I0213 16:56:56.724152 139806407255936 learning.py:512] global step 8183: loss = 0.0307 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8184: loss = 0.0197 (0.158 sec/step)\n",
            "I0213 16:56:56.883344 139806407255936 learning.py:512] global step 8184: loss = 0.0197 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8185: loss = 0.0377 (0.167 sec/step)\n",
            "I0213 16:56:57.051768 139806407255936 learning.py:512] global step 8185: loss = 0.0377 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8186: loss = 0.0511 (0.165 sec/step)\n",
            "I0213 16:56:57.218241 139806407255936 learning.py:512] global step 8186: loss = 0.0511 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8187: loss = 0.0305 (0.183 sec/step)\n",
            "I0213 16:56:57.402369 139806407255936 learning.py:512] global step 8187: loss = 0.0305 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8188: loss = 0.0258 (0.167 sec/step)\n",
            "I0213 16:56:57.570350 139806407255936 learning.py:512] global step 8188: loss = 0.0258 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8189: loss = 0.0254 (0.162 sec/step)\n",
            "I0213 16:56:57.733649 139806407255936 learning.py:512] global step 8189: loss = 0.0254 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8190: loss = 0.0323 (0.166 sec/step)\n",
            "I0213 16:56:57.901039 139806407255936 learning.py:512] global step 8190: loss = 0.0323 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8191: loss = 0.0389 (0.170 sec/step)\n",
            "I0213 16:56:58.072452 139806407255936 learning.py:512] global step 8191: loss = 0.0389 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8192: loss = 0.0148 (0.167 sec/step)\n",
            "I0213 16:56:58.240572 139806407255936 learning.py:512] global step 8192: loss = 0.0148 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8193: loss = 0.0178 (0.166 sec/step)\n",
            "I0213 16:56:58.407945 139806407255936 learning.py:512] global step 8193: loss = 0.0178 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8194: loss = 0.0397 (0.157 sec/step)\n",
            "I0213 16:56:58.566658 139806407255936 learning.py:512] global step 8194: loss = 0.0397 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8195: loss = 0.0181 (0.166 sec/step)\n",
            "I0213 16:56:58.733649 139806407255936 learning.py:512] global step 8195: loss = 0.0181 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8196: loss = 0.0532 (0.160 sec/step)\n",
            "I0213 16:56:58.895280 139806407255936 learning.py:512] global step 8196: loss = 0.0532 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8197: loss = 0.0396 (0.179 sec/step)\n",
            "I0213 16:56:59.075958 139806407255936 learning.py:512] global step 8197: loss = 0.0396 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8198: loss = 0.0268 (0.162 sec/step)\n",
            "I0213 16:56:59.239116 139806407255936 learning.py:512] global step 8198: loss = 0.0268 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8199: loss = 0.0334 (0.177 sec/step)\n",
            "I0213 16:56:59.417621 139806407255936 learning.py:512] global step 8199: loss = 0.0334 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8200: loss = 0.0324 (0.182 sec/step)\n",
            "I0213 16:56:59.601063 139806407255936 learning.py:512] global step 8200: loss = 0.0324 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8201: loss = 0.0117 (0.181 sec/step)\n",
            "I0213 16:56:59.783445 139806407255936 learning.py:512] global step 8201: loss = 0.0117 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8202: loss = 0.0132 (0.168 sec/step)\n",
            "I0213 16:56:59.953029 139806407255936 learning.py:512] global step 8202: loss = 0.0132 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8203: loss = 0.0239 (0.152 sec/step)\n",
            "I0213 16:57:00.106842 139806407255936 learning.py:512] global step 8203: loss = 0.0239 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8204: loss = 0.0131 (0.181 sec/step)\n",
            "I0213 16:57:00.289136 139806407255936 learning.py:512] global step 8204: loss = 0.0131 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8205: loss = 0.0205 (0.172 sec/step)\n",
            "I0213 16:57:00.462700 139806407255936 learning.py:512] global step 8205: loss = 0.0205 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8206: loss = 0.0344 (0.162 sec/step)\n",
            "I0213 16:57:00.625772 139806407255936 learning.py:512] global step 8206: loss = 0.0344 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8207: loss = 0.0134 (0.186 sec/step)\n",
            "I0213 16:57:00.814532 139806407255936 learning.py:512] global step 8207: loss = 0.0134 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8208: loss = 0.0328 (0.161 sec/step)\n",
            "I0213 16:57:00.976830 139806407255936 learning.py:512] global step 8208: loss = 0.0328 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8209: loss = 0.0268 (0.169 sec/step)\n",
            "I0213 16:57:01.147138 139806407255936 learning.py:512] global step 8209: loss = 0.0268 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8210: loss = 0.0130 (0.164 sec/step)\n",
            "I0213 16:57:01.313089 139806407255936 learning.py:512] global step 8210: loss = 0.0130 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8211: loss = 0.0547 (0.167 sec/step)\n",
            "I0213 16:57:01.481687 139806407255936 learning.py:512] global step 8211: loss = 0.0547 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8212: loss = 0.0157 (0.171 sec/step)\n",
            "I0213 16:57:01.654563 139806407255936 learning.py:512] global step 8212: loss = 0.0157 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8213: loss = 0.0360 (0.172 sec/step)\n",
            "I0213 16:57:01.827454 139806407255936 learning.py:512] global step 8213: loss = 0.0360 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8214: loss = 0.0181 (0.166 sec/step)\n",
            "I0213 16:57:01.995170 139806407255936 learning.py:512] global step 8214: loss = 0.0181 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8215: loss = 0.0176 (0.175 sec/step)\n",
            "I0213 16:57:02.171564 139806407255936 learning.py:512] global step 8215: loss = 0.0176 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8216: loss = 0.0267 (0.169 sec/step)\n",
            "I0213 16:57:02.341536 139806407255936 learning.py:512] global step 8216: loss = 0.0267 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8217: loss = 0.0334 (0.176 sec/step)\n",
            "I0213 16:57:02.518547 139806407255936 learning.py:512] global step 8217: loss = 0.0334 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8218: loss = 0.0176 (0.152 sec/step)\n",
            "I0213 16:57:02.671598 139806407255936 learning.py:512] global step 8218: loss = 0.0176 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8219: loss = 0.0347 (0.153 sec/step)\n",
            "I0213 16:57:02.828465 139806407255936 learning.py:512] global step 8219: loss = 0.0347 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8220: loss = 0.0512 (0.160 sec/step)\n",
            "I0213 16:57:02.990392 139806407255936 learning.py:512] global step 8220: loss = 0.0512 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8221: loss = 0.0170 (0.152 sec/step)\n",
            "I0213 16:57:03.143625 139806407255936 learning.py:512] global step 8221: loss = 0.0170 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8222: loss = 0.0137 (0.170 sec/step)\n",
            "I0213 16:57:03.314717 139806407255936 learning.py:512] global step 8222: loss = 0.0137 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8223: loss = 0.0358 (0.166 sec/step)\n",
            "I0213 16:57:03.481526 139806407255936 learning.py:512] global step 8223: loss = 0.0358 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8224: loss = 0.0648 (0.155 sec/step)\n",
            "I0213 16:57:03.637857 139806407255936 learning.py:512] global step 8224: loss = 0.0648 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8225: loss = 0.0088 (0.202 sec/step)\n",
            "I0213 16:57:03.841076 139806407255936 learning.py:512] global step 8225: loss = 0.0088 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 8226: loss = 0.0176 (0.164 sec/step)\n",
            "I0213 16:57:04.006306 139806407255936 learning.py:512] global step 8226: loss = 0.0176 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8227: loss = 0.0082 (0.164 sec/step)\n",
            "I0213 16:57:04.171753 139806407255936 learning.py:512] global step 8227: loss = 0.0082 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8228: loss = 0.0471 (0.166 sec/step)\n",
            "I0213 16:57:04.339447 139806407255936 learning.py:512] global step 8228: loss = 0.0471 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8229: loss = 0.0118 (0.176 sec/step)\n",
            "I0213 16:57:04.516373 139806407255936 learning.py:512] global step 8229: loss = 0.0118 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8230: loss = 0.0164 (0.171 sec/step)\n",
            "I0213 16:57:04.689158 139806407255936 learning.py:512] global step 8230: loss = 0.0164 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8231: loss = 0.0448 (0.169 sec/step)\n",
            "I0213 16:57:04.859919 139806407255936 learning.py:512] global step 8231: loss = 0.0448 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8232: loss = 0.0284 (0.166 sec/step)\n",
            "I0213 16:57:05.027114 139806407255936 learning.py:512] global step 8232: loss = 0.0284 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8233: loss = 0.0260 (0.158 sec/step)\n",
            "I0213 16:57:05.186275 139806407255936 learning.py:512] global step 8233: loss = 0.0260 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8234: loss = 0.0180 (0.170 sec/step)\n",
            "I0213 16:57:05.357509 139806407255936 learning.py:512] global step 8234: loss = 0.0180 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8235: loss = 0.0372 (0.170 sec/step)\n",
            "I0213 16:57:05.529237 139806407255936 learning.py:512] global step 8235: loss = 0.0372 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8236: loss = 0.0201 (0.170 sec/step)\n",
            "I0213 16:57:05.701091 139806407255936 learning.py:512] global step 8236: loss = 0.0201 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8237: loss = 0.0194 (0.161 sec/step)\n",
            "I0213 16:57:05.864794 139806407255936 learning.py:512] global step 8237: loss = 0.0194 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8238: loss = 0.0309 (0.169 sec/step)\n",
            "I0213 16:57:06.035023 139806407255936 learning.py:512] global step 8238: loss = 0.0309 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8239: loss = 0.0175 (0.162 sec/step)\n",
            "I0213 16:57:06.198241 139806407255936 learning.py:512] global step 8239: loss = 0.0175 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8240: loss = 0.0283 (0.155 sec/step)\n",
            "I0213 16:57:06.354374 139806407255936 learning.py:512] global step 8240: loss = 0.0283 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8241: loss = 0.0243 (0.168 sec/step)\n",
            "I0213 16:57:06.523665 139806407255936 learning.py:512] global step 8241: loss = 0.0243 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8242: loss = 0.0154 (0.166 sec/step)\n",
            "I0213 16:57:06.691220 139806407255936 learning.py:512] global step 8242: loss = 0.0154 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8243: loss = 0.1028 (0.184 sec/step)\n",
            "I0213 16:57:06.876175 139806407255936 learning.py:512] global step 8243: loss = 0.1028 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8244: loss = 0.0187 (0.170 sec/step)\n",
            "I0213 16:57:07.047153 139806407255936 learning.py:512] global step 8244: loss = 0.0187 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8245: loss = 0.0338 (0.181 sec/step)\n",
            "I0213 16:57:07.229572 139806407255936 learning.py:512] global step 8245: loss = 0.0338 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8246: loss = 0.0416 (0.171 sec/step)\n",
            "I0213 16:57:07.402144 139806407255936 learning.py:512] global step 8246: loss = 0.0416 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8247: loss = 0.0270 (0.167 sec/step)\n",
            "I0213 16:57:07.571136 139806407255936 learning.py:512] global step 8247: loss = 0.0270 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8248: loss = 0.0221 (0.162 sec/step)\n",
            "I0213 16:57:07.734648 139806407255936 learning.py:512] global step 8248: loss = 0.0221 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8249: loss = 0.0501 (0.183 sec/step)\n",
            "I0213 16:57:07.919316 139806407255936 learning.py:512] global step 8249: loss = 0.0501 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8250: loss = 0.0349 (0.175 sec/step)\n",
            "I0213 16:57:08.095586 139806407255936 learning.py:512] global step 8250: loss = 0.0349 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8251: loss = 0.0739 (0.157 sec/step)\n",
            "I0213 16:57:08.254054 139806407255936 learning.py:512] global step 8251: loss = 0.0739 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8252: loss = 0.0145 (0.170 sec/step)\n",
            "I0213 16:57:08.426982 139806407255936 learning.py:512] global step 8252: loss = 0.0145 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8253: loss = 0.0117 (0.171 sec/step)\n",
            "I0213 16:57:08.599445 139806407255936 learning.py:512] global step 8253: loss = 0.0117 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8254: loss = 0.0154 (0.163 sec/step)\n",
            "I0213 16:57:08.764073 139806407255936 learning.py:512] global step 8254: loss = 0.0154 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8255: loss = 0.0178 (0.170 sec/step)\n",
            "I0213 16:57:08.935639 139806407255936 learning.py:512] global step 8255: loss = 0.0178 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8256: loss = 0.0169 (0.172 sec/step)\n",
            "I0213 16:57:09.109239 139806407255936 learning.py:512] global step 8256: loss = 0.0169 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8257: loss = 0.0398 (0.165 sec/step)\n",
            "I0213 16:57:09.275611 139806407255936 learning.py:512] global step 8257: loss = 0.0398 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8258: loss = 0.0092 (0.178 sec/step)\n",
            "I0213 16:57:09.454747 139806407255936 learning.py:512] global step 8258: loss = 0.0092 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8259: loss = 0.0100 (0.172 sec/step)\n",
            "I0213 16:57:09.628240 139806407255936 learning.py:512] global step 8259: loss = 0.0100 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8260: loss = 0.0450 (0.170 sec/step)\n",
            "I0213 16:57:09.799469 139806407255936 learning.py:512] global step 8260: loss = 0.0450 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8261: loss = 0.0436 (0.177 sec/step)\n",
            "I0213 16:57:09.978058 139806407255936 learning.py:512] global step 8261: loss = 0.0436 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8262: loss = 0.0429 (0.170 sec/step)\n",
            "I0213 16:57:10.149298 139806407255936 learning.py:512] global step 8262: loss = 0.0429 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8263: loss = 0.0144 (0.181 sec/step)\n",
            "I0213 16:57:10.331887 139806407255936 learning.py:512] global step 8263: loss = 0.0144 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8264: loss = 0.0094 (0.159 sec/step)\n",
            "I0213 16:57:10.491842 139806407255936 learning.py:512] global step 8264: loss = 0.0094 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8265: loss = 0.0220 (0.170 sec/step)\n",
            "I0213 16:57:10.663425 139806407255936 learning.py:512] global step 8265: loss = 0.0220 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8266: loss = 0.0402 (0.180 sec/step)\n",
            "I0213 16:57:10.845180 139806407255936 learning.py:512] global step 8266: loss = 0.0402 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8267: loss = 0.0251 (0.162 sec/step)\n",
            "I0213 16:57:11.008740 139806407255936 learning.py:512] global step 8267: loss = 0.0251 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8268: loss = 0.0554 (0.152 sec/step)\n",
            "I0213 16:57:11.162152 139806407255936 learning.py:512] global step 8268: loss = 0.0554 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8269: loss = 0.0365 (0.189 sec/step)\n",
            "I0213 16:57:11.352556 139806407255936 learning.py:512] global step 8269: loss = 0.0365 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8270: loss = 0.0238 (0.165 sec/step)\n",
            "I0213 16:57:11.518698 139806407255936 learning.py:512] global step 8270: loss = 0.0238 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8271: loss = 0.0649 (0.149 sec/step)\n",
            "I0213 16:57:11.669297 139806407255936 learning.py:512] global step 8271: loss = 0.0649 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 8272: loss = 0.0141 (0.182 sec/step)\n",
            "I0213 16:57:11.852505 139806407255936 learning.py:512] global step 8272: loss = 0.0141 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8273: loss = 0.0380 (0.174 sec/step)\n",
            "I0213 16:57:12.028762 139806407255936 learning.py:512] global step 8273: loss = 0.0380 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8274: loss = 0.0364 (0.161 sec/step)\n",
            "I0213 16:57:12.191221 139806407255936 learning.py:512] global step 8274: loss = 0.0364 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8275: loss = 0.0404 (0.174 sec/step)\n",
            "I0213 16:57:12.367085 139806407255936 learning.py:512] global step 8275: loss = 0.0404 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8276: loss = 0.0234 (0.172 sec/step)\n",
            "I0213 16:57:12.540641 139806407255936 learning.py:512] global step 8276: loss = 0.0234 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8277: loss = 0.0240 (0.173 sec/step)\n",
            "I0213 16:57:12.714607 139806407255936 learning.py:512] global step 8277: loss = 0.0240 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8278: loss = 0.0371 (0.164 sec/step)\n",
            "I0213 16:57:12.879571 139806407255936 learning.py:512] global step 8278: loss = 0.0371 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8279: loss = 0.0265 (0.177 sec/step)\n",
            "I0213 16:57:13.058222 139806407255936 learning.py:512] global step 8279: loss = 0.0265 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8280: loss = 0.0322 (0.167 sec/step)\n",
            "I0213 16:57:13.226858 139806407255936 learning.py:512] global step 8280: loss = 0.0322 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8281: loss = 0.0319 (0.175 sec/step)\n",
            "I0213 16:57:13.403225 139806407255936 learning.py:512] global step 8281: loss = 0.0319 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8282: loss = 0.0288 (0.162 sec/step)\n",
            "I0213 16:57:13.566327 139806407255936 learning.py:512] global step 8282: loss = 0.0288 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8283: loss = 0.0211 (0.163 sec/step)\n",
            "I0213 16:57:13.730643 139806407255936 learning.py:512] global step 8283: loss = 0.0211 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8284: loss = 0.0154 (0.168 sec/step)\n",
            "I0213 16:57:13.899716 139806407255936 learning.py:512] global step 8284: loss = 0.0154 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8285: loss = 0.0277 (0.176 sec/step)\n",
            "I0213 16:57:14.076701 139806407255936 learning.py:512] global step 8285: loss = 0.0277 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8286: loss = 0.0099 (0.162 sec/step)\n",
            "I0213 16:57:14.240503 139806407255936 learning.py:512] global step 8286: loss = 0.0099 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8287: loss = 0.0204 (0.174 sec/step)\n",
            "I0213 16:57:14.416037 139806407255936 learning.py:512] global step 8287: loss = 0.0204 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8288: loss = 0.0778 (0.169 sec/step)\n",
            "I0213 16:57:14.586761 139806407255936 learning.py:512] global step 8288: loss = 0.0778 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8289: loss = 0.0324 (0.178 sec/step)\n",
            "I0213 16:57:14.766173 139806407255936 learning.py:512] global step 8289: loss = 0.0324 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8290: loss = 0.0210 (0.177 sec/step)\n",
            "I0213 16:57:14.945667 139806407255936 learning.py:512] global step 8290: loss = 0.0210 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8291: loss = 0.0194 (0.172 sec/step)\n",
            "I0213 16:57:15.119455 139806407255936 learning.py:512] global step 8291: loss = 0.0194 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8292: loss = 0.0127 (0.156 sec/step)\n",
            "I0213 16:57:15.276446 139806407255936 learning.py:512] global step 8292: loss = 0.0127 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8293: loss = 0.0295 (0.159 sec/step)\n",
            "I0213 16:57:15.437216 139806407255936 learning.py:512] global step 8293: loss = 0.0295 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8294: loss = 0.0221 (0.158 sec/step)\n",
            "I0213 16:57:15.596473 139806407255936 learning.py:512] global step 8294: loss = 0.0221 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8295: loss = 0.0313 (0.159 sec/step)\n",
            "I0213 16:57:15.756525 139806407255936 learning.py:512] global step 8295: loss = 0.0313 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8296: loss = 0.0171 (0.170 sec/step)\n",
            "I0213 16:57:15.927478 139806407255936 learning.py:512] global step 8296: loss = 0.0171 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8297: loss = 0.0201 (0.178 sec/step)\n",
            "I0213 16:57:16.106953 139806407255936 learning.py:512] global step 8297: loss = 0.0201 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8298: loss = 0.0259 (0.160 sec/step)\n",
            "I0213 16:57:16.268507 139806407255936 learning.py:512] global step 8298: loss = 0.0259 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8299: loss = 0.0263 (0.164 sec/step)\n",
            "I0213 16:57:16.433653 139806407255936 learning.py:512] global step 8299: loss = 0.0263 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8300: loss = 0.0151 (0.168 sec/step)\n",
            "I0213 16:57:16.603148 139806407255936 learning.py:512] global step 8300: loss = 0.0151 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8301: loss = 0.0227 (0.171 sec/step)\n",
            "I0213 16:57:16.775878 139806407255936 learning.py:512] global step 8301: loss = 0.0227 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8302: loss = 0.0255 (0.173 sec/step)\n",
            "I0213 16:57:16.950400 139806407255936 learning.py:512] global step 8302: loss = 0.0255 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8303: loss = 0.0401 (0.178 sec/step)\n",
            "I0213 16:57:17.129354 139806407255936 learning.py:512] global step 8303: loss = 0.0401 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8304: loss = 0.0305 (0.167 sec/step)\n",
            "I0213 16:57:17.298214 139806407255936 learning.py:512] global step 8304: loss = 0.0305 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8305: loss = 0.0427 (0.166 sec/step)\n",
            "I0213 16:57:17.465470 139806407255936 learning.py:512] global step 8305: loss = 0.0427 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8306: loss = 0.0084 (0.163 sec/step)\n",
            "I0213 16:57:17.629876 139806407255936 learning.py:512] global step 8306: loss = 0.0084 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8307: loss = 0.0207 (0.176 sec/step)\n",
            "I0213 16:57:17.807070 139806407255936 learning.py:512] global step 8307: loss = 0.0207 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8308: loss = 0.0492 (0.173 sec/step)\n",
            "I0213 16:57:17.981226 139806407255936 learning.py:512] global step 8308: loss = 0.0492 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8309: loss = 0.0199 (0.172 sec/step)\n",
            "I0213 16:57:18.154885 139806407255936 learning.py:512] global step 8309: loss = 0.0199 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8310: loss = 0.0204 (0.168 sec/step)\n",
            "I0213 16:57:18.324493 139806407255936 learning.py:512] global step 8310: loss = 0.0204 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8311: loss = 0.0298 (0.164 sec/step)\n",
            "I0213 16:57:18.489699 139806407255936 learning.py:512] global step 8311: loss = 0.0298 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8312: loss = 0.0543 (0.166 sec/step)\n",
            "I0213 16:57:18.657227 139806407255936 learning.py:512] global step 8312: loss = 0.0543 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8313: loss = 0.0358 (0.168 sec/step)\n",
            "I0213 16:57:18.827189 139806407255936 learning.py:512] global step 8313: loss = 0.0358 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8314: loss = 0.0246 (0.173 sec/step)\n",
            "I0213 16:57:19.001629 139806407255936 learning.py:512] global step 8314: loss = 0.0246 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8315: loss = 0.0484 (0.164 sec/step)\n",
            "I0213 16:57:19.167289 139806407255936 learning.py:512] global step 8315: loss = 0.0484 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8316: loss = 0.0390 (0.166 sec/step)\n",
            "I0213 16:57:19.335171 139806407255936 learning.py:512] global step 8316: loss = 0.0390 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8317: loss = 0.0375 (0.173 sec/step)\n",
            "I0213 16:57:19.509330 139806407255936 learning.py:512] global step 8317: loss = 0.0375 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8318: loss = 0.0643 (0.155 sec/step)\n",
            "I0213 16:57:19.666040 139806407255936 learning.py:512] global step 8318: loss = 0.0643 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8319: loss = 0.0459 (0.155 sec/step)\n",
            "I0213 16:57:19.822856 139806407255936 learning.py:512] global step 8319: loss = 0.0459 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8320: loss = 0.0168 (0.162 sec/step)\n",
            "I0213 16:57:19.986283 139806407255936 learning.py:512] global step 8320: loss = 0.0168 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8321: loss = 0.0342 (0.156 sec/step)\n",
            "I0213 16:57:20.143516 139806407255936 learning.py:512] global step 8321: loss = 0.0342 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8322: loss = 0.0286 (0.176 sec/step)\n",
            "I0213 16:57:20.321127 139806407255936 learning.py:512] global step 8322: loss = 0.0286 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8323: loss = 0.0362 (0.176 sec/step)\n",
            "I0213 16:57:20.499022 139806407255936 learning.py:512] global step 8323: loss = 0.0362 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8324: loss = 0.0367 (0.159 sec/step)\n",
            "I0213 16:57:20.659026 139806407255936 learning.py:512] global step 8324: loss = 0.0367 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8325: loss = 0.0498 (0.177 sec/step)\n",
            "I0213 16:57:20.837357 139806407255936 learning.py:512] global step 8325: loss = 0.0498 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8326: loss = 0.0518 (0.194 sec/step)\n",
            "I0213 16:57:21.032772 139806407255936 learning.py:512] global step 8326: loss = 0.0518 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8327: loss = 0.0141 (0.473 sec/step)\n",
            "I0213 16:57:21.508881 139806407255936 learning.py:512] global step 8327: loss = 0.0141 (0.473 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8327.\n",
            "I0213 16:57:21.731219 139802720151296 supervisor.py:1050] Recording summary at step 8327.\n",
            "INFO:tensorflow:global step 8328: loss = 0.0155 (0.301 sec/step)\n",
            "I0213 16:57:21.815336 139806407255936 learning.py:512] global step 8328: loss = 0.0155 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 8329: loss = 0.0394 (0.160 sec/step)\n",
            "I0213 16:57:21.976618 139806407255936 learning.py:512] global step 8329: loss = 0.0394 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8330: loss = 0.0379 (0.173 sec/step)\n",
            "I0213 16:57:22.151135 139806407255936 learning.py:512] global step 8330: loss = 0.0379 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8331: loss = 0.0211 (0.182 sec/step)\n",
            "I0213 16:57:22.334717 139806407255936 learning.py:512] global step 8331: loss = 0.0211 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8332: loss = 0.0164 (0.172 sec/step)\n",
            "I0213 16:57:22.508247 139806407255936 learning.py:512] global step 8332: loss = 0.0164 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8333: loss = 0.0184 (0.170 sec/step)\n",
            "I0213 16:57:22.679369 139806407255936 learning.py:512] global step 8333: loss = 0.0184 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8334: loss = 0.0129 (0.153 sec/step)\n",
            "I0213 16:57:22.833712 139806407255936 learning.py:512] global step 8334: loss = 0.0129 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8335: loss = 0.0093 (0.160 sec/step)\n",
            "I0213 16:57:22.995496 139806407255936 learning.py:512] global step 8335: loss = 0.0093 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8336: loss = 0.0291 (0.210 sec/step)\n",
            "I0213 16:57:23.207082 139806407255936 learning.py:512] global step 8336: loss = 0.0291 (0.210 sec/step)\n",
            "INFO:tensorflow:global step 8337: loss = 0.0328 (0.168 sec/step)\n",
            "I0213 16:57:23.376567 139806407255936 learning.py:512] global step 8337: loss = 0.0328 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8338: loss = 0.0343 (0.164 sec/step)\n",
            "I0213 16:57:23.541656 139806407255936 learning.py:512] global step 8338: loss = 0.0343 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8339: loss = 0.0106 (0.175 sec/step)\n",
            "I0213 16:57:23.717504 139806407255936 learning.py:512] global step 8339: loss = 0.0106 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8340: loss = 0.0154 (0.162 sec/step)\n",
            "I0213 16:57:23.880425 139806407255936 learning.py:512] global step 8340: loss = 0.0154 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8341: loss = 0.0244 (0.176 sec/step)\n",
            "I0213 16:57:24.057728 139806407255936 learning.py:512] global step 8341: loss = 0.0244 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8342: loss = 0.0315 (0.183 sec/step)\n",
            "I0213 16:57:24.242534 139806407255936 learning.py:512] global step 8342: loss = 0.0315 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8343: loss = 0.0083 (0.167 sec/step)\n",
            "I0213 16:57:24.411155 139806407255936 learning.py:512] global step 8343: loss = 0.0083 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8344: loss = 0.0752 (0.168 sec/step)\n",
            "I0213 16:57:24.580940 139806407255936 learning.py:512] global step 8344: loss = 0.0752 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8345: loss = 0.0165 (0.156 sec/step)\n",
            "I0213 16:57:24.737850 139806407255936 learning.py:512] global step 8345: loss = 0.0165 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8346: loss = 0.0274 (0.160 sec/step)\n",
            "I0213 16:57:24.899034 139806407255936 learning.py:512] global step 8346: loss = 0.0274 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8347: loss = 0.0228 (0.163 sec/step)\n",
            "I0213 16:57:25.063133 139806407255936 learning.py:512] global step 8347: loss = 0.0228 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8348: loss = 0.0282 (0.173 sec/step)\n",
            "I0213 16:57:25.237532 139806407255936 learning.py:512] global step 8348: loss = 0.0282 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8349: loss = 0.0203 (0.185 sec/step)\n",
            "I0213 16:57:25.424312 139806407255936 learning.py:512] global step 8349: loss = 0.0203 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8350: loss = 0.0300 (0.166 sec/step)\n",
            "I0213 16:57:25.591518 139806407255936 learning.py:512] global step 8350: loss = 0.0300 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8351: loss = 0.0149 (0.165 sec/step)\n",
            "I0213 16:57:25.757879 139806407255936 learning.py:512] global step 8351: loss = 0.0149 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8352: loss = 0.0217 (0.167 sec/step)\n",
            "I0213 16:57:25.926357 139806407255936 learning.py:512] global step 8352: loss = 0.0217 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8353: loss = 0.0265 (0.166 sec/step)\n",
            "I0213 16:57:26.094183 139806407255936 learning.py:512] global step 8353: loss = 0.0265 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8354: loss = 0.0150 (0.183 sec/step)\n",
            "I0213 16:57:26.278981 139806407255936 learning.py:512] global step 8354: loss = 0.0150 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8355: loss = 0.0105 (0.175 sec/step)\n",
            "I0213 16:57:26.455993 139806407255936 learning.py:512] global step 8355: loss = 0.0105 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8356: loss = 0.0241 (0.173 sec/step)\n",
            "I0213 16:57:26.631207 139806407255936 learning.py:512] global step 8356: loss = 0.0241 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8357: loss = 0.0197 (0.174 sec/step)\n",
            "I0213 16:57:26.807241 139806407255936 learning.py:512] global step 8357: loss = 0.0197 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8358: loss = 0.0116 (0.152 sec/step)\n",
            "I0213 16:57:26.960202 139806407255936 learning.py:512] global step 8358: loss = 0.0116 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8359: loss = 0.0126 (0.164 sec/step)\n",
            "I0213 16:57:27.125138 139806407255936 learning.py:512] global step 8359: loss = 0.0126 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8360: loss = 0.0320 (0.168 sec/step)\n",
            "I0213 16:57:27.296370 139806407255936 learning.py:512] global step 8360: loss = 0.0320 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8361: loss = 0.0266 (0.167 sec/step)\n",
            "I0213 16:57:27.464880 139806407255936 learning.py:512] global step 8361: loss = 0.0266 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8362: loss = 0.0208 (0.169 sec/step)\n",
            "I0213 16:57:27.635438 139806407255936 learning.py:512] global step 8362: loss = 0.0208 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8363: loss = 0.0442 (0.169 sec/step)\n",
            "I0213 16:57:27.805768 139806407255936 learning.py:512] global step 8363: loss = 0.0442 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8364: loss = 0.0160 (0.177 sec/step)\n",
            "I0213 16:57:27.983933 139806407255936 learning.py:512] global step 8364: loss = 0.0160 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8365: loss = 0.0317 (0.164 sec/step)\n",
            "I0213 16:57:28.152689 139806407255936 learning.py:512] global step 8365: loss = 0.0317 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8366: loss = 0.0379 (0.163 sec/step)\n",
            "I0213 16:57:28.317736 139806407255936 learning.py:512] global step 8366: loss = 0.0379 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8367: loss = 0.0450 (0.183 sec/step)\n",
            "I0213 16:57:28.502041 139806407255936 learning.py:512] global step 8367: loss = 0.0450 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8368: loss = 0.0261 (0.171 sec/step)\n",
            "I0213 16:57:28.675026 139806407255936 learning.py:512] global step 8368: loss = 0.0261 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8369: loss = 0.0173 (0.165 sec/step)\n",
            "I0213 16:57:28.841221 139806407255936 learning.py:512] global step 8369: loss = 0.0173 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8370: loss = 0.0197 (0.167 sec/step)\n",
            "I0213 16:57:29.010109 139806407255936 learning.py:512] global step 8370: loss = 0.0197 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8371: loss = 0.0073 (0.192 sec/step)\n",
            "I0213 16:57:29.203435 139806407255936 learning.py:512] global step 8371: loss = 0.0073 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8372: loss = 0.0125 (0.165 sec/step)\n",
            "I0213 16:57:29.370210 139806407255936 learning.py:512] global step 8372: loss = 0.0125 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8373: loss = 0.0395 (0.159 sec/step)\n",
            "I0213 16:57:29.530839 139806407255936 learning.py:512] global step 8373: loss = 0.0395 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8374: loss = 0.0203 (0.159 sec/step)\n",
            "I0213 16:57:29.691945 139806407255936 learning.py:512] global step 8374: loss = 0.0203 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8375: loss = 0.0301 (0.179 sec/step)\n",
            "I0213 16:57:29.872519 139806407255936 learning.py:512] global step 8375: loss = 0.0301 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8376: loss = 0.0353 (0.166 sec/step)\n",
            "I0213 16:57:30.040485 139806407255936 learning.py:512] global step 8376: loss = 0.0353 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8377: loss = 0.0257 (0.171 sec/step)\n",
            "I0213 16:57:30.212527 139806407255936 learning.py:512] global step 8377: loss = 0.0257 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8378: loss = 0.0323 (0.176 sec/step)\n",
            "I0213 16:57:30.390387 139806407255936 learning.py:512] global step 8378: loss = 0.0323 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8379: loss = 0.0198 (0.178 sec/step)\n",
            "I0213 16:57:30.569854 139806407255936 learning.py:512] global step 8379: loss = 0.0198 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8380: loss = 0.0369 (0.156 sec/step)\n",
            "I0213 16:57:30.727090 139806407255936 learning.py:512] global step 8380: loss = 0.0369 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8381: loss = 0.0195 (0.176 sec/step)\n",
            "I0213 16:57:30.904353 139806407255936 learning.py:512] global step 8381: loss = 0.0195 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8382: loss = 0.0130 (0.167 sec/step)\n",
            "I0213 16:57:31.072787 139806407255936 learning.py:512] global step 8382: loss = 0.0130 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8383: loss = 0.0263 (0.147 sec/step)\n",
            "I0213 16:57:31.221155 139806407255936 learning.py:512] global step 8383: loss = 0.0263 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8384: loss = 0.0292 (0.167 sec/step)\n",
            "I0213 16:57:31.389660 139806407255936 learning.py:512] global step 8384: loss = 0.0292 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8385: loss = 0.0154 (0.188 sec/step)\n",
            "I0213 16:57:31.579235 139806407255936 learning.py:512] global step 8385: loss = 0.0154 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8386: loss = 0.0254 (0.164 sec/step)\n",
            "I0213 16:57:31.744481 139806407255936 learning.py:512] global step 8386: loss = 0.0254 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8387: loss = 0.0374 (0.170 sec/step)\n",
            "I0213 16:57:31.915776 139806407255936 learning.py:512] global step 8387: loss = 0.0374 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8388: loss = 0.0232 (0.175 sec/step)\n",
            "I0213 16:57:32.092561 139806407255936 learning.py:512] global step 8388: loss = 0.0232 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8389: loss = 0.0134 (0.171 sec/step)\n",
            "I0213 16:57:32.264835 139806407255936 learning.py:512] global step 8389: loss = 0.0134 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8390: loss = 0.0164 (0.179 sec/step)\n",
            "I0213 16:57:32.445110 139806407255936 learning.py:512] global step 8390: loss = 0.0164 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8391: loss = 0.0285 (0.158 sec/step)\n",
            "I0213 16:57:32.604912 139806407255936 learning.py:512] global step 8391: loss = 0.0285 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8392: loss = 0.0209 (0.175 sec/step)\n",
            "I0213 16:57:32.780831 139806407255936 learning.py:512] global step 8392: loss = 0.0209 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8393: loss = 0.0357 (0.163 sec/step)\n",
            "I0213 16:57:32.945089 139806407255936 learning.py:512] global step 8393: loss = 0.0357 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8394: loss = 0.0187 (0.172 sec/step)\n",
            "I0213 16:57:33.118372 139806407255936 learning.py:512] global step 8394: loss = 0.0187 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8395: loss = 0.0296 (0.156 sec/step)\n",
            "I0213 16:57:33.275829 139806407255936 learning.py:512] global step 8395: loss = 0.0296 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8396: loss = 0.0116 (0.161 sec/step)\n",
            "I0213 16:57:33.438499 139806407255936 learning.py:512] global step 8396: loss = 0.0116 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8397: loss = 0.0307 (0.171 sec/step)\n",
            "I0213 16:57:33.610676 139806407255936 learning.py:512] global step 8397: loss = 0.0307 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8398: loss = 0.0132 (0.166 sec/step)\n",
            "I0213 16:57:33.778351 139806407255936 learning.py:512] global step 8398: loss = 0.0132 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8399: loss = 0.0745 (0.169 sec/step)\n",
            "I0213 16:57:33.948779 139806407255936 learning.py:512] global step 8399: loss = 0.0745 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8400: loss = 0.0219 (0.175 sec/step)\n",
            "I0213 16:57:34.125129 139806407255936 learning.py:512] global step 8400: loss = 0.0219 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8401: loss = 0.0372 (0.171 sec/step)\n",
            "I0213 16:57:34.297868 139806407255936 learning.py:512] global step 8401: loss = 0.0372 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8402: loss = 0.0105 (0.168 sec/step)\n",
            "I0213 16:57:34.467432 139806407255936 learning.py:512] global step 8402: loss = 0.0105 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8403: loss = 0.0201 (0.158 sec/step)\n",
            "I0213 16:57:34.626990 139806407255936 learning.py:512] global step 8403: loss = 0.0201 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8404: loss = 0.0124 (0.164 sec/step)\n",
            "I0213 16:57:34.792238 139806407255936 learning.py:512] global step 8404: loss = 0.0124 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8405: loss = 0.0420 (0.165 sec/step)\n",
            "I0213 16:57:34.959111 139806407255936 learning.py:512] global step 8405: loss = 0.0420 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8406: loss = 0.0214 (0.170 sec/step)\n",
            "I0213 16:57:35.130382 139806407255936 learning.py:512] global step 8406: loss = 0.0214 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8407: loss = 0.0232 (0.183 sec/step)\n",
            "I0213 16:57:35.314363 139806407255936 learning.py:512] global step 8407: loss = 0.0232 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8408: loss = 0.0250 (0.167 sec/step)\n",
            "I0213 16:57:35.482771 139806407255936 learning.py:512] global step 8408: loss = 0.0250 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8409: loss = 0.0230 (0.179 sec/step)\n",
            "I0213 16:57:35.663600 139806407255936 learning.py:512] global step 8409: loss = 0.0230 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8410: loss = 0.0171 (0.168 sec/step)\n",
            "I0213 16:57:35.833041 139806407255936 learning.py:512] global step 8410: loss = 0.0171 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8411: loss = 0.0920 (0.159 sec/step)\n",
            "I0213 16:57:35.993763 139806407255936 learning.py:512] global step 8411: loss = 0.0920 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8412: loss = 0.0221 (0.160 sec/step)\n",
            "I0213 16:57:36.155602 139806407255936 learning.py:512] global step 8412: loss = 0.0221 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8413: loss = 0.0348 (0.157 sec/step)\n",
            "I0213 16:57:36.313919 139806407255936 learning.py:512] global step 8413: loss = 0.0348 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8414: loss = 0.0493 (0.171 sec/step)\n",
            "I0213 16:57:36.486329 139806407255936 learning.py:512] global step 8414: loss = 0.0493 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8415: loss = 0.0149 (0.173 sec/step)\n",
            "I0213 16:57:36.661255 139806407255936 learning.py:512] global step 8415: loss = 0.0149 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8416: loss = 0.0610 (0.175 sec/step)\n",
            "I0213 16:57:36.837386 139806407255936 learning.py:512] global step 8416: loss = 0.0610 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8417: loss = 0.0171 (0.174 sec/step)\n",
            "I0213 16:57:37.012485 139806407255936 learning.py:512] global step 8417: loss = 0.0171 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8418: loss = 0.0143 (0.175 sec/step)\n",
            "I0213 16:57:37.188371 139806407255936 learning.py:512] global step 8418: loss = 0.0143 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8419: loss = 0.0339 (0.167 sec/step)\n",
            "I0213 16:57:37.356707 139806407255936 learning.py:512] global step 8419: loss = 0.0339 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8420: loss = 0.0309 (0.174 sec/step)\n",
            "I0213 16:57:37.532861 139806407255936 learning.py:512] global step 8420: loss = 0.0309 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8421: loss = 0.0131 (0.164 sec/step)\n",
            "I0213 16:57:37.697967 139806407255936 learning.py:512] global step 8421: loss = 0.0131 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8422: loss = 0.0095 (0.161 sec/step)\n",
            "I0213 16:57:37.860134 139806407255936 learning.py:512] global step 8422: loss = 0.0095 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8423: loss = 0.0208 (0.161 sec/step)\n",
            "I0213 16:57:38.022587 139806407255936 learning.py:512] global step 8423: loss = 0.0208 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8424: loss = 0.0789 (0.161 sec/step)\n",
            "I0213 16:57:38.185322 139806407255936 learning.py:512] global step 8424: loss = 0.0789 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8425: loss = 0.0219 (0.175 sec/step)\n",
            "I0213 16:57:38.361426 139806407255936 learning.py:512] global step 8425: loss = 0.0219 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8426: loss = 0.0141 (0.176 sec/step)\n",
            "I0213 16:57:38.539755 139806407255936 learning.py:512] global step 8426: loss = 0.0141 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8427: loss = 0.0235 (0.167 sec/step)\n",
            "I0213 16:57:38.708220 139806407255936 learning.py:512] global step 8427: loss = 0.0235 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8428: loss = 0.0158 (0.175 sec/step)\n",
            "I0213 16:57:38.884455 139806407255936 learning.py:512] global step 8428: loss = 0.0158 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8429: loss = 0.0092 (0.190 sec/step)\n",
            "I0213 16:57:39.076054 139806407255936 learning.py:512] global step 8429: loss = 0.0092 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8430: loss = 0.0318 (0.161 sec/step)\n",
            "I0213 16:57:39.238694 139806407255936 learning.py:512] global step 8430: loss = 0.0318 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8431: loss = 0.0144 (0.176 sec/step)\n",
            "I0213 16:57:39.415609 139806407255936 learning.py:512] global step 8431: loss = 0.0144 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8432: loss = 0.0363 (0.177 sec/step)\n",
            "I0213 16:57:39.594327 139806407255936 learning.py:512] global step 8432: loss = 0.0363 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8433: loss = 0.0611 (0.167 sec/step)\n",
            "I0213 16:57:39.762909 139806407255936 learning.py:512] global step 8433: loss = 0.0611 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8434: loss = 0.0300 (0.169 sec/step)\n",
            "I0213 16:57:39.932996 139806407255936 learning.py:512] global step 8434: loss = 0.0300 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8435: loss = 0.0135 (0.164 sec/step)\n",
            "I0213 16:57:40.098058 139806407255936 learning.py:512] global step 8435: loss = 0.0135 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8436: loss = 0.0165 (0.181 sec/step)\n",
            "I0213 16:57:40.280287 139806407255936 learning.py:512] global step 8436: loss = 0.0165 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8437: loss = 0.0250 (0.169 sec/step)\n",
            "I0213 16:57:40.450644 139806407255936 learning.py:512] global step 8437: loss = 0.0250 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8438: loss = 0.0229 (0.161 sec/step)\n",
            "I0213 16:57:40.613140 139806407255936 learning.py:512] global step 8438: loss = 0.0229 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8439: loss = 0.0115 (0.175 sec/step)\n",
            "I0213 16:57:40.789997 139806407255936 learning.py:512] global step 8439: loss = 0.0115 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8440: loss = 0.0314 (0.165 sec/step)\n",
            "I0213 16:57:40.956326 139806407255936 learning.py:512] global step 8440: loss = 0.0314 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8441: loss = 0.0150 (0.175 sec/step)\n",
            "I0213 16:57:41.132776 139806407255936 learning.py:512] global step 8441: loss = 0.0150 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8442: loss = 0.0139 (0.168 sec/step)\n",
            "I0213 16:57:41.302290 139806407255936 learning.py:512] global step 8442: loss = 0.0139 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8443: loss = 0.0131 (0.170 sec/step)\n",
            "I0213 16:57:41.474036 139806407255936 learning.py:512] global step 8443: loss = 0.0131 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8444: loss = 0.1055 (0.159 sec/step)\n",
            "I0213 16:57:41.634624 139806407255936 learning.py:512] global step 8444: loss = 0.1055 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8445: loss = 0.0216 (0.185 sec/step)\n",
            "I0213 16:57:41.820555 139806407255936 learning.py:512] global step 8445: loss = 0.0216 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8446: loss = 0.0298 (0.179 sec/step)\n",
            "I0213 16:57:42.001490 139806407255936 learning.py:512] global step 8446: loss = 0.0298 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8447: loss = 0.0181 (0.164 sec/step)\n",
            "I0213 16:57:42.167135 139806407255936 learning.py:512] global step 8447: loss = 0.0181 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8448: loss = 0.0643 (0.167 sec/step)\n",
            "I0213 16:57:42.335654 139806407255936 learning.py:512] global step 8448: loss = 0.0643 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8449: loss = 0.0183 (0.178 sec/step)\n",
            "I0213 16:57:42.514603 139806407255936 learning.py:512] global step 8449: loss = 0.0183 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8450: loss = 0.0314 (0.162 sec/step)\n",
            "I0213 16:57:42.678170 139806407255936 learning.py:512] global step 8450: loss = 0.0314 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8451: loss = 0.0345 (0.179 sec/step)\n",
            "I0213 16:57:42.858257 139806407255936 learning.py:512] global step 8451: loss = 0.0345 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8452: loss = 0.0491 (0.175 sec/step)\n",
            "I0213 16:57:43.034883 139806407255936 learning.py:512] global step 8452: loss = 0.0491 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8453: loss = 0.0170 (0.153 sec/step)\n",
            "I0213 16:57:43.189145 139806407255936 learning.py:512] global step 8453: loss = 0.0170 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8454: loss = 0.0316 (0.183 sec/step)\n",
            "I0213 16:57:43.373600 139806407255936 learning.py:512] global step 8454: loss = 0.0316 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8455: loss = 0.0713 (0.160 sec/step)\n",
            "I0213 16:57:43.534963 139806407255936 learning.py:512] global step 8455: loss = 0.0713 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8456: loss = 0.0263 (0.177 sec/step)\n",
            "I0213 16:57:43.713778 139806407255936 learning.py:512] global step 8456: loss = 0.0263 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8457: loss = 0.0119 (0.170 sec/step)\n",
            "I0213 16:57:43.885595 139806407255936 learning.py:512] global step 8457: loss = 0.0119 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8458: loss = 0.0231 (0.171 sec/step)\n",
            "I0213 16:57:44.057615 139806407255936 learning.py:512] global step 8458: loss = 0.0231 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8459: loss = 0.0145 (0.162 sec/step)\n",
            "I0213 16:57:44.220858 139806407255936 learning.py:512] global step 8459: loss = 0.0145 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8460: loss = 0.0297 (0.174 sec/step)\n",
            "I0213 16:57:44.396021 139806407255936 learning.py:512] global step 8460: loss = 0.0297 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8461: loss = 0.0209 (0.161 sec/step)\n",
            "I0213 16:57:44.559019 139806407255936 learning.py:512] global step 8461: loss = 0.0209 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8462: loss = 0.0195 (0.172 sec/step)\n",
            "I0213 16:57:44.733057 139806407255936 learning.py:512] global step 8462: loss = 0.0195 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8463: loss = 0.0229 (0.159 sec/step)\n",
            "I0213 16:57:44.893320 139806407255936 learning.py:512] global step 8463: loss = 0.0229 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8464: loss = 0.0174 (0.177 sec/step)\n",
            "I0213 16:57:45.071397 139806407255936 learning.py:512] global step 8464: loss = 0.0174 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8465: loss = 0.0123 (0.164 sec/step)\n",
            "I0213 16:57:45.236788 139806407255936 learning.py:512] global step 8465: loss = 0.0123 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8466: loss = 0.0122 (0.175 sec/step)\n",
            "I0213 16:57:45.412842 139806407255936 learning.py:512] global step 8466: loss = 0.0122 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8467: loss = 0.0511 (0.163 sec/step)\n",
            "I0213 16:57:45.577360 139806407255936 learning.py:512] global step 8467: loss = 0.0511 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8468: loss = 0.0253 (0.167 sec/step)\n",
            "I0213 16:57:45.745679 139806407255936 learning.py:512] global step 8468: loss = 0.0253 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8469: loss = 0.0356 (0.158 sec/step)\n",
            "I0213 16:57:45.904713 139806407255936 learning.py:512] global step 8469: loss = 0.0356 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8470: loss = 0.0095 (0.172 sec/step)\n",
            "I0213 16:57:46.078645 139806407255936 learning.py:512] global step 8470: loss = 0.0095 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8471: loss = 0.0189 (0.179 sec/step)\n",
            "I0213 16:57:46.259702 139806407255936 learning.py:512] global step 8471: loss = 0.0189 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8472: loss = 0.0090 (0.152 sec/step)\n",
            "I0213 16:57:46.415885 139806407255936 learning.py:512] global step 8472: loss = 0.0090 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8473: loss = 0.0230 (0.177 sec/step)\n",
            "I0213 16:57:46.594055 139806407255936 learning.py:512] global step 8473: loss = 0.0230 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8474: loss = 0.0387 (0.159 sec/step)\n",
            "I0213 16:57:46.754746 139806407255936 learning.py:512] global step 8474: loss = 0.0387 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8475: loss = 0.0145 (0.193 sec/step)\n",
            "I0213 16:57:46.948904 139806407255936 learning.py:512] global step 8475: loss = 0.0145 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8476: loss = 0.0283 (0.175 sec/step)\n",
            "I0213 16:57:47.125171 139806407255936 learning.py:512] global step 8476: loss = 0.0283 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8477: loss = 0.0720 (0.154 sec/step)\n",
            "I0213 16:57:47.280155 139806407255936 learning.py:512] global step 8477: loss = 0.0720 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8478: loss = 0.0257 (0.170 sec/step)\n",
            "I0213 16:57:47.451849 139806407255936 learning.py:512] global step 8478: loss = 0.0257 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8479: loss = 0.0201 (0.178 sec/step)\n",
            "I0213 16:57:47.631616 139806407255936 learning.py:512] global step 8479: loss = 0.0201 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8480: loss = 0.0293 (0.164 sec/step)\n",
            "I0213 16:57:47.796733 139806407255936 learning.py:512] global step 8480: loss = 0.0293 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8481: loss = 0.0136 (0.166 sec/step)\n",
            "I0213 16:57:47.963662 139806407255936 learning.py:512] global step 8481: loss = 0.0136 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8482: loss = 0.0598 (0.160 sec/step)\n",
            "I0213 16:57:48.125320 139806407255936 learning.py:512] global step 8482: loss = 0.0598 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8483: loss = 0.0831 (0.174 sec/step)\n",
            "I0213 16:57:48.300553 139806407255936 learning.py:512] global step 8483: loss = 0.0831 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8484: loss = 0.0310 (0.178 sec/step)\n",
            "I0213 16:57:48.480198 139806407255936 learning.py:512] global step 8484: loss = 0.0310 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8485: loss = 0.0135 (0.154 sec/step)\n",
            "I0213 16:57:48.635384 139806407255936 learning.py:512] global step 8485: loss = 0.0135 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8486: loss = 0.0285 (0.168 sec/step)\n",
            "I0213 16:57:48.805149 139806407255936 learning.py:512] global step 8486: loss = 0.0285 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8487: loss = 0.0114 (0.171 sec/step)\n",
            "I0213 16:57:48.977237 139806407255936 learning.py:512] global step 8487: loss = 0.0114 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8488: loss = 0.0195 (0.171 sec/step)\n",
            "I0213 16:57:49.149449 139806407255936 learning.py:512] global step 8488: loss = 0.0195 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8489: loss = 0.0073 (0.187 sec/step)\n",
            "I0213 16:57:49.337639 139806407255936 learning.py:512] global step 8489: loss = 0.0073 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8490: loss = 0.0323 (0.179 sec/step)\n",
            "I0213 16:57:49.518181 139806407255936 learning.py:512] global step 8490: loss = 0.0323 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8491: loss = 0.0905 (0.178 sec/step)\n",
            "I0213 16:57:49.697381 139806407255936 learning.py:512] global step 8491: loss = 0.0905 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8492: loss = 0.0150 (0.158 sec/step)\n",
            "I0213 16:57:49.856680 139806407255936 learning.py:512] global step 8492: loss = 0.0150 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8493: loss = 0.0088 (0.178 sec/step)\n",
            "I0213 16:57:50.036275 139806407255936 learning.py:512] global step 8493: loss = 0.0088 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8494: loss = 0.0491 (0.177 sec/step)\n",
            "I0213 16:57:50.214852 139806407255936 learning.py:512] global step 8494: loss = 0.0491 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8495: loss = 0.0665 (0.165 sec/step)\n",
            "I0213 16:57:50.381139 139806407255936 learning.py:512] global step 8495: loss = 0.0665 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8496: loss = 0.0828 (0.182 sec/step)\n",
            "I0213 16:57:50.564851 139806407255936 learning.py:512] global step 8496: loss = 0.0828 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8497: loss = 0.0349 (0.163 sec/step)\n",
            "I0213 16:57:50.729457 139806407255936 learning.py:512] global step 8497: loss = 0.0349 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8498: loss = 0.0512 (0.160 sec/step)\n",
            "I0213 16:57:50.890798 139806407255936 learning.py:512] global step 8498: loss = 0.0512 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8499: loss = 0.0353 (0.158 sec/step)\n",
            "I0213 16:57:51.049750 139806407255936 learning.py:512] global step 8499: loss = 0.0353 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8500: loss = 0.0168 (0.166 sec/step)\n",
            "I0213 16:57:51.216971 139806407255936 learning.py:512] global step 8500: loss = 0.0168 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8501: loss = 0.0949 (0.187 sec/step)\n",
            "I0213 16:57:51.405256 139806407255936 learning.py:512] global step 8501: loss = 0.0949 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8502: loss = 0.0154 (0.179 sec/step)\n",
            "I0213 16:57:51.585467 139806407255936 learning.py:512] global step 8502: loss = 0.0154 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8503: loss = 0.0361 (0.177 sec/step)\n",
            "I0213 16:57:51.763430 139806407255936 learning.py:512] global step 8503: loss = 0.0361 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8504: loss = 0.0151 (0.157 sec/step)\n",
            "I0213 16:57:51.922248 139806407255936 learning.py:512] global step 8504: loss = 0.0151 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8505: loss = 0.0381 (0.170 sec/step)\n",
            "I0213 16:57:52.093422 139806407255936 learning.py:512] global step 8505: loss = 0.0381 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8506: loss = 0.0149 (0.171 sec/step)\n",
            "I0213 16:57:52.265891 139806407255936 learning.py:512] global step 8506: loss = 0.0149 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8507: loss = 0.0175 (0.159 sec/step)\n",
            "I0213 16:57:52.426269 139806407255936 learning.py:512] global step 8507: loss = 0.0175 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8508: loss = 0.0244 (0.181 sec/step)\n",
            "I0213 16:57:52.608377 139806407255936 learning.py:512] global step 8508: loss = 0.0244 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8509: loss = 0.0157 (0.163 sec/step)\n",
            "I0213 16:57:52.773213 139806407255936 learning.py:512] global step 8509: loss = 0.0157 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8510: loss = 0.0372 (0.178 sec/step)\n",
            "I0213 16:57:52.952144 139806407255936 learning.py:512] global step 8510: loss = 0.0372 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8511: loss = 0.0158 (0.167 sec/step)\n",
            "I0213 16:57:53.121060 139806407255936 learning.py:512] global step 8511: loss = 0.0158 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8512: loss = 0.0250 (0.162 sec/step)\n",
            "I0213 16:57:53.284244 139806407255936 learning.py:512] global step 8512: loss = 0.0250 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8513: loss = 0.0317 (0.179 sec/step)\n",
            "I0213 16:57:53.464994 139806407255936 learning.py:512] global step 8513: loss = 0.0317 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8514: loss = 0.0177 (0.164 sec/step)\n",
            "I0213 16:57:53.630166 139806407255936 learning.py:512] global step 8514: loss = 0.0177 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8515: loss = 0.0951 (0.179 sec/step)\n",
            "I0213 16:57:53.810713 139806407255936 learning.py:512] global step 8515: loss = 0.0951 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8516: loss = 0.0176 (0.167 sec/step)\n",
            "I0213 16:57:53.979202 139806407255936 learning.py:512] global step 8516: loss = 0.0176 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8517: loss = 0.0208 (0.168 sec/step)\n",
            "I0213 16:57:54.148680 139806407255936 learning.py:512] global step 8517: loss = 0.0208 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8518: loss = 0.0129 (0.182 sec/step)\n",
            "I0213 16:57:54.332575 139806407255936 learning.py:512] global step 8518: loss = 0.0129 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8519: loss = 0.0047 (0.182 sec/step)\n",
            "I0213 16:57:54.515805 139806407255936 learning.py:512] global step 8519: loss = 0.0047 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8520: loss = 0.0132 (0.166 sec/step)\n",
            "I0213 16:57:54.682825 139806407255936 learning.py:512] global step 8520: loss = 0.0132 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8521: loss = 0.0222 (0.175 sec/step)\n",
            "I0213 16:57:54.859449 139806407255936 learning.py:512] global step 8521: loss = 0.0222 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8522: loss = 0.0285 (0.169 sec/step)\n",
            "I0213 16:57:55.029963 139806407255936 learning.py:512] global step 8522: loss = 0.0285 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8523: loss = 0.0145 (0.165 sec/step)\n",
            "I0213 16:57:55.196491 139806407255936 learning.py:512] global step 8523: loss = 0.0145 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8524: loss = 0.0117 (0.175 sec/step)\n",
            "I0213 16:57:55.372366 139806407255936 learning.py:512] global step 8524: loss = 0.0117 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8525: loss = 0.0582 (0.172 sec/step)\n",
            "I0213 16:57:55.545558 139806407255936 learning.py:512] global step 8525: loss = 0.0582 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8526: loss = 0.0068 (0.168 sec/step)\n",
            "I0213 16:57:55.715080 139806407255936 learning.py:512] global step 8526: loss = 0.0068 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8527: loss = 0.0394 (0.163 sec/step)\n",
            "I0213 16:57:55.878928 139806407255936 learning.py:512] global step 8527: loss = 0.0394 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8528: loss = 0.0131 (0.184 sec/step)\n",
            "I0213 16:57:56.063766 139806407255936 learning.py:512] global step 8528: loss = 0.0131 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8529: loss = 0.0128 (0.172 sec/step)\n",
            "I0213 16:57:56.236792 139806407255936 learning.py:512] global step 8529: loss = 0.0128 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8530: loss = 0.0189 (0.168 sec/step)\n",
            "I0213 16:57:56.405732 139806407255936 learning.py:512] global step 8530: loss = 0.0189 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8531: loss = 0.0092 (0.160 sec/step)\n",
            "I0213 16:57:56.570946 139806407255936 learning.py:512] global step 8531: loss = 0.0092 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8532: loss = 0.0164 (0.163 sec/step)\n",
            "I0213 16:57:56.735279 139806407255936 learning.py:512] global step 8532: loss = 0.0164 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8533: loss = 0.0212 (0.184 sec/step)\n",
            "I0213 16:57:56.921150 139806407255936 learning.py:512] global step 8533: loss = 0.0212 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8534: loss = 0.0177 (0.164 sec/step)\n",
            "I0213 16:57:57.086557 139806407255936 learning.py:512] global step 8534: loss = 0.0177 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8535: loss = 0.0242 (0.176 sec/step)\n",
            "I0213 16:57:57.263791 139806407255936 learning.py:512] global step 8535: loss = 0.0242 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8536: loss = 0.0116 (0.159 sec/step)\n",
            "I0213 16:57:57.424346 139806407255936 learning.py:512] global step 8536: loss = 0.0116 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8537: loss = 0.0140 (0.169 sec/step)\n",
            "I0213 16:57:57.595157 139806407255936 learning.py:512] global step 8537: loss = 0.0140 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8538: loss = 0.0113 (0.159 sec/step)\n",
            "I0213 16:57:57.755562 139806407255936 learning.py:512] global step 8538: loss = 0.0113 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8539: loss = 0.0331 (0.169 sec/step)\n",
            "I0213 16:57:57.925454 139806407255936 learning.py:512] global step 8539: loss = 0.0331 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8540: loss = 0.0339 (0.183 sec/step)\n",
            "I0213 16:57:58.109470 139806407255936 learning.py:512] global step 8540: loss = 0.0339 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8541: loss = 0.0180 (0.175 sec/step)\n",
            "I0213 16:57:58.285868 139806407255936 learning.py:512] global step 8541: loss = 0.0180 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8542: loss = 0.0220 (0.163 sec/step)\n",
            "I0213 16:57:58.450613 139806407255936 learning.py:512] global step 8542: loss = 0.0220 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8543: loss = 0.0155 (0.187 sec/step)\n",
            "I0213 16:57:58.638528 139806407255936 learning.py:512] global step 8543: loss = 0.0155 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8544: loss = 0.0168 (0.177 sec/step)\n",
            "I0213 16:57:58.816777 139806407255936 learning.py:512] global step 8544: loss = 0.0168 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8545: loss = 0.0298 (0.180 sec/step)\n",
            "I0213 16:57:58.998511 139806407255936 learning.py:512] global step 8545: loss = 0.0298 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8546: loss = 0.0150 (0.161 sec/step)\n",
            "I0213 16:57:59.161386 139806407255936 learning.py:512] global step 8546: loss = 0.0150 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8547: loss = 0.0276 (0.154 sec/step)\n",
            "I0213 16:57:59.316496 139806407255936 learning.py:512] global step 8547: loss = 0.0276 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8548: loss = 0.0218 (0.173 sec/step)\n",
            "I0213 16:57:59.490939 139806407255936 learning.py:512] global step 8548: loss = 0.0218 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8549: loss = 0.0190 (0.171 sec/step)\n",
            "I0213 16:57:59.663525 139806407255936 learning.py:512] global step 8549: loss = 0.0190 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8550: loss = 0.0485 (0.182 sec/step)\n",
            "I0213 16:57:59.846327 139806407255936 learning.py:512] global step 8550: loss = 0.0485 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8551: loss = 0.0799 (0.169 sec/step)\n",
            "I0213 16:58:00.016548 139806407255936 learning.py:512] global step 8551: loss = 0.0799 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8552: loss = 0.0183 (0.156 sec/step)\n",
            "I0213 16:58:00.173728 139806407255936 learning.py:512] global step 8552: loss = 0.0183 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8553: loss = 0.0152 (0.177 sec/step)\n",
            "I0213 16:58:00.352424 139806407255936 learning.py:512] global step 8553: loss = 0.0152 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8554: loss = 0.0351 (0.162 sec/step)\n",
            "I0213 16:58:00.515536 139806407255936 learning.py:512] global step 8554: loss = 0.0351 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8555: loss = 0.0454 (0.167 sec/step)\n",
            "I0213 16:58:00.683953 139806407255936 learning.py:512] global step 8555: loss = 0.0454 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8556: loss = 0.0297 (0.173 sec/step)\n",
            "I0213 16:58:00.858449 139806407255936 learning.py:512] global step 8556: loss = 0.0297 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8557: loss = 0.0210 (0.162 sec/step)\n",
            "I0213 16:58:01.022264 139806407255936 learning.py:512] global step 8557: loss = 0.0210 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8558: loss = 0.0317 (0.166 sec/step)\n",
            "I0213 16:58:01.189737 139806407255936 learning.py:512] global step 8558: loss = 0.0317 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8559: loss = 0.0141 (0.154 sec/step)\n",
            "I0213 16:58:01.345168 139806407255936 learning.py:512] global step 8559: loss = 0.0141 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8560: loss = 0.0421 (0.150 sec/step)\n",
            "I0213 16:58:01.496272 139806407255936 learning.py:512] global step 8560: loss = 0.0421 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8561: loss = 0.0205 (0.170 sec/step)\n",
            "I0213 16:58:01.669430 139806407255936 learning.py:512] global step 8561: loss = 0.0205 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8562: loss = 0.0263 (0.157 sec/step)\n",
            "I0213 16:58:01.828175 139806407255936 learning.py:512] global step 8562: loss = 0.0263 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8563: loss = 0.0201 (0.160 sec/step)\n",
            "I0213 16:58:01.990032 139806407255936 learning.py:512] global step 8563: loss = 0.0201 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8564: loss = 0.0472 (0.176 sec/step)\n",
            "I0213 16:58:02.167250 139806407255936 learning.py:512] global step 8564: loss = 0.0472 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8565: loss = 0.0567 (0.167 sec/step)\n",
            "I0213 16:58:02.335600 139806407255936 learning.py:512] global step 8565: loss = 0.0567 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8566: loss = 0.0135 (0.170 sec/step)\n",
            "I0213 16:58:02.507246 139806407255936 learning.py:512] global step 8566: loss = 0.0135 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8567: loss = 0.0095 (0.173 sec/step)\n",
            "I0213 16:58:02.681768 139806407255936 learning.py:512] global step 8567: loss = 0.0095 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8568: loss = 0.0794 (0.187 sec/step)\n",
            "I0213 16:58:02.869819 139806407255936 learning.py:512] global step 8568: loss = 0.0794 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8569: loss = 0.0258 (0.182 sec/step)\n",
            "I0213 16:58:03.053569 139806407255936 learning.py:512] global step 8569: loss = 0.0258 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8570: loss = 0.0183 (0.167 sec/step)\n",
            "I0213 16:58:03.222291 139806407255936 learning.py:512] global step 8570: loss = 0.0183 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8571: loss = 0.0348 (0.180 sec/step)\n",
            "I0213 16:58:03.404171 139806407255936 learning.py:512] global step 8571: loss = 0.0348 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8572: loss = 0.0152 (0.158 sec/step)\n",
            "I0213 16:58:03.563262 139806407255936 learning.py:512] global step 8572: loss = 0.0152 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8573: loss = 0.0300 (0.174 sec/step)\n",
            "I0213 16:58:03.738509 139806407255936 learning.py:512] global step 8573: loss = 0.0300 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8574: loss = 0.0331 (0.170 sec/step)\n",
            "I0213 16:58:03.909972 139806407255936 learning.py:512] global step 8574: loss = 0.0331 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8575: loss = 0.0151 (0.154 sec/step)\n",
            "I0213 16:58:04.065684 139806407255936 learning.py:512] global step 8575: loss = 0.0151 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8576: loss = 0.0245 (0.165 sec/step)\n",
            "I0213 16:58:04.231722 139806407255936 learning.py:512] global step 8576: loss = 0.0245 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8577: loss = 0.0500 (0.160 sec/step)\n",
            "I0213 16:58:04.393903 139806407255936 learning.py:512] global step 8577: loss = 0.0500 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8578: loss = 0.0187 (0.170 sec/step)\n",
            "I0213 16:58:04.565067 139806407255936 learning.py:512] global step 8578: loss = 0.0187 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8579: loss = 0.0145 (0.172 sec/step)\n",
            "I0213 16:58:04.738792 139806407255936 learning.py:512] global step 8579: loss = 0.0145 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8580: loss = 0.0159 (0.171 sec/step)\n",
            "I0213 16:58:04.910941 139806407255936 learning.py:512] global step 8580: loss = 0.0159 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8581: loss = 0.0216 (0.171 sec/step)\n",
            "I0213 16:58:05.083137 139806407255936 learning.py:512] global step 8581: loss = 0.0216 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8582: loss = 0.0132 (0.176 sec/step)\n",
            "I0213 16:58:05.260986 139806407255936 learning.py:512] global step 8582: loss = 0.0132 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8583: loss = 0.0193 (0.172 sec/step)\n",
            "I0213 16:58:05.434731 139806407255936 learning.py:512] global step 8583: loss = 0.0193 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8584: loss = 0.0261 (0.179 sec/step)\n",
            "I0213 16:58:05.615112 139806407255936 learning.py:512] global step 8584: loss = 0.0261 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8585: loss = 0.0380 (0.168 sec/step)\n",
            "I0213 16:58:05.784374 139806407255936 learning.py:512] global step 8585: loss = 0.0380 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8586: loss = 0.0634 (0.168 sec/step)\n",
            "I0213 16:58:05.953937 139806407255936 learning.py:512] global step 8586: loss = 0.0634 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8587: loss = 0.0560 (0.150 sec/step)\n",
            "I0213 16:58:06.105793 139806407255936 learning.py:512] global step 8587: loss = 0.0560 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8588: loss = 0.0194 (0.164 sec/step)\n",
            "I0213 16:58:06.271608 139806407255936 learning.py:512] global step 8588: loss = 0.0194 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8589: loss = 0.0094 (0.151 sec/step)\n",
            "I0213 16:58:06.423817 139806407255936 learning.py:512] global step 8589: loss = 0.0094 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8590: loss = 0.0333 (0.170 sec/step)\n",
            "I0213 16:58:06.595311 139806407255936 learning.py:512] global step 8590: loss = 0.0333 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8591: loss = 0.0441 (0.187 sec/step)\n",
            "I0213 16:58:06.783328 139806407255936 learning.py:512] global step 8591: loss = 0.0441 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8592: loss = 0.0126 (0.172 sec/step)\n",
            "I0213 16:58:06.956848 139806407255936 learning.py:512] global step 8592: loss = 0.0126 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8593: loss = 0.0299 (0.161 sec/step)\n",
            "I0213 16:58:07.119263 139806407255936 learning.py:512] global step 8593: loss = 0.0299 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8594: loss = 0.0124 (0.162 sec/step)\n",
            "I0213 16:58:07.282393 139806407255936 learning.py:512] global step 8594: loss = 0.0124 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8595: loss = 0.0118 (0.168 sec/step)\n",
            "I0213 16:58:07.451748 139806407255936 learning.py:512] global step 8595: loss = 0.0118 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8596: loss = 0.0239 (0.167 sec/step)\n",
            "I0213 16:58:07.620682 139806407255936 learning.py:512] global step 8596: loss = 0.0239 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8597: loss = 0.0328 (0.169 sec/step)\n",
            "I0213 16:58:07.791430 139806407255936 learning.py:512] global step 8597: loss = 0.0328 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8598: loss = 0.0389 (0.165 sec/step)\n",
            "I0213 16:58:07.957293 139806407255936 learning.py:512] global step 8598: loss = 0.0389 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8599: loss = 0.0365 (0.160 sec/step)\n",
            "I0213 16:58:08.118825 139806407255936 learning.py:512] global step 8599: loss = 0.0365 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8600: loss = 0.0190 (0.179 sec/step)\n",
            "I0213 16:58:08.299044 139806407255936 learning.py:512] global step 8600: loss = 0.0190 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8601: loss = 0.0245 (0.172 sec/step)\n",
            "I0213 16:58:08.472441 139806407255936 learning.py:512] global step 8601: loss = 0.0245 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8602: loss = 0.0196 (0.170 sec/step)\n",
            "I0213 16:58:08.644118 139806407255936 learning.py:512] global step 8602: loss = 0.0196 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8603: loss = 0.0156 (0.168 sec/step)\n",
            "I0213 16:58:08.813434 139806407255936 learning.py:512] global step 8603: loss = 0.0156 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8604: loss = 0.0461 (0.175 sec/step)\n",
            "I0213 16:58:08.989459 139806407255936 learning.py:512] global step 8604: loss = 0.0461 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8605: loss = 0.0204 (0.173 sec/step)\n",
            "I0213 16:58:09.163634 139806407255936 learning.py:512] global step 8605: loss = 0.0204 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8606: loss = 0.0206 (0.165 sec/step)\n",
            "I0213 16:58:09.330402 139806407255936 learning.py:512] global step 8606: loss = 0.0206 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8607: loss = 0.0368 (0.159 sec/step)\n",
            "I0213 16:58:09.490344 139806407255936 learning.py:512] global step 8607: loss = 0.0368 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8608: loss = 0.0164 (0.172 sec/step)\n",
            "I0213 16:58:09.663984 139806407255936 learning.py:512] global step 8608: loss = 0.0164 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8609: loss = 0.0152 (0.159 sec/step)\n",
            "I0213 16:58:09.824633 139806407255936 learning.py:512] global step 8609: loss = 0.0152 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8610: loss = 0.0217 (0.171 sec/step)\n",
            "I0213 16:58:09.996990 139806407255936 learning.py:512] global step 8610: loss = 0.0217 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8611: loss = 0.0297 (0.171 sec/step)\n",
            "I0213 16:58:10.170031 139806407255936 learning.py:512] global step 8611: loss = 0.0297 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8612: loss = 0.0167 (0.155 sec/step)\n",
            "I0213 16:58:10.326550 139806407255936 learning.py:512] global step 8612: loss = 0.0167 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8613: loss = 0.0163 (0.162 sec/step)\n",
            "I0213 16:58:10.489538 139806407255936 learning.py:512] global step 8613: loss = 0.0163 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8614: loss = 0.0301 (0.169 sec/step)\n",
            "I0213 16:58:10.659264 139806407255936 learning.py:512] global step 8614: loss = 0.0301 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8615: loss = 0.0312 (0.158 sec/step)\n",
            "I0213 16:58:10.818190 139806407255936 learning.py:512] global step 8615: loss = 0.0312 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8616: loss = 0.0100 (0.159 sec/step)\n",
            "I0213 16:58:10.978122 139806407255936 learning.py:512] global step 8616: loss = 0.0100 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8617: loss = 0.0228 (0.166 sec/step)\n",
            "I0213 16:58:11.147037 139806407255936 learning.py:512] global step 8617: loss = 0.0228 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8618: loss = 0.0547 (0.160 sec/step)\n",
            "I0213 16:58:11.308692 139806407255936 learning.py:512] global step 8618: loss = 0.0547 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8619: loss = 0.0466 (0.164 sec/step)\n",
            "I0213 16:58:11.473941 139806407255936 learning.py:512] global step 8619: loss = 0.0466 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8620: loss = 0.0535 (0.167 sec/step)\n",
            "I0213 16:58:11.642176 139806407255936 learning.py:512] global step 8620: loss = 0.0535 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8621: loss = 0.0247 (0.171 sec/step)\n",
            "I0213 16:58:11.817452 139806407255936 learning.py:512] global step 8621: loss = 0.0247 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8622: loss = 0.0232 (0.171 sec/step)\n",
            "I0213 16:58:11.992618 139806407255936 learning.py:512] global step 8622: loss = 0.0232 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8623: loss = 0.0116 (0.170 sec/step)\n",
            "I0213 16:58:12.164357 139806407255936 learning.py:512] global step 8623: loss = 0.0116 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8624: loss = 0.0232 (0.165 sec/step)\n",
            "I0213 16:58:12.330574 139806407255936 learning.py:512] global step 8624: loss = 0.0232 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8625: loss = 0.0137 (0.172 sec/step)\n",
            "I0213 16:58:12.503567 139806407255936 learning.py:512] global step 8625: loss = 0.0137 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8626: loss = 0.0124 (0.157 sec/step)\n",
            "I0213 16:58:12.661496 139806407255936 learning.py:512] global step 8626: loss = 0.0124 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8627: loss = 0.0162 (0.179 sec/step)\n",
            "I0213 16:58:12.842241 139806407255936 learning.py:512] global step 8627: loss = 0.0162 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8628: loss = 0.0457 (0.158 sec/step)\n",
            "I0213 16:58:13.004055 139806407255936 learning.py:512] global step 8628: loss = 0.0457 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8629: loss = 0.0198 (0.166 sec/step)\n",
            "I0213 16:58:13.171750 139806407255936 learning.py:512] global step 8629: loss = 0.0198 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8630: loss = 0.0377 (0.160 sec/step)\n",
            "I0213 16:58:13.333529 139806407255936 learning.py:512] global step 8630: loss = 0.0377 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8631: loss = 0.0298 (0.192 sec/step)\n",
            "I0213 16:58:13.526583 139806407255936 learning.py:512] global step 8631: loss = 0.0298 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8632: loss = 0.0125 (0.176 sec/step)\n",
            "I0213 16:58:13.704181 139806407255936 learning.py:512] global step 8632: loss = 0.0125 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8633: loss = 0.0094 (0.173 sec/step)\n",
            "I0213 16:58:13.879084 139806407255936 learning.py:512] global step 8633: loss = 0.0094 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8634: loss = 0.0300 (0.158 sec/step)\n",
            "I0213 16:58:14.038559 139806407255936 learning.py:512] global step 8634: loss = 0.0300 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8635: loss = 0.0191 (0.175 sec/step)\n",
            "I0213 16:58:14.215084 139806407255936 learning.py:512] global step 8635: loss = 0.0191 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8636: loss = 0.0144 (0.179 sec/step)\n",
            "I0213 16:58:14.396150 139806407255936 learning.py:512] global step 8636: loss = 0.0144 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8637: loss = 0.0173 (0.149 sec/step)\n",
            "I0213 16:58:14.546771 139806407255936 learning.py:512] global step 8637: loss = 0.0173 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 8638: loss = 0.0270 (0.180 sec/step)\n",
            "I0213 16:58:14.728284 139806407255936 learning.py:512] global step 8638: loss = 0.0270 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8639: loss = 0.0196 (0.160 sec/step)\n",
            "I0213 16:58:14.890919 139806407255936 learning.py:512] global step 8639: loss = 0.0196 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8640: loss = 0.0198 (0.167 sec/step)\n",
            "I0213 16:58:15.059246 139806407255936 learning.py:512] global step 8640: loss = 0.0198 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8641: loss = 0.0702 (0.176 sec/step)\n",
            "I0213 16:58:15.236997 139806407255936 learning.py:512] global step 8641: loss = 0.0702 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8642: loss = 0.0153 (0.172 sec/step)\n",
            "I0213 16:58:15.409993 139806407255936 learning.py:512] global step 8642: loss = 0.0153 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8643: loss = 0.0565 (0.166 sec/step)\n",
            "I0213 16:58:15.576878 139806407255936 learning.py:512] global step 8643: loss = 0.0565 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8644: loss = 0.0163 (0.163 sec/step)\n",
            "I0213 16:58:15.741400 139806407255936 learning.py:512] global step 8644: loss = 0.0163 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8645: loss = 0.0248 (0.188 sec/step)\n",
            "I0213 16:58:15.930800 139806407255936 learning.py:512] global step 8645: loss = 0.0248 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8646: loss = 0.0253 (0.170 sec/step)\n",
            "I0213 16:58:16.102555 139806407255936 learning.py:512] global step 8646: loss = 0.0253 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8647: loss = 0.0316 (0.166 sec/step)\n",
            "I0213 16:58:16.270352 139806407255936 learning.py:512] global step 8647: loss = 0.0316 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8648: loss = 0.0268 (0.160 sec/step)\n",
            "I0213 16:58:16.432104 139806407255936 learning.py:512] global step 8648: loss = 0.0268 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8649: loss = 0.0154 (0.171 sec/step)\n",
            "I0213 16:58:16.604616 139806407255936 learning.py:512] global step 8649: loss = 0.0154 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8650: loss = 0.0191 (0.167 sec/step)\n",
            "I0213 16:58:16.773048 139806407255936 learning.py:512] global step 8650: loss = 0.0191 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8651: loss = 0.0225 (0.189 sec/step)\n",
            "I0213 16:58:16.963353 139806407255936 learning.py:512] global step 8651: loss = 0.0225 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8652: loss = 0.0283 (0.171 sec/step)\n",
            "I0213 16:58:17.136278 139806407255936 learning.py:512] global step 8652: loss = 0.0283 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8653: loss = 0.0184 (0.182 sec/step)\n",
            "I0213 16:58:17.319456 139806407255936 learning.py:512] global step 8653: loss = 0.0184 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8654: loss = 0.0364 (0.165 sec/step)\n",
            "I0213 16:58:17.486103 139806407255936 learning.py:512] global step 8654: loss = 0.0364 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8655: loss = 0.0167 (0.173 sec/step)\n",
            "I0213 16:58:17.660998 139806407255936 learning.py:512] global step 8655: loss = 0.0167 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8656: loss = 0.0257 (0.169 sec/step)\n",
            "I0213 16:58:17.831451 139806407255936 learning.py:512] global step 8656: loss = 0.0257 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8657: loss = 0.0762 (0.179 sec/step)\n",
            "I0213 16:58:18.012243 139806407255936 learning.py:512] global step 8657: loss = 0.0762 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8658: loss = 0.0412 (0.170 sec/step)\n",
            "I0213 16:58:18.183089 139806407255936 learning.py:512] global step 8658: loss = 0.0412 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8659: loss = 0.0150 (0.171 sec/step)\n",
            "I0213 16:58:18.354924 139806407255936 learning.py:512] global step 8659: loss = 0.0150 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8660: loss = 0.0110 (0.172 sec/step)\n",
            "I0213 16:58:18.528190 139806407255936 learning.py:512] global step 8660: loss = 0.0110 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8661: loss = 0.0435 (0.173 sec/step)\n",
            "I0213 16:58:18.702845 139806407255936 learning.py:512] global step 8661: loss = 0.0435 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8662: loss = 0.0154 (0.169 sec/step)\n",
            "I0213 16:58:18.873786 139806407255936 learning.py:512] global step 8662: loss = 0.0154 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8663: loss = 0.0390 (0.177 sec/step)\n",
            "I0213 16:58:19.052113 139806407255936 learning.py:512] global step 8663: loss = 0.0390 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8664: loss = 0.0394 (0.170 sec/step)\n",
            "I0213 16:58:19.222983 139806407255936 learning.py:512] global step 8664: loss = 0.0394 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8665: loss = 0.0273 (0.161 sec/step)\n",
            "I0213 16:58:19.385678 139806407255936 learning.py:512] global step 8665: loss = 0.0273 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8666: loss = 0.0249 (0.177 sec/step)\n",
            "I0213 16:58:19.563922 139806407255936 learning.py:512] global step 8666: loss = 0.0249 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8667: loss = 0.0582 (0.147 sec/step)\n",
            "I0213 16:58:19.712286 139806407255936 learning.py:512] global step 8667: loss = 0.0582 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8668: loss = 0.0259 (0.163 sec/step)\n",
            "I0213 16:58:19.877835 139806407255936 learning.py:512] global step 8668: loss = 0.0259 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8669: loss = 0.0397 (0.176 sec/step)\n",
            "I0213 16:58:20.055240 139806407255936 learning.py:512] global step 8669: loss = 0.0397 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8670: loss = 0.0212 (0.177 sec/step)\n",
            "I0213 16:58:20.233240 139806407255936 learning.py:512] global step 8670: loss = 0.0212 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8671: loss = 0.0183 (0.185 sec/step)\n",
            "I0213 16:58:20.419193 139806407255936 learning.py:512] global step 8671: loss = 0.0183 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8672: loss = 0.0366 (0.161 sec/step)\n",
            "I0213 16:58:20.582172 139806407255936 learning.py:512] global step 8672: loss = 0.0366 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8673: loss = 0.0290 (0.162 sec/step)\n",
            "I0213 16:58:20.745457 139806407255936 learning.py:512] global step 8673: loss = 0.0290 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8674: loss = 0.0277 (0.155 sec/step)\n",
            "I0213 16:58:20.902324 139806407255936 learning.py:512] global step 8674: loss = 0.0277 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8675: loss = 0.0144 (0.165 sec/step)\n",
            "I0213 16:58:21.069097 139806407255936 learning.py:512] global step 8675: loss = 0.0144 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8676: loss = 0.0328 (0.178 sec/step)\n",
            "I0213 16:58:21.248955 139806407255936 learning.py:512] global step 8676: loss = 0.0328 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8677: loss = 0.0431 (0.175 sec/step)\n",
            "I0213 16:58:21.425031 139806407255936 learning.py:512] global step 8677: loss = 0.0431 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8678: loss = 0.0308 (0.172 sec/step)\n",
            "I0213 16:58:21.598864 139806407255936 learning.py:512] global step 8678: loss = 0.0308 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8679: loss = 0.0436 (0.176 sec/step)\n",
            "I0213 16:58:21.776590 139806407255936 learning.py:512] global step 8679: loss = 0.0436 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8680: loss = 0.0120 (0.165 sec/step)\n",
            "I0213 16:58:21.943031 139806407255936 learning.py:512] global step 8680: loss = 0.0120 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8681: loss = 0.0145 (0.176 sec/step)\n",
            "I0213 16:58:22.120362 139806407255936 learning.py:512] global step 8681: loss = 0.0145 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8682: loss = 0.0275 (0.147 sec/step)\n",
            "I0213 16:58:22.269236 139806407255936 learning.py:512] global step 8682: loss = 0.0275 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8683: loss = 0.0490 (0.166 sec/step)\n",
            "I0213 16:58:22.436723 139806407255936 learning.py:512] global step 8683: loss = 0.0490 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8684: loss = 0.0204 (0.159 sec/step)\n",
            "I0213 16:58:22.597072 139806407255936 learning.py:512] global step 8684: loss = 0.0204 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8685: loss = 0.0638 (0.173 sec/step)\n",
            "I0213 16:58:22.771398 139806407255936 learning.py:512] global step 8685: loss = 0.0638 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8686: loss = 0.0312 (0.179 sec/step)\n",
            "I0213 16:58:22.952238 139806407255936 learning.py:512] global step 8686: loss = 0.0312 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8687: loss = 0.0486 (0.186 sec/step)\n",
            "I0213 16:58:23.139375 139806407255936 learning.py:512] global step 8687: loss = 0.0486 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8688: loss = 0.0149 (0.164 sec/step)\n",
            "I0213 16:58:23.304696 139806407255936 learning.py:512] global step 8688: loss = 0.0149 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8689: loss = 0.0085 (0.166 sec/step)\n",
            "I0213 16:58:23.472050 139806407255936 learning.py:512] global step 8689: loss = 0.0085 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8690: loss = 0.0202 (0.161 sec/step)\n",
            "I0213 16:58:23.634974 139806407255936 learning.py:512] global step 8690: loss = 0.0202 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8691: loss = 0.0137 (0.173 sec/step)\n",
            "I0213 16:58:23.809580 139806407255936 learning.py:512] global step 8691: loss = 0.0137 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8692: loss = 0.0209 (0.179 sec/step)\n",
            "I0213 16:58:23.992036 139806407255936 learning.py:512] global step 8692: loss = 0.0209 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8693: loss = 0.0750 (0.170 sec/step)\n",
            "I0213 16:58:24.166255 139806407255936 learning.py:512] global step 8693: loss = 0.0750 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8694: loss = 0.0270 (0.183 sec/step)\n",
            "I0213 16:58:24.350791 139806407255936 learning.py:512] global step 8694: loss = 0.0270 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8695: loss = 0.0138 (0.165 sec/step)\n",
            "I0213 16:58:24.516943 139806407255936 learning.py:512] global step 8695: loss = 0.0138 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8696: loss = 0.0497 (0.170 sec/step)\n",
            "I0213 16:58:24.688209 139806407255936 learning.py:512] global step 8696: loss = 0.0497 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8697: loss = 0.0460 (0.169 sec/step)\n",
            "I0213 16:58:24.858864 139806407255936 learning.py:512] global step 8697: loss = 0.0460 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8698: loss = 0.0338 (0.165 sec/step)\n",
            "I0213 16:58:25.025718 139806407255936 learning.py:512] global step 8698: loss = 0.0338 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8699: loss = 0.0450 (0.178 sec/step)\n",
            "I0213 16:58:25.204641 139806407255936 learning.py:512] global step 8699: loss = 0.0450 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8700: loss = 0.0745 (0.162 sec/step)\n",
            "I0213 16:58:25.367552 139806407255936 learning.py:512] global step 8700: loss = 0.0745 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8701: loss = 0.0186 (0.175 sec/step)\n",
            "I0213 16:58:25.543489 139806407255936 learning.py:512] global step 8701: loss = 0.0186 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8702: loss = 0.0365 (0.167 sec/step)\n",
            "I0213 16:58:25.711365 139806407255936 learning.py:512] global step 8702: loss = 0.0365 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8703: loss = 0.0397 (0.165 sec/step)\n",
            "I0213 16:58:25.877361 139806407255936 learning.py:512] global step 8703: loss = 0.0397 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8704: loss = 0.0331 (0.167 sec/step)\n",
            "I0213 16:58:26.045924 139806407255936 learning.py:512] global step 8704: loss = 0.0331 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8705: loss = 0.0296 (0.161 sec/step)\n",
            "I0213 16:58:26.208212 139806407255936 learning.py:512] global step 8705: loss = 0.0296 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8706: loss = 0.0355 (0.168 sec/step)\n",
            "I0213 16:58:26.378011 139806407255936 learning.py:512] global step 8706: loss = 0.0355 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8707: loss = 0.0367 (0.163 sec/step)\n",
            "I0213 16:58:26.542584 139806407255936 learning.py:512] global step 8707: loss = 0.0367 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8708: loss = 0.0242 (0.173 sec/step)\n",
            "I0213 16:58:26.716713 139806407255936 learning.py:512] global step 8708: loss = 0.0242 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8709: loss = 0.0425 (0.174 sec/step)\n",
            "I0213 16:58:26.892279 139806407255936 learning.py:512] global step 8709: loss = 0.0425 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8710: loss = 0.0398 (0.152 sec/step)\n",
            "I0213 16:58:27.045247 139806407255936 learning.py:512] global step 8710: loss = 0.0398 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8711: loss = 0.0691 (0.165 sec/step)\n",
            "I0213 16:58:27.211204 139806407255936 learning.py:512] global step 8711: loss = 0.0691 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8712: loss = 0.0286 (0.164 sec/step)\n",
            "I0213 16:58:27.376891 139806407255936 learning.py:512] global step 8712: loss = 0.0286 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8713: loss = 0.0186 (0.163 sec/step)\n",
            "I0213 16:58:27.541307 139806407255936 learning.py:512] global step 8713: loss = 0.0186 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8714: loss = 0.0459 (0.166 sec/step)\n",
            "I0213 16:58:27.708915 139806407255936 learning.py:512] global step 8714: loss = 0.0459 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8715: loss = 0.0273 (0.171 sec/step)\n",
            "I0213 16:58:27.881846 139806407255936 learning.py:512] global step 8715: loss = 0.0273 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8716: loss = 0.0191 (0.188 sec/step)\n",
            "I0213 16:58:28.071507 139806407255936 learning.py:512] global step 8716: loss = 0.0191 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8717: loss = 0.0289 (0.176 sec/step)\n",
            "I0213 16:58:28.249052 139806407255936 learning.py:512] global step 8717: loss = 0.0289 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8718: loss = 0.0347 (0.164 sec/step)\n",
            "I0213 16:58:28.414208 139806407255936 learning.py:512] global step 8718: loss = 0.0347 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8719: loss = 0.0169 (0.180 sec/step)\n",
            "I0213 16:58:28.595627 139806407255936 learning.py:512] global step 8719: loss = 0.0169 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8720: loss = 0.0144 (0.164 sec/step)\n",
            "I0213 16:58:28.760728 139806407255936 learning.py:512] global step 8720: loss = 0.0144 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8721: loss = 0.0223 (0.179 sec/step)\n",
            "I0213 16:58:28.941030 139806407255936 learning.py:512] global step 8721: loss = 0.0223 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8722: loss = 0.0203 (0.175 sec/step)\n",
            "I0213 16:58:29.117225 139806407255936 learning.py:512] global step 8722: loss = 0.0203 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8723: loss = 0.0414 (0.151 sec/step)\n",
            "I0213 16:58:29.269122 139806407255936 learning.py:512] global step 8723: loss = 0.0414 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8724: loss = 0.0140 (0.160 sec/step)\n",
            "I0213 16:58:29.430328 139806407255936 learning.py:512] global step 8724: loss = 0.0140 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8725: loss = 0.0403 (0.162 sec/step)\n",
            "I0213 16:58:29.593511 139806407255936 learning.py:512] global step 8725: loss = 0.0403 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8726: loss = 0.0427 (0.159 sec/step)\n",
            "I0213 16:58:29.753816 139806407255936 learning.py:512] global step 8726: loss = 0.0427 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8727: loss = 0.0546 (0.166 sec/step)\n",
            "I0213 16:58:29.921009 139806407255936 learning.py:512] global step 8727: loss = 0.0546 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8728: loss = 0.0253 (0.176 sec/step)\n",
            "I0213 16:58:30.098237 139806407255936 learning.py:512] global step 8728: loss = 0.0253 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8729: loss = 0.0137 (0.159 sec/step)\n",
            "I0213 16:58:30.258618 139806407255936 learning.py:512] global step 8729: loss = 0.0137 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8730: loss = 0.0236 (0.176 sec/step)\n",
            "I0213 16:58:30.436460 139806407255936 learning.py:512] global step 8730: loss = 0.0236 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8731: loss = 0.0307 (0.160 sec/step)\n",
            "I0213 16:58:30.599727 139806407255936 learning.py:512] global step 8731: loss = 0.0307 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8732: loss = 0.0236 (0.176 sec/step)\n",
            "I0213 16:58:30.776965 139806407255936 learning.py:512] global step 8732: loss = 0.0236 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8733: loss = 0.0304 (0.174 sec/step)\n",
            "I0213 16:58:30.952597 139806407255936 learning.py:512] global step 8733: loss = 0.0304 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8734: loss = 0.0170 (0.159 sec/step)\n",
            "I0213 16:58:31.112774 139806407255936 learning.py:512] global step 8734: loss = 0.0170 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8735: loss = 0.0106 (0.181 sec/step)\n",
            "I0213 16:58:31.295267 139806407255936 learning.py:512] global step 8735: loss = 0.0106 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8736: loss = 0.0188 (0.164 sec/step)\n",
            "I0213 16:58:31.461038 139806407255936 learning.py:512] global step 8736: loss = 0.0188 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8737: loss = 0.0251 (0.170 sec/step)\n",
            "I0213 16:58:31.632018 139806407255936 learning.py:512] global step 8737: loss = 0.0251 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8738: loss = 0.0147 (0.150 sec/step)\n",
            "I0213 16:58:31.783697 139806407255936 learning.py:512] global step 8738: loss = 0.0147 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8739: loss = 0.0122 (0.170 sec/step)\n",
            "I0213 16:58:31.955291 139806407255936 learning.py:512] global step 8739: loss = 0.0122 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8740: loss = 0.0206 (0.170 sec/step)\n",
            "I0213 16:58:32.127012 139806407255936 learning.py:512] global step 8740: loss = 0.0206 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8741: loss = 0.0205 (0.178 sec/step)\n",
            "I0213 16:58:32.306503 139806407255936 learning.py:512] global step 8741: loss = 0.0205 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8742: loss = 0.0332 (0.163 sec/step)\n",
            "I0213 16:58:32.470846 139806407255936 learning.py:512] global step 8742: loss = 0.0332 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8743: loss = 0.0222 (0.171 sec/step)\n",
            "I0213 16:58:32.642889 139806407255936 learning.py:512] global step 8743: loss = 0.0222 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8744: loss = 0.0364 (0.172 sec/step)\n",
            "I0213 16:58:32.816050 139806407255936 learning.py:512] global step 8744: loss = 0.0364 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8745: loss = 0.0203 (0.170 sec/step)\n",
            "I0213 16:58:32.987140 139806407255936 learning.py:512] global step 8745: loss = 0.0203 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8746: loss = 0.0557 (0.156 sec/step)\n",
            "I0213 16:58:33.144859 139806407255936 learning.py:512] global step 8746: loss = 0.0557 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8747: loss = 0.0208 (0.168 sec/step)\n",
            "I0213 16:58:33.313999 139806407255936 learning.py:512] global step 8747: loss = 0.0208 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8748: loss = 0.0168 (0.177 sec/step)\n",
            "I0213 16:58:33.492177 139806407255936 learning.py:512] global step 8748: loss = 0.0168 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8749: loss = 0.0274 (0.176 sec/step)\n",
            "I0213 16:58:33.669539 139806407255936 learning.py:512] global step 8749: loss = 0.0274 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8750: loss = 0.0408 (0.175 sec/step)\n",
            "I0213 16:58:33.845829 139806407255936 learning.py:512] global step 8750: loss = 0.0408 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8751: loss = 0.0182 (0.195 sec/step)\n",
            "I0213 16:58:34.042663 139806407255936 learning.py:512] global step 8751: loss = 0.0182 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8752: loss = 0.0107 (0.171 sec/step)\n",
            "I0213 16:58:34.214958 139806407255936 learning.py:512] global step 8752: loss = 0.0107 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8753: loss = 0.0147 (0.176 sec/step)\n",
            "I0213 16:58:34.392855 139806407255936 learning.py:512] global step 8753: loss = 0.0147 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8754: loss = 0.0425 (0.150 sec/step)\n",
            "I0213 16:58:34.544619 139806407255936 learning.py:512] global step 8754: loss = 0.0425 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8755: loss = 0.0313 (0.173 sec/step)\n",
            "I0213 16:58:34.718937 139806407255936 learning.py:512] global step 8755: loss = 0.0313 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8756: loss = 0.0231 (0.166 sec/step)\n",
            "I0213 16:58:34.885994 139806407255936 learning.py:512] global step 8756: loss = 0.0231 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8757: loss = 0.0336 (0.168 sec/step)\n",
            "I0213 16:58:35.055170 139806407255936 learning.py:512] global step 8757: loss = 0.0336 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8758: loss = 0.1544 (0.165 sec/step)\n",
            "I0213 16:58:35.222080 139806407255936 learning.py:512] global step 8758: loss = 0.1544 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8759: loss = 0.0375 (0.166 sec/step)\n",
            "I0213 16:58:35.390085 139806407255936 learning.py:512] global step 8759: loss = 0.0375 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8760: loss = 0.0224 (0.168 sec/step)\n",
            "I0213 16:58:35.559109 139806407255936 learning.py:512] global step 8760: loss = 0.0224 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8761: loss = 0.0097 (0.164 sec/step)\n",
            "I0213 16:58:35.724121 139806407255936 learning.py:512] global step 8761: loss = 0.0097 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8762: loss = 0.0296 (0.158 sec/step)\n",
            "I0213 16:58:35.884111 139806407255936 learning.py:512] global step 8762: loss = 0.0296 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8763: loss = 0.0259 (0.170 sec/step)\n",
            "I0213 16:58:36.055789 139806407255936 learning.py:512] global step 8763: loss = 0.0259 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8764: loss = 0.0090 (0.171 sec/step)\n",
            "I0213 16:58:36.227997 139806407255936 learning.py:512] global step 8764: loss = 0.0090 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8765: loss = 0.0207 (0.153 sec/step)\n",
            "I0213 16:58:36.382821 139806407255936 learning.py:512] global step 8765: loss = 0.0207 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8766: loss = 0.0120 (0.172 sec/step)\n",
            "I0213 16:58:36.556088 139806407255936 learning.py:512] global step 8766: loss = 0.0120 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8767: loss = 0.0264 (0.181 sec/step)\n",
            "I0213 16:58:36.738481 139806407255936 learning.py:512] global step 8767: loss = 0.0264 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8768: loss = 0.0279 (0.168 sec/step)\n",
            "I0213 16:58:36.907890 139806407255936 learning.py:512] global step 8768: loss = 0.0279 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8769: loss = 0.0104 (0.168 sec/step)\n",
            "I0213 16:58:37.077072 139806407255936 learning.py:512] global step 8769: loss = 0.0104 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8770: loss = 0.0094 (0.175 sec/step)\n",
            "I0213 16:58:37.253345 139806407255936 learning.py:512] global step 8770: loss = 0.0094 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8771: loss = 0.0219 (0.158 sec/step)\n",
            "I0213 16:58:37.413226 139806407255936 learning.py:512] global step 8771: loss = 0.0219 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8772: loss = 0.0226 (0.170 sec/step)\n",
            "I0213 16:58:37.584541 139806407255936 learning.py:512] global step 8772: loss = 0.0226 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8773: loss = 0.0240 (0.177 sec/step)\n",
            "I0213 16:58:37.763233 139806407255936 learning.py:512] global step 8773: loss = 0.0240 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8774: loss = 0.0303 (0.167 sec/step)\n",
            "I0213 16:58:37.931230 139806407255936 learning.py:512] global step 8774: loss = 0.0303 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8775: loss = 0.0196 (0.156 sec/step)\n",
            "I0213 16:58:38.088541 139806407255936 learning.py:512] global step 8775: loss = 0.0196 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8776: loss = 0.0119 (0.174 sec/step)\n",
            "I0213 16:58:38.263833 139806407255936 learning.py:512] global step 8776: loss = 0.0119 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8777: loss = 0.0075 (0.161 sec/step)\n",
            "I0213 16:58:38.426105 139806407255936 learning.py:512] global step 8777: loss = 0.0075 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8778: loss = 0.0095 (0.169 sec/step)\n",
            "I0213 16:58:38.596661 139806407255936 learning.py:512] global step 8778: loss = 0.0095 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8779: loss = 0.0128 (0.160 sec/step)\n",
            "I0213 16:58:38.758212 139806407255936 learning.py:512] global step 8779: loss = 0.0128 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8780: loss = 0.0216 (0.175 sec/step)\n",
            "I0213 16:58:38.934307 139806407255936 learning.py:512] global step 8780: loss = 0.0216 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8781: loss = 0.0166 (0.172 sec/step)\n",
            "I0213 16:58:39.107430 139806407255936 learning.py:512] global step 8781: loss = 0.0166 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8782: loss = 0.0148 (0.187 sec/step)\n",
            "I0213 16:58:39.295986 139806407255936 learning.py:512] global step 8782: loss = 0.0148 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8783: loss = 0.0376 (0.162 sec/step)\n",
            "I0213 16:58:39.459800 139806407255936 learning.py:512] global step 8783: loss = 0.0376 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8784: loss = 0.0257 (0.162 sec/step)\n",
            "I0213 16:58:39.623110 139806407255936 learning.py:512] global step 8784: loss = 0.0257 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8785: loss = 0.0188 (0.164 sec/step)\n",
            "I0213 16:58:39.788156 139806407255936 learning.py:512] global step 8785: loss = 0.0188 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8786: loss = 0.0110 (0.174 sec/step)\n",
            "I0213 16:58:39.963962 139806407255936 learning.py:512] global step 8786: loss = 0.0110 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8787: loss = 0.0615 (0.175 sec/step)\n",
            "I0213 16:58:40.140297 139806407255936 learning.py:512] global step 8787: loss = 0.0615 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8788: loss = 0.0154 (0.166 sec/step)\n",
            "I0213 16:58:40.307292 139806407255936 learning.py:512] global step 8788: loss = 0.0154 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8789: loss = 0.0253 (0.154 sec/step)\n",
            "I0213 16:58:40.462318 139806407255936 learning.py:512] global step 8789: loss = 0.0253 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8790: loss = 0.0247 (0.160 sec/step)\n",
            "I0213 16:58:40.624738 139806407255936 learning.py:512] global step 8790: loss = 0.0247 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8791: loss = 0.0212 (0.168 sec/step)\n",
            "I0213 16:58:40.794429 139806407255936 learning.py:512] global step 8791: loss = 0.0212 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8792: loss = 0.0322 (0.163 sec/step)\n",
            "I0213 16:58:40.958433 139806407255936 learning.py:512] global step 8792: loss = 0.0322 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8793: loss = 0.0205 (0.170 sec/step)\n",
            "I0213 16:58:41.129610 139806407255936 learning.py:512] global step 8793: loss = 0.0205 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8794: loss = 0.0173 (0.172 sec/step)\n",
            "I0213 16:58:41.303173 139806407255936 learning.py:512] global step 8794: loss = 0.0173 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8795: loss = 0.0167 (0.175 sec/step)\n",
            "I0213 16:58:41.479559 139806407255936 learning.py:512] global step 8795: loss = 0.0167 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8796: loss = 0.0644 (0.152 sec/step)\n",
            "I0213 16:58:41.632894 139806407255936 learning.py:512] global step 8796: loss = 0.0644 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8797: loss = 0.0384 (0.175 sec/step)\n",
            "I0213 16:58:41.808993 139806407255936 learning.py:512] global step 8797: loss = 0.0384 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8798: loss = 0.0394 (0.168 sec/step)\n",
            "I0213 16:58:41.978896 139806407255936 learning.py:512] global step 8798: loss = 0.0394 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8799: loss = 0.0197 (0.159 sec/step)\n",
            "I0213 16:58:42.139242 139806407255936 learning.py:512] global step 8799: loss = 0.0197 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8800: loss = 0.0199 (0.161 sec/step)\n",
            "I0213 16:58:42.301982 139806407255936 learning.py:512] global step 8800: loss = 0.0199 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8801: loss = 0.0105 (0.166 sec/step)\n",
            "I0213 16:58:42.469505 139806407255936 learning.py:512] global step 8801: loss = 0.0105 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8802: loss = 0.0247 (0.173 sec/step)\n",
            "I0213 16:58:42.643914 139806407255936 learning.py:512] global step 8802: loss = 0.0247 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8803: loss = 0.0319 (0.168 sec/step)\n",
            "I0213 16:58:42.813583 139806407255936 learning.py:512] global step 8803: loss = 0.0319 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8804: loss = 0.0297 (0.170 sec/step)\n",
            "I0213 16:58:42.984724 139806407255936 learning.py:512] global step 8804: loss = 0.0297 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8805: loss = 0.0139 (0.170 sec/step)\n",
            "I0213 16:58:43.155580 139806407255936 learning.py:512] global step 8805: loss = 0.0139 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8806: loss = 0.0255 (0.174 sec/step)\n",
            "I0213 16:58:43.330504 139806407255936 learning.py:512] global step 8806: loss = 0.0255 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8807: loss = 0.0177 (0.163 sec/step)\n",
            "I0213 16:58:43.494787 139806407255936 learning.py:512] global step 8807: loss = 0.0177 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8808: loss = 0.0231 (0.155 sec/step)\n",
            "I0213 16:58:43.651284 139806407255936 learning.py:512] global step 8808: loss = 0.0231 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8809: loss = 0.0277 (0.177 sec/step)\n",
            "I0213 16:58:43.829515 139806407255936 learning.py:512] global step 8809: loss = 0.0277 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8810: loss = 0.0167 (0.179 sec/step)\n",
            "I0213 16:58:44.009697 139806407255936 learning.py:512] global step 8810: loss = 0.0167 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8811: loss = 0.0126 (0.164 sec/step)\n",
            "I0213 16:58:44.175197 139806407255936 learning.py:512] global step 8811: loss = 0.0126 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8812: loss = 0.0240 (0.159 sec/step)\n",
            "I0213 16:58:44.335222 139806407255936 learning.py:512] global step 8812: loss = 0.0240 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8813: loss = 0.0223 (0.174 sec/step)\n",
            "I0213 16:58:44.510685 139806407255936 learning.py:512] global step 8813: loss = 0.0223 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8814: loss = 0.0267 (0.189 sec/step)\n",
            "I0213 16:58:44.700886 139806407255936 learning.py:512] global step 8814: loss = 0.0267 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8815: loss = 0.0178 (0.170 sec/step)\n",
            "I0213 16:58:44.872071 139806407255936 learning.py:512] global step 8815: loss = 0.0178 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8816: loss = 0.0456 (0.171 sec/step)\n",
            "I0213 16:58:45.044098 139806407255936 learning.py:512] global step 8816: loss = 0.0456 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8817: loss = 0.0437 (0.188 sec/step)\n",
            "I0213 16:58:45.233300 139806407255936 learning.py:512] global step 8817: loss = 0.0437 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8818: loss = 0.0798 (0.179 sec/step)\n",
            "I0213 16:58:45.413985 139806407255936 learning.py:512] global step 8818: loss = 0.0798 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8819: loss = 0.0303 (0.170 sec/step)\n",
            "I0213 16:58:45.585187 139806407255936 learning.py:512] global step 8819: loss = 0.0303 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8820: loss = 0.0505 (0.178 sec/step)\n",
            "I0213 16:58:45.764117 139806407255936 learning.py:512] global step 8820: loss = 0.0505 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8821: loss = 0.0797 (0.182 sec/step)\n",
            "I0213 16:58:45.948249 139806407255936 learning.py:512] global step 8821: loss = 0.0797 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8822: loss = 0.0114 (0.170 sec/step)\n",
            "I0213 16:58:46.120880 139806407255936 learning.py:512] global step 8822: loss = 0.0114 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8823: loss = 0.0430 (0.160 sec/step)\n",
            "I0213 16:58:46.282436 139806407255936 learning.py:512] global step 8823: loss = 0.0430 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8824: loss = 0.0098 (0.171 sec/step)\n",
            "I0213 16:58:46.454566 139806407255936 learning.py:512] global step 8824: loss = 0.0098 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8825: loss = 0.0700 (0.167 sec/step)\n",
            "I0213 16:58:46.623347 139806407255936 learning.py:512] global step 8825: loss = 0.0700 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8826: loss = 0.0468 (0.162 sec/step)\n",
            "I0213 16:58:46.786485 139806407255936 learning.py:512] global step 8826: loss = 0.0468 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8827: loss = 0.0225 (0.185 sec/step)\n",
            "I0213 16:58:46.972384 139806407255936 learning.py:512] global step 8827: loss = 0.0225 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8828: loss = 0.0414 (0.170 sec/step)\n",
            "I0213 16:58:47.143439 139806407255936 learning.py:512] global step 8828: loss = 0.0414 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8829: loss = 0.0693 (0.162 sec/step)\n",
            "I0213 16:58:47.307475 139806407255936 learning.py:512] global step 8829: loss = 0.0693 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8830: loss = 0.0330 (0.178 sec/step)\n",
            "I0213 16:58:47.487105 139806407255936 learning.py:512] global step 8830: loss = 0.0330 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8831: loss = 0.0400 (0.190 sec/step)\n",
            "I0213 16:58:47.680039 139806407255936 learning.py:512] global step 8831: loss = 0.0400 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8832: loss = 0.0544 (0.162 sec/step)\n",
            "I0213 16:58:47.843855 139806407255936 learning.py:512] global step 8832: loss = 0.0544 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8833: loss = 0.0198 (0.165 sec/step)\n",
            "I0213 16:58:48.010879 139806407255936 learning.py:512] global step 8833: loss = 0.0198 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8834: loss = 0.0429 (0.173 sec/step)\n",
            "I0213 16:58:48.184912 139806407255936 learning.py:512] global step 8834: loss = 0.0429 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8835: loss = 0.0139 (0.177 sec/step)\n",
            "I0213 16:58:48.363880 139806407255936 learning.py:512] global step 8835: loss = 0.0139 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8836: loss = 0.0273 (0.194 sec/step)\n",
            "I0213 16:58:48.559301 139806407255936 learning.py:512] global step 8836: loss = 0.0273 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8837: loss = 0.0282 (0.156 sec/step)\n",
            "I0213 16:58:48.716247 139806407255936 learning.py:512] global step 8837: loss = 0.0282 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8838: loss = 0.0289 (0.178 sec/step)\n",
            "I0213 16:58:48.895513 139806407255936 learning.py:512] global step 8838: loss = 0.0289 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8839: loss = 0.0149 (0.169 sec/step)\n",
            "I0213 16:58:49.066394 139806407255936 learning.py:512] global step 8839: loss = 0.0149 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8840: loss = 0.0213 (0.158 sec/step)\n",
            "I0213 16:58:49.225692 139806407255936 learning.py:512] global step 8840: loss = 0.0213 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8841: loss = 0.0207 (0.171 sec/step)\n",
            "I0213 16:58:49.398463 139806407255936 learning.py:512] global step 8841: loss = 0.0207 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8842: loss = 0.0195 (0.172 sec/step)\n",
            "I0213 16:58:49.572215 139806407255936 learning.py:512] global step 8842: loss = 0.0195 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8843: loss = 0.0342 (0.180 sec/step)\n",
            "I0213 16:58:49.754114 139806407255936 learning.py:512] global step 8843: loss = 0.0342 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8844: loss = 0.0969 (0.171 sec/step)\n",
            "I0213 16:58:49.926731 139806407255936 learning.py:512] global step 8844: loss = 0.0969 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8845: loss = 0.0146 (0.175 sec/step)\n",
            "I0213 16:58:50.102598 139806407255936 learning.py:512] global step 8845: loss = 0.0146 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8846: loss = 0.0154 (0.171 sec/step)\n",
            "I0213 16:58:50.275362 139806407255936 learning.py:512] global step 8846: loss = 0.0154 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8847: loss = 0.0161 (0.170 sec/step)\n",
            "I0213 16:58:50.446708 139806407255936 learning.py:512] global step 8847: loss = 0.0161 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8848: loss = 0.0144 (0.168 sec/step)\n",
            "I0213 16:58:50.616282 139806407255936 learning.py:512] global step 8848: loss = 0.0144 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8849: loss = 0.0154 (0.181 sec/step)\n",
            "I0213 16:58:50.798548 139806407255936 learning.py:512] global step 8849: loss = 0.0154 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8850: loss = 0.0212 (0.152 sec/step)\n",
            "I0213 16:58:50.951887 139806407255936 learning.py:512] global step 8850: loss = 0.0212 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8851: loss = 0.0159 (0.162 sec/step)\n",
            "I0213 16:58:51.115275 139806407255936 learning.py:512] global step 8851: loss = 0.0159 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8852: loss = 0.0180 (0.170 sec/step)\n",
            "I0213 16:58:51.286301 139806407255936 learning.py:512] global step 8852: loss = 0.0180 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8853: loss = 0.0163 (0.181 sec/step)\n",
            "I0213 16:58:51.470546 139806407255936 learning.py:512] global step 8853: loss = 0.0163 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8854: loss = 0.0411 (0.168 sec/step)\n",
            "I0213 16:58:51.639760 139806407255936 learning.py:512] global step 8854: loss = 0.0411 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8855: loss = 0.0190 (0.179 sec/step)\n",
            "I0213 16:58:51.819767 139806407255936 learning.py:512] global step 8855: loss = 0.0190 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8856: loss = 0.0348 (0.162 sec/step)\n",
            "I0213 16:58:51.983246 139806407255936 learning.py:512] global step 8856: loss = 0.0348 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8857: loss = 0.0174 (0.174 sec/step)\n",
            "I0213 16:58:52.159041 139806407255936 learning.py:512] global step 8857: loss = 0.0174 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8858: loss = 0.0418 (0.176 sec/step)\n",
            "I0213 16:58:52.336822 139806407255936 learning.py:512] global step 8858: loss = 0.0418 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8859: loss = 0.0495 (0.180 sec/step)\n",
            "I0213 16:58:52.518266 139806407255936 learning.py:512] global step 8859: loss = 0.0495 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8860: loss = 0.0244 (0.153 sec/step)\n",
            "I0213 16:58:52.672369 139806407255936 learning.py:512] global step 8860: loss = 0.0244 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8861: loss = 0.0175 (0.169 sec/step)\n",
            "I0213 16:58:52.842995 139806407255936 learning.py:512] global step 8861: loss = 0.0175 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8862: loss = 0.0364 (0.168 sec/step)\n",
            "I0213 16:58:53.011878 139806407255936 learning.py:512] global step 8862: loss = 0.0364 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8863: loss = 0.0406 (0.171 sec/step)\n",
            "I0213 16:58:53.184357 139806407255936 learning.py:512] global step 8863: loss = 0.0406 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8864: loss = 0.0229 (0.155 sec/step)\n",
            "I0213 16:58:53.341170 139806407255936 learning.py:512] global step 8864: loss = 0.0229 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8865: loss = 0.0292 (0.180 sec/step)\n",
            "I0213 16:58:53.522182 139806407255936 learning.py:512] global step 8865: loss = 0.0292 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8866: loss = 0.0173 (0.181 sec/step)\n",
            "I0213 16:58:53.704607 139806407255936 learning.py:512] global step 8866: loss = 0.0173 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8867: loss = 0.0841 (0.164 sec/step)\n",
            "I0213 16:58:53.870388 139806407255936 learning.py:512] global step 8867: loss = 0.0841 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8868: loss = 0.0191 (0.156 sec/step)\n",
            "I0213 16:58:54.027474 139806407255936 learning.py:512] global step 8868: loss = 0.0191 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8869: loss = 0.0231 (0.150 sec/step)\n",
            "I0213 16:58:54.178796 139806407255936 learning.py:512] global step 8869: loss = 0.0231 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8870: loss = 0.0239 (0.162 sec/step)\n",
            "I0213 16:58:54.342653 139806407255936 learning.py:512] global step 8870: loss = 0.0239 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8871: loss = 0.0388 (0.176 sec/step)\n",
            "I0213 16:58:54.519522 139806407255936 learning.py:512] global step 8871: loss = 0.0388 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8872: loss = 0.0304 (0.157 sec/step)\n",
            "I0213 16:58:54.677778 139806407255936 learning.py:512] global step 8872: loss = 0.0304 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8873: loss = 0.0313 (0.164 sec/step)\n",
            "I0213 16:58:54.843699 139806407255936 learning.py:512] global step 8873: loss = 0.0313 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8874: loss = 0.0411 (0.161 sec/step)\n",
            "I0213 16:58:55.006321 139806407255936 learning.py:512] global step 8874: loss = 0.0411 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8875: loss = 0.0325 (0.160 sec/step)\n",
            "I0213 16:58:55.167165 139806407255936 learning.py:512] global step 8875: loss = 0.0325 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8876: loss = 0.0166 (0.164 sec/step)\n",
            "I0213 16:58:55.332375 139806407255936 learning.py:512] global step 8876: loss = 0.0166 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8877: loss = 0.0203 (0.170 sec/step)\n",
            "I0213 16:58:55.504279 139806407255936 learning.py:512] global step 8877: loss = 0.0203 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8878: loss = 0.0291 (0.156 sec/step)\n",
            "I0213 16:58:55.661917 139806407255936 learning.py:512] global step 8878: loss = 0.0291 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8879: loss = 0.0181 (0.169 sec/step)\n",
            "I0213 16:58:55.832603 139806407255936 learning.py:512] global step 8879: loss = 0.0181 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8880: loss = 0.0144 (0.170 sec/step)\n",
            "I0213 16:58:56.003765 139806407255936 learning.py:512] global step 8880: loss = 0.0144 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8881: loss = 0.0240 (0.161 sec/step)\n",
            "I0213 16:58:56.165926 139806407255936 learning.py:512] global step 8881: loss = 0.0240 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8882: loss = 0.0093 (0.176 sec/step)\n",
            "I0213 16:58:56.343329 139806407255936 learning.py:512] global step 8882: loss = 0.0093 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8883: loss = 0.0149 (0.188 sec/step)\n",
            "I0213 16:58:56.532379 139806407255936 learning.py:512] global step 8883: loss = 0.0149 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8884: loss = 0.0212 (0.161 sec/step)\n",
            "I0213 16:58:56.694722 139806407255936 learning.py:512] global step 8884: loss = 0.0212 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8885: loss = 0.0464 (0.176 sec/step)\n",
            "I0213 16:58:56.872495 139806407255936 learning.py:512] global step 8885: loss = 0.0464 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8886: loss = 0.0223 (0.164 sec/step)\n",
            "I0213 16:58:57.038216 139806407255936 learning.py:512] global step 8886: loss = 0.0223 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8887: loss = 0.0335 (0.166 sec/step)\n",
            "I0213 16:58:57.205507 139806407255936 learning.py:512] global step 8887: loss = 0.0335 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8888: loss = 0.0371 (0.155 sec/step)\n",
            "I0213 16:58:57.361794 139806407255936 learning.py:512] global step 8888: loss = 0.0371 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8889: loss = 0.0270 (0.182 sec/step)\n",
            "I0213 16:58:57.545510 139806407255936 learning.py:512] global step 8889: loss = 0.0270 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8890: loss = 0.0397 (0.168 sec/step)\n",
            "I0213 16:58:57.714831 139806407255936 learning.py:512] global step 8890: loss = 0.0397 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8891: loss = 0.0267 (0.167 sec/step)\n",
            "I0213 16:58:57.883009 139806407255936 learning.py:512] global step 8891: loss = 0.0267 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8892: loss = 0.0215 (0.162 sec/step)\n",
            "I0213 16:58:58.046178 139806407255936 learning.py:512] global step 8892: loss = 0.0215 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8893: loss = 0.0172 (0.159 sec/step)\n",
            "I0213 16:58:58.207175 139806407255936 learning.py:512] global step 8893: loss = 0.0172 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8894: loss = 0.0297 (0.175 sec/step)\n",
            "I0213 16:58:58.383251 139806407255936 learning.py:512] global step 8894: loss = 0.0297 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8895: loss = 0.0162 (0.180 sec/step)\n",
            "I0213 16:58:58.565085 139806407255936 learning.py:512] global step 8895: loss = 0.0162 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8896: loss = 0.0677 (0.177 sec/step)\n",
            "I0213 16:58:58.743400 139806407255936 learning.py:512] global step 8896: loss = 0.0677 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8897: loss = 0.0287 (0.176 sec/step)\n",
            "I0213 16:58:58.920439 139806407255936 learning.py:512] global step 8897: loss = 0.0287 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8898: loss = 0.0523 (0.174 sec/step)\n",
            "I0213 16:58:59.095628 139806407255936 learning.py:512] global step 8898: loss = 0.0523 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8899: loss = 0.0473 (0.171 sec/step)\n",
            "I0213 16:58:59.267957 139806407255936 learning.py:512] global step 8899: loss = 0.0473 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8900: loss = 0.0483 (0.169 sec/step)\n",
            "I0213 16:58:59.438309 139806407255936 learning.py:512] global step 8900: loss = 0.0483 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8901: loss = 0.0265 (0.169 sec/step)\n",
            "I0213 16:58:59.608437 139806407255936 learning.py:512] global step 8901: loss = 0.0265 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8902: loss = 0.0192 (0.170 sec/step)\n",
            "I0213 16:58:59.779647 139806407255936 learning.py:512] global step 8902: loss = 0.0192 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8903: loss = 0.0124 (0.168 sec/step)\n",
            "I0213 16:58:59.948468 139806407255936 learning.py:512] global step 8903: loss = 0.0124 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8904: loss = 0.0384 (0.178 sec/step)\n",
            "I0213 16:59:00.127556 139806407255936 learning.py:512] global step 8904: loss = 0.0384 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8905: loss = 0.0251 (0.165 sec/step)\n",
            "I0213 16:59:00.293615 139806407255936 learning.py:512] global step 8905: loss = 0.0251 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8906: loss = 0.0235 (0.165 sec/step)\n",
            "I0213 16:59:00.460129 139806407255936 learning.py:512] global step 8906: loss = 0.0235 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8907: loss = 0.0340 (0.171 sec/step)\n",
            "I0213 16:59:00.633265 139806407255936 learning.py:512] global step 8907: loss = 0.0340 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8908: loss = 0.0161 (0.180 sec/step)\n",
            "I0213 16:59:00.814035 139806407255936 learning.py:512] global step 8908: loss = 0.0161 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8909: loss = 0.0323 (0.163 sec/step)\n",
            "I0213 16:59:00.978761 139806407255936 learning.py:512] global step 8909: loss = 0.0323 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8910: loss = 0.0415 (0.171 sec/step)\n",
            "I0213 16:59:01.150709 139806407255936 learning.py:512] global step 8910: loss = 0.0415 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8911: loss = 0.0287 (0.161 sec/step)\n",
            "I0213 16:59:01.313126 139806407255936 learning.py:512] global step 8911: loss = 0.0287 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8912: loss = 0.0660 (0.170 sec/step)\n",
            "I0213 16:59:01.484269 139806407255936 learning.py:512] global step 8912: loss = 0.0660 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8913: loss = 0.0217 (0.179 sec/step)\n",
            "I0213 16:59:01.664178 139806407255936 learning.py:512] global step 8913: loss = 0.0217 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8914: loss = 0.0213 (0.169 sec/step)\n",
            "I0213 16:59:01.834981 139806407255936 learning.py:512] global step 8914: loss = 0.0213 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8915: loss = 0.0198 (0.172 sec/step)\n",
            "I0213 16:59:02.008459 139806407255936 learning.py:512] global step 8915: loss = 0.0198 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8916: loss = 0.0447 (0.170 sec/step)\n",
            "I0213 16:59:02.180139 139806407255936 learning.py:512] global step 8916: loss = 0.0447 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8917: loss = 0.0284 (0.177 sec/step)\n",
            "I0213 16:59:02.358483 139806407255936 learning.py:512] global step 8917: loss = 0.0284 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8918: loss = 0.0060 (0.183 sec/step)\n",
            "I0213 16:59:02.542635 139806407255936 learning.py:512] global step 8918: loss = 0.0060 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8919: loss = 0.0485 (0.165 sec/step)\n",
            "I0213 16:59:02.709131 139806407255936 learning.py:512] global step 8919: loss = 0.0485 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8920: loss = 0.0985 (0.194 sec/step)\n",
            "I0213 16:59:02.904977 139806407255936 learning.py:512] global step 8920: loss = 0.0985 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8921: loss = 0.0209 (0.152 sec/step)\n",
            "I0213 16:59:03.058133 139806407255936 learning.py:512] global step 8921: loss = 0.0209 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8922: loss = 0.0213 (0.158 sec/step)\n",
            "I0213 16:59:03.217452 139806407255936 learning.py:512] global step 8922: loss = 0.0213 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8923: loss = 0.0281 (0.172 sec/step)\n",
            "I0213 16:59:03.390698 139806407255936 learning.py:512] global step 8923: loss = 0.0281 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8924: loss = 0.0446 (0.179 sec/step)\n",
            "I0213 16:59:03.570732 139806407255936 learning.py:512] global step 8924: loss = 0.0446 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8925: loss = 0.0170 (0.169 sec/step)\n",
            "I0213 16:59:03.741580 139806407255936 learning.py:512] global step 8925: loss = 0.0170 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8926: loss = 0.0343 (0.167 sec/step)\n",
            "I0213 16:59:03.909482 139806407255936 learning.py:512] global step 8926: loss = 0.0343 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8927: loss = 0.0364 (0.182 sec/step)\n",
            "I0213 16:59:04.092649 139806407255936 learning.py:512] global step 8927: loss = 0.0364 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8928: loss = 0.0327 (0.169 sec/step)\n",
            "I0213 16:59:04.263165 139806407255936 learning.py:512] global step 8928: loss = 0.0327 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8929: loss = 0.0270 (0.174 sec/step)\n",
            "I0213 16:59:04.438422 139806407255936 learning.py:512] global step 8929: loss = 0.0270 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8930: loss = 0.0174 (0.174 sec/step)\n",
            "I0213 16:59:04.613915 139806407255936 learning.py:512] global step 8930: loss = 0.0174 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8931: loss = 0.0149 (0.185 sec/step)\n",
            "I0213 16:59:04.799909 139806407255936 learning.py:512] global step 8931: loss = 0.0149 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8932: loss = 0.0473 (0.165 sec/step)\n",
            "I0213 16:59:04.966023 139806407255936 learning.py:512] global step 8932: loss = 0.0473 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8933: loss = 0.0325 (0.161 sec/step)\n",
            "I0213 16:59:05.128829 139806407255936 learning.py:512] global step 8933: loss = 0.0325 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8934: loss = 0.0235 (0.183 sec/step)\n",
            "I0213 16:59:05.313311 139806407255936 learning.py:512] global step 8934: loss = 0.0235 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8935: loss = 0.0510 (0.172 sec/step)\n",
            "I0213 16:59:05.487017 139806407255936 learning.py:512] global step 8935: loss = 0.0510 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8936: loss = 0.0201 (0.180 sec/step)\n",
            "I0213 16:59:05.668732 139806407255936 learning.py:512] global step 8936: loss = 0.0201 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8937: loss = 0.0157 (0.176 sec/step)\n",
            "I0213 16:59:05.846618 139806407255936 learning.py:512] global step 8937: loss = 0.0157 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8938: loss = 0.0231 (0.167 sec/step)\n",
            "I0213 16:59:06.015321 139806407255936 learning.py:512] global step 8938: loss = 0.0231 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8939: loss = 0.0158 (0.157 sec/step)\n",
            "I0213 16:59:06.173445 139806407255936 learning.py:512] global step 8939: loss = 0.0158 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8940: loss = 0.0240 (0.165 sec/step)\n",
            "I0213 16:59:06.339789 139806407255936 learning.py:512] global step 8940: loss = 0.0240 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8941: loss = 0.0177 (0.167 sec/step)\n",
            "I0213 16:59:06.508595 139806407255936 learning.py:512] global step 8941: loss = 0.0177 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8942: loss = 0.0174 (0.173 sec/step)\n",
            "I0213 16:59:06.682700 139806407255936 learning.py:512] global step 8942: loss = 0.0174 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8943: loss = 0.0253 (0.177 sec/step)\n",
            "I0213 16:59:06.861540 139806407255936 learning.py:512] global step 8943: loss = 0.0253 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8944: loss = 0.0292 (0.172 sec/step)\n",
            "I0213 16:59:07.034539 139806407255936 learning.py:512] global step 8944: loss = 0.0292 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8945: loss = 0.0427 (0.170 sec/step)\n",
            "I0213 16:59:07.205390 139806407255936 learning.py:512] global step 8945: loss = 0.0427 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8946: loss = 0.0331 (0.158 sec/step)\n",
            "I0213 16:59:07.364991 139806407255936 learning.py:512] global step 8946: loss = 0.0331 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8947: loss = 0.0425 (0.165 sec/step)\n",
            "I0213 16:59:07.531360 139806407255936 learning.py:512] global step 8947: loss = 0.0425 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8948: loss = 0.0163 (0.168 sec/step)\n",
            "I0213 16:59:07.701247 139806407255936 learning.py:512] global step 8948: loss = 0.0163 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8949: loss = 0.0247 (0.185 sec/step)\n",
            "I0213 16:59:07.887605 139806407255936 learning.py:512] global step 8949: loss = 0.0247 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8950: loss = 0.0168 (0.165 sec/step)\n",
            "I0213 16:59:08.054355 139806407255936 learning.py:512] global step 8950: loss = 0.0168 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8951: loss = 0.0739 (0.165 sec/step)\n",
            "I0213 16:59:08.220849 139806407255936 learning.py:512] global step 8951: loss = 0.0739 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8952: loss = 0.0138 (0.167 sec/step)\n",
            "I0213 16:59:08.388998 139806407255936 learning.py:512] global step 8952: loss = 0.0138 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8953: loss = 0.0176 (0.179 sec/step)\n",
            "I0213 16:59:08.569082 139806407255936 learning.py:512] global step 8953: loss = 0.0176 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8954: loss = 0.0305 (0.187 sec/step)\n",
            "I0213 16:59:08.757386 139806407255936 learning.py:512] global step 8954: loss = 0.0305 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8955: loss = 0.0146 (0.159 sec/step)\n",
            "I0213 16:59:08.918148 139806407255936 learning.py:512] global step 8955: loss = 0.0146 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8956: loss = 0.0124 (0.171 sec/step)\n",
            "I0213 16:59:09.090239 139806407255936 learning.py:512] global step 8956: loss = 0.0124 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8957: loss = 0.0125 (0.162 sec/step)\n",
            "I0213 16:59:09.253493 139806407255936 learning.py:512] global step 8957: loss = 0.0125 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8958: loss = 0.0118 (0.171 sec/step)\n",
            "I0213 16:59:09.426208 139806407255936 learning.py:512] global step 8958: loss = 0.0118 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8959: loss = 0.0143 (0.171 sec/step)\n",
            "I0213 16:59:09.598529 139806407255936 learning.py:512] global step 8959: loss = 0.0143 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8960: loss = 0.0231 (0.173 sec/step)\n",
            "I0213 16:59:09.772505 139806407255936 learning.py:512] global step 8960: loss = 0.0231 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8961: loss = 0.0108 (0.171 sec/step)\n",
            "I0213 16:59:09.945214 139806407255936 learning.py:512] global step 8961: loss = 0.0108 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8962: loss = 0.0200 (0.167 sec/step)\n",
            "I0213 16:59:10.113460 139806407255936 learning.py:512] global step 8962: loss = 0.0200 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8963: loss = 0.0283 (0.157 sec/step)\n",
            "I0213 16:59:10.272118 139806407255936 learning.py:512] global step 8963: loss = 0.0283 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8964: loss = 0.0222 (0.162 sec/step)\n",
            "I0213 16:59:10.435727 139806407255936 learning.py:512] global step 8964: loss = 0.0222 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8965: loss = 0.0115 (0.160 sec/step)\n",
            "I0213 16:59:10.597372 139806407255936 learning.py:512] global step 8965: loss = 0.0115 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8966: loss = 0.0158 (0.186 sec/step)\n",
            "I0213 16:59:10.784631 139806407255936 learning.py:512] global step 8966: loss = 0.0158 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8967: loss = 0.0287 (0.170 sec/step)\n",
            "I0213 16:59:10.956024 139806407255936 learning.py:512] global step 8967: loss = 0.0287 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8968: loss = 0.0454 (0.170 sec/step)\n",
            "I0213 16:59:11.127531 139806407255936 learning.py:512] global step 8968: loss = 0.0454 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8969: loss = 0.0188 (0.165 sec/step)\n",
            "I0213 16:59:11.293325 139806407255936 learning.py:512] global step 8969: loss = 0.0188 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8970: loss = 0.0142 (0.179 sec/step)\n",
            "I0213 16:59:11.474135 139806407255936 learning.py:512] global step 8970: loss = 0.0142 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8971: loss = 0.0124 (0.174 sec/step)\n",
            "I0213 16:59:11.649712 139806407255936 learning.py:512] global step 8971: loss = 0.0124 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8972: loss = 0.0781 (0.173 sec/step)\n",
            "I0213 16:59:11.823743 139806407255936 learning.py:512] global step 8972: loss = 0.0781 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8973: loss = 0.0648 (0.169 sec/step)\n",
            "I0213 16:59:11.994135 139806407255936 learning.py:512] global step 8973: loss = 0.0648 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8974: loss = 0.0230 (0.171 sec/step)\n",
            "I0213 16:59:12.166278 139806407255936 learning.py:512] global step 8974: loss = 0.0230 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8975: loss = 0.0226 (0.164 sec/step)\n",
            "I0213 16:59:12.332468 139806407255936 learning.py:512] global step 8975: loss = 0.0226 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8976: loss = 0.0368 (0.166 sec/step)\n",
            "I0213 16:59:12.500100 139806407255936 learning.py:512] global step 8976: loss = 0.0368 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8977: loss = 0.0348 (0.167 sec/step)\n",
            "I0213 16:59:12.668123 139806407255936 learning.py:512] global step 8977: loss = 0.0348 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8978: loss = 0.0228 (0.173 sec/step)\n",
            "I0213 16:59:12.842125 139806407255936 learning.py:512] global step 8978: loss = 0.0228 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8979: loss = 0.0301 (0.155 sec/step)\n",
            "I0213 16:59:12.998938 139806407255936 learning.py:512] global step 8979: loss = 0.0301 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8980: loss = 0.0146 (0.163 sec/step)\n",
            "I0213 16:59:13.163423 139806407255936 learning.py:512] global step 8980: loss = 0.0146 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8981: loss = 0.0462 (0.170 sec/step)\n",
            "I0213 16:59:13.335015 139806407255936 learning.py:512] global step 8981: loss = 0.0462 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8982: loss = 0.0172 (0.161 sec/step)\n",
            "I0213 16:59:13.497219 139806407255936 learning.py:512] global step 8982: loss = 0.0172 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8983: loss = 0.0092 (0.166 sec/step)\n",
            "I0213 16:59:13.664884 139806407255936 learning.py:512] global step 8983: loss = 0.0092 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8984: loss = 0.0093 (0.172 sec/step)\n",
            "I0213 16:59:13.838400 139806407255936 learning.py:512] global step 8984: loss = 0.0093 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8985: loss = 0.0258 (0.169 sec/step)\n",
            "I0213 16:59:14.009218 139806407255936 learning.py:512] global step 8985: loss = 0.0258 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8986: loss = 0.0110 (0.163 sec/step)\n",
            "I0213 16:59:14.173982 139806407255936 learning.py:512] global step 8986: loss = 0.0110 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8987: loss = 0.0170 (0.166 sec/step)\n",
            "I0213 16:59:14.341307 139806407255936 learning.py:512] global step 8987: loss = 0.0170 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8988: loss = 0.0103 (0.168 sec/step)\n",
            "I0213 16:59:14.510898 139806407255936 learning.py:512] global step 8988: loss = 0.0103 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8989: loss = 0.0151 (0.176 sec/step)\n",
            "I0213 16:59:14.689082 139806407255936 learning.py:512] global step 8989: loss = 0.0151 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8990: loss = 0.0172 (0.174 sec/step)\n",
            "I0213 16:59:14.864322 139806407255936 learning.py:512] global step 8990: loss = 0.0172 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8991: loss = 0.0652 (0.168 sec/step)\n",
            "I0213 16:59:15.033671 139806407255936 learning.py:512] global step 8991: loss = 0.0652 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8992: loss = 0.0622 (0.166 sec/step)\n",
            "I0213 16:59:15.200499 139806407255936 learning.py:512] global step 8992: loss = 0.0622 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8993: loss = 0.0122 (0.164 sec/step)\n",
            "I0213 16:59:15.365508 139806407255936 learning.py:512] global step 8993: loss = 0.0122 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8994: loss = 0.0227 (0.172 sec/step)\n",
            "I0213 16:59:15.538350 139806407255936 learning.py:512] global step 8994: loss = 0.0227 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8995: loss = 0.0057 (0.172 sec/step)\n",
            "I0213 16:59:15.712245 139806407255936 learning.py:512] global step 8995: loss = 0.0057 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8996: loss = 0.0290 (0.173 sec/step)\n",
            "I0213 16:59:15.886402 139806407255936 learning.py:512] global step 8996: loss = 0.0290 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8997: loss = 0.0244 (0.162 sec/step)\n",
            "I0213 16:59:16.049875 139806407255936 learning.py:512] global step 8997: loss = 0.0244 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8998: loss = 0.0452 (0.179 sec/step)\n",
            "I0213 16:59:16.230882 139806407255936 learning.py:512] global step 8998: loss = 0.0452 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8999: loss = 0.0150 (0.169 sec/step)\n",
            "I0213 16:59:16.401393 139806407255936 learning.py:512] global step 8999: loss = 0.0150 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9000: loss = 0.0131 (0.170 sec/step)\n",
            "I0213 16:59:16.572563 139806407255936 learning.py:512] global step 9000: loss = 0.0131 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9001: loss = 0.0313 (0.159 sec/step)\n",
            "I0213 16:59:16.733109 139806407255936 learning.py:512] global step 9001: loss = 0.0313 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9002: loss = 0.0235 (0.167 sec/step)\n",
            "I0213 16:59:16.901907 139806407255936 learning.py:512] global step 9002: loss = 0.0235 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9003: loss = 0.0320 (0.172 sec/step)\n",
            "I0213 16:59:17.074928 139806407255936 learning.py:512] global step 9003: loss = 0.0320 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9004: loss = 0.0138 (0.162 sec/step)\n",
            "I0213 16:59:17.238088 139806407255936 learning.py:512] global step 9004: loss = 0.0138 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9005: loss = 0.0163 (0.162 sec/step)\n",
            "I0213 16:59:17.401185 139806407255936 learning.py:512] global step 9005: loss = 0.0163 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9006: loss = 0.0125 (0.162 sec/step)\n",
            "I0213 16:59:17.564252 139806407255936 learning.py:512] global step 9006: loss = 0.0125 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9007: loss = 0.0186 (0.166 sec/step)\n",
            "I0213 16:59:17.731637 139806407255936 learning.py:512] global step 9007: loss = 0.0186 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9008: loss = 0.0215 (0.168 sec/step)\n",
            "I0213 16:59:17.900783 139806407255936 learning.py:512] global step 9008: loss = 0.0215 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9009: loss = 0.0234 (0.174 sec/step)\n",
            "I0213 16:59:18.076359 139806407255936 learning.py:512] global step 9009: loss = 0.0234 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9010: loss = 0.0411 (0.167 sec/step)\n",
            "I0213 16:59:18.244654 139806407255936 learning.py:512] global step 9010: loss = 0.0411 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9011: loss = 0.0141 (0.159 sec/step)\n",
            "I0213 16:59:18.404713 139806407255936 learning.py:512] global step 9011: loss = 0.0141 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9012: loss = 0.0575 (0.174 sec/step)\n",
            "I0213 16:59:18.579710 139806407255936 learning.py:512] global step 9012: loss = 0.0575 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9013: loss = 0.0196 (0.171 sec/step)\n",
            "I0213 16:59:18.752018 139806407255936 learning.py:512] global step 9013: loss = 0.0196 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9014: loss = 0.0053 (0.195 sec/step)\n",
            "I0213 16:59:18.949112 139806407255936 learning.py:512] global step 9014: loss = 0.0053 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 9015: loss = 0.0251 (0.161 sec/step)\n",
            "I0213 16:59:19.111744 139806407255936 learning.py:512] global step 9015: loss = 0.0251 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9016: loss = 0.0131 (0.170 sec/step)\n",
            "I0213 16:59:19.283555 139806407255936 learning.py:512] global step 9016: loss = 0.0131 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9017: loss = 0.0174 (0.152 sec/step)\n",
            "I0213 16:59:19.436585 139806407255936 learning.py:512] global step 9017: loss = 0.0174 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9018: loss = 0.0378 (0.163 sec/step)\n",
            "I0213 16:59:19.600686 139806407255936 learning.py:512] global step 9018: loss = 0.0378 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9019: loss = 0.0231 (0.168 sec/step)\n",
            "I0213 16:59:19.769820 139806407255936 learning.py:512] global step 9019: loss = 0.0231 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9020: loss = 0.0126 (0.178 sec/step)\n",
            "I0213 16:59:19.949388 139806407255936 learning.py:512] global step 9020: loss = 0.0126 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9021: loss = 0.0235 (0.152 sec/step)\n",
            "I0213 16:59:20.102625 139806407255936 learning.py:512] global step 9021: loss = 0.0235 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9022: loss = 0.0200 (0.171 sec/step)\n",
            "I0213 16:59:20.274713 139806407255936 learning.py:512] global step 9022: loss = 0.0200 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9023: loss = 0.0255 (0.154 sec/step)\n",
            "I0213 16:59:20.430436 139806407255936 learning.py:512] global step 9023: loss = 0.0255 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9024: loss = 0.0271 (0.167 sec/step)\n",
            "I0213 16:59:20.599076 139806407255936 learning.py:512] global step 9024: loss = 0.0271 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9025: loss = 0.0217 (0.159 sec/step)\n",
            "I0213 16:59:20.759965 139806407255936 learning.py:512] global step 9025: loss = 0.0217 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9026: loss = 0.0275 (0.175 sec/step)\n",
            "I0213 16:59:20.936208 139806407255936 learning.py:512] global step 9026: loss = 0.0275 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9027: loss = 0.0218 (0.307 sec/step)\n",
            "I0213 16:59:21.424720 139806407255936 learning.py:512] global step 9027: loss = 0.0218 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 9028: loss = 0.0563 (0.282 sec/step)\n",
            "I0213 16:59:21.716965 139806407255936 learning.py:512] global step 9028: loss = 0.0563 (0.282 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9028.\n",
            "I0213 16:59:21.776432 139802720151296 supervisor.py:1050] Recording summary at step 9028.\n",
            "INFO:tensorflow:global step 9029: loss = 0.0143 (0.192 sec/step)\n",
            "I0213 16:59:21.920184 139806407255936 learning.py:512] global step 9029: loss = 0.0143 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9030: loss = 0.0164 (0.166 sec/step)\n",
            "I0213 16:59:22.087765 139806407255936 learning.py:512] global step 9030: loss = 0.0164 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9031: loss = 0.1315 (0.159 sec/step)\n",
            "I0213 16:59:22.248136 139806407255936 learning.py:512] global step 9031: loss = 0.1315 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9032: loss = 0.0170 (0.160 sec/step)\n",
            "I0213 16:59:22.409682 139806407255936 learning.py:512] global step 9032: loss = 0.0170 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9033: loss = 0.0349 (0.169 sec/step)\n",
            "I0213 16:59:22.579982 139806407255936 learning.py:512] global step 9033: loss = 0.0349 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9034: loss = 0.0471 (0.172 sec/step)\n",
            "I0213 16:59:22.753085 139806407255936 learning.py:512] global step 9034: loss = 0.0471 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9035: loss = 0.0838 (0.163 sec/step)\n",
            "I0213 16:59:22.917306 139806407255936 learning.py:512] global step 9035: loss = 0.0838 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9036: loss = 0.0275 (0.171 sec/step)\n",
            "I0213 16:59:23.092149 139806407255936 learning.py:512] global step 9036: loss = 0.0275 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9037: loss = 0.0257 (0.162 sec/step)\n",
            "I0213 16:59:23.255769 139806407255936 learning.py:512] global step 9037: loss = 0.0257 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9038: loss = 0.0146 (0.196 sec/step)\n",
            "I0213 16:59:23.452777 139806407255936 learning.py:512] global step 9038: loss = 0.0146 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9039: loss = 0.0563 (0.175 sec/step)\n",
            "I0213 16:59:23.628856 139806407255936 learning.py:512] global step 9039: loss = 0.0563 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9040: loss = 0.0214 (0.166 sec/step)\n",
            "I0213 16:59:23.796293 139806407255936 learning.py:512] global step 9040: loss = 0.0214 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9041: loss = 0.0449 (0.166 sec/step)\n",
            "I0213 16:59:23.963849 139806407255936 learning.py:512] global step 9041: loss = 0.0449 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9042: loss = 0.0747 (0.183 sec/step)\n",
            "I0213 16:59:24.148193 139806407255936 learning.py:512] global step 9042: loss = 0.0747 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9043: loss = 0.0372 (0.161 sec/step)\n",
            "I0213 16:59:24.310669 139806407255936 learning.py:512] global step 9043: loss = 0.0372 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9044: loss = 0.0210 (0.156 sec/step)\n",
            "I0213 16:59:24.468070 139806407255936 learning.py:512] global step 9044: loss = 0.0210 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9045: loss = 0.0831 (0.165 sec/step)\n",
            "I0213 16:59:24.634078 139806407255936 learning.py:512] global step 9045: loss = 0.0831 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9046: loss = 0.0154 (0.159 sec/step)\n",
            "I0213 16:59:24.794391 139806407255936 learning.py:512] global step 9046: loss = 0.0154 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9047: loss = 0.0255 (0.175 sec/step)\n",
            "I0213 16:59:24.972084 139806407255936 learning.py:512] global step 9047: loss = 0.0255 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9048: loss = 0.0252 (0.148 sec/step)\n",
            "I0213 16:59:25.121769 139806407255936 learning.py:512] global step 9048: loss = 0.0252 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9049: loss = 0.0368 (0.162 sec/step)\n",
            "I0213 16:59:25.285331 139806407255936 learning.py:512] global step 9049: loss = 0.0368 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9050: loss = 0.0217 (0.176 sec/step)\n",
            "I0213 16:59:25.462397 139806407255936 learning.py:512] global step 9050: loss = 0.0217 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9051: loss = 0.0215 (0.166 sec/step)\n",
            "I0213 16:59:25.629574 139806407255936 learning.py:512] global step 9051: loss = 0.0215 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9052: loss = 0.0142 (0.177 sec/step)\n",
            "I0213 16:59:25.807535 139806407255936 learning.py:512] global step 9052: loss = 0.0142 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9053: loss = 0.0097 (0.180 sec/step)\n",
            "I0213 16:59:25.988777 139806407255936 learning.py:512] global step 9053: loss = 0.0097 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9054: loss = 0.0204 (0.162 sec/step)\n",
            "I0213 16:59:26.152248 139806407255936 learning.py:512] global step 9054: loss = 0.0204 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9055: loss = 0.0180 (0.168 sec/step)\n",
            "I0213 16:59:26.321892 139806407255936 learning.py:512] global step 9055: loss = 0.0180 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9056: loss = 0.0591 (0.167 sec/step)\n",
            "I0213 16:59:26.490034 139806407255936 learning.py:512] global step 9056: loss = 0.0591 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9057: loss = 0.0659 (0.179 sec/step)\n",
            "I0213 16:59:26.670602 139806407255936 learning.py:512] global step 9057: loss = 0.0659 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9058: loss = 0.0079 (0.167 sec/step)\n",
            "I0213 16:59:26.838904 139806407255936 learning.py:512] global step 9058: loss = 0.0079 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9059: loss = 0.0469 (0.174 sec/step)\n",
            "I0213 16:59:27.014097 139806407255936 learning.py:512] global step 9059: loss = 0.0469 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9060: loss = 0.0086 (0.170 sec/step)\n",
            "I0213 16:59:27.185698 139806407255936 learning.py:512] global step 9060: loss = 0.0086 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9061: loss = 0.0157 (0.186 sec/step)\n",
            "I0213 16:59:27.373117 139806407255936 learning.py:512] global step 9061: loss = 0.0157 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9062: loss = 0.0472 (0.181 sec/step)\n",
            "I0213 16:59:27.555734 139806407255936 learning.py:512] global step 9062: loss = 0.0472 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9063: loss = 0.0075 (0.193 sec/step)\n",
            "I0213 16:59:27.749936 139806407255936 learning.py:512] global step 9063: loss = 0.0075 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9064: loss = 0.0123 (0.169 sec/step)\n",
            "I0213 16:59:27.920760 139806407255936 learning.py:512] global step 9064: loss = 0.0123 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9065: loss = 0.0169 (0.163 sec/step)\n",
            "I0213 16:59:28.084977 139806407255936 learning.py:512] global step 9065: loss = 0.0169 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9066: loss = 0.0283 (0.157 sec/step)\n",
            "I0213 16:59:28.242788 139806407255936 learning.py:512] global step 9066: loss = 0.0283 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9067: loss = 0.0263 (0.168 sec/step)\n",
            "I0213 16:59:28.412423 139806407255936 learning.py:512] global step 9067: loss = 0.0263 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9068: loss = 0.0169 (0.181 sec/step)\n",
            "I0213 16:59:28.594780 139806407255936 learning.py:512] global step 9068: loss = 0.0169 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9069: loss = 0.0480 (0.168 sec/step)\n",
            "I0213 16:59:28.764211 139806407255936 learning.py:512] global step 9069: loss = 0.0480 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9070: loss = 0.0199 (0.185 sec/step)\n",
            "I0213 16:59:28.950373 139806407255936 learning.py:512] global step 9070: loss = 0.0199 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9071: loss = 0.0216 (0.161 sec/step)\n",
            "I0213 16:59:29.113088 139806407255936 learning.py:512] global step 9071: loss = 0.0216 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9072: loss = 0.0117 (0.160 sec/step)\n",
            "I0213 16:59:29.274784 139806407255936 learning.py:512] global step 9072: loss = 0.0117 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9073: loss = 0.0259 (0.162 sec/step)\n",
            "I0213 16:59:29.437850 139806407255936 learning.py:512] global step 9073: loss = 0.0259 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9074: loss = 0.0090 (0.176 sec/step)\n",
            "I0213 16:59:29.615229 139806407255936 learning.py:512] global step 9074: loss = 0.0090 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9075: loss = 0.0360 (0.157 sec/step)\n",
            "I0213 16:59:29.773554 139806407255936 learning.py:512] global step 9075: loss = 0.0360 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9076: loss = 0.0295 (0.155 sec/step)\n",
            "I0213 16:59:29.929553 139806407255936 learning.py:512] global step 9076: loss = 0.0295 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9077: loss = 0.0287 (0.176 sec/step)\n",
            "I0213 16:59:30.106324 139806407255936 learning.py:512] global step 9077: loss = 0.0287 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9078: loss = 0.0359 (0.165 sec/step)\n",
            "I0213 16:59:30.272489 139806407255936 learning.py:512] global step 9078: loss = 0.0359 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9079: loss = 0.0338 (0.175 sec/step)\n",
            "I0213 16:59:30.448510 139806407255936 learning.py:512] global step 9079: loss = 0.0338 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9080: loss = 0.0288 (0.172 sec/step)\n",
            "I0213 16:59:30.621508 139806407255936 learning.py:512] global step 9080: loss = 0.0288 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9081: loss = 0.0202 (0.155 sec/step)\n",
            "I0213 16:59:30.778137 139806407255936 learning.py:512] global step 9081: loss = 0.0202 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9082: loss = 0.0823 (0.165 sec/step)\n",
            "I0213 16:59:30.944424 139806407255936 learning.py:512] global step 9082: loss = 0.0823 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9083: loss = 0.0694 (0.174 sec/step)\n",
            "I0213 16:59:31.119820 139806407255936 learning.py:512] global step 9083: loss = 0.0694 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9084: loss = 0.0484 (0.161 sec/step)\n",
            "I0213 16:59:31.282232 139806407255936 learning.py:512] global step 9084: loss = 0.0484 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9085: loss = 0.0321 (0.167 sec/step)\n",
            "I0213 16:59:31.450763 139806407255936 learning.py:512] global step 9085: loss = 0.0321 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9086: loss = 0.0071 (0.172 sec/step)\n",
            "I0213 16:59:31.623942 139806407255936 learning.py:512] global step 9086: loss = 0.0071 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9087: loss = 0.0229 (0.163 sec/step)\n",
            "I0213 16:59:31.788785 139806407255936 learning.py:512] global step 9087: loss = 0.0229 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9088: loss = 0.0197 (0.166 sec/step)\n",
            "I0213 16:59:31.956267 139806407255936 learning.py:512] global step 9088: loss = 0.0197 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9089: loss = 0.0145 (0.195 sec/step)\n",
            "I0213 16:59:32.152296 139806407255936 learning.py:512] global step 9089: loss = 0.0145 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 9090: loss = 0.0286 (0.172 sec/step)\n",
            "I0213 16:59:32.325276 139806407255936 learning.py:512] global step 9090: loss = 0.0286 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9091: loss = 0.0229 (0.178 sec/step)\n",
            "I0213 16:59:32.504647 139806407255936 learning.py:512] global step 9091: loss = 0.0229 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9092: loss = 0.0840 (0.177 sec/step)\n",
            "I0213 16:59:32.683220 139806407255936 learning.py:512] global step 9092: loss = 0.0840 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9093: loss = 0.0261 (0.177 sec/step)\n",
            "I0213 16:59:32.861937 139806407255936 learning.py:512] global step 9093: loss = 0.0261 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9094: loss = 0.0203 (0.160 sec/step)\n",
            "I0213 16:59:33.023398 139806407255936 learning.py:512] global step 9094: loss = 0.0203 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9095: loss = 0.0283 (0.180 sec/step)\n",
            "I0213 16:59:33.204938 139806407255936 learning.py:512] global step 9095: loss = 0.0283 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9096: loss = 0.0229 (0.163 sec/step)\n",
            "I0213 16:59:33.369400 139806407255936 learning.py:512] global step 9096: loss = 0.0229 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9097: loss = 0.0122 (0.176 sec/step)\n",
            "I0213 16:59:33.546583 139806407255936 learning.py:512] global step 9097: loss = 0.0122 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9098: loss = 0.0259 (0.162 sec/step)\n",
            "I0213 16:59:33.710276 139806407255936 learning.py:512] global step 9098: loss = 0.0259 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9099: loss = 0.0210 (0.184 sec/step)\n",
            "I0213 16:59:33.895873 139806407255936 learning.py:512] global step 9099: loss = 0.0210 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9100: loss = 0.0181 (0.173 sec/step)\n",
            "I0213 16:59:34.070525 139806407255936 learning.py:512] global step 9100: loss = 0.0181 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9101: loss = 0.0200 (0.164 sec/step)\n",
            "I0213 16:59:34.236196 139806407255936 learning.py:512] global step 9101: loss = 0.0200 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9102: loss = 0.0162 (0.166 sec/step)\n",
            "I0213 16:59:34.403347 139806407255936 learning.py:512] global step 9102: loss = 0.0162 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9103: loss = 0.0253 (0.172 sec/step)\n",
            "I0213 16:59:34.576780 139806407255936 learning.py:512] global step 9103: loss = 0.0253 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9104: loss = 0.0125 (0.151 sec/step)\n",
            "I0213 16:59:34.730133 139806407255936 learning.py:512] global step 9104: loss = 0.0125 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9105: loss = 0.0612 (0.171 sec/step)\n",
            "I0213 16:59:34.902888 139806407255936 learning.py:512] global step 9105: loss = 0.0612 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9106: loss = 0.0243 (0.177 sec/step)\n",
            "I0213 16:59:35.080952 139806407255936 learning.py:512] global step 9106: loss = 0.0243 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9107: loss = 0.0077 (0.187 sec/step)\n",
            "I0213 16:59:35.269872 139806407255936 learning.py:512] global step 9107: loss = 0.0077 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9108: loss = 0.0119 (0.166 sec/step)\n",
            "I0213 16:59:35.437648 139806407255936 learning.py:512] global step 9108: loss = 0.0119 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9109: loss = 0.0292 (0.154 sec/step)\n",
            "I0213 16:59:35.592459 139806407255936 learning.py:512] global step 9109: loss = 0.0292 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9110: loss = 0.0295 (0.163 sec/step)\n",
            "I0213 16:59:35.756379 139806407255936 learning.py:512] global step 9110: loss = 0.0295 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9111: loss = 0.0118 (0.173 sec/step)\n",
            "I0213 16:59:35.930895 139806407255936 learning.py:512] global step 9111: loss = 0.0118 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9112: loss = 0.0290 (0.174 sec/step)\n",
            "I0213 16:59:36.106482 139806407255936 learning.py:512] global step 9112: loss = 0.0290 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9113: loss = 0.0116 (0.190 sec/step)\n",
            "I0213 16:59:36.298314 139806407255936 learning.py:512] global step 9113: loss = 0.0116 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9114: loss = 0.0152 (0.194 sec/step)\n",
            "I0213 16:59:36.494249 139806407255936 learning.py:512] global step 9114: loss = 0.0152 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9115: loss = 0.0167 (0.174 sec/step)\n",
            "I0213 16:59:36.670156 139806407255936 learning.py:512] global step 9115: loss = 0.0167 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9116: loss = 0.0237 (0.158 sec/step)\n",
            "I0213 16:59:36.829195 139806407255936 learning.py:512] global step 9116: loss = 0.0237 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9117: loss = 0.0261 (0.170 sec/step)\n",
            "I0213 16:59:37.000417 139806407255936 learning.py:512] global step 9117: loss = 0.0261 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9118: loss = 0.0632 (0.160 sec/step)\n",
            "I0213 16:59:37.161607 139806407255936 learning.py:512] global step 9118: loss = 0.0632 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9119: loss = 0.0227 (0.165 sec/step)\n",
            "I0213 16:59:37.327828 139806407255936 learning.py:512] global step 9119: loss = 0.0227 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9120: loss = 0.0223 (0.171 sec/step)\n",
            "I0213 16:59:37.500440 139806407255936 learning.py:512] global step 9120: loss = 0.0223 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9121: loss = 0.0245 (0.180 sec/step)\n",
            "I0213 16:59:37.681566 139806407255936 learning.py:512] global step 9121: loss = 0.0245 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9122: loss = 0.0303 (0.174 sec/step)\n",
            "I0213 16:59:37.857366 139806407255936 learning.py:512] global step 9122: loss = 0.0303 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9123: loss = 0.0195 (0.164 sec/step)\n",
            "I0213 16:59:38.022480 139806407255936 learning.py:512] global step 9123: loss = 0.0195 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9124: loss = 0.0088 (0.168 sec/step)\n",
            "I0213 16:59:38.191621 139806407255936 learning.py:512] global step 9124: loss = 0.0088 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9125: loss = 0.0366 (0.171 sec/step)\n",
            "I0213 16:59:38.363678 139806407255936 learning.py:512] global step 9125: loss = 0.0366 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9126: loss = 0.0180 (0.174 sec/step)\n",
            "I0213 16:59:38.539659 139806407255936 learning.py:512] global step 9126: loss = 0.0180 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9127: loss = 0.0129 (0.175 sec/step)\n",
            "I0213 16:59:38.716463 139806407255936 learning.py:512] global step 9127: loss = 0.0129 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9128: loss = 0.0151 (0.164 sec/step)\n",
            "I0213 16:59:38.881615 139806407255936 learning.py:512] global step 9128: loss = 0.0151 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9129: loss = 0.0165 (0.172 sec/step)\n",
            "I0213 16:59:39.054698 139806407255936 learning.py:512] global step 9129: loss = 0.0165 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9130: loss = 0.0110 (0.174 sec/step)\n",
            "I0213 16:59:39.229841 139806407255936 learning.py:512] global step 9130: loss = 0.0110 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9131: loss = 0.0135 (0.172 sec/step)\n",
            "I0213 16:59:39.403004 139806407255936 learning.py:512] global step 9131: loss = 0.0135 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9132: loss = 0.0341 (0.175 sec/step)\n",
            "I0213 16:59:39.579461 139806407255936 learning.py:512] global step 9132: loss = 0.0341 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9133: loss = 0.0143 (0.173 sec/step)\n",
            "I0213 16:59:39.754074 139806407255936 learning.py:512] global step 9133: loss = 0.0143 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9134: loss = 0.0225 (0.164 sec/step)\n",
            "I0213 16:59:39.919682 139806407255936 learning.py:512] global step 9134: loss = 0.0225 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9135: loss = 0.0242 (0.170 sec/step)\n",
            "I0213 16:59:40.091096 139806407255936 learning.py:512] global step 9135: loss = 0.0242 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9136: loss = 0.0248 (0.170 sec/step)\n",
            "I0213 16:59:40.262943 139806407255936 learning.py:512] global step 9136: loss = 0.0248 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9137: loss = 0.0144 (0.176 sec/step)\n",
            "I0213 16:59:40.440366 139806407255936 learning.py:512] global step 9137: loss = 0.0144 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9138: loss = 0.0194 (0.160 sec/step)\n",
            "I0213 16:59:40.601981 139806407255936 learning.py:512] global step 9138: loss = 0.0194 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9139: loss = 0.0143 (0.174 sec/step)\n",
            "I0213 16:59:40.777304 139806407255936 learning.py:512] global step 9139: loss = 0.0143 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9140: loss = 0.0091 (0.190 sec/step)\n",
            "I0213 16:59:40.968494 139806407255936 learning.py:512] global step 9140: loss = 0.0091 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9141: loss = 0.0099 (0.157 sec/step)\n",
            "I0213 16:59:41.127107 139806407255936 learning.py:512] global step 9141: loss = 0.0099 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9142: loss = 0.0136 (0.178 sec/step)\n",
            "I0213 16:59:41.306358 139806407255936 learning.py:512] global step 9142: loss = 0.0136 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9143: loss = 0.0158 (0.173 sec/step)\n",
            "I0213 16:59:41.480242 139806407255936 learning.py:512] global step 9143: loss = 0.0158 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9144: loss = 0.0281 (0.155 sec/step)\n",
            "I0213 16:59:41.637193 139806407255936 learning.py:512] global step 9144: loss = 0.0281 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9145: loss = 0.0198 (0.155 sec/step)\n",
            "I0213 16:59:41.793571 139806407255936 learning.py:512] global step 9145: loss = 0.0198 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9146: loss = 0.0454 (0.164 sec/step)\n",
            "I0213 16:59:41.959449 139806407255936 learning.py:512] global step 9146: loss = 0.0454 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9147: loss = 0.0224 (0.162 sec/step)\n",
            "I0213 16:59:42.122538 139806407255936 learning.py:512] global step 9147: loss = 0.0224 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9148: loss = 0.0101 (0.180 sec/step)\n",
            "I0213 16:59:42.303773 139806407255936 learning.py:512] global step 9148: loss = 0.0101 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9149: loss = 0.0311 (0.162 sec/step)\n",
            "I0213 16:59:42.467224 139806407255936 learning.py:512] global step 9149: loss = 0.0311 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9150: loss = 0.0129 (0.168 sec/step)\n",
            "I0213 16:59:42.636351 139806407255936 learning.py:512] global step 9150: loss = 0.0129 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9151: loss = 0.0827 (0.172 sec/step)\n",
            "I0213 16:59:42.809666 139806407255936 learning.py:512] global step 9151: loss = 0.0827 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9152: loss = 0.0233 (0.156 sec/step)\n",
            "I0213 16:59:42.967660 139806407255936 learning.py:512] global step 9152: loss = 0.0233 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9153: loss = 0.0128 (0.152 sec/step)\n",
            "I0213 16:59:43.121200 139806407255936 learning.py:512] global step 9153: loss = 0.0128 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9154: loss = 0.0252 (0.180 sec/step)\n",
            "I0213 16:59:43.302452 139806407255936 learning.py:512] global step 9154: loss = 0.0252 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9155: loss = 0.0131 (0.166 sec/step)\n",
            "I0213 16:59:43.470259 139806407255936 learning.py:512] global step 9155: loss = 0.0131 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9156: loss = 0.0272 (0.163 sec/step)\n",
            "I0213 16:59:43.634726 139806407255936 learning.py:512] global step 9156: loss = 0.0272 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9157: loss = 0.0069 (0.157 sec/step)\n",
            "I0213 16:59:43.792947 139806407255936 learning.py:512] global step 9157: loss = 0.0069 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9158: loss = 0.0231 (0.153 sec/step)\n",
            "I0213 16:59:43.948924 139806407255936 learning.py:512] global step 9158: loss = 0.0231 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9159: loss = 0.0257 (0.171 sec/step)\n",
            "I0213 16:59:44.122279 139806407255936 learning.py:512] global step 9159: loss = 0.0257 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9160: loss = 0.0217 (0.164 sec/step)\n",
            "I0213 16:59:44.288158 139806407255936 learning.py:512] global step 9160: loss = 0.0217 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9161: loss = 0.0370 (0.165 sec/step)\n",
            "I0213 16:59:44.454442 139806407255936 learning.py:512] global step 9161: loss = 0.0370 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9162: loss = 0.0216 (0.171 sec/step)\n",
            "I0213 16:59:44.627179 139806407255936 learning.py:512] global step 9162: loss = 0.0216 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9163: loss = 0.0746 (0.173 sec/step)\n",
            "I0213 16:59:44.802505 139806407255936 learning.py:512] global step 9163: loss = 0.0746 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9164: loss = 0.0185 (0.176 sec/step)\n",
            "I0213 16:59:44.979611 139806407255936 learning.py:512] global step 9164: loss = 0.0185 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9165: loss = 0.0281 (0.175 sec/step)\n",
            "I0213 16:59:45.155804 139806407255936 learning.py:512] global step 9165: loss = 0.0281 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9166: loss = 0.0118 (0.183 sec/step)\n",
            "I0213 16:59:45.340539 139806407255936 learning.py:512] global step 9166: loss = 0.0118 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9167: loss = 0.0123 (0.173 sec/step)\n",
            "I0213 16:59:45.514749 139806407255936 learning.py:512] global step 9167: loss = 0.0123 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9168: loss = 0.0693 (0.173 sec/step)\n",
            "I0213 16:59:45.689681 139806407255936 learning.py:512] global step 9168: loss = 0.0693 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9169: loss = 0.0186 (0.157 sec/step)\n",
            "I0213 16:59:45.848017 139806407255936 learning.py:512] global step 9169: loss = 0.0186 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9170: loss = 0.0341 (0.170 sec/step)\n",
            "I0213 16:59:46.019157 139806407255936 learning.py:512] global step 9170: loss = 0.0341 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9171: loss = 0.0077 (0.176 sec/step)\n",
            "I0213 16:59:46.196111 139806407255936 learning.py:512] global step 9171: loss = 0.0077 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9172: loss = 0.0322 (0.172 sec/step)\n",
            "I0213 16:59:46.369185 139806407255936 learning.py:512] global step 9172: loss = 0.0322 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9173: loss = 0.0175 (0.177 sec/step)\n",
            "I0213 16:59:46.547891 139806407255936 learning.py:512] global step 9173: loss = 0.0175 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9174: loss = 0.0319 (0.188 sec/step)\n",
            "I0213 16:59:46.737069 139806407255936 learning.py:512] global step 9174: loss = 0.0319 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9175: loss = 0.0160 (0.165 sec/step)\n",
            "I0213 16:59:46.903824 139806407255936 learning.py:512] global step 9175: loss = 0.0160 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9176: loss = 0.0137 (0.171 sec/step)\n",
            "I0213 16:59:47.076531 139806407255936 learning.py:512] global step 9176: loss = 0.0137 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9177: loss = 0.0105 (0.164 sec/step)\n",
            "I0213 16:59:47.242107 139806407255936 learning.py:512] global step 9177: loss = 0.0105 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9178: loss = 0.0157 (0.165 sec/step)\n",
            "I0213 16:59:47.408811 139806407255936 learning.py:512] global step 9178: loss = 0.0157 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9179: loss = 0.0095 (0.176 sec/step)\n",
            "I0213 16:59:47.585758 139806407255936 learning.py:512] global step 9179: loss = 0.0095 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9180: loss = 0.0187 (0.181 sec/step)\n",
            "I0213 16:59:47.768278 139806407255936 learning.py:512] global step 9180: loss = 0.0187 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9181: loss = 0.0231 (0.165 sec/step)\n",
            "I0213 16:59:47.934977 139806407255936 learning.py:512] global step 9181: loss = 0.0231 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9182: loss = 0.0197 (0.168 sec/step)\n",
            "I0213 16:59:48.104388 139806407255936 learning.py:512] global step 9182: loss = 0.0197 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9183: loss = 0.0355 (0.173 sec/step)\n",
            "I0213 16:59:48.279152 139806407255936 learning.py:512] global step 9183: loss = 0.0355 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9184: loss = 0.0318 (0.168 sec/step)\n",
            "I0213 16:59:48.448754 139806407255936 learning.py:512] global step 9184: loss = 0.0318 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9185: loss = 0.0220 (0.169 sec/step)\n",
            "I0213 16:59:48.619740 139806407255936 learning.py:512] global step 9185: loss = 0.0220 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9186: loss = 0.0289 (0.165 sec/step)\n",
            "I0213 16:59:48.786727 139806407255936 learning.py:512] global step 9186: loss = 0.0289 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9187: loss = 0.0161 (0.176 sec/step)\n",
            "I0213 16:59:48.964320 139806407255936 learning.py:512] global step 9187: loss = 0.0161 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9188: loss = 0.0424 (0.160 sec/step)\n",
            "I0213 16:59:49.126176 139806407255936 learning.py:512] global step 9188: loss = 0.0424 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9189: loss = 0.0138 (0.157 sec/step)\n",
            "I0213 16:59:49.284544 139806407255936 learning.py:512] global step 9189: loss = 0.0138 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9190: loss = 0.0993 (0.173 sec/step)\n",
            "I0213 16:59:49.458575 139806407255936 learning.py:512] global step 9190: loss = 0.0993 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9191: loss = 0.0174 (0.159 sec/step)\n",
            "I0213 16:59:49.618393 139806407255936 learning.py:512] global step 9191: loss = 0.0174 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9192: loss = 0.0127 (0.168 sec/step)\n",
            "I0213 16:59:49.787435 139806407255936 learning.py:512] global step 9192: loss = 0.0127 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9193: loss = 0.0146 (0.161 sec/step)\n",
            "I0213 16:59:49.950325 139806407255936 learning.py:512] global step 9193: loss = 0.0146 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9194: loss = 0.0241 (0.159 sec/step)\n",
            "I0213 16:59:50.110638 139806407255936 learning.py:512] global step 9194: loss = 0.0241 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9195: loss = 0.0162 (0.180 sec/step)\n",
            "I0213 16:59:50.292014 139806407255936 learning.py:512] global step 9195: loss = 0.0162 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9196: loss = 0.0147 (0.168 sec/step)\n",
            "I0213 16:59:50.461647 139806407255936 learning.py:512] global step 9196: loss = 0.0147 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9197: loss = 0.0183 (0.174 sec/step)\n",
            "I0213 16:59:50.636922 139806407255936 learning.py:512] global step 9197: loss = 0.0183 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9198: loss = 0.0715 (0.164 sec/step)\n",
            "I0213 16:59:50.802330 139806407255936 learning.py:512] global step 9198: loss = 0.0715 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9199: loss = 0.0172 (0.177 sec/step)\n",
            "I0213 16:59:50.981205 139806407255936 learning.py:512] global step 9199: loss = 0.0172 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9200: loss = 0.0236 (0.171 sec/step)\n",
            "I0213 16:59:51.153596 139806407255936 learning.py:512] global step 9200: loss = 0.0236 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9201: loss = 0.0148 (0.164 sec/step)\n",
            "I0213 16:59:51.318942 139806407255936 learning.py:512] global step 9201: loss = 0.0148 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9202: loss = 0.0418 (0.175 sec/step)\n",
            "I0213 16:59:51.495086 139806407255936 learning.py:512] global step 9202: loss = 0.0418 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9203: loss = 0.0219 (0.168 sec/step)\n",
            "I0213 16:59:51.664691 139806407255936 learning.py:512] global step 9203: loss = 0.0219 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9204: loss = 0.0266 (0.162 sec/step)\n",
            "I0213 16:59:51.828673 139806407255936 learning.py:512] global step 9204: loss = 0.0266 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9205: loss = 0.0190 (0.172 sec/step)\n",
            "I0213 16:59:52.001638 139806407255936 learning.py:512] global step 9205: loss = 0.0190 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9206: loss = 0.0156 (0.169 sec/step)\n",
            "I0213 16:59:52.172293 139806407255936 learning.py:512] global step 9206: loss = 0.0156 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9207: loss = 0.0151 (0.160 sec/step)\n",
            "I0213 16:59:52.333488 139806407255936 learning.py:512] global step 9207: loss = 0.0151 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9208: loss = 0.0266 (0.187 sec/step)\n",
            "I0213 16:59:52.522637 139806407255936 learning.py:512] global step 9208: loss = 0.0266 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9209: loss = 0.0175 (0.161 sec/step)\n",
            "I0213 16:59:52.685562 139806407255936 learning.py:512] global step 9209: loss = 0.0175 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9210: loss = 0.0207 (0.169 sec/step)\n",
            "I0213 16:59:52.856178 139806407255936 learning.py:512] global step 9210: loss = 0.0207 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9211: loss = 0.0331 (0.160 sec/step)\n",
            "I0213 16:59:53.017889 139806407255936 learning.py:512] global step 9211: loss = 0.0331 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9212: loss = 0.0121 (0.162 sec/step)\n",
            "I0213 16:59:53.181098 139806407255936 learning.py:512] global step 9212: loss = 0.0121 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9213: loss = 0.0195 (0.161 sec/step)\n",
            "I0213 16:59:53.343178 139806407255936 learning.py:512] global step 9213: loss = 0.0195 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9214: loss = 0.0248 (0.186 sec/step)\n",
            "I0213 16:59:53.530678 139806407255936 learning.py:512] global step 9214: loss = 0.0248 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9215: loss = 0.0215 (0.166 sec/step)\n",
            "I0213 16:59:53.697832 139806407255936 learning.py:512] global step 9215: loss = 0.0215 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9216: loss = 0.0330 (0.167 sec/step)\n",
            "I0213 16:59:53.865988 139806407255936 learning.py:512] global step 9216: loss = 0.0330 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9217: loss = 0.0245 (0.177 sec/step)\n",
            "I0213 16:59:54.044595 139806407255936 learning.py:512] global step 9217: loss = 0.0245 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9218: loss = 0.0519 (0.164 sec/step)\n",
            "I0213 16:59:54.210072 139806407255936 learning.py:512] global step 9218: loss = 0.0519 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9219: loss = 0.0150 (0.185 sec/step)\n",
            "I0213 16:59:54.397027 139806407255936 learning.py:512] global step 9219: loss = 0.0150 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9220: loss = 0.0214 (0.170 sec/step)\n",
            "I0213 16:59:54.568908 139806407255936 learning.py:512] global step 9220: loss = 0.0214 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9221: loss = 0.0178 (0.156 sec/step)\n",
            "I0213 16:59:54.726343 139806407255936 learning.py:512] global step 9221: loss = 0.0178 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9222: loss = 0.0344 (0.163 sec/step)\n",
            "I0213 16:59:54.890656 139806407255936 learning.py:512] global step 9222: loss = 0.0344 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9223: loss = 0.0222 (0.163 sec/step)\n",
            "I0213 16:59:55.054785 139806407255936 learning.py:512] global step 9223: loss = 0.0222 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9224: loss = 0.0102 (0.169 sec/step)\n",
            "I0213 16:59:55.225159 139806407255936 learning.py:512] global step 9224: loss = 0.0102 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9225: loss = 0.0074 (0.169 sec/step)\n",
            "I0213 16:59:55.395397 139806407255936 learning.py:512] global step 9225: loss = 0.0074 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9226: loss = 0.0207 (0.179 sec/step)\n",
            "I0213 16:59:55.576206 139806407255936 learning.py:512] global step 9226: loss = 0.0207 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9227: loss = 0.0216 (0.177 sec/step)\n",
            "I0213 16:59:55.754925 139806407255936 learning.py:512] global step 9227: loss = 0.0216 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9228: loss = 0.0270 (0.167 sec/step)\n",
            "I0213 16:59:55.923173 139806407255936 learning.py:512] global step 9228: loss = 0.0270 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9229: loss = 0.0259 (0.160 sec/step)\n",
            "I0213 16:59:56.084494 139806407255936 learning.py:512] global step 9229: loss = 0.0259 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9230: loss = 0.0120 (0.175 sec/step)\n",
            "I0213 16:59:56.260727 139806407255936 learning.py:512] global step 9230: loss = 0.0120 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9231: loss = 0.0185 (0.172 sec/step)\n",
            "I0213 16:59:56.434263 139806407255936 learning.py:512] global step 9231: loss = 0.0185 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9232: loss = 0.0188 (0.175 sec/step)\n",
            "I0213 16:59:56.611171 139806407255936 learning.py:512] global step 9232: loss = 0.0188 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9233: loss = 0.0336 (0.185 sec/step)\n",
            "I0213 16:59:56.798141 139806407255936 learning.py:512] global step 9233: loss = 0.0336 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9234: loss = 0.0159 (0.188 sec/step)\n",
            "I0213 16:59:56.987588 139806407255936 learning.py:512] global step 9234: loss = 0.0159 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9235: loss = 0.0214 (0.179 sec/step)\n",
            "I0213 16:59:57.168430 139806407255936 learning.py:512] global step 9235: loss = 0.0214 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9236: loss = 0.0201 (0.168 sec/step)\n",
            "I0213 16:59:57.338506 139806407255936 learning.py:512] global step 9236: loss = 0.0201 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9237: loss = 0.0451 (0.174 sec/step)\n",
            "I0213 16:59:57.514106 139806407255936 learning.py:512] global step 9237: loss = 0.0451 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9238: loss = 0.0067 (0.187 sec/step)\n",
            "I0213 16:59:57.702688 139806407255936 learning.py:512] global step 9238: loss = 0.0067 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9239: loss = 0.0175 (0.166 sec/step)\n",
            "I0213 16:59:57.869605 139806407255936 learning.py:512] global step 9239: loss = 0.0175 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9240: loss = 0.0174 (0.164 sec/step)\n",
            "I0213 16:59:58.034522 139806407255936 learning.py:512] global step 9240: loss = 0.0174 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9241: loss = 0.0140 (0.165 sec/step)\n",
            "I0213 16:59:58.200702 139806407255936 learning.py:512] global step 9241: loss = 0.0140 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9242: loss = 0.0080 (0.183 sec/step)\n",
            "I0213 16:59:58.385064 139806407255936 learning.py:512] global step 9242: loss = 0.0080 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9243: loss = 0.0161 (0.168 sec/step)\n",
            "I0213 16:59:58.554170 139806407255936 learning.py:512] global step 9243: loss = 0.0161 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9244: loss = 0.0377 (0.161 sec/step)\n",
            "I0213 16:59:58.716339 139806407255936 learning.py:512] global step 9244: loss = 0.0377 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9245: loss = 0.0825 (0.170 sec/step)\n",
            "I0213 16:59:58.887338 139806407255936 learning.py:512] global step 9245: loss = 0.0825 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9246: loss = 0.0068 (0.163 sec/step)\n",
            "I0213 16:59:59.051899 139806407255936 learning.py:512] global step 9246: loss = 0.0068 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9247: loss = 0.0166 (0.168 sec/step)\n",
            "I0213 16:59:59.221093 139806407255936 learning.py:512] global step 9247: loss = 0.0166 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9248: loss = 0.0171 (0.180 sec/step)\n",
            "I0213 16:59:59.402802 139806407255936 learning.py:512] global step 9248: loss = 0.0171 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9249: loss = 0.0481 (0.180 sec/step)\n",
            "I0213 16:59:59.584485 139806407255936 learning.py:512] global step 9249: loss = 0.0481 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9250: loss = 0.0834 (0.189 sec/step)\n",
            "I0213 16:59:59.775350 139806407255936 learning.py:512] global step 9250: loss = 0.0834 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9251: loss = 0.0617 (0.160 sec/step)\n",
            "I0213 16:59:59.937311 139806407255936 learning.py:512] global step 9251: loss = 0.0617 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9252: loss = 0.0746 (0.177 sec/step)\n",
            "I0213 17:00:00.116536 139806407255936 learning.py:512] global step 9252: loss = 0.0746 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9253: loss = 0.0260 (0.149 sec/step)\n",
            "I0213 17:00:00.266665 139806407255936 learning.py:512] global step 9253: loss = 0.0260 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 9254: loss = 0.0441 (0.157 sec/step)\n",
            "I0213 17:00:00.425216 139806407255936 learning.py:512] global step 9254: loss = 0.0441 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9255: loss = 0.0281 (0.188 sec/step)\n",
            "I0213 17:00:00.614872 139806407255936 learning.py:512] global step 9255: loss = 0.0281 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9256: loss = 0.0248 (0.166 sec/step)\n",
            "I0213 17:00:00.781944 139806407255936 learning.py:512] global step 9256: loss = 0.0248 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9257: loss = 0.0266 (0.179 sec/step)\n",
            "I0213 17:00:00.962268 139806407255936 learning.py:512] global step 9257: loss = 0.0266 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9258: loss = 0.0403 (0.170 sec/step)\n",
            "I0213 17:00:01.133876 139806407255936 learning.py:512] global step 9258: loss = 0.0403 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9259: loss = 0.0222 (0.177 sec/step)\n",
            "I0213 17:00:01.311813 139806407255936 learning.py:512] global step 9259: loss = 0.0222 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9260: loss = 0.0095 (0.176 sec/step)\n",
            "I0213 17:00:01.489634 139806407255936 learning.py:512] global step 9260: loss = 0.0095 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9261: loss = 0.0379 (0.169 sec/step)\n",
            "I0213 17:00:01.659592 139806407255936 learning.py:512] global step 9261: loss = 0.0379 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9262: loss = 0.0311 (0.173 sec/step)\n",
            "I0213 17:00:01.834602 139806407255936 learning.py:512] global step 9262: loss = 0.0311 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9263: loss = 0.0326 (0.168 sec/step)\n",
            "I0213 17:00:02.005871 139806407255936 learning.py:512] global step 9263: loss = 0.0326 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9264: loss = 0.0218 (0.161 sec/step)\n",
            "I0213 17:00:02.167895 139806407255936 learning.py:512] global step 9264: loss = 0.0218 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9265: loss = 0.0301 (0.176 sec/step)\n",
            "I0213 17:00:02.345152 139806407255936 learning.py:512] global step 9265: loss = 0.0301 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9266: loss = 0.0219 (0.161 sec/step)\n",
            "I0213 17:00:02.507396 139806407255936 learning.py:512] global step 9266: loss = 0.0219 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9267: loss = 0.0106 (0.179 sec/step)\n",
            "I0213 17:00:02.688344 139806407255936 learning.py:512] global step 9267: loss = 0.0106 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9268: loss = 0.0187 (0.164 sec/step)\n",
            "I0213 17:00:02.853593 139806407255936 learning.py:512] global step 9268: loss = 0.0187 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9269: loss = 0.0096 (0.171 sec/step)\n",
            "I0213 17:00:03.025806 139806407255936 learning.py:512] global step 9269: loss = 0.0096 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9270: loss = 0.0042 (0.153 sec/step)\n",
            "I0213 17:00:03.180446 139806407255936 learning.py:512] global step 9270: loss = 0.0042 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9271: loss = 0.0325 (0.175 sec/step)\n",
            "I0213 17:00:03.356964 139806407255936 learning.py:512] global step 9271: loss = 0.0325 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9272: loss = 0.0105 (0.170 sec/step)\n",
            "I0213 17:00:03.528307 139806407255936 learning.py:512] global step 9272: loss = 0.0105 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9273: loss = 0.0097 (0.175 sec/step)\n",
            "I0213 17:00:03.704431 139806407255936 learning.py:512] global step 9273: loss = 0.0097 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9274: loss = 0.0047 (0.173 sec/step)\n",
            "I0213 17:00:03.878762 139806407255936 learning.py:512] global step 9274: loss = 0.0047 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9275: loss = 0.0180 (0.185 sec/step)\n",
            "I0213 17:00:04.064954 139806407255936 learning.py:512] global step 9275: loss = 0.0180 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9276: loss = 0.0242 (0.165 sec/step)\n",
            "I0213 17:00:04.231350 139806407255936 learning.py:512] global step 9276: loss = 0.0242 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9277: loss = 0.0183 (0.156 sec/step)\n",
            "I0213 17:00:04.388805 139806407255936 learning.py:512] global step 9277: loss = 0.0183 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9278: loss = 0.0144 (0.181 sec/step)\n",
            "I0213 17:00:04.570712 139806407255936 learning.py:512] global step 9278: loss = 0.0144 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9279: loss = 0.0257 (0.162 sec/step)\n",
            "I0213 17:00:04.734247 139806407255936 learning.py:512] global step 9279: loss = 0.0257 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9280: loss = 0.0161 (0.163 sec/step)\n",
            "I0213 17:00:04.899062 139806407255936 learning.py:512] global step 9280: loss = 0.0161 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9281: loss = 0.0268 (0.165 sec/step)\n",
            "I0213 17:00:05.066076 139806407255936 learning.py:512] global step 9281: loss = 0.0268 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9282: loss = 0.0281 (0.167 sec/step)\n",
            "I0213 17:00:05.235380 139806407255936 learning.py:512] global step 9282: loss = 0.0281 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9283: loss = 0.0271 (0.173 sec/step)\n",
            "I0213 17:00:05.410058 139806407255936 learning.py:512] global step 9283: loss = 0.0271 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9284: loss = 0.0165 (0.177 sec/step)\n",
            "I0213 17:00:05.588593 139806407255936 learning.py:512] global step 9284: loss = 0.0165 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9285: loss = 0.0236 (0.176 sec/step)\n",
            "I0213 17:00:05.768755 139806407255936 learning.py:512] global step 9285: loss = 0.0236 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9286: loss = 0.0203 (0.177 sec/step)\n",
            "I0213 17:00:05.947375 139806407255936 learning.py:512] global step 9286: loss = 0.0203 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9287: loss = 0.0100 (0.161 sec/step)\n",
            "I0213 17:00:06.110277 139806407255936 learning.py:512] global step 9287: loss = 0.0100 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9288: loss = 0.0506 (0.176 sec/step)\n",
            "I0213 17:00:06.288084 139806407255936 learning.py:512] global step 9288: loss = 0.0506 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9289: loss = 0.0197 (0.166 sec/step)\n",
            "I0213 17:00:06.455483 139806407255936 learning.py:512] global step 9289: loss = 0.0197 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9290: loss = 0.0210 (0.182 sec/step)\n",
            "I0213 17:00:06.639977 139806407255936 learning.py:512] global step 9290: loss = 0.0210 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9291: loss = 0.0139 (0.161 sec/step)\n",
            "I0213 17:00:06.802616 139806407255936 learning.py:512] global step 9291: loss = 0.0139 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9292: loss = 0.0178 (0.195 sec/step)\n",
            "I0213 17:00:06.999190 139806407255936 learning.py:512] global step 9292: loss = 0.0178 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 9293: loss = 0.0714 (0.170 sec/step)\n",
            "I0213 17:00:07.171026 139806407255936 learning.py:512] global step 9293: loss = 0.0714 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9294: loss = 0.0131 (0.173 sec/step)\n",
            "I0213 17:00:07.345574 139806407255936 learning.py:512] global step 9294: loss = 0.0131 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9295: loss = 0.0261 (0.166 sec/step)\n",
            "I0213 17:00:07.512591 139806407255936 learning.py:512] global step 9295: loss = 0.0261 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9296: loss = 0.0121 (0.165 sec/step)\n",
            "I0213 17:00:07.678812 139806407255936 learning.py:512] global step 9296: loss = 0.0121 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9297: loss = 0.0216 (0.169 sec/step)\n",
            "I0213 17:00:07.849616 139806407255936 learning.py:512] global step 9297: loss = 0.0216 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9298: loss = 0.0560 (0.165 sec/step)\n",
            "I0213 17:00:08.016152 139806407255936 learning.py:512] global step 9298: loss = 0.0560 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9299: loss = 0.0476 (0.177 sec/step)\n",
            "I0213 17:00:08.194164 139806407255936 learning.py:512] global step 9299: loss = 0.0476 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9300: loss = 0.0500 (0.170 sec/step)\n",
            "I0213 17:00:08.365694 139806407255936 learning.py:512] global step 9300: loss = 0.0500 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9301: loss = 0.0235 (0.148 sec/step)\n",
            "I0213 17:00:08.515434 139806407255936 learning.py:512] global step 9301: loss = 0.0235 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9302: loss = 0.0527 (0.168 sec/step)\n",
            "I0213 17:00:08.685302 139806407255936 learning.py:512] global step 9302: loss = 0.0527 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9303: loss = 0.0203 (0.166 sec/step)\n",
            "I0213 17:00:08.852238 139806407255936 learning.py:512] global step 9303: loss = 0.0203 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9304: loss = 0.0234 (0.163 sec/step)\n",
            "I0213 17:00:09.016508 139806407255936 learning.py:512] global step 9304: loss = 0.0234 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9305: loss = 0.0447 (0.164 sec/step)\n",
            "I0213 17:00:09.181796 139806407255936 learning.py:512] global step 9305: loss = 0.0447 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9306: loss = 0.0271 (0.164 sec/step)\n",
            "I0213 17:00:09.346871 139806407255936 learning.py:512] global step 9306: loss = 0.0271 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9307: loss = 0.0142 (0.171 sec/step)\n",
            "I0213 17:00:09.519593 139806407255936 learning.py:512] global step 9307: loss = 0.0142 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9308: loss = 0.0099 (0.173 sec/step)\n",
            "I0213 17:00:09.694291 139806407255936 learning.py:512] global step 9308: loss = 0.0099 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9309: loss = 0.0263 (0.172 sec/step)\n",
            "I0213 17:00:09.867434 139806407255936 learning.py:512] global step 9309: loss = 0.0263 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9310: loss = 0.0065 (0.176 sec/step)\n",
            "I0213 17:00:10.044639 139806407255936 learning.py:512] global step 9310: loss = 0.0065 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9311: loss = 0.0716 (0.173 sec/step)\n",
            "I0213 17:00:10.219362 139806407255936 learning.py:512] global step 9311: loss = 0.0716 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9312: loss = 0.0148 (0.168 sec/step)\n",
            "I0213 17:00:10.388389 139806407255936 learning.py:512] global step 9312: loss = 0.0148 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9313: loss = 0.0281 (0.170 sec/step)\n",
            "I0213 17:00:10.561733 139806407255936 learning.py:512] global step 9313: loss = 0.0281 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9314: loss = 0.0162 (0.169 sec/step)\n",
            "I0213 17:00:10.732665 139806407255936 learning.py:512] global step 9314: loss = 0.0162 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9315: loss = 0.0416 (0.171 sec/step)\n",
            "I0213 17:00:10.904708 139806407255936 learning.py:512] global step 9315: loss = 0.0416 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9316: loss = 0.0324 (0.182 sec/step)\n",
            "I0213 17:00:11.088589 139806407255936 learning.py:512] global step 9316: loss = 0.0324 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9317: loss = 0.0119 (0.175 sec/step)\n",
            "I0213 17:00:11.264575 139806407255936 learning.py:512] global step 9317: loss = 0.0119 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9318: loss = 0.0221 (0.166 sec/step)\n",
            "I0213 17:00:11.431986 139806407255936 learning.py:512] global step 9318: loss = 0.0221 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9319: loss = 0.0125 (0.171 sec/step)\n",
            "I0213 17:00:11.604163 139806407255936 learning.py:512] global step 9319: loss = 0.0125 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9320: loss = 0.0137 (0.177 sec/step)\n",
            "I0213 17:00:11.782780 139806407255936 learning.py:512] global step 9320: loss = 0.0137 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9321: loss = 0.0165 (0.183 sec/step)\n",
            "I0213 17:00:11.967003 139806407255936 learning.py:512] global step 9321: loss = 0.0165 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9322: loss = 0.0149 (0.172 sec/step)\n",
            "I0213 17:00:12.140376 139806407255936 learning.py:512] global step 9322: loss = 0.0149 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9323: loss = 0.0247 (0.165 sec/step)\n",
            "I0213 17:00:12.306904 139806407255936 learning.py:512] global step 9323: loss = 0.0247 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9324: loss = 0.0161 (0.159 sec/step)\n",
            "I0213 17:00:12.467354 139806407255936 learning.py:512] global step 9324: loss = 0.0161 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9325: loss = 0.0422 (0.177 sec/step)\n",
            "I0213 17:00:12.645521 139806407255936 learning.py:512] global step 9325: loss = 0.0422 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9326: loss = 0.0267 (0.192 sec/step)\n",
            "I0213 17:00:12.838942 139806407255936 learning.py:512] global step 9326: loss = 0.0267 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9327: loss = 0.0339 (0.162 sec/step)\n",
            "I0213 17:00:13.002123 139806407255936 learning.py:512] global step 9327: loss = 0.0339 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9328: loss = 0.0160 (0.157 sec/step)\n",
            "I0213 17:00:13.160166 139806407255936 learning.py:512] global step 9328: loss = 0.0160 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9329: loss = 0.0114 (0.166 sec/step)\n",
            "I0213 17:00:13.327212 139806407255936 learning.py:512] global step 9329: loss = 0.0114 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9330: loss = 0.0155 (0.180 sec/step)\n",
            "I0213 17:00:13.508565 139806407255936 learning.py:512] global step 9330: loss = 0.0155 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9331: loss = 0.0166 (0.166 sec/step)\n",
            "I0213 17:00:13.678889 139806407255936 learning.py:512] global step 9331: loss = 0.0166 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9332: loss = 0.0085 (0.173 sec/step)\n",
            "I0213 17:00:13.853663 139806407255936 learning.py:512] global step 9332: loss = 0.0085 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9333: loss = 0.0541 (0.167 sec/step)\n",
            "I0213 17:00:14.022429 139806407255936 learning.py:512] global step 9333: loss = 0.0541 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9334: loss = 0.0122 (0.160 sec/step)\n",
            "I0213 17:00:14.183311 139806407255936 learning.py:512] global step 9334: loss = 0.0122 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9335: loss = 0.0236 (0.170 sec/step)\n",
            "I0213 17:00:14.354659 139806407255936 learning.py:512] global step 9335: loss = 0.0236 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9336: loss = 0.0357 (0.175 sec/step)\n",
            "I0213 17:00:14.531158 139806407255936 learning.py:512] global step 9336: loss = 0.0357 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9337: loss = 0.0049 (0.177 sec/step)\n",
            "I0213 17:00:14.709958 139806407255936 learning.py:512] global step 9337: loss = 0.0049 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9338: loss = 0.0230 (0.163 sec/step)\n",
            "I0213 17:00:14.874718 139806407255936 learning.py:512] global step 9338: loss = 0.0230 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9339: loss = 0.0576 (0.188 sec/step)\n",
            "I0213 17:00:15.064572 139806407255936 learning.py:512] global step 9339: loss = 0.0576 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9340: loss = 0.0232 (0.156 sec/step)\n",
            "I0213 17:00:15.222707 139806407255936 learning.py:512] global step 9340: loss = 0.0232 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9341: loss = 0.0228 (0.175 sec/step)\n",
            "I0213 17:00:15.399184 139806407255936 learning.py:512] global step 9341: loss = 0.0228 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9342: loss = 0.0084 (0.172 sec/step)\n",
            "I0213 17:00:15.572658 139806407255936 learning.py:512] global step 9342: loss = 0.0084 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9343: loss = 0.0467 (0.161 sec/step)\n",
            "I0213 17:00:15.734856 139806407255936 learning.py:512] global step 9343: loss = 0.0467 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9344: loss = 0.0125 (0.169 sec/step)\n",
            "I0213 17:00:15.905041 139806407255936 learning.py:512] global step 9344: loss = 0.0125 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9345: loss = 0.0190 (0.170 sec/step)\n",
            "I0213 17:00:16.076219 139806407255936 learning.py:512] global step 9345: loss = 0.0190 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9346: loss = 0.0161 (0.177 sec/step)\n",
            "I0213 17:00:16.254830 139806407255936 learning.py:512] global step 9346: loss = 0.0161 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9347: loss = 0.0160 (0.164 sec/step)\n",
            "I0213 17:00:16.420745 139806407255936 learning.py:512] global step 9347: loss = 0.0160 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9348: loss = 0.0368 (0.172 sec/step)\n",
            "I0213 17:00:16.593732 139806407255936 learning.py:512] global step 9348: loss = 0.0368 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9349: loss = 0.0280 (0.179 sec/step)\n",
            "I0213 17:00:16.776563 139806407255936 learning.py:512] global step 9349: loss = 0.0280 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9350: loss = 0.0199 (0.176 sec/step)\n",
            "I0213 17:00:16.954807 139806407255936 learning.py:512] global step 9350: loss = 0.0199 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9351: loss = 0.0612 (0.165 sec/step)\n",
            "I0213 17:00:17.121383 139806407255936 learning.py:512] global step 9351: loss = 0.0612 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9352: loss = 0.0154 (0.166 sec/step)\n",
            "I0213 17:00:17.288495 139806407255936 learning.py:512] global step 9352: loss = 0.0154 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9353: loss = 0.0274 (0.183 sec/step)\n",
            "I0213 17:00:17.472976 139806407255936 learning.py:512] global step 9353: loss = 0.0274 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9354: loss = 0.0157 (0.166 sec/step)\n",
            "I0213 17:00:17.640890 139806407255936 learning.py:512] global step 9354: loss = 0.0157 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9355: loss = 0.0250 (0.176 sec/step)\n",
            "I0213 17:00:17.818148 139806407255936 learning.py:512] global step 9355: loss = 0.0250 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9356: loss = 0.0268 (0.166 sec/step)\n",
            "I0213 17:00:17.985223 139806407255936 learning.py:512] global step 9356: loss = 0.0268 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9357: loss = 0.0229 (0.165 sec/step)\n",
            "I0213 17:00:18.151955 139806407255936 learning.py:512] global step 9357: loss = 0.0229 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9358: loss = 0.0249 (0.166 sec/step)\n",
            "I0213 17:00:18.319552 139806407255936 learning.py:512] global step 9358: loss = 0.0249 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9359: loss = 0.0272 (0.201 sec/step)\n",
            "I0213 17:00:18.522364 139806407255936 learning.py:512] global step 9359: loss = 0.0272 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 9360: loss = 0.0225 (0.175 sec/step)\n",
            "I0213 17:00:18.699061 139806407255936 learning.py:512] global step 9360: loss = 0.0225 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9361: loss = 0.0440 (0.186 sec/step)\n",
            "I0213 17:00:18.886183 139806407255936 learning.py:512] global step 9361: loss = 0.0440 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9362: loss = 0.0403 (0.179 sec/step)\n",
            "I0213 17:00:19.066342 139806407255936 learning.py:512] global step 9362: loss = 0.0403 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9363: loss = 0.1042 (0.165 sec/step)\n",
            "I0213 17:00:19.232590 139806407255936 learning.py:512] global step 9363: loss = 0.1042 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9364: loss = 0.0205 (0.160 sec/step)\n",
            "I0213 17:00:19.394111 139806407255936 learning.py:512] global step 9364: loss = 0.0205 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9365: loss = 0.0162 (0.180 sec/step)\n",
            "I0213 17:00:19.574898 139806407255936 learning.py:512] global step 9365: loss = 0.0162 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9366: loss = 0.0190 (0.169 sec/step)\n",
            "I0213 17:00:19.745823 139806407255936 learning.py:512] global step 9366: loss = 0.0190 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9367: loss = 0.0366 (0.186 sec/step)\n",
            "I0213 17:00:19.933491 139806407255936 learning.py:512] global step 9367: loss = 0.0366 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9368: loss = 0.0306 (0.162 sec/step)\n",
            "I0213 17:00:20.096730 139806407255936 learning.py:512] global step 9368: loss = 0.0306 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9369: loss = 0.0183 (0.177 sec/step)\n",
            "I0213 17:00:20.275022 139806407255936 learning.py:512] global step 9369: loss = 0.0183 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9370: loss = 0.0365 (0.167 sec/step)\n",
            "I0213 17:00:20.443648 139806407255936 learning.py:512] global step 9370: loss = 0.0365 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9371: loss = 0.0129 (0.174 sec/step)\n",
            "I0213 17:00:20.618701 139806407255936 learning.py:512] global step 9371: loss = 0.0129 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9372: loss = 0.0284 (0.150 sec/step)\n",
            "I0213 17:00:20.770231 139806407255936 learning.py:512] global step 9372: loss = 0.0284 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 9373: loss = 0.0367 (0.174 sec/step)\n",
            "I0213 17:00:20.945964 139806407255936 learning.py:512] global step 9373: loss = 0.0367 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9374: loss = 0.0620 (0.153 sec/step)\n",
            "I0213 17:00:21.099882 139806407255936 learning.py:512] global step 9374: loss = 0.0620 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9375: loss = 0.0176 (0.179 sec/step)\n",
            "I0213 17:00:21.280058 139806407255936 learning.py:512] global step 9375: loss = 0.0176 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9376: loss = 0.0401 (0.159 sec/step)\n",
            "I0213 17:00:21.440309 139806407255936 learning.py:512] global step 9376: loss = 0.0401 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9377: loss = 0.0385 (0.168 sec/step)\n",
            "I0213 17:00:21.610442 139806407255936 learning.py:512] global step 9377: loss = 0.0385 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9378: loss = 0.0410 (0.174 sec/step)\n",
            "I0213 17:00:21.785464 139806407255936 learning.py:512] global step 9378: loss = 0.0410 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9379: loss = 0.0241 (0.169 sec/step)\n",
            "I0213 17:00:21.955758 139806407255936 learning.py:512] global step 9379: loss = 0.0241 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9380: loss = 0.0339 (0.173 sec/step)\n",
            "I0213 17:00:22.129640 139806407255936 learning.py:512] global step 9380: loss = 0.0339 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9381: loss = 0.0113 (0.160 sec/step)\n",
            "I0213 17:00:22.290892 139806407255936 learning.py:512] global step 9381: loss = 0.0113 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9382: loss = 0.0173 (0.157 sec/step)\n",
            "I0213 17:00:22.449391 139806407255936 learning.py:512] global step 9382: loss = 0.0173 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9383: loss = 0.0413 (0.161 sec/step)\n",
            "I0213 17:00:22.611450 139806407255936 learning.py:512] global step 9383: loss = 0.0413 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9384: loss = 0.0283 (0.165 sec/step)\n",
            "I0213 17:00:22.777582 139806407255936 learning.py:512] global step 9384: loss = 0.0283 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9385: loss = 0.0081 (0.191 sec/step)\n",
            "I0213 17:00:22.970394 139806407255936 learning.py:512] global step 9385: loss = 0.0081 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 9386: loss = 0.0222 (0.168 sec/step)\n",
            "I0213 17:00:23.139693 139806407255936 learning.py:512] global step 9386: loss = 0.0222 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9387: loss = 0.0196 (0.176 sec/step)\n",
            "I0213 17:00:23.317648 139806407255936 learning.py:512] global step 9387: loss = 0.0196 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9388: loss = 0.0141 (0.170 sec/step)\n",
            "I0213 17:00:23.489421 139806407255936 learning.py:512] global step 9388: loss = 0.0141 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9389: loss = 0.0132 (0.169 sec/step)\n",
            "I0213 17:00:23.659853 139806407255936 learning.py:512] global step 9389: loss = 0.0132 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9390: loss = 0.0257 (0.163 sec/step)\n",
            "I0213 17:00:23.823834 139806407255936 learning.py:512] global step 9390: loss = 0.0257 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9391: loss = 0.0128 (0.167 sec/step)\n",
            "I0213 17:00:23.992141 139806407255936 learning.py:512] global step 9391: loss = 0.0128 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9392: loss = 0.0107 (0.164 sec/step)\n",
            "I0213 17:00:24.157393 139806407255936 learning.py:512] global step 9392: loss = 0.0107 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9393: loss = 0.0254 (0.167 sec/step)\n",
            "I0213 17:00:24.325433 139806407255936 learning.py:512] global step 9393: loss = 0.0254 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9394: loss = 0.0546 (0.177 sec/step)\n",
            "I0213 17:00:24.504158 139806407255936 learning.py:512] global step 9394: loss = 0.0546 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9395: loss = 0.0215 (0.168 sec/step)\n",
            "I0213 17:00:24.673286 139806407255936 learning.py:512] global step 9395: loss = 0.0215 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9396: loss = 0.0430 (0.164 sec/step)\n",
            "I0213 17:00:24.838472 139806407255936 learning.py:512] global step 9396: loss = 0.0430 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9397: loss = 0.0101 (0.178 sec/step)\n",
            "I0213 17:00:25.018118 139806407255936 learning.py:512] global step 9397: loss = 0.0101 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9398: loss = 0.0133 (0.172 sec/step)\n",
            "I0213 17:00:25.191685 139806407255936 learning.py:512] global step 9398: loss = 0.0133 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9399: loss = 0.0138 (0.182 sec/step)\n",
            "I0213 17:00:25.375387 139806407255936 learning.py:512] global step 9399: loss = 0.0138 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9400: loss = 0.0161 (0.167 sec/step)\n",
            "I0213 17:00:25.545571 139806407255936 learning.py:512] global step 9400: loss = 0.0161 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9401: loss = 0.0320 (0.171 sec/step)\n",
            "I0213 17:00:25.720320 139806407255936 learning.py:512] global step 9401: loss = 0.0320 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9402: loss = 0.0167 (0.170 sec/step)\n",
            "I0213 17:00:25.891708 139806407255936 learning.py:512] global step 9402: loss = 0.0167 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9403: loss = 0.0243 (0.168 sec/step)\n",
            "I0213 17:00:26.061540 139806407255936 learning.py:512] global step 9403: loss = 0.0243 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9404: loss = 0.0416 (0.173 sec/step)\n",
            "I0213 17:00:26.236092 139806407255936 learning.py:512] global step 9404: loss = 0.0416 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9405: loss = 0.0246 (0.173 sec/step)\n",
            "I0213 17:00:26.410554 139806407255936 learning.py:512] global step 9405: loss = 0.0246 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9406: loss = 0.0384 (0.155 sec/step)\n",
            "I0213 17:00:26.567123 139806407255936 learning.py:512] global step 9406: loss = 0.0384 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9407: loss = 0.0394 (0.173 sec/step)\n",
            "I0213 17:00:26.741144 139806407255936 learning.py:512] global step 9407: loss = 0.0394 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9408: loss = 0.0143 (0.147 sec/step)\n",
            "I0213 17:00:26.889506 139806407255936 learning.py:512] global step 9408: loss = 0.0143 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 9409: loss = 0.0133 (0.179 sec/step)\n",
            "I0213 17:00:27.070199 139806407255936 learning.py:512] global step 9409: loss = 0.0133 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9410: loss = 0.0134 (0.162 sec/step)\n",
            "I0213 17:00:27.233523 139806407255936 learning.py:512] global step 9410: loss = 0.0134 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9411: loss = 0.0569 (0.182 sec/step)\n",
            "I0213 17:00:27.416777 139806407255936 learning.py:512] global step 9411: loss = 0.0569 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9412: loss = 0.0115 (0.151 sec/step)\n",
            "I0213 17:00:27.568775 139806407255936 learning.py:512] global step 9412: loss = 0.0115 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9413: loss = 0.0193 (0.168 sec/step)\n",
            "I0213 17:00:27.738080 139806407255936 learning.py:512] global step 9413: loss = 0.0193 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9414: loss = 0.0365 (0.176 sec/step)\n",
            "I0213 17:00:27.916171 139806407255936 learning.py:512] global step 9414: loss = 0.0365 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9415: loss = 0.0229 (0.173 sec/step)\n",
            "I0213 17:00:28.090643 139806407255936 learning.py:512] global step 9415: loss = 0.0229 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9416: loss = 0.0212 (0.163 sec/step)\n",
            "I0213 17:00:28.255261 139806407255936 learning.py:512] global step 9416: loss = 0.0212 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9417: loss = 0.0162 (0.158 sec/step)\n",
            "I0213 17:00:28.414125 139806407255936 learning.py:512] global step 9417: loss = 0.0162 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9418: loss = 0.0057 (0.159 sec/step)\n",
            "I0213 17:00:28.574651 139806407255936 learning.py:512] global step 9418: loss = 0.0057 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9419: loss = 0.0210 (0.165 sec/step)\n",
            "I0213 17:00:28.741155 139806407255936 learning.py:512] global step 9419: loss = 0.0210 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9420: loss = 0.0138 (0.164 sec/step)\n",
            "I0213 17:00:28.906221 139806407255936 learning.py:512] global step 9420: loss = 0.0138 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9421: loss = 0.0337 (0.180 sec/step)\n",
            "I0213 17:00:29.087266 139806407255936 learning.py:512] global step 9421: loss = 0.0337 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9422: loss = 0.0192 (0.169 sec/step)\n",
            "I0213 17:00:29.257700 139806407255936 learning.py:512] global step 9422: loss = 0.0192 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9423: loss = 0.0191 (0.177 sec/step)\n",
            "I0213 17:00:29.436260 139806407255936 learning.py:512] global step 9423: loss = 0.0191 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9424: loss = 0.0190 (0.173 sec/step)\n",
            "I0213 17:00:29.610543 139806407255936 learning.py:512] global step 9424: loss = 0.0190 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9425: loss = 0.0050 (0.169 sec/step)\n",
            "I0213 17:00:29.781184 139806407255936 learning.py:512] global step 9425: loss = 0.0050 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9426: loss = 0.0151 (0.171 sec/step)\n",
            "I0213 17:00:29.953571 139806407255936 learning.py:512] global step 9426: loss = 0.0151 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9427: loss = 0.0180 (0.169 sec/step)\n",
            "I0213 17:00:30.123551 139806407255936 learning.py:512] global step 9427: loss = 0.0180 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9428: loss = 0.0297 (0.175 sec/step)\n",
            "I0213 17:00:30.299915 139806407255936 learning.py:512] global step 9428: loss = 0.0297 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9429: loss = 0.0397 (0.171 sec/step)\n",
            "I0213 17:00:30.471829 139806407255936 learning.py:512] global step 9429: loss = 0.0397 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9430: loss = 0.0323 (0.175 sec/step)\n",
            "I0213 17:00:30.648522 139806407255936 learning.py:512] global step 9430: loss = 0.0323 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9431: loss = 0.0123 (0.180 sec/step)\n",
            "I0213 17:00:30.829942 139806407255936 learning.py:512] global step 9431: loss = 0.0123 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9432: loss = 0.0205 (0.152 sec/step)\n",
            "I0213 17:00:30.983728 139806407255936 learning.py:512] global step 9432: loss = 0.0205 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9433: loss = 0.0229 (0.172 sec/step)\n",
            "I0213 17:00:31.156960 139806407255936 learning.py:512] global step 9433: loss = 0.0229 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9434: loss = 0.0462 (0.161 sec/step)\n",
            "I0213 17:00:31.319024 139806407255936 learning.py:512] global step 9434: loss = 0.0462 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9435: loss = 0.0315 (0.173 sec/step)\n",
            "I0213 17:00:31.493652 139806407255936 learning.py:512] global step 9435: loss = 0.0315 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9436: loss = 0.1067 (0.164 sec/step)\n",
            "I0213 17:00:31.658563 139806407255936 learning.py:512] global step 9436: loss = 0.1067 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9437: loss = 0.0601 (0.160 sec/step)\n",
            "I0213 17:00:31.820371 139806407255936 learning.py:512] global step 9437: loss = 0.0601 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9438: loss = 0.0113 (0.160 sec/step)\n",
            "I0213 17:00:31.981786 139806407255936 learning.py:512] global step 9438: loss = 0.0113 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9439: loss = 0.0470 (0.168 sec/step)\n",
            "I0213 17:00:32.151610 139806407255936 learning.py:512] global step 9439: loss = 0.0470 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9440: loss = 0.0117 (0.158 sec/step)\n",
            "I0213 17:00:32.311094 139806407255936 learning.py:512] global step 9440: loss = 0.0117 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9441: loss = 0.0127 (0.155 sec/step)\n",
            "I0213 17:00:32.467429 139806407255936 learning.py:512] global step 9441: loss = 0.0127 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9442: loss = 0.0619 (0.152 sec/step)\n",
            "I0213 17:00:32.621149 139806407255936 learning.py:512] global step 9442: loss = 0.0619 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9443: loss = 0.0759 (0.159 sec/step)\n",
            "I0213 17:00:32.781516 139806407255936 learning.py:512] global step 9443: loss = 0.0759 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9444: loss = 0.0350 (0.167 sec/step)\n",
            "I0213 17:00:32.949752 139806407255936 learning.py:512] global step 9444: loss = 0.0350 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9445: loss = 0.0273 (0.166 sec/step)\n",
            "I0213 17:00:33.117231 139806407255936 learning.py:512] global step 9445: loss = 0.0273 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9446: loss = 0.0156 (0.159 sec/step)\n",
            "I0213 17:00:33.277299 139806407255936 learning.py:512] global step 9446: loss = 0.0156 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9447: loss = 0.0178 (0.155 sec/step)\n",
            "I0213 17:00:33.433343 139806407255936 learning.py:512] global step 9447: loss = 0.0178 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9448: loss = 0.0115 (0.175 sec/step)\n",
            "I0213 17:00:33.610172 139806407255936 learning.py:512] global step 9448: loss = 0.0115 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9449: loss = 0.0304 (0.166 sec/step)\n",
            "I0213 17:00:33.777712 139806407255936 learning.py:512] global step 9449: loss = 0.0304 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9450: loss = 0.0150 (0.175 sec/step)\n",
            "I0213 17:00:33.954857 139806407255936 learning.py:512] global step 9450: loss = 0.0150 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9451: loss = 0.0204 (0.196 sec/step)\n",
            "I0213 17:00:34.152720 139806407255936 learning.py:512] global step 9451: loss = 0.0204 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9452: loss = 0.0567 (0.173 sec/step)\n",
            "I0213 17:00:34.327335 139806407255936 learning.py:512] global step 9452: loss = 0.0567 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9453: loss = 0.0371 (0.166 sec/step)\n",
            "I0213 17:00:34.494617 139806407255936 learning.py:512] global step 9453: loss = 0.0371 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9454: loss = 0.0100 (0.164 sec/step)\n",
            "I0213 17:00:34.659848 139806407255936 learning.py:512] global step 9454: loss = 0.0100 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9455: loss = 0.0416 (0.176 sec/step)\n",
            "I0213 17:00:34.837216 139806407255936 learning.py:512] global step 9455: loss = 0.0416 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9456: loss = 0.0227 (0.167 sec/step)\n",
            "I0213 17:00:35.005274 139806407255936 learning.py:512] global step 9456: loss = 0.0227 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9457: loss = 0.0077 (0.169 sec/step)\n",
            "I0213 17:00:35.175642 139806407255936 learning.py:512] global step 9457: loss = 0.0077 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9458: loss = 0.0131 (0.180 sec/step)\n",
            "I0213 17:00:35.357358 139806407255936 learning.py:512] global step 9458: loss = 0.0131 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9459: loss = 0.0225 (0.168 sec/step)\n",
            "I0213 17:00:35.526543 139806407255936 learning.py:512] global step 9459: loss = 0.0225 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9460: loss = 0.0297 (0.168 sec/step)\n",
            "I0213 17:00:35.696213 139806407255936 learning.py:512] global step 9460: loss = 0.0297 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9461: loss = 0.0170 (0.168 sec/step)\n",
            "I0213 17:00:35.865922 139806407255936 learning.py:512] global step 9461: loss = 0.0170 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9462: loss = 0.0115 (0.155 sec/step)\n",
            "I0213 17:00:36.022660 139806407255936 learning.py:512] global step 9462: loss = 0.0115 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9463: loss = 0.0138 (0.162 sec/step)\n",
            "I0213 17:00:36.186193 139806407255936 learning.py:512] global step 9463: loss = 0.0138 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9464: loss = 0.0128 (0.173 sec/step)\n",
            "I0213 17:00:36.360521 139806407255936 learning.py:512] global step 9464: loss = 0.0128 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9465: loss = 0.0366 (0.164 sec/step)\n",
            "I0213 17:00:36.526221 139806407255936 learning.py:512] global step 9465: loss = 0.0366 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9466: loss = 0.0153 (0.160 sec/step)\n",
            "I0213 17:00:36.687942 139806407255936 learning.py:512] global step 9466: loss = 0.0153 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9467: loss = 0.0083 (0.167 sec/step)\n",
            "I0213 17:00:36.855906 139806407255936 learning.py:512] global step 9467: loss = 0.0083 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9468: loss = 0.0169 (0.170 sec/step)\n",
            "I0213 17:00:37.027006 139806407255936 learning.py:512] global step 9468: loss = 0.0169 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9469: loss = 0.0188 (0.177 sec/step)\n",
            "I0213 17:00:37.205611 139806407255936 learning.py:512] global step 9469: loss = 0.0188 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9470: loss = 0.0093 (0.171 sec/step)\n",
            "I0213 17:00:37.377531 139806407255936 learning.py:512] global step 9470: loss = 0.0093 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9471: loss = 0.0121 (0.163 sec/step)\n",
            "I0213 17:00:37.541651 139806407255936 learning.py:512] global step 9471: loss = 0.0121 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9472: loss = 0.0136 (0.156 sec/step)\n",
            "I0213 17:00:37.699262 139806407255936 learning.py:512] global step 9472: loss = 0.0136 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9473: loss = 0.0101 (0.183 sec/step)\n",
            "I0213 17:00:37.883288 139806407255936 learning.py:512] global step 9473: loss = 0.0101 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9474: loss = 0.0205 (0.180 sec/step)\n",
            "I0213 17:00:38.064616 139806407255936 learning.py:512] global step 9474: loss = 0.0205 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9475: loss = 0.0312 (0.181 sec/step)\n",
            "I0213 17:00:38.246991 139806407255936 learning.py:512] global step 9475: loss = 0.0312 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9476: loss = 0.0320 (0.148 sec/step)\n",
            "I0213 17:00:38.396626 139806407255936 learning.py:512] global step 9476: loss = 0.0320 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9477: loss = 0.0197 (0.174 sec/step)\n",
            "I0213 17:00:38.572009 139806407255936 learning.py:512] global step 9477: loss = 0.0197 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9478: loss = 0.0214 (0.179 sec/step)\n",
            "I0213 17:00:38.752612 139806407255936 learning.py:512] global step 9478: loss = 0.0214 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9479: loss = 0.0129 (0.172 sec/step)\n",
            "I0213 17:00:38.925749 139806407255936 learning.py:512] global step 9479: loss = 0.0129 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9480: loss = 0.0157 (0.164 sec/step)\n",
            "I0213 17:00:39.091561 139806407255936 learning.py:512] global step 9480: loss = 0.0157 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9481: loss = 0.0205 (0.180 sec/step)\n",
            "I0213 17:00:39.272752 139806407255936 learning.py:512] global step 9481: loss = 0.0205 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9482: loss = 0.0194 (0.164 sec/step)\n",
            "I0213 17:00:39.438573 139806407255936 learning.py:512] global step 9482: loss = 0.0194 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9483: loss = 0.0359 (0.163 sec/step)\n",
            "I0213 17:00:39.603167 139806407255936 learning.py:512] global step 9483: loss = 0.0359 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9484: loss = 0.0131 (0.196 sec/step)\n",
            "I0213 17:00:39.800960 139806407255936 learning.py:512] global step 9484: loss = 0.0131 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9485: loss = 0.0430 (0.172 sec/step)\n",
            "I0213 17:00:39.974285 139806407255936 learning.py:512] global step 9485: loss = 0.0430 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9486: loss = 0.0596 (0.170 sec/step)\n",
            "I0213 17:00:40.145832 139806407255936 learning.py:512] global step 9486: loss = 0.0596 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9487: loss = 0.0351 (0.163 sec/step)\n",
            "I0213 17:00:40.310128 139806407255936 learning.py:512] global step 9487: loss = 0.0351 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9488: loss = 0.0314 (0.168 sec/step)\n",
            "I0213 17:00:40.479083 139806407255936 learning.py:512] global step 9488: loss = 0.0314 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9489: loss = 0.0314 (0.176 sec/step)\n",
            "I0213 17:00:40.655911 139806407255936 learning.py:512] global step 9489: loss = 0.0314 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9490: loss = 0.0381 (0.181 sec/step)\n",
            "I0213 17:00:40.838721 139806407255936 learning.py:512] global step 9490: loss = 0.0381 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9491: loss = 0.0173 (0.168 sec/step)\n",
            "I0213 17:00:41.007723 139806407255936 learning.py:512] global step 9491: loss = 0.0173 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9492: loss = 0.0180 (0.178 sec/step)\n",
            "I0213 17:00:41.187117 139806407255936 learning.py:512] global step 9492: loss = 0.0180 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9493: loss = 0.0325 (0.166 sec/step)\n",
            "I0213 17:00:41.354767 139806407255936 learning.py:512] global step 9493: loss = 0.0325 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9494: loss = 0.0097 (0.174 sec/step)\n",
            "I0213 17:00:41.530033 139806407255936 learning.py:512] global step 9494: loss = 0.0097 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9495: loss = 0.0674 (0.157 sec/step)\n",
            "I0213 17:00:41.688704 139806407255936 learning.py:512] global step 9495: loss = 0.0674 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9496: loss = 0.0208 (0.146 sec/step)\n",
            "I0213 17:00:41.836354 139806407255936 learning.py:512] global step 9496: loss = 0.0208 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 9497: loss = 0.0082 (0.174 sec/step)\n",
            "I0213 17:00:42.011479 139806407255936 learning.py:512] global step 9497: loss = 0.0082 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9498: loss = 0.0136 (0.173 sec/step)\n",
            "I0213 17:00:42.185982 139806407255936 learning.py:512] global step 9498: loss = 0.0136 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9499: loss = 0.0089 (0.178 sec/step)\n",
            "I0213 17:00:42.364944 139806407255936 learning.py:512] global step 9499: loss = 0.0089 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9500: loss = 0.0437 (0.161 sec/step)\n",
            "I0213 17:00:42.527771 139806407255936 learning.py:512] global step 9500: loss = 0.0437 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9501: loss = 0.0173 (0.173 sec/step)\n",
            "I0213 17:00:42.701817 139806407255936 learning.py:512] global step 9501: loss = 0.0173 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9502: loss = 0.0197 (0.180 sec/step)\n",
            "I0213 17:00:42.883479 139806407255936 learning.py:512] global step 9502: loss = 0.0197 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9503: loss = 0.0151 (0.175 sec/step)\n",
            "I0213 17:00:43.060287 139806407255936 learning.py:512] global step 9503: loss = 0.0151 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9504: loss = 0.0072 (0.179 sec/step)\n",
            "I0213 17:00:43.240589 139806407255936 learning.py:512] global step 9504: loss = 0.0072 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9505: loss = 0.0187 (0.164 sec/step)\n",
            "I0213 17:00:43.406140 139806407255936 learning.py:512] global step 9505: loss = 0.0187 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9506: loss = 0.0196 (0.155 sec/step)\n",
            "I0213 17:00:43.562598 139806407255936 learning.py:512] global step 9506: loss = 0.0196 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9507: loss = 0.0431 (0.178 sec/step)\n",
            "I0213 17:00:43.741536 139806407255936 learning.py:512] global step 9507: loss = 0.0431 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9508: loss = 0.0239 (0.179 sec/step)\n",
            "I0213 17:00:43.922214 139806407255936 learning.py:512] global step 9508: loss = 0.0239 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9509: loss = 0.0073 (0.176 sec/step)\n",
            "I0213 17:00:44.100026 139806407255936 learning.py:512] global step 9509: loss = 0.0073 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9510: loss = 0.0261 (0.172 sec/step)\n",
            "I0213 17:00:44.274253 139806407255936 learning.py:512] global step 9510: loss = 0.0261 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9511: loss = 0.0175 (0.168 sec/step)\n",
            "I0213 17:00:44.443430 139806407255936 learning.py:512] global step 9511: loss = 0.0175 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9512: loss = 0.0773 (0.178 sec/step)\n",
            "I0213 17:00:44.622756 139806407255936 learning.py:512] global step 9512: loss = 0.0773 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9513: loss = 0.0160 (0.164 sec/step)\n",
            "I0213 17:00:44.787664 139806407255936 learning.py:512] global step 9513: loss = 0.0160 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9514: loss = 0.0320 (0.164 sec/step)\n",
            "I0213 17:00:44.953735 139806407255936 learning.py:512] global step 9514: loss = 0.0320 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9515: loss = 0.0199 (0.171 sec/step)\n",
            "I0213 17:00:45.126785 139806407255936 learning.py:512] global step 9515: loss = 0.0199 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9516: loss = 0.0181 (0.175 sec/step)\n",
            "I0213 17:00:45.303432 139806407255936 learning.py:512] global step 9516: loss = 0.0181 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9517: loss = 0.0155 (0.158 sec/step)\n",
            "I0213 17:00:45.462835 139806407255936 learning.py:512] global step 9517: loss = 0.0155 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9518: loss = 0.0189 (0.171 sec/step)\n",
            "I0213 17:00:45.634831 139806407255936 learning.py:512] global step 9518: loss = 0.0189 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9519: loss = 0.0376 (0.179 sec/step)\n",
            "I0213 17:00:45.815226 139806407255936 learning.py:512] global step 9519: loss = 0.0376 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9520: loss = 0.0106 (0.177 sec/step)\n",
            "I0213 17:00:45.994186 139806407255936 learning.py:512] global step 9520: loss = 0.0106 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9521: loss = 0.0137 (0.158 sec/step)\n",
            "I0213 17:00:46.153222 139806407255936 learning.py:512] global step 9521: loss = 0.0137 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9522: loss = 0.0141 (0.181 sec/step)\n",
            "I0213 17:00:46.335637 139806407255936 learning.py:512] global step 9522: loss = 0.0141 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9523: loss = 0.0152 (0.166 sec/step)\n",
            "I0213 17:00:46.503136 139806407255936 learning.py:512] global step 9523: loss = 0.0152 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9524: loss = 0.0099 (0.163 sec/step)\n",
            "I0213 17:00:46.667634 139806407255936 learning.py:512] global step 9524: loss = 0.0099 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9525: loss = 0.0285 (0.166 sec/step)\n",
            "I0213 17:00:46.834656 139806407255936 learning.py:512] global step 9525: loss = 0.0285 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9526: loss = 0.0306 (0.166 sec/step)\n",
            "I0213 17:00:47.002025 139806407255936 learning.py:512] global step 9526: loss = 0.0306 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9527: loss = 0.0301 (0.164 sec/step)\n",
            "I0213 17:00:47.167383 139806407255936 learning.py:512] global step 9527: loss = 0.0301 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9528: loss = 0.0145 (0.164 sec/step)\n",
            "I0213 17:00:47.332844 139806407255936 learning.py:512] global step 9528: loss = 0.0145 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9529: loss = 0.0176 (0.174 sec/step)\n",
            "I0213 17:00:47.509072 139806407255936 learning.py:512] global step 9529: loss = 0.0176 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9530: loss = 0.0185 (0.170 sec/step)\n",
            "I0213 17:00:47.681071 139806407255936 learning.py:512] global step 9530: loss = 0.0185 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9531: loss = 0.0119 (0.171 sec/step)\n",
            "I0213 17:00:47.853819 139806407255936 learning.py:512] global step 9531: loss = 0.0119 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9532: loss = 0.0186 (0.163 sec/step)\n",
            "I0213 17:00:48.017899 139806407255936 learning.py:512] global step 9532: loss = 0.0186 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9533: loss = 0.0212 (0.160 sec/step)\n",
            "I0213 17:00:48.178898 139806407255936 learning.py:512] global step 9533: loss = 0.0212 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9534: loss = 0.0236 (0.179 sec/step)\n",
            "I0213 17:00:48.359561 139806407255936 learning.py:512] global step 9534: loss = 0.0236 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9535: loss = 0.0188 (0.160 sec/step)\n",
            "I0213 17:00:48.520786 139806407255936 learning.py:512] global step 9535: loss = 0.0188 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9536: loss = 0.0451 (0.154 sec/step)\n",
            "I0213 17:00:48.676401 139806407255936 learning.py:512] global step 9536: loss = 0.0451 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9537: loss = 0.0250 (0.177 sec/step)\n",
            "I0213 17:00:48.855537 139806407255936 learning.py:512] global step 9537: loss = 0.0250 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9538: loss = 0.0304 (0.156 sec/step)\n",
            "I0213 17:00:49.013394 139806407255936 learning.py:512] global step 9538: loss = 0.0304 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9539: loss = 0.0216 (0.174 sec/step)\n",
            "I0213 17:00:49.188697 139806407255936 learning.py:512] global step 9539: loss = 0.0216 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9540: loss = 0.0177 (0.178 sec/step)\n",
            "I0213 17:00:49.367835 139806407255936 learning.py:512] global step 9540: loss = 0.0177 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9541: loss = 0.0213 (0.173 sec/step)\n",
            "I0213 17:00:49.542526 139806407255936 learning.py:512] global step 9541: loss = 0.0213 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9542: loss = 0.0154 (0.186 sec/step)\n",
            "I0213 17:00:49.729979 139806407255936 learning.py:512] global step 9542: loss = 0.0154 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9543: loss = 0.0197 (0.166 sec/step)\n",
            "I0213 17:00:49.897400 139806407255936 learning.py:512] global step 9543: loss = 0.0197 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9544: loss = 0.0204 (0.169 sec/step)\n",
            "I0213 17:00:50.067966 139806407255936 learning.py:512] global step 9544: loss = 0.0204 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9545: loss = 0.0138 (0.161 sec/step)\n",
            "I0213 17:00:50.230909 139806407255936 learning.py:512] global step 9545: loss = 0.0138 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9546: loss = 0.0210 (0.190 sec/step)\n",
            "I0213 17:00:50.422556 139806407255936 learning.py:512] global step 9546: loss = 0.0210 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9547: loss = 0.0120 (0.163 sec/step)\n",
            "I0213 17:00:50.587019 139806407255936 learning.py:512] global step 9547: loss = 0.0120 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9548: loss = 0.0254 (0.171 sec/step)\n",
            "I0213 17:00:50.759518 139806407255936 learning.py:512] global step 9548: loss = 0.0254 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9549: loss = 0.0105 (0.163 sec/step)\n",
            "I0213 17:00:50.924034 139806407255936 learning.py:512] global step 9549: loss = 0.0105 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9550: loss = 0.0118 (0.168 sec/step)\n",
            "I0213 17:00:51.093242 139806407255936 learning.py:512] global step 9550: loss = 0.0118 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9551: loss = 0.0569 (0.169 sec/step)\n",
            "I0213 17:00:51.263670 139806407255936 learning.py:512] global step 9551: loss = 0.0569 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9552: loss = 0.0057 (0.163 sec/step)\n",
            "I0213 17:00:51.428362 139806407255936 learning.py:512] global step 9552: loss = 0.0057 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9553: loss = 0.0232 (0.167 sec/step)\n",
            "I0213 17:00:51.596482 139806407255936 learning.py:512] global step 9553: loss = 0.0232 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9554: loss = 0.0102 (0.186 sec/step)\n",
            "I0213 17:00:51.784610 139806407255936 learning.py:512] global step 9554: loss = 0.0102 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9555: loss = 0.0287 (0.160 sec/step)\n",
            "I0213 17:00:51.945702 139806407255936 learning.py:512] global step 9555: loss = 0.0287 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9556: loss = 0.0169 (0.163 sec/step)\n",
            "I0213 17:00:52.110565 139806407255936 learning.py:512] global step 9556: loss = 0.0169 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9557: loss = 0.0276 (0.158 sec/step)\n",
            "I0213 17:00:52.269606 139806407255936 learning.py:512] global step 9557: loss = 0.0276 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9558: loss = 0.0276 (0.168 sec/step)\n",
            "I0213 17:00:52.439953 139806407255936 learning.py:512] global step 9558: loss = 0.0276 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9559: loss = 0.0387 (0.161 sec/step)\n",
            "I0213 17:00:52.602316 139806407255936 learning.py:512] global step 9559: loss = 0.0387 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9560: loss = 0.0374 (0.167 sec/step)\n",
            "I0213 17:00:52.771095 139806407255936 learning.py:512] global step 9560: loss = 0.0374 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9561: loss = 0.0385 (0.167 sec/step)\n",
            "I0213 17:00:52.940029 139806407255936 learning.py:512] global step 9561: loss = 0.0385 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9562: loss = 0.0205 (0.168 sec/step)\n",
            "I0213 17:00:53.109605 139806407255936 learning.py:512] global step 9562: loss = 0.0205 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9563: loss = 0.0139 (0.192 sec/step)\n",
            "I0213 17:00:53.302971 139806407255936 learning.py:512] global step 9563: loss = 0.0139 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9564: loss = 0.0386 (0.171 sec/step)\n",
            "I0213 17:00:53.475493 139806407255936 learning.py:512] global step 9564: loss = 0.0386 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9565: loss = 0.0149 (0.173 sec/step)\n",
            "I0213 17:00:53.650340 139806407255936 learning.py:512] global step 9565: loss = 0.0149 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9566: loss = 0.0470 (0.176 sec/step)\n",
            "I0213 17:00:53.827989 139806407255936 learning.py:512] global step 9566: loss = 0.0470 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9567: loss = 0.0298 (0.163 sec/step)\n",
            "I0213 17:00:53.992960 139806407255936 learning.py:512] global step 9567: loss = 0.0298 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9568: loss = 0.0315 (0.165 sec/step)\n",
            "I0213 17:00:54.159796 139806407255936 learning.py:512] global step 9568: loss = 0.0315 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9569: loss = 0.0254 (0.156 sec/step)\n",
            "I0213 17:00:54.316734 139806407255936 learning.py:512] global step 9569: loss = 0.0254 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9570: loss = 0.0123 (0.189 sec/step)\n",
            "I0213 17:00:54.506666 139806407255936 learning.py:512] global step 9570: loss = 0.0123 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9571: loss = 0.0307 (0.183 sec/step)\n",
            "I0213 17:00:54.690734 139806407255936 learning.py:512] global step 9571: loss = 0.0307 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9572: loss = 0.0186 (0.165 sec/step)\n",
            "I0213 17:00:54.857243 139806407255936 learning.py:512] global step 9572: loss = 0.0186 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9573: loss = 0.0185 (0.167 sec/step)\n",
            "I0213 17:00:55.025954 139806407255936 learning.py:512] global step 9573: loss = 0.0185 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9574: loss = 0.0232 (0.162 sec/step)\n",
            "I0213 17:00:55.188924 139806407255936 learning.py:512] global step 9574: loss = 0.0232 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9575: loss = 0.0159 (0.161 sec/step)\n",
            "I0213 17:00:55.350958 139806407255936 learning.py:512] global step 9575: loss = 0.0159 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9576: loss = 0.0117 (0.172 sec/step)\n",
            "I0213 17:00:55.524479 139806407255936 learning.py:512] global step 9576: loss = 0.0117 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9577: loss = 0.0193 (0.162 sec/step)\n",
            "I0213 17:00:55.687960 139806407255936 learning.py:512] global step 9577: loss = 0.0193 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9578: loss = 0.0109 (0.170 sec/step)\n",
            "I0213 17:00:55.859044 139806407255936 learning.py:512] global step 9578: loss = 0.0109 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9579: loss = 0.0134 (0.169 sec/step)\n",
            "I0213 17:00:56.029690 139806407255936 learning.py:512] global step 9579: loss = 0.0134 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9580: loss = 0.0333 (0.168 sec/step)\n",
            "I0213 17:00:56.199147 139806407255936 learning.py:512] global step 9580: loss = 0.0333 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9581: loss = 0.0541 (0.161 sec/step)\n",
            "I0213 17:00:56.361918 139806407255936 learning.py:512] global step 9581: loss = 0.0541 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9582: loss = 0.0138 (0.189 sec/step)\n",
            "I0213 17:00:56.551766 139806407255936 learning.py:512] global step 9582: loss = 0.0138 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9583: loss = 0.0390 (0.166 sec/step)\n",
            "I0213 17:00:56.719768 139806407255936 learning.py:512] global step 9583: loss = 0.0390 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9584: loss = 0.0105 (0.172 sec/step)\n",
            "I0213 17:00:56.893286 139806407255936 learning.py:512] global step 9584: loss = 0.0105 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9585: loss = 0.0182 (0.163 sec/step)\n",
            "I0213 17:00:57.057990 139806407255936 learning.py:512] global step 9585: loss = 0.0182 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9586: loss = 0.0100 (0.188 sec/step)\n",
            "I0213 17:00:57.247292 139806407255936 learning.py:512] global step 9586: loss = 0.0100 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9587: loss = 0.0578 (0.174 sec/step)\n",
            "I0213 17:00:57.422174 139806407255936 learning.py:512] global step 9587: loss = 0.0578 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9588: loss = 0.0115 (0.193 sec/step)\n",
            "I0213 17:00:57.616934 139806407255936 learning.py:512] global step 9588: loss = 0.0115 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9589: loss = 0.0166 (0.166 sec/step)\n",
            "I0213 17:00:57.784046 139806407255936 learning.py:512] global step 9589: loss = 0.0166 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9590: loss = 0.0193 (0.171 sec/step)\n",
            "I0213 17:00:57.956392 139806407255936 learning.py:512] global step 9590: loss = 0.0193 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9591: loss = 0.0118 (0.164 sec/step)\n",
            "I0213 17:00:58.121449 139806407255936 learning.py:512] global step 9591: loss = 0.0118 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9592: loss = 0.0235 (0.161 sec/step)\n",
            "I0213 17:00:58.284114 139806407255936 learning.py:512] global step 9592: loss = 0.0235 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9593: loss = 0.0206 (0.177 sec/step)\n",
            "I0213 17:00:58.462173 139806407255936 learning.py:512] global step 9593: loss = 0.0206 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9594: loss = 0.0249 (0.170 sec/step)\n",
            "I0213 17:00:58.633129 139806407255936 learning.py:512] global step 9594: loss = 0.0249 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9595: loss = 0.0227 (0.173 sec/step)\n",
            "I0213 17:00:58.807391 139806407255936 learning.py:512] global step 9595: loss = 0.0227 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9596: loss = 0.0097 (0.172 sec/step)\n",
            "I0213 17:00:58.980547 139806407255936 learning.py:512] global step 9596: loss = 0.0097 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9597: loss = 0.0150 (0.171 sec/step)\n",
            "I0213 17:00:59.152579 139806407255936 learning.py:512] global step 9597: loss = 0.0150 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9598: loss = 0.0222 (0.168 sec/step)\n",
            "I0213 17:00:59.321689 139806407255936 learning.py:512] global step 9598: loss = 0.0222 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9599: loss = 0.0123 (0.155 sec/step)\n",
            "I0213 17:00:59.478573 139806407255936 learning.py:512] global step 9599: loss = 0.0123 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9600: loss = 0.0276 (0.168 sec/step)\n",
            "I0213 17:00:59.648141 139806407255936 learning.py:512] global step 9600: loss = 0.0276 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9601: loss = 0.0356 (0.176 sec/step)\n",
            "I0213 17:00:59.825507 139806407255936 learning.py:512] global step 9601: loss = 0.0356 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9602: loss = 0.0164 (0.176 sec/step)\n",
            "I0213 17:01:00.003232 139806407255936 learning.py:512] global step 9602: loss = 0.0164 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9603: loss = 0.0131 (0.165 sec/step)\n",
            "I0213 17:01:00.169809 139806407255936 learning.py:512] global step 9603: loss = 0.0131 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9604: loss = 0.0098 (0.168 sec/step)\n",
            "I0213 17:01:00.339600 139806407255936 learning.py:512] global step 9604: loss = 0.0098 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9605: loss = 0.0069 (0.166 sec/step)\n",
            "I0213 17:01:00.507127 139806407255936 learning.py:512] global step 9605: loss = 0.0069 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9606: loss = 0.0197 (0.170 sec/step)\n",
            "I0213 17:01:00.679232 139806407255936 learning.py:512] global step 9606: loss = 0.0197 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9607: loss = 0.0266 (0.181 sec/step)\n",
            "I0213 17:01:00.861294 139806407255936 learning.py:512] global step 9607: loss = 0.0266 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9608: loss = 0.0206 (0.171 sec/step)\n",
            "I0213 17:01:01.034075 139806407255936 learning.py:512] global step 9608: loss = 0.0206 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9609: loss = 0.0178 (0.166 sec/step)\n",
            "I0213 17:01:01.201803 139806407255936 learning.py:512] global step 9609: loss = 0.0178 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9610: loss = 0.0432 (0.169 sec/step)\n",
            "I0213 17:01:01.371755 139806407255936 learning.py:512] global step 9610: loss = 0.0432 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9611: loss = 0.1250 (0.155 sec/step)\n",
            "I0213 17:01:01.527808 139806407255936 learning.py:512] global step 9611: loss = 0.1250 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9612: loss = 0.0346 (0.186 sec/step)\n",
            "I0213 17:01:01.715230 139806407255936 learning.py:512] global step 9612: loss = 0.0346 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9613: loss = 0.0178 (0.162 sec/step)\n",
            "I0213 17:01:01.879199 139806407255936 learning.py:512] global step 9613: loss = 0.0178 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9614: loss = 0.0103 (0.160 sec/step)\n",
            "I0213 17:01:02.041246 139806407255936 learning.py:512] global step 9614: loss = 0.0103 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9615: loss = 0.0234 (0.158 sec/step)\n",
            "I0213 17:01:02.200901 139806407255936 learning.py:512] global step 9615: loss = 0.0234 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9616: loss = 0.0199 (0.174 sec/step)\n",
            "I0213 17:01:02.376646 139806407255936 learning.py:512] global step 9616: loss = 0.0199 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9617: loss = 0.0160 (0.175 sec/step)\n",
            "I0213 17:01:02.553051 139806407255936 learning.py:512] global step 9617: loss = 0.0160 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9618: loss = 0.0441 (0.168 sec/step)\n",
            "I0213 17:01:02.722358 139806407255936 learning.py:512] global step 9618: loss = 0.0441 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9619: loss = 0.0225 (0.163 sec/step)\n",
            "I0213 17:01:02.887152 139806407255936 learning.py:512] global step 9619: loss = 0.0225 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9620: loss = 0.0188 (0.168 sec/step)\n",
            "I0213 17:01:03.056385 139806407255936 learning.py:512] global step 9620: loss = 0.0188 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9621: loss = 0.0199 (0.161 sec/step)\n",
            "I0213 17:01:03.218259 139806407255936 learning.py:512] global step 9621: loss = 0.0199 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9622: loss = 0.0264 (0.176 sec/step)\n",
            "I0213 17:01:03.395980 139806407255936 learning.py:512] global step 9622: loss = 0.0264 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9623: loss = 0.0220 (0.159 sec/step)\n",
            "I0213 17:01:03.556256 139806407255936 learning.py:512] global step 9623: loss = 0.0220 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9624: loss = 0.0414 (0.180 sec/step)\n",
            "I0213 17:01:03.737264 139806407255936 learning.py:512] global step 9624: loss = 0.0414 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9625: loss = 0.0115 (0.166 sec/step)\n",
            "I0213 17:01:03.904830 139806407255936 learning.py:512] global step 9625: loss = 0.0115 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9626: loss = 0.0497 (0.161 sec/step)\n",
            "I0213 17:01:04.067484 139806407255936 learning.py:512] global step 9626: loss = 0.0497 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9627: loss = 0.0170 (0.179 sec/step)\n",
            "I0213 17:01:04.248091 139806407255936 learning.py:512] global step 9627: loss = 0.0170 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9628: loss = 0.0075 (0.156 sec/step)\n",
            "I0213 17:01:04.405527 139806407255936 learning.py:512] global step 9628: loss = 0.0075 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9629: loss = 0.0142 (0.182 sec/step)\n",
            "I0213 17:01:04.589185 139806407255936 learning.py:512] global step 9629: loss = 0.0142 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9630: loss = 0.0188 (0.176 sec/step)\n",
            "I0213 17:01:04.767137 139806407255936 learning.py:512] global step 9630: loss = 0.0188 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9631: loss = 0.0163 (0.154 sec/step)\n",
            "I0213 17:01:04.922586 139806407255936 learning.py:512] global step 9631: loss = 0.0163 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9632: loss = 0.0258 (0.165 sec/step)\n",
            "I0213 17:01:05.088723 139806407255936 learning.py:512] global step 9632: loss = 0.0258 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9633: loss = 0.0149 (0.169 sec/step)\n",
            "I0213 17:01:05.258802 139806407255936 learning.py:512] global step 9633: loss = 0.0149 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9634: loss = 0.0142 (0.171 sec/step)\n",
            "I0213 17:01:05.431116 139806407255936 learning.py:512] global step 9634: loss = 0.0142 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9635: loss = 0.0078 (0.173 sec/step)\n",
            "I0213 17:01:05.605289 139806407255936 learning.py:512] global step 9635: loss = 0.0078 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9636: loss = 0.0266 (0.166 sec/step)\n",
            "I0213 17:01:05.772964 139806407255936 learning.py:512] global step 9636: loss = 0.0266 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9637: loss = 0.0177 (0.157 sec/step)\n",
            "I0213 17:01:05.931518 139806407255936 learning.py:512] global step 9637: loss = 0.0177 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9638: loss = 0.0154 (0.176 sec/step)\n",
            "I0213 17:01:06.108525 139806407255936 learning.py:512] global step 9638: loss = 0.0154 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9639: loss = 0.0222 (0.171 sec/step)\n",
            "I0213 17:01:06.280629 139806407255936 learning.py:512] global step 9639: loss = 0.0222 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9640: loss = 0.0143 (0.187 sec/step)\n",
            "I0213 17:01:06.469260 139806407255936 learning.py:512] global step 9640: loss = 0.0143 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9641: loss = 0.0115 (0.167 sec/step)\n",
            "I0213 17:01:06.638161 139806407255936 learning.py:512] global step 9641: loss = 0.0115 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9642: loss = 0.0106 (0.184 sec/step)\n",
            "I0213 17:01:06.823457 139806407255936 learning.py:512] global step 9642: loss = 0.0106 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9643: loss = 0.0116 (0.171 sec/step)\n",
            "I0213 17:01:06.995508 139806407255936 learning.py:512] global step 9643: loss = 0.0116 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9644: loss = 0.0606 (0.175 sec/step)\n",
            "I0213 17:01:07.171806 139806407255936 learning.py:512] global step 9644: loss = 0.0606 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9645: loss = 0.0338 (0.167 sec/step)\n",
            "I0213 17:01:07.339622 139806407255936 learning.py:512] global step 9645: loss = 0.0338 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9646: loss = 0.0150 (0.165 sec/step)\n",
            "I0213 17:01:07.506048 139806407255936 learning.py:512] global step 9646: loss = 0.0150 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9647: loss = 0.0145 (0.181 sec/step)\n",
            "I0213 17:01:07.688244 139806407255936 learning.py:512] global step 9647: loss = 0.0145 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9648: loss = 0.0130 (0.163 sec/step)\n",
            "I0213 17:01:07.852327 139806407255936 learning.py:512] global step 9648: loss = 0.0130 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9649: loss = 0.0248 (0.173 sec/step)\n",
            "I0213 17:01:08.026542 139806407255936 learning.py:512] global step 9649: loss = 0.0248 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9650: loss = 0.0364 (0.176 sec/step)\n",
            "I0213 17:01:08.204230 139806407255936 learning.py:512] global step 9650: loss = 0.0364 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9651: loss = 0.0101 (0.163 sec/step)\n",
            "I0213 17:01:08.368183 139806407255936 learning.py:512] global step 9651: loss = 0.0101 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9652: loss = 0.0554 (0.157 sec/step)\n",
            "I0213 17:01:08.527119 139806407255936 learning.py:512] global step 9652: loss = 0.0554 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9653: loss = 0.0384 (0.164 sec/step)\n",
            "I0213 17:01:08.692862 139806407255936 learning.py:512] global step 9653: loss = 0.0384 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9654: loss = 0.0135 (0.170 sec/step)\n",
            "I0213 17:01:08.864182 139806407255936 learning.py:512] global step 9654: loss = 0.0135 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9655: loss = 0.0150 (0.174 sec/step)\n",
            "I0213 17:01:09.039901 139806407255936 learning.py:512] global step 9655: loss = 0.0150 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9656: loss = 0.0092 (0.174 sec/step)\n",
            "I0213 17:01:09.214792 139806407255936 learning.py:512] global step 9656: loss = 0.0092 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9657: loss = 0.0151 (0.168 sec/step)\n",
            "I0213 17:01:09.384377 139806407255936 learning.py:512] global step 9657: loss = 0.0151 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9658: loss = 0.0297 (0.165 sec/step)\n",
            "I0213 17:01:09.551092 139806407255936 learning.py:512] global step 9658: loss = 0.0297 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9659: loss = 0.0219 (0.173 sec/step)\n",
            "I0213 17:01:09.725680 139806407255936 learning.py:512] global step 9659: loss = 0.0219 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9660: loss = 0.0410 (0.165 sec/step)\n",
            "I0213 17:01:09.892689 139806407255936 learning.py:512] global step 9660: loss = 0.0410 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9661: loss = 0.0206 (0.187 sec/step)\n",
            "I0213 17:01:10.080822 139806407255936 learning.py:512] global step 9661: loss = 0.0206 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9662: loss = 0.0487 (0.170 sec/step)\n",
            "I0213 17:01:10.252129 139806407255936 learning.py:512] global step 9662: loss = 0.0487 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9663: loss = 0.0265 (0.163 sec/step)\n",
            "I0213 17:01:10.416082 139806407255936 learning.py:512] global step 9663: loss = 0.0265 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9664: loss = 0.0225 (0.181 sec/step)\n",
            "I0213 17:01:10.598255 139806407255936 learning.py:512] global step 9664: loss = 0.0225 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9665: loss = 0.0104 (0.177 sec/step)\n",
            "I0213 17:01:10.776971 139806407255936 learning.py:512] global step 9665: loss = 0.0104 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9666: loss = 0.0328 (0.172 sec/step)\n",
            "I0213 17:01:10.950061 139806407255936 learning.py:512] global step 9666: loss = 0.0328 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9667: loss = 0.0141 (0.178 sec/step)\n",
            "I0213 17:01:11.129980 139806407255936 learning.py:512] global step 9667: loss = 0.0141 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9668: loss = 0.0348 (0.161 sec/step)\n",
            "I0213 17:01:11.292027 139806407255936 learning.py:512] global step 9668: loss = 0.0348 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9669: loss = 0.0578 (0.160 sec/step)\n",
            "I0213 17:01:11.453109 139806407255936 learning.py:512] global step 9669: loss = 0.0578 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9670: loss = 0.0199 (0.166 sec/step)\n",
            "I0213 17:01:11.620452 139806407255936 learning.py:512] global step 9670: loss = 0.0199 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9671: loss = 0.0245 (0.185 sec/step)\n",
            "I0213 17:01:11.806792 139806407255936 learning.py:512] global step 9671: loss = 0.0245 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9672: loss = 0.0120 (0.170 sec/step)\n",
            "I0213 17:01:11.978092 139806407255936 learning.py:512] global step 9672: loss = 0.0120 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9673: loss = 0.0347 (0.160 sec/step)\n",
            "I0213 17:01:12.139465 139806407255936 learning.py:512] global step 9673: loss = 0.0347 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9674: loss = 0.0343 (0.160 sec/step)\n",
            "I0213 17:01:12.301447 139806407255936 learning.py:512] global step 9674: loss = 0.0343 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9675: loss = 0.0328 (0.168 sec/step)\n",
            "I0213 17:01:12.471170 139806407255936 learning.py:512] global step 9675: loss = 0.0328 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9676: loss = 0.0165 (0.177 sec/step)\n",
            "I0213 17:01:12.649487 139806407255936 learning.py:512] global step 9676: loss = 0.0165 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9677: loss = 0.0119 (0.173 sec/step)\n",
            "I0213 17:01:12.823633 139806407255936 learning.py:512] global step 9677: loss = 0.0119 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9678: loss = 0.0311 (0.163 sec/step)\n",
            "I0213 17:01:12.987866 139806407255936 learning.py:512] global step 9678: loss = 0.0311 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9679: loss = 0.0090 (0.161 sec/step)\n",
            "I0213 17:01:13.150399 139806407255936 learning.py:512] global step 9679: loss = 0.0090 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9680: loss = 0.0143 (0.178 sec/step)\n",
            "I0213 17:01:13.329743 139806407255936 learning.py:512] global step 9680: loss = 0.0143 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9681: loss = 0.0231 (0.166 sec/step)\n",
            "I0213 17:01:13.497565 139806407255936 learning.py:512] global step 9681: loss = 0.0231 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9682: loss = 0.0107 (0.154 sec/step)\n",
            "I0213 17:01:13.659568 139806407255936 learning.py:512] global step 9682: loss = 0.0107 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9683: loss = 0.0101 (0.172 sec/step)\n",
            "I0213 17:01:13.834313 139806407255936 learning.py:512] global step 9683: loss = 0.0101 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9684: loss = 0.0113 (0.174 sec/step)\n",
            "I0213 17:01:14.009504 139806407255936 learning.py:512] global step 9684: loss = 0.0113 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9685: loss = 0.0117 (0.175 sec/step)\n",
            "I0213 17:01:14.185983 139806407255936 learning.py:512] global step 9685: loss = 0.0117 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9686: loss = 0.0370 (0.183 sec/step)\n",
            "I0213 17:01:14.369902 139806407255936 learning.py:512] global step 9686: loss = 0.0370 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9687: loss = 0.0085 (0.179 sec/step)\n",
            "I0213 17:01:14.549975 139806407255936 learning.py:512] global step 9687: loss = 0.0085 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9688: loss = 0.0105 (0.175 sec/step)\n",
            "I0213 17:01:14.725950 139806407255936 learning.py:512] global step 9688: loss = 0.0105 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9689: loss = 0.0168 (0.163 sec/step)\n",
            "I0213 17:01:14.890350 139806407255936 learning.py:512] global step 9689: loss = 0.0168 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9690: loss = 0.0238 (0.157 sec/step)\n",
            "I0213 17:01:15.048671 139806407255936 learning.py:512] global step 9690: loss = 0.0238 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9691: loss = 0.0416 (0.158 sec/step)\n",
            "I0213 17:01:15.208069 139806407255936 learning.py:512] global step 9691: loss = 0.0416 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9692: loss = 0.0133 (0.164 sec/step)\n",
            "I0213 17:01:15.373597 139806407255936 learning.py:512] global step 9692: loss = 0.0133 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9693: loss = 0.0304 (0.161 sec/step)\n",
            "I0213 17:01:15.536043 139806407255936 learning.py:512] global step 9693: loss = 0.0304 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9694: loss = 0.0362 (0.192 sec/step)\n",
            "I0213 17:01:15.729099 139806407255936 learning.py:512] global step 9694: loss = 0.0362 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9695: loss = 0.0132 (0.177 sec/step)\n",
            "I0213 17:01:15.907377 139806407255936 learning.py:512] global step 9695: loss = 0.0132 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9696: loss = 0.0249 (0.179 sec/step)\n",
            "I0213 17:01:16.087385 139806407255936 learning.py:512] global step 9696: loss = 0.0249 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9697: loss = 0.0185 (0.175 sec/step)\n",
            "I0213 17:01:16.263637 139806407255936 learning.py:512] global step 9697: loss = 0.0185 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9698: loss = 0.0118 (0.181 sec/step)\n",
            "I0213 17:01:16.446453 139806407255936 learning.py:512] global step 9698: loss = 0.0118 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9699: loss = 0.0155 (0.167 sec/step)\n",
            "I0213 17:01:16.614451 139806407255936 learning.py:512] global step 9699: loss = 0.0155 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9700: loss = 0.0257 (0.175 sec/step)\n",
            "I0213 17:01:16.791362 139806407255936 learning.py:512] global step 9700: loss = 0.0257 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9701: loss = 0.0143 (0.166 sec/step)\n",
            "I0213 17:01:16.959063 139806407255936 learning.py:512] global step 9701: loss = 0.0143 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9702: loss = 0.0441 (0.172 sec/step)\n",
            "I0213 17:01:17.132067 139806407255936 learning.py:512] global step 9702: loss = 0.0441 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9703: loss = 0.0330 (0.170 sec/step)\n",
            "I0213 17:01:17.303543 139806407255936 learning.py:512] global step 9703: loss = 0.0330 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9704: loss = 0.0157 (0.192 sec/step)\n",
            "I0213 17:01:17.497379 139806407255936 learning.py:512] global step 9704: loss = 0.0157 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9705: loss = 0.0112 (0.151 sec/step)\n",
            "I0213 17:01:17.650293 139806407255936 learning.py:512] global step 9705: loss = 0.0112 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9706: loss = 0.0382 (0.168 sec/step)\n",
            "I0213 17:01:17.819937 139806407255936 learning.py:512] global step 9706: loss = 0.0382 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9707: loss = 0.0162 (0.150 sec/step)\n",
            "I0213 17:01:17.970835 139806407255936 learning.py:512] global step 9707: loss = 0.0162 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 9708: loss = 0.0246 (0.161 sec/step)\n",
            "I0213 17:01:18.133314 139806407255936 learning.py:512] global step 9708: loss = 0.0246 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9709: loss = 0.0698 (0.163 sec/step)\n",
            "I0213 17:01:18.297229 139806407255936 learning.py:512] global step 9709: loss = 0.0698 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9710: loss = 0.0120 (0.168 sec/step)\n",
            "I0213 17:01:18.466218 139806407255936 learning.py:512] global step 9710: loss = 0.0120 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9711: loss = 0.0208 (0.161 sec/step)\n",
            "I0213 17:01:18.628629 139806407255936 learning.py:512] global step 9711: loss = 0.0208 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9712: loss = 0.0177 (0.173 sec/step)\n",
            "I0213 17:01:18.803020 139806407255936 learning.py:512] global step 9712: loss = 0.0177 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9713: loss = 0.0155 (0.162 sec/step)\n",
            "I0213 17:01:18.966534 139806407255936 learning.py:512] global step 9713: loss = 0.0155 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9714: loss = 0.0189 (0.161 sec/step)\n",
            "I0213 17:01:19.129281 139806407255936 learning.py:512] global step 9714: loss = 0.0189 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9715: loss = 0.0139 (0.182 sec/step)\n",
            "I0213 17:01:19.312541 139806407255936 learning.py:512] global step 9715: loss = 0.0139 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9716: loss = 0.0132 (0.156 sec/step)\n",
            "I0213 17:01:19.469513 139806407255936 learning.py:512] global step 9716: loss = 0.0132 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9717: loss = 0.2199 (0.173 sec/step)\n",
            "I0213 17:01:19.644184 139806407255936 learning.py:512] global step 9717: loss = 0.2199 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9718: loss = 0.0285 (0.154 sec/step)\n",
            "I0213 17:01:19.799192 139806407255936 learning.py:512] global step 9718: loss = 0.0285 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9719: loss = 0.0914 (0.158 sec/step)\n",
            "I0213 17:01:19.959041 139806407255936 learning.py:512] global step 9719: loss = 0.0914 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9720: loss = 0.0362 (0.156 sec/step)\n",
            "I0213 17:01:20.116621 139806407255936 learning.py:512] global step 9720: loss = 0.0362 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9721: loss = 0.0872 (0.161 sec/step)\n",
            "I0213 17:01:20.278589 139806407255936 learning.py:512] global step 9721: loss = 0.0872 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9722: loss = 0.0922 (0.162 sec/step)\n",
            "I0213 17:01:20.442148 139806407255936 learning.py:512] global step 9722: loss = 0.0922 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9723: loss = 0.0395 (0.168 sec/step)\n",
            "I0213 17:01:20.611133 139806407255936 learning.py:512] global step 9723: loss = 0.0395 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9724: loss = 0.0278 (0.159 sec/step)\n",
            "I0213 17:01:20.771844 139806407255936 learning.py:512] global step 9724: loss = 0.0278 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9725: loss = 0.0196 (0.167 sec/step)\n",
            "I0213 17:01:20.940522 139806407255936 learning.py:512] global step 9725: loss = 0.0196 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9726: loss = 0.0218 (0.277 sec/step)\n",
            "I0213 17:01:21.397650 139806407255936 learning.py:512] global step 9726: loss = 0.0218 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 9727: loss = 0.0149 (0.284 sec/step)\n",
            "I0213 17:01:21.683587 139806407255936 learning.py:512] global step 9727: loss = 0.0149 (0.284 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9727.\n",
            "I0213 17:01:21.782159 139802720151296 supervisor.py:1050] Recording summary at step 9727.\n",
            "INFO:tensorflow:global step 9728: loss = 0.0190 (0.209 sec/step)\n",
            "I0213 17:01:21.894256 139806407255936 learning.py:512] global step 9728: loss = 0.0190 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 9729: loss = 0.0151 (0.166 sec/step)\n",
            "I0213 17:01:22.062092 139806407255936 learning.py:512] global step 9729: loss = 0.0151 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9730: loss = 0.0482 (0.178 sec/step)\n",
            "I0213 17:01:22.241762 139806407255936 learning.py:512] global step 9730: loss = 0.0482 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9731: loss = 0.0727 (0.183 sec/step)\n",
            "I0213 17:01:22.425991 139806407255936 learning.py:512] global step 9731: loss = 0.0727 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9732: loss = 0.0199 (0.179 sec/step)\n",
            "I0213 17:01:22.606132 139806407255936 learning.py:512] global step 9732: loss = 0.0199 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9733: loss = 0.0298 (0.162 sec/step)\n",
            "I0213 17:01:22.769320 139806407255936 learning.py:512] global step 9733: loss = 0.0298 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9734: loss = 0.0298 (0.181 sec/step)\n",
            "I0213 17:01:22.952136 139806407255936 learning.py:512] global step 9734: loss = 0.0298 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9735: loss = 0.0249 (0.164 sec/step)\n",
            "I0213 17:01:23.117577 139806407255936 learning.py:512] global step 9735: loss = 0.0249 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9736: loss = 0.0136 (0.161 sec/step)\n",
            "I0213 17:01:23.279554 139806407255936 learning.py:512] global step 9736: loss = 0.0136 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9737: loss = 0.0283 (0.177 sec/step)\n",
            "I0213 17:01:23.457968 139806407255936 learning.py:512] global step 9737: loss = 0.0283 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9738: loss = 0.0302 (0.169 sec/step)\n",
            "I0213 17:01:23.628679 139806407255936 learning.py:512] global step 9738: loss = 0.0302 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9739: loss = 0.0640 (0.187 sec/step)\n",
            "I0213 17:01:23.817770 139806407255936 learning.py:512] global step 9739: loss = 0.0640 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9740: loss = 0.0292 (0.177 sec/step)\n",
            "I0213 17:01:23.996774 139806407255936 learning.py:512] global step 9740: loss = 0.0292 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9741: loss = 0.0204 (0.163 sec/step)\n",
            "I0213 17:01:24.161040 139806407255936 learning.py:512] global step 9741: loss = 0.0204 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9742: loss = 0.0175 (0.166 sec/step)\n",
            "I0213 17:01:24.328475 139806407255936 learning.py:512] global step 9742: loss = 0.0175 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9743: loss = 0.0098 (0.172 sec/step)\n",
            "I0213 17:01:24.501878 139806407255936 learning.py:512] global step 9743: loss = 0.0098 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9744: loss = 0.0159 (0.161 sec/step)\n",
            "I0213 17:01:24.664956 139806407255936 learning.py:512] global step 9744: loss = 0.0159 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9745: loss = 0.0094 (0.177 sec/step)\n",
            "I0213 17:01:24.843133 139806407255936 learning.py:512] global step 9745: loss = 0.0094 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9746: loss = 0.0250 (0.164 sec/step)\n",
            "I0213 17:01:25.009022 139806407255936 learning.py:512] global step 9746: loss = 0.0250 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9747: loss = 0.0125 (0.161 sec/step)\n",
            "I0213 17:01:25.171836 139806407255936 learning.py:512] global step 9747: loss = 0.0125 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9748: loss = 0.0200 (0.165 sec/step)\n",
            "I0213 17:01:25.338680 139806407255936 learning.py:512] global step 9748: loss = 0.0200 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9749: loss = 0.0381 (0.160 sec/step)\n",
            "I0213 17:01:25.500392 139806407255936 learning.py:512] global step 9749: loss = 0.0381 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9750: loss = 0.0243 (0.169 sec/step)\n",
            "I0213 17:01:25.670634 139806407255936 learning.py:512] global step 9750: loss = 0.0243 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9751: loss = 0.0194 (0.174 sec/step)\n",
            "I0213 17:01:25.845937 139806407255936 learning.py:512] global step 9751: loss = 0.0194 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9752: loss = 0.0172 (0.172 sec/step)\n",
            "I0213 17:01:26.020037 139806407255936 learning.py:512] global step 9752: loss = 0.0172 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9753: loss = 0.0252 (0.174 sec/step)\n",
            "I0213 17:01:26.195035 139806407255936 learning.py:512] global step 9753: loss = 0.0252 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9754: loss = 0.0256 (0.164 sec/step)\n",
            "I0213 17:01:26.360388 139806407255936 learning.py:512] global step 9754: loss = 0.0256 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9755: loss = 0.0438 (0.180 sec/step)\n",
            "I0213 17:01:26.541650 139806407255936 learning.py:512] global step 9755: loss = 0.0438 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9756: loss = 0.0438 (0.161 sec/step)\n",
            "I0213 17:01:26.704111 139806407255936 learning.py:512] global step 9756: loss = 0.0438 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9757: loss = 0.0143 (0.171 sec/step)\n",
            "I0213 17:01:26.876696 139806407255936 learning.py:512] global step 9757: loss = 0.0143 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9758: loss = 0.0122 (0.170 sec/step)\n",
            "I0213 17:01:27.047848 139806407255936 learning.py:512] global step 9758: loss = 0.0122 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9759: loss = 0.0203 (0.159 sec/step)\n",
            "I0213 17:01:27.207743 139806407255936 learning.py:512] global step 9759: loss = 0.0203 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9760: loss = 0.0152 (0.163 sec/step)\n",
            "I0213 17:01:27.371694 139806407255936 learning.py:512] global step 9760: loss = 0.0152 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9761: loss = 0.0390 (0.188 sec/step)\n",
            "I0213 17:01:27.561133 139806407255936 learning.py:512] global step 9761: loss = 0.0390 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9762: loss = 0.0317 (0.162 sec/step)\n",
            "I0213 17:01:27.724995 139806407255936 learning.py:512] global step 9762: loss = 0.0317 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9763: loss = 0.0165 (0.172 sec/step)\n",
            "I0213 17:01:27.898476 139806407255936 learning.py:512] global step 9763: loss = 0.0165 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9764: loss = 0.0308 (0.159 sec/step)\n",
            "I0213 17:01:28.058627 139806407255936 learning.py:512] global step 9764: loss = 0.0308 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9765: loss = 0.0553 (0.165 sec/step)\n",
            "I0213 17:01:28.225279 139806407255936 learning.py:512] global step 9765: loss = 0.0553 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9766: loss = 0.0207 (0.162 sec/step)\n",
            "I0213 17:01:28.388809 139806407255936 learning.py:512] global step 9766: loss = 0.0207 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9767: loss = 0.0081 (0.174 sec/step)\n",
            "I0213 17:01:28.564508 139806407255936 learning.py:512] global step 9767: loss = 0.0081 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9768: loss = 0.0087 (0.176 sec/step)\n",
            "I0213 17:01:28.741663 139806407255936 learning.py:512] global step 9768: loss = 0.0087 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9769: loss = 0.0149 (0.167 sec/step)\n",
            "I0213 17:01:28.909576 139806407255936 learning.py:512] global step 9769: loss = 0.0149 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9770: loss = 0.0450 (0.178 sec/step)\n",
            "I0213 17:01:29.088752 139806407255936 learning.py:512] global step 9770: loss = 0.0450 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9771: loss = 0.0368 (0.167 sec/step)\n",
            "I0213 17:01:29.257246 139806407255936 learning.py:512] global step 9771: loss = 0.0368 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9772: loss = 0.0394 (0.167 sec/step)\n",
            "I0213 17:01:29.425514 139806407255936 learning.py:512] global step 9772: loss = 0.0394 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9773: loss = 0.0350 (0.165 sec/step)\n",
            "I0213 17:01:29.592247 139806407255936 learning.py:512] global step 9773: loss = 0.0350 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9774: loss = 0.0131 (0.174 sec/step)\n",
            "I0213 17:01:29.767815 139806407255936 learning.py:512] global step 9774: loss = 0.0131 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9775: loss = 0.0101 (0.187 sec/step)\n",
            "I0213 17:01:29.956090 139806407255936 learning.py:512] global step 9775: loss = 0.0101 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9776: loss = 0.0202 (0.161 sec/step)\n",
            "I0213 17:01:30.118485 139806407255936 learning.py:512] global step 9776: loss = 0.0202 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9777: loss = 0.0306 (0.176 sec/step)\n",
            "I0213 17:01:30.295626 139806407255936 learning.py:512] global step 9777: loss = 0.0306 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9778: loss = 0.0543 (0.160 sec/step)\n",
            "I0213 17:01:30.457507 139806407255936 learning.py:512] global step 9778: loss = 0.0543 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9779: loss = 0.0428 (0.161 sec/step)\n",
            "I0213 17:01:30.620249 139806407255936 learning.py:512] global step 9779: loss = 0.0428 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9780: loss = 0.0309 (0.159 sec/step)\n",
            "I0213 17:01:30.781642 139806407255936 learning.py:512] global step 9780: loss = 0.0309 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9781: loss = 0.0273 (0.172 sec/step)\n",
            "I0213 17:01:30.955636 139806407255936 learning.py:512] global step 9781: loss = 0.0273 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9782: loss = 0.0161 (0.152 sec/step)\n",
            "I0213 17:01:31.109362 139806407255936 learning.py:512] global step 9782: loss = 0.0161 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9783: loss = 0.0145 (0.180 sec/step)\n",
            "I0213 17:01:31.290278 139806407255936 learning.py:512] global step 9783: loss = 0.0145 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9784: loss = 0.0232 (0.166 sec/step)\n",
            "I0213 17:01:31.457994 139806407255936 learning.py:512] global step 9784: loss = 0.0232 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9785: loss = 0.0083 (0.165 sec/step)\n",
            "I0213 17:01:31.624327 139806407255936 learning.py:512] global step 9785: loss = 0.0083 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9786: loss = 0.0301 (0.164 sec/step)\n",
            "I0213 17:01:31.789706 139806407255936 learning.py:512] global step 9786: loss = 0.0301 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9787: loss = 0.0298 (0.161 sec/step)\n",
            "I0213 17:01:31.952624 139806407255936 learning.py:512] global step 9787: loss = 0.0298 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9788: loss = 0.0197 (0.173 sec/step)\n",
            "I0213 17:01:32.127281 139806407255936 learning.py:512] global step 9788: loss = 0.0197 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9789: loss = 0.0311 (0.160 sec/step)\n",
            "I0213 17:01:32.288629 139806407255936 learning.py:512] global step 9789: loss = 0.0311 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9790: loss = 0.0444 (0.165 sec/step)\n",
            "I0213 17:01:32.455106 139806407255936 learning.py:512] global step 9790: loss = 0.0444 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9791: loss = 0.0243 (0.164 sec/step)\n",
            "I0213 17:01:32.620327 139806407255936 learning.py:512] global step 9791: loss = 0.0243 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9792: loss = 0.0229 (0.162 sec/step)\n",
            "I0213 17:01:32.783735 139806407255936 learning.py:512] global step 9792: loss = 0.0229 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9793: loss = 0.0126 (0.177 sec/step)\n",
            "I0213 17:01:32.962659 139806407255936 learning.py:512] global step 9793: loss = 0.0126 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9794: loss = 0.0071 (0.172 sec/step)\n",
            "I0213 17:01:33.136177 139806407255936 learning.py:512] global step 9794: loss = 0.0071 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9795: loss = 0.0226 (0.166 sec/step)\n",
            "I0213 17:01:33.303683 139806407255936 learning.py:512] global step 9795: loss = 0.0226 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9796: loss = 0.0283 (0.169 sec/step)\n",
            "I0213 17:01:33.474220 139806407255936 learning.py:512] global step 9796: loss = 0.0283 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9797: loss = 0.0387 (0.166 sec/step)\n",
            "I0213 17:01:33.641782 139806407255936 learning.py:512] global step 9797: loss = 0.0387 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9798: loss = 0.0419 (0.163 sec/step)\n",
            "I0213 17:01:33.807026 139806407255936 learning.py:512] global step 9798: loss = 0.0419 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9799: loss = 0.0176 (0.170 sec/step)\n",
            "I0213 17:01:33.978659 139806407255936 learning.py:512] global step 9799: loss = 0.0176 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9800: loss = 0.0114 (0.158 sec/step)\n",
            "I0213 17:01:34.138077 139806407255936 learning.py:512] global step 9800: loss = 0.0114 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9801: loss = 0.0162 (0.158 sec/step)\n",
            "I0213 17:01:34.297714 139806407255936 learning.py:512] global step 9801: loss = 0.0162 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9802: loss = 0.0103 (0.187 sec/step)\n",
            "I0213 17:01:34.485653 139806407255936 learning.py:512] global step 9802: loss = 0.0103 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9803: loss = 0.0505 (0.157 sec/step)\n",
            "I0213 17:01:34.644597 139806407255936 learning.py:512] global step 9803: loss = 0.0505 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9804: loss = 0.0349 (0.161 sec/step)\n",
            "I0213 17:01:34.806940 139806407255936 learning.py:512] global step 9804: loss = 0.0349 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9805: loss = 0.0154 (0.196 sec/step)\n",
            "I0213 17:01:35.004271 139806407255936 learning.py:512] global step 9805: loss = 0.0154 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9806: loss = 0.0266 (0.165 sec/step)\n",
            "I0213 17:01:35.170595 139806407255936 learning.py:512] global step 9806: loss = 0.0266 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9807: loss = 0.0150 (0.154 sec/step)\n",
            "I0213 17:01:35.325962 139806407255936 learning.py:512] global step 9807: loss = 0.0150 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9808: loss = 0.0317 (0.165 sec/step)\n",
            "I0213 17:01:35.492163 139806407255936 learning.py:512] global step 9808: loss = 0.0317 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9809: loss = 0.0550 (0.160 sec/step)\n",
            "I0213 17:01:35.653445 139806407255936 learning.py:512] global step 9809: loss = 0.0550 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9810: loss = 0.0269 (0.173 sec/step)\n",
            "I0213 17:01:35.827771 139806407255936 learning.py:512] global step 9810: loss = 0.0269 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9811: loss = 0.0174 (0.178 sec/step)\n",
            "I0213 17:01:36.007344 139806407255936 learning.py:512] global step 9811: loss = 0.0174 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9812: loss = 0.0206 (0.161 sec/step)\n",
            "I0213 17:01:36.170278 139806407255936 learning.py:512] global step 9812: loss = 0.0206 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9813: loss = 0.0239 (0.154 sec/step)\n",
            "I0213 17:01:36.325444 139806407255936 learning.py:512] global step 9813: loss = 0.0239 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9814: loss = 0.0329 (0.166 sec/step)\n",
            "I0213 17:01:36.492843 139806407255936 learning.py:512] global step 9814: loss = 0.0329 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9815: loss = 0.0154 (0.170 sec/step)\n",
            "I0213 17:01:36.664767 139806407255936 learning.py:512] global step 9815: loss = 0.0154 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9816: loss = 0.0185 (0.176 sec/step)\n",
            "I0213 17:01:36.842378 139806407255936 learning.py:512] global step 9816: loss = 0.0185 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9817: loss = 0.0146 (0.173 sec/step)\n",
            "I0213 17:01:37.017163 139806407255936 learning.py:512] global step 9817: loss = 0.0146 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9818: loss = 0.0258 (0.179 sec/step)\n",
            "I0213 17:01:37.197764 139806407255936 learning.py:512] global step 9818: loss = 0.0258 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9819: loss = 0.0227 (0.170 sec/step)\n",
            "I0213 17:01:37.369157 139806407255936 learning.py:512] global step 9819: loss = 0.0227 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9820: loss = 0.0215 (0.165 sec/step)\n",
            "I0213 17:01:37.535558 139806407255936 learning.py:512] global step 9820: loss = 0.0215 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9821: loss = 0.0223 (0.172 sec/step)\n",
            "I0213 17:01:37.709350 139806407255936 learning.py:512] global step 9821: loss = 0.0223 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9822: loss = 0.0708 (0.170 sec/step)\n",
            "I0213 17:01:37.880933 139806407255936 learning.py:512] global step 9822: loss = 0.0708 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9823: loss = 0.0222 (0.154 sec/step)\n",
            "I0213 17:01:38.037016 139806407255936 learning.py:512] global step 9823: loss = 0.0222 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9824: loss = 0.0300 (0.172 sec/step)\n",
            "I0213 17:01:38.210022 139806407255936 learning.py:512] global step 9824: loss = 0.0300 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9825: loss = 0.0161 (0.163 sec/step)\n",
            "I0213 17:01:38.374837 139806407255936 learning.py:512] global step 9825: loss = 0.0161 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9826: loss = 0.0258 (0.157 sec/step)\n",
            "I0213 17:01:38.533346 139806407255936 learning.py:512] global step 9826: loss = 0.0258 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9827: loss = 0.0412 (0.183 sec/step)\n",
            "I0213 17:01:38.718093 139806407255936 learning.py:512] global step 9827: loss = 0.0412 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9828: loss = 0.0236 (0.171 sec/step)\n",
            "I0213 17:01:38.889978 139806407255936 learning.py:512] global step 9828: loss = 0.0236 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9829: loss = 0.0093 (0.174 sec/step)\n",
            "I0213 17:01:39.065432 139806407255936 learning.py:512] global step 9829: loss = 0.0093 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9830: loss = 0.0167 (0.165 sec/step)\n",
            "I0213 17:01:39.231514 139806407255936 learning.py:512] global step 9830: loss = 0.0167 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9831: loss = 0.0122 (0.170 sec/step)\n",
            "I0213 17:01:39.402865 139806407255936 learning.py:512] global step 9831: loss = 0.0122 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9832: loss = 0.0344 (0.163 sec/step)\n",
            "I0213 17:01:39.567474 139806407255936 learning.py:512] global step 9832: loss = 0.0344 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9833: loss = 0.0306 (0.185 sec/step)\n",
            "I0213 17:01:39.754227 139806407255936 learning.py:512] global step 9833: loss = 0.0306 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9834: loss = 0.0309 (0.166 sec/step)\n",
            "I0213 17:01:39.921617 139806407255936 learning.py:512] global step 9834: loss = 0.0309 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9835: loss = 0.0268 (0.186 sec/step)\n",
            "I0213 17:01:40.108499 139806407255936 learning.py:512] global step 9835: loss = 0.0268 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9836: loss = 0.0219 (0.165 sec/step)\n",
            "I0213 17:01:40.275055 139806407255936 learning.py:512] global step 9836: loss = 0.0219 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9837: loss = 0.0174 (0.166 sec/step)\n",
            "I0213 17:01:40.442662 139806407255936 learning.py:512] global step 9837: loss = 0.0174 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9838: loss = 0.0363 (0.166 sec/step)\n",
            "I0213 17:01:40.610118 139806407255936 learning.py:512] global step 9838: loss = 0.0363 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9839: loss = 0.0265 (0.179 sec/step)\n",
            "I0213 17:01:40.790565 139806407255936 learning.py:512] global step 9839: loss = 0.0265 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9840: loss = 0.0209 (0.171 sec/step)\n",
            "I0213 17:01:40.962479 139806407255936 learning.py:512] global step 9840: loss = 0.0209 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9841: loss = 0.0401 (0.174 sec/step)\n",
            "I0213 17:01:41.138156 139806407255936 learning.py:512] global step 9841: loss = 0.0401 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9842: loss = 0.0123 (0.167 sec/step)\n",
            "I0213 17:01:41.306512 139806407255936 learning.py:512] global step 9842: loss = 0.0123 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9843: loss = 0.0158 (0.163 sec/step)\n",
            "I0213 17:01:41.471108 139806407255936 learning.py:512] global step 9843: loss = 0.0158 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9844: loss = 0.0324 (0.183 sec/step)\n",
            "I0213 17:01:41.655095 139806407255936 learning.py:512] global step 9844: loss = 0.0324 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9845: loss = 0.0214 (0.155 sec/step)\n",
            "I0213 17:01:41.811671 139806407255936 learning.py:512] global step 9845: loss = 0.0214 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9846: loss = 0.0494 (0.174 sec/step)\n",
            "I0213 17:01:41.987176 139806407255936 learning.py:512] global step 9846: loss = 0.0494 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9847: loss = 0.0134 (0.170 sec/step)\n",
            "I0213 17:01:42.158267 139806407255936 learning.py:512] global step 9847: loss = 0.0134 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9848: loss = 0.0273 (0.162 sec/step)\n",
            "I0213 17:01:42.321432 139806407255936 learning.py:512] global step 9848: loss = 0.0273 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9849: loss = 0.0385 (0.166 sec/step)\n",
            "I0213 17:01:42.488459 139806407255936 learning.py:512] global step 9849: loss = 0.0385 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9850: loss = 0.0193 (0.159 sec/step)\n",
            "I0213 17:01:42.649039 139806407255936 learning.py:512] global step 9850: loss = 0.0193 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9851: loss = 0.0083 (0.178 sec/step)\n",
            "I0213 17:01:42.828193 139806407255936 learning.py:512] global step 9851: loss = 0.0083 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9852: loss = 0.0419 (0.163 sec/step)\n",
            "I0213 17:01:42.993136 139806407255936 learning.py:512] global step 9852: loss = 0.0419 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9853: loss = 0.0684 (0.171 sec/step)\n",
            "I0213 17:01:43.165102 139806407255936 learning.py:512] global step 9853: loss = 0.0684 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9854: loss = 0.0474 (0.161 sec/step)\n",
            "I0213 17:01:43.327802 139806407255936 learning.py:512] global step 9854: loss = 0.0474 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9855: loss = 0.0237 (0.173 sec/step)\n",
            "I0213 17:01:43.502212 139806407255936 learning.py:512] global step 9855: loss = 0.0237 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9856: loss = 0.0549 (0.155 sec/step)\n",
            "I0213 17:01:43.659000 139806407255936 learning.py:512] global step 9856: loss = 0.0549 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9857: loss = 0.0180 (0.181 sec/step)\n",
            "I0213 17:01:43.841459 139806407255936 learning.py:512] global step 9857: loss = 0.0180 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9858: loss = 0.0109 (0.179 sec/step)\n",
            "I0213 17:01:44.021769 139806407255936 learning.py:512] global step 9858: loss = 0.0109 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9859: loss = 0.0661 (0.168 sec/step)\n",
            "I0213 17:01:44.191637 139806407255936 learning.py:512] global step 9859: loss = 0.0661 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9860: loss = 0.0264 (0.162 sec/step)\n",
            "I0213 17:01:44.355020 139806407255936 learning.py:512] global step 9860: loss = 0.0264 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9861: loss = 0.0098 (0.156 sec/step)\n",
            "I0213 17:01:44.512517 139806407255936 learning.py:512] global step 9861: loss = 0.0098 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9862: loss = 0.0259 (0.164 sec/step)\n",
            "I0213 17:01:44.678125 139806407255936 learning.py:512] global step 9862: loss = 0.0259 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9863: loss = 0.0187 (0.166 sec/step)\n",
            "I0213 17:01:44.845458 139806407255936 learning.py:512] global step 9863: loss = 0.0187 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9864: loss = 0.0405 (0.182 sec/step)\n",
            "I0213 17:01:45.028654 139806407255936 learning.py:512] global step 9864: loss = 0.0405 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9865: loss = 0.0277 (0.178 sec/step)\n",
            "I0213 17:01:45.208104 139806407255936 learning.py:512] global step 9865: loss = 0.0277 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9866: loss = 0.0472 (0.174 sec/step)\n",
            "I0213 17:01:45.383785 139806407255936 learning.py:512] global step 9866: loss = 0.0472 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9867: loss = 0.0291 (0.165 sec/step)\n",
            "I0213 17:01:45.549837 139806407255936 learning.py:512] global step 9867: loss = 0.0291 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9868: loss = 0.0248 (0.163 sec/step)\n",
            "I0213 17:01:45.714144 139806407255936 learning.py:512] global step 9868: loss = 0.0248 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9869: loss = 0.0166 (0.169 sec/step)\n",
            "I0213 17:01:45.884840 139806407255936 learning.py:512] global step 9869: loss = 0.0166 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9870: loss = 0.0099 (0.174 sec/step)\n",
            "I0213 17:01:46.060454 139806407255936 learning.py:512] global step 9870: loss = 0.0099 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9871: loss = 0.0282 (0.187 sec/step)\n",
            "I0213 17:01:46.248987 139806407255936 learning.py:512] global step 9871: loss = 0.0282 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9872: loss = 0.0305 (0.168 sec/step)\n",
            "I0213 17:01:46.418880 139806407255936 learning.py:512] global step 9872: loss = 0.0305 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9873: loss = 0.0399 (0.177 sec/step)\n",
            "I0213 17:01:46.597661 139806407255936 learning.py:512] global step 9873: loss = 0.0399 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9874: loss = 0.0337 (0.162 sec/step)\n",
            "I0213 17:01:46.761092 139806407255936 learning.py:512] global step 9874: loss = 0.0337 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9875: loss = 0.0116 (0.182 sec/step)\n",
            "I0213 17:01:46.944976 139806407255936 learning.py:512] global step 9875: loss = 0.0116 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9876: loss = 0.0373 (0.172 sec/step)\n",
            "I0213 17:01:47.118171 139806407255936 learning.py:512] global step 9876: loss = 0.0373 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9877: loss = 0.0188 (0.174 sec/step)\n",
            "I0213 17:01:47.294032 139806407255936 learning.py:512] global step 9877: loss = 0.0188 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9878: loss = 0.0197 (0.168 sec/step)\n",
            "I0213 17:01:47.463184 139806407255936 learning.py:512] global step 9878: loss = 0.0197 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9879: loss = 0.0199 (0.156 sec/step)\n",
            "I0213 17:01:47.620804 139806407255936 learning.py:512] global step 9879: loss = 0.0199 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9880: loss = 0.0103 (0.180 sec/step)\n",
            "I0213 17:01:47.802670 139806407255936 learning.py:512] global step 9880: loss = 0.0103 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9881: loss = 0.0134 (0.175 sec/step)\n",
            "I0213 17:01:47.978682 139806407255936 learning.py:512] global step 9881: loss = 0.0134 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9882: loss = 0.0366 (0.152 sec/step)\n",
            "I0213 17:01:48.132156 139806407255936 learning.py:512] global step 9882: loss = 0.0366 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9883: loss = 0.0312 (0.174 sec/step)\n",
            "I0213 17:01:48.308072 139806407255936 learning.py:512] global step 9883: loss = 0.0312 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9884: loss = 0.0319 (0.177 sec/step)\n",
            "I0213 17:01:48.486257 139806407255936 learning.py:512] global step 9884: loss = 0.0319 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9885: loss = 0.0198 (0.164 sec/step)\n",
            "I0213 17:01:48.651978 139806407255936 learning.py:512] global step 9885: loss = 0.0198 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9886: loss = 0.0090 (0.187 sec/step)\n",
            "I0213 17:01:48.840511 139806407255936 learning.py:512] global step 9886: loss = 0.0090 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9887: loss = 0.0203 (0.165 sec/step)\n",
            "I0213 17:01:49.006877 139806407255936 learning.py:512] global step 9887: loss = 0.0203 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9888: loss = 0.0275 (0.179 sec/step)\n",
            "I0213 17:01:49.187795 139806407255936 learning.py:512] global step 9888: loss = 0.0275 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9889: loss = 0.0156 (0.176 sec/step)\n",
            "I0213 17:01:49.365213 139806407255936 learning.py:512] global step 9889: loss = 0.0156 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9890: loss = 0.0325 (0.163 sec/step)\n",
            "I0213 17:01:49.529586 139806407255936 learning.py:512] global step 9890: loss = 0.0325 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9891: loss = 0.0102 (0.173 sec/step)\n",
            "I0213 17:01:49.703656 139806407255936 learning.py:512] global step 9891: loss = 0.0102 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9892: loss = 0.0273 (0.168 sec/step)\n",
            "I0213 17:01:49.873001 139806407255936 learning.py:512] global step 9892: loss = 0.0273 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9893: loss = 0.0285 (0.173 sec/step)\n",
            "I0213 17:01:50.047896 139806407255936 learning.py:512] global step 9893: loss = 0.0285 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9894: loss = 0.0302 (0.166 sec/step)\n",
            "I0213 17:01:50.215608 139806407255936 learning.py:512] global step 9894: loss = 0.0302 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9895: loss = 0.0753 (0.179 sec/step)\n",
            "I0213 17:01:50.396206 139806407255936 learning.py:512] global step 9895: loss = 0.0753 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9896: loss = 0.0336 (0.168 sec/step)\n",
            "I0213 17:01:50.565803 139806407255936 learning.py:512] global step 9896: loss = 0.0336 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9897: loss = 0.0459 (0.152 sec/step)\n",
            "I0213 17:01:50.719479 139806407255936 learning.py:512] global step 9897: loss = 0.0459 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9898: loss = 0.0131 (0.177 sec/step)\n",
            "I0213 17:01:50.897426 139806407255936 learning.py:512] global step 9898: loss = 0.0131 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9899: loss = 0.0288 (0.160 sec/step)\n",
            "I0213 17:01:51.058505 139806407255936 learning.py:512] global step 9899: loss = 0.0288 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9900: loss = 0.0315 (0.161 sec/step)\n",
            "I0213 17:01:51.221335 139806407255936 learning.py:512] global step 9900: loss = 0.0315 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9901: loss = 0.0110 (0.174 sec/step)\n",
            "I0213 17:01:51.396666 139806407255936 learning.py:512] global step 9901: loss = 0.0110 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9902: loss = 0.0164 (0.178 sec/step)\n",
            "I0213 17:01:51.575777 139806407255936 learning.py:512] global step 9902: loss = 0.0164 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9903: loss = 0.0071 (0.178 sec/step)\n",
            "I0213 17:01:51.754999 139806407255936 learning.py:512] global step 9903: loss = 0.0071 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9904: loss = 0.0239 (0.169 sec/step)\n",
            "I0213 17:01:51.925125 139806407255936 learning.py:512] global step 9904: loss = 0.0239 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9905: loss = 0.0148 (0.161 sec/step)\n",
            "I0213 17:01:52.087069 139806407255936 learning.py:512] global step 9905: loss = 0.0148 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9906: loss = 0.0218 (0.171 sec/step)\n",
            "I0213 17:01:52.260927 139806407255936 learning.py:512] global step 9906: loss = 0.0218 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9907: loss = 0.0552 (0.164 sec/step)\n",
            "I0213 17:01:52.427785 139806407255936 learning.py:512] global step 9907: loss = 0.0552 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9908: loss = 0.0098 (0.173 sec/step)\n",
            "I0213 17:01:52.601852 139806407255936 learning.py:512] global step 9908: loss = 0.0098 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9909: loss = 0.0183 (0.177 sec/step)\n",
            "I0213 17:01:52.780001 139806407255936 learning.py:512] global step 9909: loss = 0.0183 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9910: loss = 0.0367 (0.166 sec/step)\n",
            "I0213 17:01:52.947839 139806407255936 learning.py:512] global step 9910: loss = 0.0367 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9911: loss = 0.0148 (0.167 sec/step)\n",
            "I0213 17:01:53.115713 139806407255936 learning.py:512] global step 9911: loss = 0.0148 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9912: loss = 0.0182 (0.169 sec/step)\n",
            "I0213 17:01:53.285860 139806407255936 learning.py:512] global step 9912: loss = 0.0182 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9913: loss = 0.0284 (0.172 sec/step)\n",
            "I0213 17:01:53.459885 139806407255936 learning.py:512] global step 9913: loss = 0.0284 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9914: loss = 0.0147 (0.165 sec/step)\n",
            "I0213 17:01:53.626150 139806407255936 learning.py:512] global step 9914: loss = 0.0147 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9915: loss = 0.0206 (0.172 sec/step)\n",
            "I0213 17:01:53.799576 139806407255936 learning.py:512] global step 9915: loss = 0.0206 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9916: loss = 0.0114 (0.172 sec/step)\n",
            "I0213 17:01:53.972697 139806407255936 learning.py:512] global step 9916: loss = 0.0114 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9917: loss = 0.0395 (0.158 sec/step)\n",
            "I0213 17:01:54.132018 139806407255936 learning.py:512] global step 9917: loss = 0.0395 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9918: loss = 0.0451 (0.171 sec/step)\n",
            "I0213 17:01:54.304861 139806407255936 learning.py:512] global step 9918: loss = 0.0451 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9919: loss = 0.0317 (0.174 sec/step)\n",
            "I0213 17:01:54.479961 139806407255936 learning.py:512] global step 9919: loss = 0.0317 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9920: loss = 0.0653 (0.169 sec/step)\n",
            "I0213 17:01:54.650134 139806407255936 learning.py:512] global step 9920: loss = 0.0653 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9921: loss = 0.0141 (0.162 sec/step)\n",
            "I0213 17:01:54.814073 139806407255936 learning.py:512] global step 9921: loss = 0.0141 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9922: loss = 0.0109 (0.172 sec/step)\n",
            "I0213 17:01:54.987282 139806407255936 learning.py:512] global step 9922: loss = 0.0109 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9923: loss = 0.0422 (0.154 sec/step)\n",
            "I0213 17:01:55.142901 139806407255936 learning.py:512] global step 9923: loss = 0.0422 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9924: loss = 0.0115 (0.190 sec/step)\n",
            "I0213 17:01:55.334173 139806407255936 learning.py:512] global step 9924: loss = 0.0115 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9925: loss = 0.0152 (0.161 sec/step)\n",
            "I0213 17:01:55.496441 139806407255936 learning.py:512] global step 9925: loss = 0.0152 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9926: loss = 0.0389 (0.148 sec/step)\n",
            "I0213 17:01:55.645562 139806407255936 learning.py:512] global step 9926: loss = 0.0389 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9927: loss = 0.0137 (0.174 sec/step)\n",
            "I0213 17:01:55.821296 139806407255936 learning.py:512] global step 9927: loss = 0.0137 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9928: loss = 0.0116 (0.177 sec/step)\n",
            "I0213 17:01:55.999391 139806407255936 learning.py:512] global step 9928: loss = 0.0116 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9929: loss = 0.0126 (0.175 sec/step)\n",
            "I0213 17:01:56.176644 139806407255936 learning.py:512] global step 9929: loss = 0.0126 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9930: loss = 0.0328 (0.156 sec/step)\n",
            "I0213 17:01:56.334538 139806407255936 learning.py:512] global step 9930: loss = 0.0328 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9931: loss = 0.0423 (0.159 sec/step)\n",
            "I0213 17:01:56.495152 139806407255936 learning.py:512] global step 9931: loss = 0.0423 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9932: loss = 0.0108 (0.152 sec/step)\n",
            "I0213 17:01:56.648938 139806407255936 learning.py:512] global step 9932: loss = 0.0108 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9933: loss = 0.0103 (0.167 sec/step)\n",
            "I0213 17:01:56.817034 139806407255936 learning.py:512] global step 9933: loss = 0.0103 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9934: loss = 0.0192 (0.152 sec/step)\n",
            "I0213 17:01:56.970551 139806407255936 learning.py:512] global step 9934: loss = 0.0192 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9935: loss = 0.0309 (0.168 sec/step)\n",
            "I0213 17:01:57.139799 139806407255936 learning.py:512] global step 9935: loss = 0.0309 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9936: loss = 0.0245 (0.162 sec/step)\n",
            "I0213 17:01:57.302838 139806407255936 learning.py:512] global step 9936: loss = 0.0245 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9937: loss = 0.0175 (0.155 sec/step)\n",
            "I0213 17:01:57.459214 139806407255936 learning.py:512] global step 9937: loss = 0.0175 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9938: loss = 0.0449 (0.153 sec/step)\n",
            "I0213 17:01:57.613459 139806407255936 learning.py:512] global step 9938: loss = 0.0449 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9939: loss = 0.0242 (0.170 sec/step)\n",
            "I0213 17:01:57.786701 139806407255936 learning.py:512] global step 9939: loss = 0.0242 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9940: loss = 0.0365 (0.163 sec/step)\n",
            "I0213 17:01:57.950685 139806407255936 learning.py:512] global step 9940: loss = 0.0365 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9941: loss = 0.0321 (0.184 sec/step)\n",
            "I0213 17:01:58.136122 139806407255936 learning.py:512] global step 9941: loss = 0.0321 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9942: loss = 0.0149 (0.166 sec/step)\n",
            "I0213 17:01:58.303217 139806407255936 learning.py:512] global step 9942: loss = 0.0149 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9943: loss = 0.0120 (0.177 sec/step)\n",
            "I0213 17:01:58.481386 139806407255936 learning.py:512] global step 9943: loss = 0.0120 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9944: loss = 0.0261 (0.161 sec/step)\n",
            "I0213 17:01:58.644268 139806407255936 learning.py:512] global step 9944: loss = 0.0261 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9945: loss = 0.0051 (0.179 sec/step)\n",
            "I0213 17:01:58.824353 139806407255936 learning.py:512] global step 9945: loss = 0.0051 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9946: loss = 0.0050 (0.164 sec/step)\n",
            "I0213 17:01:58.990189 139806407255936 learning.py:512] global step 9946: loss = 0.0050 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9947: loss = 0.0093 (0.159 sec/step)\n",
            "I0213 17:01:59.150672 139806407255936 learning.py:512] global step 9947: loss = 0.0093 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9948: loss = 0.0342 (0.152 sec/step)\n",
            "I0213 17:01:59.304090 139806407255936 learning.py:512] global step 9948: loss = 0.0342 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9949: loss = 0.0882 (0.188 sec/step)\n",
            "I0213 17:01:59.493262 139806407255936 learning.py:512] global step 9949: loss = 0.0882 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9950: loss = 0.0359 (0.163 sec/step)\n",
            "I0213 17:01:59.657413 139806407255936 learning.py:512] global step 9950: loss = 0.0359 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9951: loss = 0.0198 (0.168 sec/step)\n",
            "I0213 17:01:59.827253 139806407255936 learning.py:512] global step 9951: loss = 0.0198 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9952: loss = 0.0189 (0.159 sec/step)\n",
            "I0213 17:01:59.988250 139806407255936 learning.py:512] global step 9952: loss = 0.0189 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9953: loss = 0.0191 (0.160 sec/step)\n",
            "I0213 17:02:00.150242 139806407255936 learning.py:512] global step 9953: loss = 0.0191 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9954: loss = 0.0138 (0.167 sec/step)\n",
            "I0213 17:02:00.319022 139806407255936 learning.py:512] global step 9954: loss = 0.0138 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9955: loss = 0.0137 (0.160 sec/step)\n",
            "I0213 17:02:00.480063 139806407255936 learning.py:512] global step 9955: loss = 0.0137 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9956: loss = 0.0113 (0.170 sec/step)\n",
            "I0213 17:02:00.651623 139806407255936 learning.py:512] global step 9956: loss = 0.0113 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9957: loss = 0.0256 (0.176 sec/step)\n",
            "I0213 17:02:00.828747 139806407255936 learning.py:512] global step 9957: loss = 0.0256 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9958: loss = 0.0252 (0.170 sec/step)\n",
            "I0213 17:02:01.000573 139806407255936 learning.py:512] global step 9958: loss = 0.0252 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9959: loss = 0.0163 (0.167 sec/step)\n",
            "I0213 17:02:01.168521 139806407255936 learning.py:512] global step 9959: loss = 0.0163 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9960: loss = 0.0174 (0.182 sec/step)\n",
            "I0213 17:02:01.352244 139806407255936 learning.py:512] global step 9960: loss = 0.0174 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9961: loss = 0.0228 (0.190 sec/step)\n",
            "I0213 17:02:01.544190 139806407255936 learning.py:512] global step 9961: loss = 0.0228 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9962: loss = 0.0168 (0.173 sec/step)\n",
            "I0213 17:02:01.718213 139806407255936 learning.py:512] global step 9962: loss = 0.0168 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9963: loss = 0.0286 (0.178 sec/step)\n",
            "I0213 17:02:01.897799 139806407255936 learning.py:512] global step 9963: loss = 0.0286 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9964: loss = 0.0198 (0.175 sec/step)\n",
            "I0213 17:02:02.074249 139806407255936 learning.py:512] global step 9964: loss = 0.0198 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9965: loss = 0.0389 (0.180 sec/step)\n",
            "I0213 17:02:02.255491 139806407255936 learning.py:512] global step 9965: loss = 0.0389 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9966: loss = 0.0416 (0.189 sec/step)\n",
            "I0213 17:02:02.445368 139806407255936 learning.py:512] global step 9966: loss = 0.0416 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9967: loss = 0.0330 (0.165 sec/step)\n",
            "I0213 17:02:02.611277 139806407255936 learning.py:512] global step 9967: loss = 0.0330 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9968: loss = 0.0174 (0.177 sec/step)\n",
            "I0213 17:02:02.790153 139806407255936 learning.py:512] global step 9968: loss = 0.0174 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9969: loss = 0.0374 (0.180 sec/step)\n",
            "I0213 17:02:02.971304 139806407255936 learning.py:512] global step 9969: loss = 0.0374 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9970: loss = 0.0353 (0.166 sec/step)\n",
            "I0213 17:02:03.139043 139806407255936 learning.py:512] global step 9970: loss = 0.0353 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9971: loss = 0.0161 (0.177 sec/step)\n",
            "I0213 17:02:03.317357 139806407255936 learning.py:512] global step 9971: loss = 0.0161 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9972: loss = 0.0134 (0.152 sec/step)\n",
            "I0213 17:02:03.470423 139806407255936 learning.py:512] global step 9972: loss = 0.0134 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9973: loss = 0.0390 (0.172 sec/step)\n",
            "I0213 17:02:03.643796 139806407255936 learning.py:512] global step 9973: loss = 0.0390 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9974: loss = 0.0133 (0.168 sec/step)\n",
            "I0213 17:02:03.813390 139806407255936 learning.py:512] global step 9974: loss = 0.0133 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9975: loss = 0.0179 (0.165 sec/step)\n",
            "I0213 17:02:03.979892 139806407255936 learning.py:512] global step 9975: loss = 0.0179 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9976: loss = 0.0232 (0.159 sec/step)\n",
            "I0213 17:02:04.140134 139806407255936 learning.py:512] global step 9976: loss = 0.0232 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9977: loss = 0.0144 (0.186 sec/step)\n",
            "I0213 17:02:04.327268 139806407255936 learning.py:512] global step 9977: loss = 0.0144 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9978: loss = 0.0161 (0.171 sec/step)\n",
            "I0213 17:02:04.499698 139806407255936 learning.py:512] global step 9978: loss = 0.0161 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9979: loss = 0.0208 (0.183 sec/step)\n",
            "I0213 17:02:04.684272 139806407255936 learning.py:512] global step 9979: loss = 0.0208 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9980: loss = 0.0109 (0.164 sec/step)\n",
            "I0213 17:02:04.849193 139806407255936 learning.py:512] global step 9980: loss = 0.0109 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9981: loss = 0.0252 (0.182 sec/step)\n",
            "I0213 17:02:05.032125 139806407255936 learning.py:512] global step 9981: loss = 0.0252 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9982: loss = 0.0235 (0.165 sec/step)\n",
            "I0213 17:02:05.198662 139806407255936 learning.py:512] global step 9982: loss = 0.0235 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9983: loss = 0.0177 (0.176 sec/step)\n",
            "I0213 17:02:05.375467 139806407255936 learning.py:512] global step 9983: loss = 0.0177 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9984: loss = 0.0197 (0.176 sec/step)\n",
            "I0213 17:02:05.552773 139806407255936 learning.py:512] global step 9984: loss = 0.0197 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9985: loss = 0.0284 (0.166 sec/step)\n",
            "I0213 17:02:05.720031 139806407255936 learning.py:512] global step 9985: loss = 0.0284 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9986: loss = 0.0146 (0.164 sec/step)\n",
            "I0213 17:02:05.885468 139806407255936 learning.py:512] global step 9986: loss = 0.0146 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9987: loss = 0.0087 (0.156 sec/step)\n",
            "I0213 17:02:06.042453 139806407255936 learning.py:512] global step 9987: loss = 0.0087 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9988: loss = 0.0164 (0.165 sec/step)\n",
            "I0213 17:02:06.208452 139806407255936 learning.py:512] global step 9988: loss = 0.0164 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9989: loss = 0.0081 (0.171 sec/step)\n",
            "I0213 17:02:06.380842 139806407255936 learning.py:512] global step 9989: loss = 0.0081 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9990: loss = 0.0090 (0.179 sec/step)\n",
            "I0213 17:02:06.561488 139806407255936 learning.py:512] global step 9990: loss = 0.0090 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9991: loss = 0.0539 (0.175 sec/step)\n",
            "I0213 17:02:06.737508 139806407255936 learning.py:512] global step 9991: loss = 0.0539 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9992: loss = 0.0324 (0.178 sec/step)\n",
            "I0213 17:02:06.917265 139806407255936 learning.py:512] global step 9992: loss = 0.0324 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9993: loss = 0.0211 (0.169 sec/step)\n",
            "I0213 17:02:07.088034 139806407255936 learning.py:512] global step 9993: loss = 0.0211 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9994: loss = 0.0311 (0.164 sec/step)\n",
            "I0213 17:02:07.253010 139806407255936 learning.py:512] global step 9994: loss = 0.0311 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9995: loss = 0.0319 (0.168 sec/step)\n",
            "I0213 17:02:07.422559 139806407255936 learning.py:512] global step 9995: loss = 0.0319 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9996: loss = 0.0064 (0.177 sec/step)\n",
            "I0213 17:02:07.600425 139806407255936 learning.py:512] global step 9996: loss = 0.0064 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9997: loss = 0.0107 (0.174 sec/step)\n",
            "I0213 17:02:07.775759 139806407255936 learning.py:512] global step 9997: loss = 0.0107 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9998: loss = 0.0237 (0.165 sec/step)\n",
            "I0213 17:02:07.942183 139806407255936 learning.py:512] global step 9998: loss = 0.0237 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9999: loss = 0.0380 (0.185 sec/step)\n",
            "I0213 17:02:08.128460 139806407255936 learning.py:512] global step 9999: loss = 0.0380 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 10000: loss = 0.0313 (0.162 sec/step)\n",
            "I0213 17:02:08.291549 139806407255936 learning.py:512] global step 10000: loss = 0.0313 (0.162 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0213 17:02:08.292250 139806407255936 learning.py:769] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0213 17:02:08.292478 139806407255936 learning.py:777] Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaxwL13IdftO"
      },
      "source": [
        "# 5. Tensorboard Training Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w5x4EJQbM59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1190280-ffc5-465f-88a9-b8b60781dcff"
      },
      "source": [
        "%cd /content/models/research/object_detection/training/\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/training\n",
            "--2021-02-13 17:07:01--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.171.116.247, 34.205.198.58, 54.145.36.98, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.171.116.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ngrok-stable-linux-amd64.zip.1\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  47.3MB/s    in 0.3s    \n",
            "\n",
            "2021-02-13 17:07:01 (47.3 MB/s) - ngrok-stable-linux-amd64.zip.1 saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F36HIisRcClB"
      },
      "source": [
        "LOG_DIR = '/content/models/research/object_detection/training/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFxPaub4A_GB"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTQxZXmZcNtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68b98cc-a5dd-4538-86a9-209b3e1ab768"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ca3a346f1dd7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hb9qzlQiffl"
      },
      "source": [
        "# 6 Tensor Board Eval Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwbTu781iovB",
        "outputId": "6bf31490-26d5-4062-c45e-39aba5e6f183"
      },
      "source": [
        "%cd /content/models/research/object_detection/\r\n",
        "!cp /content/models/research/object_detection/legacy/eval.py /content/models/research/object_detection"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y0IF7uxjWak",
        "outputId": "a6f0350f-06a1-45ab-c9a1-25e89090002e"
      },
      "source": [
        "!pip install lvis"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4EcgSMaimLv",
        "outputId": "88d6598e-18cc-4346-da15-9a114dced869"
      },
      "source": [
        "!python eval.py \\\r\n",
        "  --logtostderr \\\r\n",
        "  --pipeline_config_path=/content/dataset/data/faster_rcnn_inception_v2_coco.config \\\r\n",
        "  --checkpoint_dir=training/ \\\r\n",
        "  --eval_dir=eval/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0213 18:11:55.609905 140057236469632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/dataset/data/test.record']\n",
            "I0213 18:11:55.634628 140057236469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/dataset/data/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/dataset/data/test.record']\n",
            "I0213 18:11:55.635586 140057236469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/dataset/data/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0213 18:11:55.635710 140057236469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0213 18:11:55.640635 140057236469632 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0213 18:11:55.663851 140057236469632 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0213 18:11:57.983084 140057236469632 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0213 18:11:57.992726 140057236469632 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0213 18:11:57.993664 140057236469632 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0213 18:11:58.044644 140057236469632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:59.345287 140057236469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:59.474934 140057236469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0213 18:11:59.475328 140057236469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0213 18:11:59.524950 140057236469632 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0213 18:11:59.958553 140057236469632 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0213 18:12:00.446554 140057236469632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:12:00.448698 140057236469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:12:00.463838 140057236469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0213 18:12:04.010725 140057236469632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0213 18:12:04.334218 140057236469632 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0213 18:12:04.586893 140057236469632 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:927: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-13-18:12:05\n",
            "I0213 18:12:05.042566 140057236469632 eval_util.py:506] Starting evaluation at 2021-02-13-18:12:05\n",
            "2021-02-13 18:12:05.045654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-13 18:12:05.051903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.052366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:12:05.052662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:12:05.054118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:12:05.055212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:12:05.055581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:12:05.057211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:12:05.058311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:12:05.062111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:12:05.062233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.062744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.063161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:12:05.063436: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-02-13 18:12:05.067923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-02-13 18:12:05.068099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172c840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-13 18:12:05.068126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-02-13 18:12:05.155130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.155767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172c680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-13 18:12:05.155804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-02-13 18:12:05.156001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.156489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:12:05.156573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:12:05.156607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:12:05.156632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:12:05.156656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:12:05.156680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:12:05.156704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:12:05.156728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:12:05.156809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.157309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.157765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:12:05.157849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:12:05.159109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-13 18:12:05.159141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-02-13 18:12:05.159153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-02-13 18:12:05.159278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.159787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:12:05.160213: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-13 18:12:05.160257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9555 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0213 18:12:07.062505 140057236469632 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "2021-02-13 18:12:10.411420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:12:10.998548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:15.838357 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-0.\n",
            "I0213 18:12:17.195562 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-0.\n",
            "W0213 18:12:17.196910 140057236469632 object_detection_evaluation.py:343] image b'batman_0.jpg' does not have groundtruth difficult flag specified\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:17.285386 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-1.\n",
            "I0213 18:12:17.512774 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-1.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:17.621452 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-2.\n",
            "I0213 18:12:17.835606 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-2.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:17.953294 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-3.\n",
            "I0213 18:12:18.168815 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-3.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:18.297071 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-4.\n",
            "I0213 18:12:18.514558 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-4.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:18.635505 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-5.\n",
            "I0213 18:12:18.842972 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-5.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:18.961902 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-6.\n",
            "I0213 18:12:19.179757 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-6.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:19.312473 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-7.\n",
            "I0213 18:12:19.518815 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-7.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:19.641807 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-8.\n",
            "I0213 18:12:19.850321 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-8.\n",
            "INFO:tensorflow:Creating detection visualizations.\n",
            "I0213 18:12:19.979742 140057236469632 eval_util.py:178] Creating detection visualizations.\n",
            "INFO:tensorflow:Detection visualizations written to summary with tag image-9.\n",
            "I0213 18:12:20.188846 140057236469632 eval_util.py:243] Detection visualizations written to summary with tag image-9.\n",
            "INFO:tensorflow:Running eval batches done.\n",
            "I0213 18:12:21.137754 140057236469632 eval_util.py:376] Running eval batches done.\n",
            "INFO:tensorflow:# success: 19\n",
            "I0213 18:12:21.137961 140057236469632 eval_util.py:381] # success: 19\n",
            "INFO:tensorflow:# skipped: 0\n",
            "I0213 18:12:21.138059 140057236469632 eval_util.py:382] # skipped: 0\n",
            "I0213 18:12:21.138641 140057236469632 object_detection_evaluation.py:1335] average_precision: 1.000000\n",
            "INFO:tensorflow:Writing metrics to tf summary.\n",
            "I0213 18:12:21.566286 140057236469632 eval_util.py:90] Writing metrics to tf summary.\n",
            "INFO:tensorflow:Losses/Loss/BoxClassifierLoss/classification_loss: 0.057634\n",
            "I0213 18:12:21.566683 140057236469632 eval_util.py:97] Losses/Loss/BoxClassifierLoss/classification_loss: 0.057634\n",
            "INFO:tensorflow:Losses/Loss/BoxClassifierLoss/localization_loss: 0.041929\n",
            "I0213 18:12:21.567071 140057236469632 eval_util.py:97] Losses/Loss/BoxClassifierLoss/localization_loss: 0.041929\n",
            "INFO:tensorflow:Losses/Loss/RPNLoss/localization_loss: 0.222813\n",
            "I0213 18:12:21.567394 140057236469632 eval_util.py:97] Losses/Loss/RPNLoss/localization_loss: 0.222813\n",
            "INFO:tensorflow:Losses/Loss/RPNLoss/objectness_loss: 0.049351\n",
            "I0213 18:12:21.567661 140057236469632 eval_util.py:97] Losses/Loss/RPNLoss/objectness_loss: 0.049351\n",
            "INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/batman: 1.000000\n",
            "I0213 18:12:21.567878 140057236469632 eval_util.py:97] PascalBoxes_PerformanceByCategory/AP@0.5IOU/batman: 1.000000\n",
            "INFO:tensorflow:PascalBoxes_Precision/mAP@0.5IOU: 1.000000\n",
            "I0213 18:12:21.568092 140057236469632 eval_util.py:97] PascalBoxes_Precision/mAP@0.5IOU: 1.000000\n",
            "INFO:tensorflow:Metrics written to tf summary.\n",
            "I0213 18:12:21.568247 140057236469632 eval_util.py:98] Metrics written to tf summary.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_WNzm0Dk35k",
        "outputId": "84d5c4ec-1bc8-474d-aa11-7c464f27d37d"
      },
      "source": [
        "LOG_DIR = '/content/models/research/object_detection/eval/'\r\n",
        "get_ipython().system_raw(\r\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\r\n",
        "    .format(LOG_DIR)\r\n",
        ")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.15.0 at http://c89b25a93ab4:6007/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugDZQ69Ql_Tj"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEgBV-omCz0"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\r\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJCB5NKK4Nb"
      },
      "source": [
        "# 6. Export trained model\n",
        "\n",
        "Export trained model with highest step number in filename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNlbs1R-B2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f85df72-a3d6-4f6e-aff8-a10a418c4189"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "%rm -rf inference_graph/*\n",
        "\n",
        "!python export_inference_graph.py \\\n",
        "  --input_type image_tensor \\\n",
        "  --pipeline_config_path /content/dataset/data/faster_rcnn_inception_v2_coco.config \\\n",
        "  --trained_checkpoint_prefix /content/models/research/object_detection/training/model.ckpt-10000 \\\n",
        "  --output_directory /content/dataset/models/inference_graph"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0213 18:11:09.429981 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:10.648009 140373094274944 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:10.778941 140373094274944 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0213 18:11:10.779458 140373094274944 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0213 18:11:10.837843 140373094274944 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0213 18:11:11.384694 140373094274944 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0213 18:11:11.971924 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:11.977125 140373094274944 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0213 18:11:11.995515 140373094274944 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0213 18:11:15.679809 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0213 18:11:15.775694 140373094274944 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0213 18:11:15.778663 140373094274944 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0213 18:11:15.779804 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "385 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/13.30m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/462.27k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/369.00k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (360, 360/360 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x360, 368.64k/368.64k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/93.28k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (91, 91/91 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x91, 93.18k/93.18k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "385 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.43k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_179 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_35 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_34 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_33 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_30 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_31 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_32 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_36 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_29 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_28 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_27 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_26 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_25 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_24 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_23 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_22 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_21 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_20 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_167 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_47 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_57 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_56 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_55 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_54 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_53 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_52 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_51 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_50 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_49 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_48 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_37 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_46 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_45 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_44 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_43 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_42 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_41 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_40 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_39 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_38 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_147 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_157 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_156 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_155 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_154 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_153 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_152 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_151 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_150 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_149 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_148 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_158 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_146 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_145 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_144 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_143 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_142 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_141 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_140 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_139 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_138 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_168 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_177 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_176 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_175 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_174 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_173 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_172 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_171 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_170 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_169 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_178 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_69 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_166 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_165 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_164 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_163 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_162 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_161 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_160 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_159 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_99 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_68 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_78 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_77 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_76 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_75 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_74 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_73 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_72 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_71 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_70 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_135 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_79 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_67 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_66 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_65 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_64 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_63 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_62 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_61 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_60 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_59 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_89 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_98 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_97 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_96 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_95 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_94 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_93 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_92 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_91 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_90 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_58 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_88 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_87 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_86 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_85 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_84 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_83 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_82 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_81 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_80 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_40 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_39 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_38 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_37 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_36 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_35 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_34 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_33 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_32 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_31 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_30 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_29 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_28 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_27 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_26 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_25 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_24 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_23 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_22 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_21 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_20 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_41 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_102 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_113 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_112 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_111 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_110 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_109 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_108 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_107 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_106 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_105 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_104 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_103 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_114 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_101 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_100 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_90 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_89 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_88 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_125 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_136 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_134 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_133 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_132 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_131 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_130 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_129 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_128 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_127 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_126 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_87 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_124 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_123 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_122 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_121 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_120 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_119 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_118 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_117 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_116 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_115 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_52 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_63 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_62 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_61 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_60 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_59 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_58 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_57 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_56 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_55 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_54 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_53 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_64 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_51 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_50 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_49 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_48 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_47 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_46 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_45 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_44 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_43 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_42 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_75 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_86 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_85 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_84 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_83 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_82 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_81 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_80 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_79 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_78 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_77 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_76 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_137 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_74 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_73 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_72 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_71 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_70 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_69 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_68 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_67 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_66 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_65 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-02-13 18:11:19.469773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-13 18:11:19.475614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.476110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:11:19.476372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:11:19.477354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:11:19.479275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:11:19.479630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:11:19.480809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:11:19.481722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:11:19.484838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:11:19.484951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.485444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.485848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:11:19.486137: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-02-13 18:11:19.490667: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-02-13 18:11:19.490846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24b0d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-13 18:11:19.490874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-02-13 18:11:19.575633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.576270: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24b1640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-13 18:11:19.576306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-02-13 18:11:19.576519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.577002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:11:19.577090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:11:19.577129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:11:19.577159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:11:19.577181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:11:19.577206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:11:19.577229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:11:19.577254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:11:19.577331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.577979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.578432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:11:19.578520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:11:19.579625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-13 18:11:19.579655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-02-13 18:11:19.579670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-02-13 18:11:19.579795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.580305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:19.580789: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-13 18:11:19.580831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9555 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/object_detection/training/model.ckpt-10000\n",
            "I0213 18:11:19.582788 140373094274944 saver.py:1284] Restoring parameters from /content/models/research/object_detection/training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0213 18:11:21.712011 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-02-13 18:11:22.954109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:22.954619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:11:22.954705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:11:22.954731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:11:22.954753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:11:22.954781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:11:22.954801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:11:22.954820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:11:22.954840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:11:22.954925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:22.955375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:22.955776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:11:22.955819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-13 18:11:22.955833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-02-13 18:11:22.955843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-02-13 18:11:22.955945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:22.956412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:22.956880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9555 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/object_detection/training/model.ckpt-10000\n",
            "I0213 18:11:22.958053 140373094274944 saver.py:1284] Restoring parameters from /content/models/research/object_detection/training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0213 18:11:23.966615 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0213 18:11:23.966902 140373094274944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0213 18:11:24.582932 140373094274944 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0213 18:11:24.728863 140373094274944 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "2021-02-13 18:11:25.052719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:25.053219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-13 18:11:25.053325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-13 18:11:25.053352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-13 18:11:25.053378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-13 18:11:25.053399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-13 18:11:25.053438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-13 18:11:25.053460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-13 18:11:25.053483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-13 18:11:25.053577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:25.054051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:25.054646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-13 18:11:25.054704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-13 18:11:25.054719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-02-13 18:11:25.054729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-02-13 18:11:25.054875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:25.055366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-13 18:11:25.055782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9555 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0213 18:11:26.033621 140373094274944 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0213 18:11:26.034585 140373094274944 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0213 18:11:26.034764 140373094274944 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/dataset/models/inference_graph/saved_model/saved_model.pb\n",
            "I0213 18:11:26.700080 140373094274944 builder_impl.py:425] SavedModel written to: /content/dataset/models/inference_graph/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/dataset/models/inference_graph/pipeline.config\n",
            "I0213 18:11:26.761376 140373094274944 config_util.py:254] Writing pipeline config file to /content/dataset/models/inference_graph/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llq00Y-zQbAk"
      },
      "source": [
        "# 7. Test Model (Inferencing)\r\n",
        "- Upload image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI8Ya_6GE9ll",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ffe54946-7175-403a-b603-c016c9d7b898"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "from google.colab import files\n",
        "from os import path\n",
        "\n",
        "uploaded = files.upload()\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open('image1.jpg', 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e5ca24c-c805-43c1-b6cf-50bfe7192fb5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e5ca24c-c805-43c1-b6cf-50bfe7192fb5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving batman_13.jpg to batman_13.jpg\n",
            "saved file batman_13.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvwN58CCcA3j"
      },
      "source": [
        "- upload arial font (`arial.ttf`) from cloned repo ([ObjectDetection-DatasetPreparation](http://github.com/Muhammad-Yunus/ObjectDetection-DatasetPreparation)) using script below,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "DrZQ_i-Ebc4-",
        "outputId": "3576f9c0-c936-432f-943d-4185b8c866e8"
      },
      "source": [
        "uploaded = files.upload()\r\n",
        "  \r\n",
        "for name, data in uploaded.items():\r\n",
        "  with open('/content/models/research/object_detection/utils/arial.ttf', 'wb') as f:\r\n",
        "    f.write(data)\r\n",
        "    f.close()\r\n",
        "    print('saved file ' + name)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6fae900-ed4e-403b-aba0-37dc969119fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6fae900-ed4e-403b-aba0-37dc969119fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving arial.ttf to arial.ttf\n",
            "saved file arial.ttf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG98BJDOdmny"
      },
      "source": [
        "- open `/content/models/research/object_detection/utils/visualization_utils.py` and navigate to line `212`, change font size to a proper value (e.g/ 50).\r\n",
        "    ```\r\n",
        "    try:\r\n",
        "      font = ImageFont.truetype('arial.ttf', 50)\r\n",
        "    except IOError:\r\n",
        "      font = ImageFont.load_default()\r\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUiDDKD-Qj6I"
      },
      "source": [
        "- predict on `image1.jpg`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUy6KXMToLVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "46dd8f87-0d36-4495-c1a8-7cade120013f"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "#if tf.__version__ < '1.4.0':\n",
        "#  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
        "  \n",
        "  \n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "import importlib\n",
        "importlib.reload(vis_util)\n",
        "\n",
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/dataset/models/inference_graph' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/dataset/data', 'object-detection.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  print(\"IMAGE SIZE :\",image.size)\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (8, 17)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n",
        "  "
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "IMAGE SIZE : (720, 1280)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAM8CAYAAAB6SfhYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9z64su/Im9IWz1tr7nPvrISNgwIA5QgKeAIkZU+ABesQD8Cw9YMwTtMQz9BgkUAsJ0UxQI9H3nrP/rFXpYGCHIxwOO7NqrX1u7XtWbK1dVZlOO2yH44sI/0liZnzQB33QB33QB33Q41P6ezPwQR/0QR/0QR/0QefoA7Q/6IM+6IM+6IN+EvoA7Q/6oA/6oA/6oJ+EPkD7gz7ogz7ogz7oJ6EP0P6gD/qgD/qgD/pJ6AO0P+iDPuiDPuiDfhL6w0GbiP4rIvrfiOhfE9H/8EeX/0Ef9EEf9EEf9LMS/ZH7tIloA/C/A/gvAfwbAP8KwH/LzP/rH8bEB33QB33QB33QT0p/tKf9nwP418z8fzDzC4D/CcB//Qfz8EEf9EEf9EEf9FPS5Q8u798H8H+Z3/8GwH8xS3y5XPjXX35BSgkAgYjAzMg5gzmDGfW7Xss5IzODAJT/ChERqH5aYrB86dKXx6mlIX/ziKjmCXaXNR+Gj3JQu2MzYQYa20y1DnKdkFJCSgmUCIkSiFKpLwESSWGW71zbqLQV51zZdLwE1T3TArMaTa/6Kp8qY9YfmglLf9p8b+zCu4m7D1O+cu3lsKVv/cX1KweJupr2t4N2/Djz8NGo9D05/WQ/z9G8Z9nLvVygmSbzg0XTnpWf24ebfcIqAtVvlY3TNKgx6q/ZvPrxNfbJj6GxRSOdeb3u/5aZ/70ohz8atA+JiP45gH8OAM9PT/jP/pP/FL/88gtS2pDShtfrFS8vL3h5ecH379/b57dvX/Dt+zf8/uU3vFxfADCICJfLpYIa4ZIStq18L0qxAFgBOIKdKvCDx/5mZoDRGQFDHomQcwaYsQVi78srX901jB2akCowE4gStm3DP/tn/wz/9E//hKenJ2zbBZ+eP2O7bEA1anJm7HvG9XrF9fqKb9+/4MuX3/D9+3d8f/mGnPfCq9QD3CRd68enFErOo/Uza0v7Kf0RtZO2kQKatLe9559n6q9HfPjnbL9EZUf5dGXW/JgJu+RNCSDCtm3NyNq2DQCQUmp55z1j3/dmUO3X8hvMDdCZGcQiG4xs+W9lM3L5CQIhA0Bri9owB/V4C1VR/tPSDIBVrtQJIQJSUsO7yIgfe7GBWnrZyCYDQOrGSVFU83EDrgY/oaWz9fB66ohaHVHq6Nskqpcdb8Ljvu8xvxPyefl8fdqiw0edUdrC1jlPy4ow47CtaKvt3I9dyyvRhn/7//y//+csiz8atP9vAP+h+f0f1GuNmPlfAPgXAPCXX39lZq4dSM1bHJRtBd+cdzD3jSzpbWcUYOnTeAGR3/57I1KvObqnwutuHSj8KG0nfGITpISnpydcLk94fn6u3y/Ytg1pkzYpifd9r3+veH19wcvLd3z79g3X63UYMCxRCseTsO3TryhstxvuR21i2yW6JsZHSmkJHCuFOLt2Rnk10EYvA/7JmUy1xGyUZnlAGDnkg4hAzAWbw6RBWOldSb2kf3QKIyZGR0U0A5O38GCV/6zcobzqaTIzKCVMhOU0deVW/RiB0oxmxvu97eUNhQ5gy8XwudX4mhny53ly0QhjqBjOlvRHg/a/AvAfE9F/hALW/w2A/26WWDp933dIZfZ9byFxoDRcZsaed1yvV+TMIEILETdyesqDTwnB670VoFjwDK24ViC6+MwZgbUkyt8CUkLCdtnw9PSEz58/49OnT/j8+XMDbbHYxcApz+14fX3B6+srvr98w7dv3/Dy8oKc9866ViMhD6LTh5LOkx9wEViuFM0sr5W1q2C39o7tgPFGWkQzpRL2a5dkLkdDfl37OJ6qLLXpETtJ4GQlcJz+MPqT4PWSzhqkbwFu71Qw+P7GL2GZ0/wc6kfz/Ww9o2jWkbF8i05d6YCzkbQzPK2o6VECUsOKMf8V/aGgzcxXIvrvAfzPADYA/yMz/y/T9GAzZ80AFKzFcwaAzHub0y5KrTxPKB72JW0zo6qkI+rC5LOwjXwvnxgGiBdOMoANlEiBd7usLREJg72W0obLdsHTU/Guf/nlF3z+/BmXy1PxsCtgp5Sal51zCYu/vLzgy9cveHn5hpeX79W6jkPBNVTQ1+MAACOKDJpZyHD2vL1vDasZH9bA4QM27xl4R1a/yo692CuhqB3acygBuTD0VqWFiUG5TGNwu6dyVB11oMI6GUDnqpw1JcyTH3QLvVeUaJX3Mr34BSoJgSeoY3cwUIu7eYqfW3juWDwJ2GcjXjO62QAyunk1psVWjsq6BegBCWxU4wgDfHT5r+gPn9Nm5n8J4F+eS+3nfTWEbT1tCf++vl5LeDRpSPdCCQQgURrngKCAHZUhv6NOvSXAqH6rXdihOUi0Xr105SUxI2FrPH16esanT5/w6dOnNoctBozMj+77jmK/sM7/v3wr8/7fvtb6SkRibSjA8XPOG709lHXkvYYgNnmm4xP3K40Zf7O0LTTODFS5q0yA0mgIRpRSKlMbex7qyKCy36NkLwb7MC7aFAdRAW1S/sgyZT4+gPvvS7b/ZFzae4OsO02C9m2Ika0NY/PkmYig5ekMvQWw32Ma4ZZox4yPNxTvChN9VPMGOmNajKyUHsjTvp2MEsTM4yXkFhovii4RgVLCpS78KXnoquuW+w1h6wisJHx/bBVb63e8ZpVqFwKuk5wCyqOHfen+ygIXXdB0vV7x+vqKr9++4rff/oYvX37Hvu9IiarS91a5tvtYlxjEbTvNAPtoUET5njEQZtQB9gSM7p23OuMBtTRSto++mLy7aZlyUW629E0moGqZCMhmCkZC4QQTuTGeWOY85KeZ3mKCftBb6B4gCr1I7yXWS+yuW/LRnpLwuPxbIwqiB4pVSSpfVMcE9dI20wG30i1h9HsNgsjLttejcmxko1uPb7x94aVElcfFb5YeHLS10lKRbCqpC6xkAZoFVBuK3Ew4aMzfe2inBKZZTRMFT/U3Y7Bgj/K3gyshtQVmz8/Wy35uq023bUOiDQC1leCvr68lJP7lC37729/w+5ffcb2+1nY44CPU4aPFKVGKSFh9XY7orEV+djC3dDReW3npPt2t1PI+YNMCdjMM4UC3fiYqK9GborZlWR0gYXCg7pAAiAk7587A9NGlW+lUZObDBjhJ/di5xbPzUUgNh7sSoghUA5IajSkJ76tBOJ6AGhuqvgHrtcZDBpAgiy7fSiv9MDh7GIdorJ91a601iGaOySovAsqCv7p6XO705R23w08B2kXBKGjLPG0Jib+2VdDWk+6Aj8S+kWujwJ/hQ/JTK3UEbQlxa55jeH9VhhWObbvgkrYG2J8/f8bnz5/x/FyAu81h0waiVLYJ1TZ5eXktgP3bb/j9y294fX0FwMXLbg7gJAwONXqUr7EtgHGeGdB2P6KZEXPGI795Dsvl8R5K4jQdOLJR6DNRgW9G8ajVy1bjkyBAbYwEIvvRFKL0Z2i4EJ3yuD7ofeldQ6/AoZwBMXh5nm4hH4kcE4xleFAE5kb0PR63pyg6e1Z/tIjBgo7yoV55lvycPqVu3K7z+ylAe993EG3t4JTMuf19f/neQsHNk0gVrNtiNbEkxSKVvK1xGVuj3d0+mtHNJzZ+zf9hffTJMKVYzKmC9dPTM57NSvHnZ5nLLvt8pX4tHF5D4t++fcPf/vY3/Pbbb/j2/RsArntAR+WtdVVNP9SrayvTBoOXTU7w1ta//x63mE0bpKheaxgpsYPODFpL4nXOQlwr6rir4Fc+jLCY7Hz+Ymc2jhngXC4kohJZYn3WVaw3SpnbVi/rjRNqXlnnyXtFgmF7WCTBfyrn+QgrSoPfnu8pBR+Nv2iLoBOe6sn2Yy+OIs3L7n97EW5PE2r0xt+Qn957DLzTLq7knud+atTm5Ntw1NOBbgmdtFE3xRGDtVfNVTmKSAz4QQSuYw+tf5XfbqoiMHI8PThok4JJ82AzrtcX7Ptr+7u+fsO+v5QnUgJTAicynbc3Lxvms6z56T2PnBkVD4vC476TE8rhFiBCZqoh8tSyDhvc9En5r9ZHwi31tIwECZcC2/aEy9Mznj59wudffsHz8zO2y9YWNIlHn1G2dO37jtfrK16vV3x7+Ya//vbv8Ne//hUvLy/1GQGLhHKqmtaxhGblMAQG0waQzJkygIRyREfglQ9WbB/x0JrHW+r8vPjQdK0b+wHGYrGCQDTJr6U1v237MQf8x0MmMnRQlZqvKTMcHxr6LvKTkSgBeQdIvOoC9CxyTgSkskiRq4LsrE3ogC/HbOTaZwAoAbn8bilN+/jPQllyDOsvdTsD3H8Kx/2eCrbGk5ELAPagFTJyXR9ZeLDtSx1uqqvqXy8uQ346TsUid2WJrnIdLz/V0AxWjrAAl+XTrW6HRupmkU8ilfseHIMOmEXs7HiB6J9s9Iq9u6a+n0zdkGr9tG6dR00EcRq1Dcr3TbCn7/opPThoFyrHk15BdQW4zNl++/YVL/VEL22IeuJUPeVnNT8ZdfxgRfXS2cGYKMyuI4xubUIvP9p1Pyi5XtOTkSQcLnPYsqVrq3uxc8sqY9+5OyXut9//2gA7573OceoK82ZEdKO51GxoEgYIGXRm028Fl1ioR5qFrbosh35zVmxgwcfPKRsrY2EVlhvyDJTiPdS8CgCZc1kkmIuXbT1mq2B0TlKte1FwXOUo53pohmNwAO4qm8PCPd+EzXFYt3e1aU/V+9HpjJHybmWRnpJ2z/SNl12RHg+pkUdtv3vDVyFP0pzh5mS0QIDYGcWr8Rd634652ZjWMkZ+497WFljqBGvUTNLpNGM9dbIrpTof2UcpRnp40LbKLJEcy5nbIqtv374h74BYq1vakCghEdVtXhqi8GZMJLy99aWWawkzirfIzS+ZhmqCdi9Wnv1dhSkXzNxSKvuwn5/xy+fP+Pz5Fzx/esbz07OGtlOJImTOTQhfX/cK2N/w2+9/w1//+ld8/foVvBcfbIMc35oa+EaLLfqK1P+aLC/az7bZAoCH505Rf4a6zUOVwDo/5WUc9J5PCSGfIW4RhNUg1fZY5Sty3hSMyByRGmg+f6No5Lki88Duyo7KGxVqWJU/Nb13cxxJlgXtlcPhc4oM0dUYBGIQ7Q15al6Lpu11RRR6X0WrhvviOU/yiup2RFGd4giDp7f0tug/tC1bXKdz6+X2X4kYVFxpnkTFg0DXeXp40KZUw38VrAG0ldEvdT67dIp4khtSbQDbWbkevALcBhoShu5tz5q/s65CD6TdD7y0iuIpJWxEuNCGp8sTfvn0Gb/+8is+PX/CdrlgS5tuX6uPSnu0hWffv+Hr77/hb//fv8OXL1+wX3cA/bnGaVOA0TOvbe3Mtjhm6OiceFYBWFuDVQB1JYM+LHY2IqL5r6n3KEf+Zt7AGSUx2sujFxvVJVJeRLqCN+cMUAZnVZaZs7PmNb+xEJjQ+bqNJP8mDzbw4zOttf5T0ANUc+UR+9PPIjm4B/g6mUQ6BSKz8mfj82jtyDBlyTq95EoIcdbv6lkZr733HnnboyEU882Dt81Wt4pxwjIiJ0YDtbX8U3ps0C6ap3mUsmr8+/fveH19bUeaSkNKCLgAuBdAOjUQa7TG/FbPlNpK6YPQSwP2Po/BK6vCu10ueNoueEqXtgf7+fkTLpdns6WLwMhIiXA1gP39+3d8//YNX377HX/729/w5csXXF9fW5uU56U9TF0M3+Ue0ABc5K8CuN63K46hdbGh1a7tTnqsLIvv7Er0cRDNFQ/XsvoowhlPw6f3z61CdUe67KznobVAP5bt5msep2FE0jr+uPRfgjc2pcz2cMdnr7xqdEO5QqzQPujH0Kx/+ujYWjbPg+hYOkHWoHRGdRC4ZWbd6XAS3HvdY3TlKjqHItM2H2kDS7nKqYJjFKWLx72mG/X7wI/BJVIFeUgWsGMnjw8N7ccGbfSey76XMPDXr1/x5csXvL5eWzoBKHu8qc/Df5+UOHh/QjlnXTiBCJRbDk3Auo7lsoiNUjn8JaWyB/vydMFlu+Dz06d2aMrT5ckcmkKQsNSe5W1dZZX49+/f8eW33/H7b7/h69ev9Zx2sQqhxguNh9QMA8SgRsNm6gV5aLvewKz5jscpljnWPOQxeJvU98EIKBjulaDAsccekQ2HC58ia2oE9vuaIw/oSGFFMmX7wYbvtS1qiLNbedoyiQsiD+QaXK8iWPtU5BLtelO88hqxYErkg96HbP+O8hSlBTxoy70oWnS2fEucIQqjygSHhp+nApDjvPSKH6sT2aSPDGaJQhFoyM+bkk1ihfeubbJJ1fOmecbGQMT/YCwv9EIxblJZYLrK/8SQe2zQrsoTTMiZcX3N+PbtO75+/Yrv37+Xld6prKjetkt79SGATshDyy5QtKo4fUeOQAEnQB24ZAZSb4kJsAiYy1u6np+f8fmXz3h+esZTKgAtYN29trG+3OPl5aWsEn99xe+/f8GX33/H1y9f8PXrV/PWrqKML5cL0pZAqWwh60GxKG+pokYJUMO+a+HV7R7qbRfvLE6/UiSqvPprK+oHmyiZWBkpz2gDWZ6dGRDe+JuFtDX6NT85L65rVG5DzzY3Lau6RYFKMGOmIKsG7OrcbrFZCOMMhubAt3qUzE7o/w/COcPtnjwLGei0l04/P/cqtb/7V2n2GcV5HJUZXfPjqGlc5gGvPI+7jfqYiJETeRMllHLmbw6L+IzG8MoRnNHwPAEUgPtQ/vYTe9rMwH5lcNrb4rOvX77h5fsr8p6RUBaeXZ6f2juzuZ7+5KV62Ic67cQRsD1Pcp/IXhNPhouV173+syheotTmwcXLltdrCkjI/us9lzebiVLd8yuYGd++fcP378Vw+f3339sbu67XKwRk07Zhq/u8U7LCqAaEpBWexcbpjZpR8LoB2P739m5PK0MpaOHuGW13H+JyaxZyf69cC47uPKmAVp6CDmoZf/0WKvs9ymOu2Kjtp+7ekw1rSM15ZWGo9SMPazs8P/11Y3TA4MOfGLlvVcxngC16PkrftbtEvO7oihlA2XEpQNfxQbHcjqC2Hvu3yk80drwsDvJsnx9yVGN1VeYZXeB5a78PDCQ/lqM6nKUHB21u89bFs/y9epQ7wKiLqzakTRZqAZxLOBGMBpBipyYnbPFAkSfGxi7zpuNLRwZFbcJFYkgACUS5gbUcQbrnjG/fv+Fpu4C3C5ifGm9EqZ78dm0h8a9fv+Lr169ti5fMbTNzCbtvG9Jlw5YS0gYT4p0Da/HcZu+fXgw4cW9hFABosCSjSIdct8aSANdMyYRhs6ZIDMcTRdOWhrj+92GslZfs8wf6PCxw30yEdrAKGGN9J4/NDBpgjF5YWY0UatkhRs1oOIocfFChe8Bp5q2NzhhP7eKVrHr58fftpxh7psTh2ZnepNFHCstiJ1PtnoybRX1Wea5pPZb99zNlrsB9buDH1++hhwZtoISDM2e8fH/B719+x/eX72VuuXqlz8/PePr8qXgoezmsohwDkgGr7EjDMEIFrEronUDdCnMRoJx1+YW8OUsGULvP9hzn6uGwWm9U3Vii2rFZ5+cvTxdQSnhKGzaSbVmp8pXbMa2vryUk/vrygpeXciRpgzsu4SLaygrxsvhM1yCSHVVd/Kny5VudxcwZw7h9KNade0Tjauo+T5tWP/24W3mFkedvox6VLf1dq17Cy3FoauYRd/UaAHntkXT5MINJ+yMqr9WZDdPUtw9BjcqWQ3tuaMSay3w9RwTKrV/q/zp+lL8P+FZahVJvBXLtG4/QPWj6MlqqaVnU/u+iRFJSBLrMzelpkcuJMS7GYTRO7TUxylv5pF9WUSlm3dx4Dqxvl9AIVFfA2ukCGdvqf0DGqGLA3Ei4FdAfGrQzM769fmsA9/31OzIy0qV4q58+f8avv/6KT58+4eXlBbssdiLxirWjmTOovpISXELrxLL1KZcmZgkJCyAXv3rPXLfV9VvPhKTzRBAl3NSFn8yKxUw7kBK+fv3WFpoRynpNmcfWozXRzln3e4hF6coe7LRtBbjFu+7mpPXEM2JAtivJW+AkWSlD63ZkXSIQ7qNQsJQngETVqlp74uuBqthVAbzpB9FOpWPvdRgLL0CJmMTA6z/7DFBONjPt1dW38pqobCXMVOpRJLNu5Adag2UXaSi/U0uClm1f1uzT1oVIi6staCwHcjc+yNJ5rw0AZOfL+jlmMhhukWEO2FYWCbKNiMqZEHbMipEYlN+Cc3V8WpOi3Yc+eqbuFril7lyYEsabwxI9e69nfYaiSN4ZUsDmzjGkySs23xq1emjQ5sz4/v17Cw0LXS4X/OUvf8EvcrzntrWV3cyM6zWBUVZRcxOCHahhZBYgymUPoIQly7OlHAHJLB5aBW0P0PZNTb6PZcCo715A8coZ6bIBRPVFHiXvzShzHXQmLwdoOg9eAHt7urQBmTCm9yIkZo23kj1Ngdvk2YAox8/4cJ3P25cXWtvOao+u+Qr2Zc4WH87r6EPhkdft7GR0iqO5NOvDLmQNhL99FKq3v8UIaoDtPLdbgRtOYpocqwv209JbwpPvn/eYPgKNvk9GuYijPQSbfyw3a0+wKwNi6Mu0X5+Xjsl+3Ngc2rHPiKM/Pf9jDms+z42X6P6t/TZ3SGjg5Iwjc5YeGrQzZ3z9+q2+fjNXkLzUt1x9xqdPn6unim7l+LZtDbRzLieH5b1ss5LfnDOQ6hxnBei9zg+3Z3I/fy0C5s/LlcNLlIdyWIoNH6HOqFItm4iATflBE1bruZvrci45is3bPOvmVdotJEFjVuPjZnVypyCvwL8yVA2f+ZaVW04ns89FZTYP8mR+Ebhb46b1PZXXZpbfqfW/3VbVIotcvKZSb9mzr/1V+ry+0Y6zfgdM2SIn/dvVtN2BTkmjDz+qIWk+Ca0vVm2g5shMIX/QrePFjvWcc1uIKvckzxYinmQ/Mwh9cmuo+WfPAFczDrNuxfJlcfvBLiAgY1HG9doTtXzyNPXa4fBpVnRL353x+p35fiqvMzw8NGgXz3dve4+3ray2FsB+enoGABAxLpdLNwCInkDE2PPeQDqhDAw2i7dyLtvxU/28PD21+9ab9R0kQE1EdQX4pa7WvuD5+RmXtLU6WCBLDDAyrtdXZGa81kVmBbzr60dr+cKj7dBEqQS7EpXtXJ2FDCgQOM96IWAr4bslTFTS5wYoa8H2YBV5Fse/rbKJQ+nURnuxgXplFdUt9sZ7z9RSOSo8uSYuQ1b6wYKd2GIKvDZf8d65XVegLusvJHfhbax/b2SK3e8hWGYKGSUcr3zXeiXU8tRzaHk1L26lTtc0k6u3hg/fk36kRw6g63Ppa7vV06WGjO3ybJxnJwsBcnidRC1Es6bee4fKtnUygHoQVJW4ppNgnlNdZfOLxq/l1euJM8B5C92q685Q5JQc8XBEDw3aYCBfdwAMqp7s58+f8Ze//AW//vprC4vnXELa1gsWi3DjrU43FNCWjt/3ApLX6xWpGgPizQPqoTdf2ezbJSpe+2VLbX94e6HH9tRAW0/pqp2W1XPec1lg9v362kB736/tpDcLKB1oB4fH6KDQT9v3omgpTL8GLSKz1Yiry2jzpnHARdf7UG0pN+e5dX8ErrOweDdAGDq1QXIm8CJEPSgNyVde+xk+hhb/INcOLC5sr/zH7/Fqcy8DCs6xgpuRthVa/zXIZVW+NXV9BvqM9Jm8ualL+/6g9t7K+PHJyi+G8Q+ozilpdAxNczQAG3lxzHX9RLUgidaLSP34Syl1Z2vbcluNBiMboevpo1dhlK6b1++f+3vQmbKlh1aetDV2zub92KANAMzYUgFHefPVr7/+is+fP7dQNtA3hj3JCpBwUy6HiNZGenoq76Deth1PT7k1VJkbV/lovkQdNE1xUjlWT7ZvFUDdsG11O1faWghJwkGUZbUhkPbKcz0bfN+vYNZ5eQVn5zWRP16Q3QA1J3eZZjwKLfk2LBckpO48rcZWvHhsLqRroJkBsc3bC/msvGbhCt+sNVhZv52HvpgL7PhC9bbhBihQzs5nMdxKSNx7DB6EhdpUjpFN3xYrmhkKMk3SgNso01nfidHCrK1iowfvBd5/hCL+0d7z7aQGGVEs/2Q7DNJPcGlG47U3Pr0Xbl8Le9wuHbg6o3HUHYERi95rHvgJymn6pxkDsqc8NhbC0MJJui2iOCsfXfvemveZdA8P2lKJp6cLfv3lF/zyyy8N2ETIAdfRFfTEAy43EhL1YRyiEtq2zzEzLlvZTkYA8t5WVqkCrvEdQm8gSHgcKDLF8pptSmW1+gbs+xV7vqonz2hbu8TLLvwDBRRbSxgLW+XBerAFpAxgBIq0f8XmOLclZLcKnekf/T4qCPXWxnJ9uGtFK6Af+LfX28WY75jmA25QNIS6Ih9VWVV0gxqDVA0yeftcpLzaVE6gEPp6nqlDD6beY2+fFcA9WOu75stzZcz5IviHALfQLIrzHnk+Cvkxo9f877j/TxlubnxJZOWMUR/xA+FmZXiHmVatZPNjgeEygMZV4wwmBjFBXmDSGKDYe51F5c7U62y6pRGvHbR2im4oz9LDgzYzY9s2fHr+hF8/l5dpPD09Ve90R657niWkJJ1u54W816pWbexxbQllJTcDqMdJinddLrlQOZEppyi6Mh9YtmuBy5YccJljlzdzCUhf9x2vJkyuIeSoPfIw+ErokoHAy46U/SHRiQVrNBoFooD8GFmFlm37zSzuGRiv0s3JTR1Qb0D0nvY8z0ExgPXIbkBnjK3CrW4qoRp13gAD61YuyDux82TgR3yx+/TtNa5+F+AGR8quzyus/wDcM94eg26Tlb8HnTVggchz7XKqOsx60ZEf6nXgNC/znbnfOz3jY6ZjOzmWqF3dAqeeqn3AMy7K+MdHZixFET1PrS2GSMNI86jknB4etImohcWfn5/xfHlq3nE5azu3t3/Z08HkiFBtXFQFY72J1JVT/jESq5IlUNs7m1Iq+x0mgijbzlIqW7mYyxayBLQDVQSw5cAUuSbn6pbw9jFA2wwAACAASURBVLgVJ+xY8frZH/DSt59OIQArhToLGdu8PA8euAvwoWvbVV7js/ctBvHhtvk8UcSvL3NtWc/47CMKg2o0f6hat7jozAAlrl56XTXveDy/kj4q1/btCNwl+sjgapWqEdovRCuyNBoEqk817b30VjA9Ap9HI4kW/igjwgJ2K3OWLrju2/OITxv5665VYLaFtOvVcEwoxzyrt607TIjnhsER3dK25+uHgRcfzbqnzDPRk4cHbVl89ks9RKUcJELIe0au4cTcwPAF+3WHhCe5gtnl8oREKHuXU2rgVZMhpTJXrMAtCy2KkhWPtoSzawBaPCUxBnLJe9+veH3J5XQ2ANd9BzK340gLn/q9GBmob+0si+6aedw+hZwV2y6Nq5rZWqFUAUXHiDyt9RJruXrQszmbXhgZAgKAAra9p0AVg7TP+6xnG+VhPQD7jHrSqO3s6yb82u++vLgOIkORQrEGBJGCffEo6rG7kjejetdk2pHaXzOOWuVmkRibaE4zD8jel/cYo9VtVDC2Zez0TaSk/wh6BE/6NlCRPj6ZVL6aMbyaH5ZkVizESBAjzmY9i0Aup2yO2rrJcpSXhuq5RgxFliQCxFxD5KbsLus757ALL4aTG4E2muLTfI1uFAPdqJDOaDZlnwH8hwZtBmN73vD8yyfzco0LNgIoAU9bwn4FCAziHbxfy5wuA9fXHXl/Be8X7NtL9azR5rhTSsh7mfcGp3JmeQt7O2VfwzZgAl+rV0vAnuqxpwTwrnu7eS/bynLOeL3u2HnHy8vrsLCoqO8qnDmDeEfbBMS5hZ6ATuTRC+m4mhgo7SNAITJgvSErF9ZbliE0yA3FY3NI1i6IwROlii34mfdt00Qk8RMCyilEYThZU2q7eB76XK0Pqd/7qRWNcAi46tOtfJZ3u5X/d64vkGmDuixqzFw2GAAJ4HIcH7F4GWb/7mL65BYF1pQzF9luwEuyPqKe188A14A/g8BEyMZQlMVMLdZTldRb/Ny3esn3Rmz+KGLm6izotSm/pPftOoOjNtL7Pp2Ash6ZXAuY5hXx1m1NixRGNfL8ZsOePxNNdFNByGhjpKiR4JS0rj43GEDKheYVblWNI5iSzqYfZE6MXukvEzkYyxnzndFDgzaRvqZye6pbq6qnTCkBba+0PmOVPIAWgk6peDHX67Xtsc6pvJDDH8xyId2b3XuBqR0DyMS4orwKk3Px9uWI01y96zJffcUuYfK6mEdAQ+vJDWjOgFRPs8CWtqFtGwEcva7AZK+PlnWY+2GZ9trMI4gszrP1iTgpEYM5eGfOXfueAwhx0+/gTSIYq/u1Ek1JEbV1G0N74U2+BWZG1OygFfHe1YAUr4EAo7jV2ya0Cf5gq84HjbSUweoYrJ47E1aNn63Ppx6wImCZjevjMm7zYs/mfdY7XY1z7yz8aEMvihZ4+qnD44Syulv2QMtB2bZKnc8pFn+WQ0pkJTY1oC6/U1vJK50mwL2lDVeT1wg2QDkkNGNP1aPec+dFF297R97rmeadRc1tXrBtBSMCtxjWOeo7tljNvfCOoBgKqFgRJl/rSfbpXFu7sNdZgfehIV8nz+NMiBUsqJ2saSkK81urP6rrW8hb25Y/mU7xdWt/6H1135Y+JOgNvxs5RQjcLW/bHj7qwhoFKi0MGE8DjTcpx+b+x9E0KnOHZ/MjqZtSCHjp23Q07D1gkeuLeZlSVo2K5AwKDnUJjctJfrPfR+AanTMe1W32/Gr8HoHjvL1tVGPMe6WT5mX2BmzbQTThYUYPDdog1H3QFbTFg4KusgXQLY7pw7IFGHMub/CiHQAR0t6fdFYchhoqR9lP7YXFLqwq8y0AJ25nlnM9dpIrkEl4EQA475XH7AYYUN9EAlk5fD/l2jwjKCyJoo1h+nzPbA9CZz38iKxg3mONW+C3nmqXprJc8EP3yFuDLOJ33g0ZaPA6OPODUm3XoXvdYYE67J9SH7tqfGXg3E8euI0BhFjx9Aq8Lg8IDCNrOOrExToi5GkWlZB79yjpn5YWVTrrbUbP+MxnADIYoSe9xCiiNnv+R0xnLA3fyVgddUIvtyu583kO5WviVt/56XdzemjQJhAuT0+4XMyJYymBSUG7eMsAIKuuBdtdIzLXSF2dO8xloZiA8b7vbXuWDVG2kB+pxyFeRHtfN2dzT4/mY9gDBvqDVhrJnCjbOVVqdak3TatwKBTa8f3cjlf8fuAQqXc35mX6goQvIHRrJxSV+R7KQfmKAbvlW8edT7cGBYB5vK+DeM5L2HbGeyb5tKAtHn8zIAnMhJxviwIcGUJWRqwH3akl6iMU1vv2ZREBiTXKIQqolVPrxDcC9op+tGJfgc6PoGis2h6xBtBgpBqKAOMW3onInbhm+bstcrFKP7s/A/iBxxvyXbXTUbo+bXx99eyUz4nDEI3dGT02aBPwVBegJaL2jmqA9XQzMIi0caXCY8jFLRKq6eyRgUXh2PLLPHhunrcs3qiPt9BW/5yGvMqAtO/2NqlAdl+18QB7oCvFzAZSFEYC1BiZhQNbHmfHNRthozF8FRkHZ6zSrggBL5fnirwiCy3nBtyTqoVGwsq6jhX7nO8RtHzfSfSm3CvPRAAiMr86/Oacsub+k8b5+lKmjqsQ4Iibkev3lLfKtPEA3APeMwV+D90TzfmjaO4ZjmPf8zY1GA/G0gqQznqBR8B9BPxH+UVGv89vZYT76+8lT50ePfl88X1iQ9GO8RU9NGh3rgDQvF5Rb3q6VDrVac1tcAI/b6ji7fTEBkQVdGPFXZW1exkDMyPd4LFFdYusTjHamRk570hpmw5yzZc753GebhH2OWElr+pq876bDOjFBTU7bSh75Fe3A/ZFrLdITVmDvrecmTvY6rxvLhEkBXPxnlYVO2co3Uu97AEiLK0sKmYpsy6eazwMfXI/cP9j0/v02S2RKnVUVM36swDOylIUAfCOxTRKYAzXWdmzvI9oxZPcP2qrpiMPyvZtNdXfmEv/2QjjY4M2qreLsiXGek0ACviWVCgzbAW1vPczs9zOkBW44rzOBXnq5QEoW4MSyrq0XhAiOgMOGoYsfNWgZ/HaoYPAn8/e5T1ECBZeVVBHnz7yPFf18IN6ZpT8iDDlLIQsgD0zRvxzq77SduuVoyyGrAnbM4nK/uhEBBBhz1ltPhbxJ+RTRuft9e8TdLWBnPanzJatadQ9Ml8joYas5vkedK/B+AhUeLey3o+zWwEqckb0Ond6gUj15aysMyHrFaiu5NKPrxZJeuNYP+31BjrI8mJp5Sy9he6p70ODNgF1i1cPMmLRA0Xfye+yYC2HpzbJs57WgO4tsX7xmjoU1fsPPOoyVHrBV0PD5h0LzcpSFT5smVE9vKD13jeGFcsrqzH67a+dCT/dasXf+uxbPP8o+5XCOs6v32qnNicbeahlVMA2EmzkpXza0Hg06N9NqZA51AUEOa0PpHtv7aSTvRbLqrTXyt84Tytv7Gci0WH6+7geK690lt7eUsAyTByUcysvWu59DkrP5/owoFWeM73m8xfq041gHRlGZ/kJ47nBOFnRQ4M2gBq9VQudjWUvlmLbwpVUKTagrKDU5gHrPVVFpiE7ANRV5QKonQCyHDdRmKS2cIwhq58YFnxNhcynPDP0U2WseWown6xCVJ4ThRrk0T7U1ROlLwdngLlLfLRVyrebZ30lePE0wvwZPygiMFYgPAegER9z0sWN6zzXwMkiG7W1cs7toB8rEdlIL5eM0NYQUJdFWK+B+0WkQNc9WC6ssjNldPclpiOyUrgmKu+Lh8gkuFszweZLG4PWHpchewf43uKR3kLvFeE54q9E8uzbCc/RbFokku/S3r3hSFDhnnnpb6Xe6TIhp5PG91sMZsljfDYbx6uXfaJRL9l+ucXhGK7Z4tAP5bOi9uCgTWgLoBIAqgu60HemgJd4AuUNRXrmtrRURi4rdGVOnI0yrAmJUiszgQDO9T3MDLCBLkLNywAaC4BkLVaIAbJxTjtsmmJ2wEvuK5n0XbKqKQnuAe4HaBsrsv3JWts9mAVI3P/sGLCr5GOlcxR+Sm4Q9nzHg6UprKG0+JkoxB8qt9ZOuitAvKG+HroAUYC7/Hb1JGCX0CS4nWWf5bsYcImQ9wreBJV1KrLL9i1HJ+rrySqg+XSHHVMmT2tcVkNvqw2T22lq5fGMctIfJAIlkQEdJhX3w56b8j+r889Ew9itjoe2tU6fnCUP3P53K1POuRCZTtTKj/iMXnsc/R7G7ZFBPDE0jqIHR/0d8TXTRb3TBMDI6SyCuYpijPlP7nc2S+CMnEDuBwdtFQIP0kLl8BJdjEZESEgFoOVZ9FZ+ycRdq0oZBGx1JW0iLzBctrhIBo5HTytL9aijbZpemMXHceWk9cCal8Nn5ORmK/Nc2ea6G+xd2okn0DOIwdG2r3C1HvutITYfilbga9w4nr1xgSYuUZ72ezsFDc4YYWMcdpGnc96G8hJEjSa0CnWSNTYOFHDJy14P2ge9Z/9nJDWU1oaXpLXPraaQVn1eDKgxz8ioO6PLznrnK9lbjvPF9VVUaWyP3qM+Ewk5o1PvqbuPJh7l8fCgPQOz9mfm+CS8JHPaHuw21D2lonxbhjVP/SlPBVYmVIF2nkj9XjNY6UOJDNjfUdjT18GmpaHs+arvpYK+EYNXAiX9ERbjFEc0qCzA3mJVlwDE2rO+B9zsvVmkoLctVOEO5bWTXupSrcwojjO1s7sBtDO9EQLiKCSRUftHkTVc+v6M5VHvV4U53PsAbiCQt9DQUc+MeXIwk+gJr2tMHhTI1K0g5HmeeqQHefrV615f3CLf0XjwUbIzUR2vq6I8Z8B/Zkye0U2eHhq0bYWYuc0DynuGAQ3xCGinlLBnaiEYebYXmApmtd8SATBGAIC6UjxWkHK9Ha4ycE4dqCdYQZS/XjhViNgoL0JqHtfMkuaWts/PcRR4q2fpjFemicdIgAxGy4OE/6Qfm7cNrYktkSZ8EI1hdMnPhveOLPaZwRMNKr3XJKFx3fJr98s9qv93bVMf84NbjBAbKYDJRbIQ3pZeyxCCiAwrDT9Z+db6anm2DVqY0RRRIl2MDJq2reRlr94fv/nHoQj0ZE0N+36sxl8zmtjJMuuYWo35brwdRkvOGYbTyMuBMTAbpz/OGB2NoYhmYG0/h5wn+nYVEZH0R7r2oUEbMF6o+W0VVaJUBdYe+wgQJT3btV4kRgs7ikcsW6Q6tea3tqBvfHnBh4YHrZfQC0IBlbIHd1o/iJcqct1vnCHzv9wtAzlYwCZpFgOksx4tL1KZbvJRogoY5Hs2iIeaUuWWJTcG76NHrOCk/HSG0SIklh0v0fdbFYIdmPEglH7Sazo3rwZYdXkGnsQAbTJdQjglT1JPo5XL0o5NgsOIhW1HlSl01/p62vtBe7DejSM6milX/hMXoMl0DAZNovnP620PfQ2nwIf5/7NbWXX6673A7xZPfDBIF+nFGYuiZbd4/PLcGlDt31jejF8P1kcROvv91mjfjB4etHPO5dxwokGw259Jz1xWrEqYsQMCdtY/o78P6cZ+36Ss6JXr0s3cDSTpTAnx9GFObidH+fx7hQzqw6UREQlsC3ibfCbkrfgWckrmmvm/axT0lnzHd1T2RO+3k+tA5f3jgeKpmUHmnXrPUv7rB4GNkJziD6MyuTe8rD6q+cJiFPbbuVaGhHro1Le7kXO2feDAcBYpgBilYjyAMLT4UO9ZO6gxOZw4SPrBrEYoMbC7LL1S7vpS2fxT0Cj/ERhwa5MovOtDuF7HheNRxr+5dqsBu6oHtTHcCfOUD8+DjSLdMi5X4ewYYI/TnjH2V3XwuspHUuII1pweHrR9hbyn7b0gUW5gnedmZnBdkakAxZBF4fZZAtrBFgWwW+EQh5OYOsD2Vl3z/lpY2HRkLWs4ZtS9B3qptYyCax7oRIh8W/m29WDi70d5LtOSr4detunS5DWXvaDDALZGNcK2ORjXftCcVTzR812hwl9Lh74vieDPavfGpz2zm4A2P2mnEMoz3N54eQtxZVX3jHXc3Jib1iFSSJnlpSqaLoGRud9f3vF3oKT+DKRtEPXRrXn0xt1snUlJt45seO//lr46A0BHeZ7RT9F9+9wxD6PH7fM6ZZQYvqyxbQ1ci2HR71l9LD08aAO91WUBqFWc64lpaHaTznsLgAP1hQwlVTkusnbXVBFzE3rxmjnL/mu0FdteufsO6eoi+brnim6fnxduuANgBMYpcS+oKwG5xZK1g3dmpGhkYazzAORGmazCWP7dJAx9q/VZCzxUZkA4GG/J16f1BmR76QjFPPv0/oUbkVKiahTNJGSQOauLAnvqpuDC8OzYfiklcHYejIkwdXWu9chkIit3GCX/KLTyEkei9llEomgWHX/1+0Fj2nMfIm8zApQVWA5c2vyia+8wBs+UfatheI+Hb8s8A8ozPXpEDw/a4n1E4RL9NFu+QNjqu6VbyBmq7FIFbUJqYXe574OsbRuV9e4kzI26l9YRQU8kjyIDYjSwCbe3Z2kUlmGAzBT5YnSujApPU+tR6ha8+zZM2F0IPFgT4ZByI55K04+KzAJ+5+W/E0VydjSolHdnuRuQFXCO5cLnM5SAqmGBwGv9Iz3WpfJO1Zg09xMPAYc2FdUODuJBeP4U1NlY1O8s6T3m4cnuuZLe5tfrhQhYqMrTuVByxPsNi1TfkWbedRSStuln1zS/vr1m5cye907RbCyvjPcj+glAe2/ATdBjTTnnAo7VQk9tFbmCWNUdDUfUmix5+9W5QEtY09RPwRjjXYPLmegg9RjK8xVOWBW23jLAT/6gjFEBTgeDAz3Fc7PYKwjntGJU7wfCai1jNS7A/bYSC1BHckatEesiNHbqxNgjqm9IufKRi9BC7YFsZekeUTSNoIyeA/AWUxHBaU+LEZrLm+ugLxPx9bJec6uPVSqatV6wDbvol7WxdL6tQgOz3DDXy2dCOchIgWXccBSsk5aSTvFzixf4CFRkc3a3yFAbCQxnmBqErp42EepiLrmPbqC1hbitUO+dWz25cB7c9VvojBdrwfco7WDoHzgC9l7PU5dLx6vVIx6YZ/nODNuVAbS6L/TgoM0g5PpXQFiUXvlkVXgGk4CiFGXBltwpyiIGMwVUgl0wpXIvq7XrLwLAJa149erwcju2Ug0GO75EoY+8HA+C6ue7wesNE+Z9nEMU5RladXINnUAK7zOuylM6Px0qW6c0NJ1OV7AgthVu+bSCX9tarss2v2wGuaejNp3d7w2D8qmvaZ0rL+1nPeAnVf6LzKoRWmQ7NRADjStope6c9y7q5KmKHLTlaMA6742M7TXmGxktPi/5PbAg9aYy/kr3lZty6luq/V+iODq3r8X+HAB8CzH3488baKJnmpHmrZvWFVYWJBo5RsOYFbDFeC6UKy9pKP/IY7w1hOwpAkG5fvQ9+g30ryT2su7LjOsU87YCan22HwdHQH0WpD09NGjbRrDhcbkmn6mcW6pgiF4A9JleCGNvVMB9BI9OgARjmOpctGwt63BF/K1gQPZW3FQRe0G1wGfTWy8nkAFRhA0gJ/lHNPXanRK/9fmzA96my8z9edYTS3fWx/bejNcodFU8mP7aLO+zdfHXiRKQGWzkY6jfJL+4XK/p+zF1xvq/x5OyIW8rK6PsFx7ZxM3D+ozV+OnJioEXiS5iAQMgncFrnyej9czaiDbtgB6onR0vP72+vTVC9VayAHtGRx2N7Zmn3fSPPGOeI/P7qKzZ/Vv0Q2QYHenFhwZtANj3fVrRrnOot/SpvjZQ0rE3/xdkwyHlwsRSMp92kY0OhIrsBmTPgsk0tEPoQNsrdh3wdSBLnly4sl7ztIyDtlFW3q5J7+EhUjS2Xc7mFw00ImpnP4+W9Tke58A/ela2v8tZAzAuZmw8DtdnRlXArpe9t3pLUZ7SF03smiHcxLCF0MtzZZz67S/y3D8CYHuvzbe5jgPrhXNd1LfOw7d9sTDt9TrpYIwBe8ZE+ayefejx2zT3GXJn6KwcngXQlS4lGWdkFjAbm0bWG2XZ8Dt1XOL8Z+NqpvtvGYMPDdqRF+o9BfsnC3y2bSsKMFdQkwzZbQOTxksESuIR915IAblJB5htLIRImKgIR3tt8rpjznRc5GXPvHfYiMENys8qBlvGyEVvKMF9g0vjKQo3nRJeMYfdpcFlWZQxG/giPz6Ps8A9k1f5HinsPl2vJKPBH3pagVKZqbYIuO8jBYWeRa6AbIDaggSj3VeeRk+vXT8SXNN0bzVAPP1Ib1NlpO9/0SdA7wXKM9bj9rrHG7FhqHzKy/He6Pdu3yj/FeieNTht2sibbf5UuzbusvH52bwiWutMhNdD3g7ooUEbXOa57B8wAnZKqQlyV/HWQaWHEpm5V2akRNjlFW3Ds71FqlnahtXhkwlAGhVlpGDl8ygkcqQsIqXeBE68HeEyUfhcZFXbgTsOot6/tkriHtW2CkPNLFUpD84rfQtZsNV3tduBf9xHZ6zoWZ207csCx+wUR2QE3EORYjqfJ2Ps5ejZWOENipTIpSyW5QhSE9mKWHlnTPlRgG3zF0chKm8AD53l7tpyBnQNjLoAhg2mU2fsRKB5S13OPLeSOx85jPI/opm83VKfFtXA3IiJDJyjcmYGfcT/jB4btI0ijZT5CCr2KLwoQ13NS1QOTtHX06ki4bo4aCYizdolo8aY9XQxdS86heP5tvU543W2dIzDjgeqkWLAVw7pOLIIvbdYrskJ6oZX879oy7Ohn1sHUUik5fryZjIzzWoCYjowe74j5bLqCyurMwNJPK7Sx9wWpJ1RVj/aAxJez5VVozwtDh6gKevM95hfBOXumu1bk+6RycqONU6a3VvvtQ0qkwqJkyF5MvPQwr3si46yefj2VB/nyLD0xumZaAQZnTgYZcHYm0WPbP2O0sz47/VX+UIEPXtIDClTluc5+nwrnc3vsUG7kq2E9YKE9Ps4Twi9A+sprDxgCRON13vP0i7sbIPGeg/MfcKA75WQ+nKZuYTkT3ijduvMypv3JMI5vM+XY1DuIXvk+YhmxsMRr2FbLQyH6TOD8oqNJzH27qEjo0UjSNrmVNP46NKsHjGJkTq5e6PhFCn66Dra62s79w4yPmWwEPSsduVlNAKtd9llBwQm289LBbDt+I4BqR3wZIJOMyAtWElOC41kvf2Z53hktB3K0gS4bVmn8nHpj67ZFeVyv38rGgdGYZPA4dmZk3XEyz06LaKHB23roTRLNOm7s5ug1a0/5kkAMci6JP3vms4K1aqxiai8DETSmmzbeu3AY559n3lxQuwELPKchQ8L2Gc8ePvnowFHNPPezw7w97JWfRn35Ot51wNlJpEPnGtnm38kw51HSrr2Yt/3N9XH8+y/r/Lt65icESCKy+7VJ/twS9P0NUualcFQErYxXxdRdWPyXHV/KqKCnCdtQ9UDMw/wpnJvuHdLhCnKLxojZzz1SCefKfuMZzy/prJorx+VP6vjUVufqc9PAdry6cHMKrxEffiGSNOUAx24s0jFG7VUnKm4cyKeUg3wJaJmuRXQtkq4B89VvnLP1teX6UNcM+MiAnebvy8rEqyeT/XaWIyUwBCaWdCrdvSGgg9HvYWOjKCIBFRn+dl8VwZZdN0Ctk/fG/8nwo2O5yBVGwdnIzqejvuuZ7dclnK5Ga7WNW7rdQlgHl+fqm1jZdUyFbL6Q2gWCfph5ZVCza94OqYB/IQUoIC+H6ICzc8Deb5FdmZFzTz3W8fo2WfOgnRcjzkoH+nwM/yc1R+WHhq0CWgHqoAzwOWQlfJbwEOMU5kDzMh5B9cFZpKPzPqIkrBbHjRdAbqZEJXiqANDmQiRFzkUgC6gRmEeCzBqnojwZVbYzsZcMADK9wBRHR/2+Si/wYKv/0l7RwvBbvHQZwZYxOOsT46UylnLdmr8dO3alTTNd0U+777c0pzNvrcFite67tZT5UZ0SmEGBt+8DDVi5Vt3v405HScEqhtsbH4MMFcA1ymfbiHVA9NsnDGXUxzrLzRvLvVmv428OMuoS1VgOZlxWa5pN7HmNUQAjeKx0xiI+1nZoMa3fCdjzPfpbiM/Lm0UcJXefj/yXKO+OYoQ3kMdP4AOClI5viV29NCgDQPYhLJAY0uERMBeT6ZKlEBJ5DhXUFZAZjAos7Fgi2JgKDAW4gZIrXgPWrk81K43xZPq81ke1M8A2EKq+ngUFlmYhDYgiPx+1v65puwQC6MdCP5Zn36waMljhuMDsQd6K608wns8ntVzXkFE4A2oku3zoVM8+TaJ+oABsCgoxztEZzcZuL99z3npk2dhFY1cMfeaZWdTUEvXDO2aluoYkXzldDQGVeMXQGZQ88gtz7e3wXu2W0S3eXBqrJXf5Q1pmt5B96p47j+pgXw2z1GnyyhVuUJ1cEgW4fZbHl1tBuPMGp168lFgvGvnNR4tEPtxFOm4s17z6vrs3ir9LdGAJZ+ua2e6ZkUPDdoE6kKJnbVVB7scY0kkikEbgUGgLAKRwLwXpQzx3rSso1CndsKoeC3HoPEAlRFQJ/UNyzsPVF3e7JVrD0oeoHxZ3ruNFnPYMr3XeBYIfHmr0JHN1wp7ZGDcMgjO9smMbqlrFBlpdZ9cF2Br+aT+93uQ9cimdbaOGQA5yazFnsyK8FMkHhnQ41HzsCu6k12kJh5dz8uj0pH8zMbb2chIlM7mWU58L2si9IQ0M04icIWeCjnKrOhY8c6tzgKaw2T+t3yK83TWG47qvNIRZz3lmU4+4qVv23k58zFUR8tg1No0SxYeG7TFo7CCIyANBjIY+35tDd3Ooc7VgsuAnOvcHzKwANFVJ1SLmFkt4l6AzumQWYd6q1Pq1F0zlvTSknT53sLHzHg5M9Bu8X9uAdZ7BvatoB+lnRkTt3r7UZvGCjFW5OrE/Ai0ouC7liMGceGJ63czVCpfhUcCJ3Rh7q6koe3E+6hGtBxYVEEji6dI8qzy1prswYEbiEFiAeU1tQAAIABJREFU5STY30dhYZ+3LJy0z5Wmqm07AF15rjk/rNsPPb8RGx0PtU+8Hoj4PGPk++v3RNk83aL37I6OGZ3x0KP8/VMUpInosUHbkFWefWhMPzslJ0ox8JA9dQp56ACx7Amy9aRc6cWSSAeG5XlWTn8jruuMZgJ/a8gnCtn68md53wLk/pkZf15JnLGa7wHPqE4elO8F5lV4dOpFCw/BlEYXXSoXT/Fy61xZpLB6z0rSqKcrnhpaKmpjY9V+bYwa5G9rTqB5SvlSbJFXbYIC8tazP28E/r3J6yoA4ZgW8gsjz47L8r1eI13nUxKjRDMqyrb2rm0+9h8boyAyig1wQ2VQwGhIHQDaykA5Q6vIg72f3DgjKlOtbCIIzUdaiNVMh4ZvkITr69urB+AnAO1BsYkSM/cu24YXo2SaYA1hFLN30eQHGLB27jJVL0DCza3TB+HwnaAuAJljU3ur1HhXHZ9xOxiGBkEs32XqoH9uBk7yOzIuosG/utZVO8jnCLBntOJtln6Wxht0UVjdr+yOPPdZG0aRkohvD8TtOtDAKcrD8+SJg++3KoaVZ7B6pp3lbMbKqedqfexr2m1b1dUiigcV59WD5NpmaGPjZ6FIBlbyK89YOusYlHSM3sTpFEU555wAnY7w+Quv9emQx36fOVFdfHXSAJ85Hmfbo+MkMIyFUqlBjyWNP+oTTsoZHcm+fqJLZs9GDs8ZnfjQoG3ntMvAzq0Dc+Y2gDdK7T3bnUI2Vng3KAAQ9QDqPR490IEbL+13zTSRzuDFq1h1nnIYnAAyA6ivb7QKZ2adaatEnjYjyxQAz63YFUUCtno2sjCjwXyk/FdlzAyEGa8z63alIOUUvdkAvzeS4Xn2xkG0rWwF/KeJjEJaGViu3MgjCbM37Uxcxxz0tMGzs9pq1s6VWBtXjZ1+zYh+toy6Ov2RtCpvjCLNn51tN/Q0GzdT49KUZQ1Fal8W5Uqz8mzcu/En140zNJOxyLE4itJE9YvSzca0rZj4Za2equKHuoV1xThebLlH/bT6HtFDg7ZQ5ClSSkgMMCfsO+qrMnsrp28ka2FWwCwZtsURbRmNMbaydAxpLrLKNXPuOi4iqnkM6ZpncuyRutZQ5sw1xjsoexxZ6uP34ZqzNG2+kbdpy5yBxlkwmdXHlmkHUzQIj/rT5jvzY5ftM7k/o8FbkHab5UH9s8rr2oOf8bqMWpgmYJBxi4FR7fXPNl6ax6x0bAgBYhx2dfuJHO1ip99m3B6lWRndhQI9WvWdlbNQF5UFQpAtZYf6io43490D1P65VVo/7rs8Ko9F36sBUx7sCmt5RUC9Mop9ubZtxUnw9Tk2Mn4C0LahRNuxiai80K8KUEqpbP8iApCwUUb2b/NqvjJjplQ6q6tuwWDXcVQBHoO36/KaAQ+AXK2G6OUUq7bwKw+1VscWemSlWmGM0szAbKbIyxRC6o7fDI2uhUfry3iLEQIgPArU8vYWj+xWxSuyOn8u9syLN2RPCfMZH/N41jPx5c8fgnol8v2gq8L2mUVM5Pbk+T/YkT5BEcd6vcNALpHDy+VySlHfSysgLH/97pyYj5Uh0MvXPca1H4MrXXoUOZq15Ux/zfRuw5k01tXrzhWt2uOmsWbo4UHbv+XLNrZ4yFLfLYkgos0jS1pkLitRzSKDcdR7z1wWZOjVruPRC9KsA1dgeXTy1pD/0LcSGrxNAGYCMxvA5weh6Z8D7/XIcvXpbuMDrR42nzPGUVS+z7O/dv/A7XgDIds1Ga4EG960CDA3Qccy4utSwon0PsBgcCriYVlnya6OT0mvIVbUSJgaqtr2bHIRFv5erjah6RSsxt8cHIYcF2Nh9lxsgGpb6erx/q5PN5bXX/dhbn/9iHwdjn5Hz/p0K+N55vGeKc/266ouZ2imT2/Vsw8O2kXACnC6tx6xBb4NZWk+IYGQIIBdBK6FgGr8ru44Ln/M7busWxVFQs0gGIUzmY5feYQMgCm3XwSg7pophx+1EPu5eazi4OducYeEt4S3eygaODacbIV85pVLHYUn2Hl21H5saY4Besz7PnqLx+7B2Sqsck9kzXjFK+ONEhiEXF/ikIia7AJFJkKFjBL38WDep4mNr7EeEfl842kEHx5tar+BNyvDJq8WWjX18SaylbfeMPFlrqjMrcuYeqvsTEsZogO27aP03uAYvbQjb3N1/RzPgIQSrZctjo6HcH1IvsvjznFCfQFH00dloFNay+BK53jdY9OtIopNv0KNPd3hMP/NzE0G7bPWSu34YhkLXN6maKvW7o1GaDuQa9H3R3L+0KAtUGqVIiCNXpVcSgAlJNqQ0oZEJUy+m9OFRB6pbm+QRTORbSk2qf7NPME5EHTzFXKqUwv3WQHWww0krHzYJg44tT2UZp0+Cz/P6Mgbl+tdPq3Z2lEOqqhIh4ufF/P5+4F+FnCjvPzzZ6IMYzpbQTXq/P1DRWyUpqiHaiXWkHC/66EZq/X76F+2lEO5vs63Kfx42kCyFENaPJE2RqV+cGVjBG3lNVboMt8oeOgVum+NKnYYTYL3pbFdVLHPaADFIHlkJB1Fh476tPSN9pVcK9N7xSNqY8T8BTnZQscx5PUR9TK48oRtPuF4NZU50gMJaN3f6tmppx6wLf/yDolmLzJ06se1RMNzmHKkHpCFzFxl0ukY13ZnIxRCDw3aQtqRwL7v4Cfu1rzI4E2UupO7ZMW3bNVKJHPcYhmTG+g9nZk/WfPbpGLIXvjrx8J5a2tVdhwmGykCp5mCWOW3uhcNwlb3kzytylqFuO4NqccKRk+JsodXWKt/Fu3ofmcG0nqgkmha9Er7SIH7PHxb3A7cAV8DyapxU3/ntDPzMNfd82K947UHYuuRiJCJS5vKYzkA/x/kbb8XRf00u3/mulBk/DYnqFc93TOel7MGtHjv3h0689ysXgQCVfk5A/wC1jbNke6aGe4FYB2v4jK660c6UAzX6JmZ8zKjhwZtAtriMvE45A6lAttEBNo2cCLwRkBKapERIIcH9GDGWgB6y9AqIWD0qM4AwJi+mhW16AiwC3+3tc8RD/cC2Ax8onuDkTDxdD3NlNMZqzMCoBmv7wHiEa2MhJrCfDIkfMrMYLe9jIFeLidljWWsebu1nm9pn+7ZXmcXgHCepn/OfkZGpP+0z5R0Wlbf9iN/bwXxH2EIeNn342rmNMz4iIz31m4t2hfzsfq9rEMmULIANXrOs4ja4Ghw9ZrNWeaWp5lOpuYer/mXaGjYPj5qcCd5Y5ugk1C3OGieHhq0RZnt+1730nIF7x0p52J9JQJlM/dRkL4sOWMJ23hBKbkX8MQQPon2mXohOWpma9mKDitlaXimG6BQL+6WTowGrhUWIAZIX6ejPFfP9b/VAJqBjVrk52llSJRSJWoynFXXxn3rNe6fA893FpNJJ3NfiajlwZTBw5LpYihahStNUeb+ZvXQUPPMcJz3TezdDKkO2vEMjYp35KRHBG7jMeYrXuwTAbaU3/KRwmunl+PKbR3Pea230nsYfp6OxrG/7r/7vMLrDUj7uWLfZz7flfFdqB/Pna4jmtalz8MYLyxdavR6ANRjBKofBzOj54wzUfRyb0gQVKLOyMBQ54NHzuT50KANaCeKJ7LvO/KekbdcFD+Xc45pS+BXPd1GgIPRH1kHuS9KtTVSkxKd9yAahMNkMnOM+rJqNxerUb3sZASj5I/QWJgN5KP7ZzzPkN/JwPD3XCUhYG3TWV4kj7bFDX3enuxg9OkiTzKhL7PlseJbM1TlHzNjP1SJyLPoH++NQln2WLedIZlnhoAZ0OpR8mlWugPueVXW834zY+oeQ3GmgDuTlni4fyb/1TNThUvF05J20wH6+CHyWb/1gFQo8ggtzbzlou/Kp9/KdERLI1ygzGRZhsB9kRsLjP1VDPkN3100JqJjh0Tuc6uWGPcwd335s3K8wflWenjQbs4RM/a9rLSWQ03A7BqkPtIpOLSVfEJRKJJrWd4qHF7Y0T2AYwUo10QZowfnvhPXwu0t7FmaM/fPXvPgGSQsH8lfHg2fjqpVbNs6MjhWobAuXWOF7JX27ZC6wWpYtL8R2WoyTTMZkGO2rowmSMCgmGLDaxaNOYqsDGW6524FbskrbCfH+6wZtJ42v/sUW5tyMm9BY3nffeNXp9gegbwxFhnKs5CyN1BXxnxLL4Frtl43Oi/Wpj/ivbR6d6qO6leK0sfUPGyYfjwoW6ZL+3VMx2XNdEi55343R+6kHsFo1HZ9GKrC2+T9oUHbqrHSqblt+8o5IzVQrekp2PfMKOCOsSOHjiVq6iNK218bQ2/C5xB2stdmdSXqPKsVnVHIK8E8k88qjRXA1TGuEYjc4ulHtPK6FLgrczevIPb8RiA842/0uBtXFAOpl4kiu3lIcyZCInzLM00JnpSls2Uc5SMKu+XEAhb3U0J5kUPLg3KLZkjZJapmPCQTsdC+yZiN25+BogjEKiIVgXtpDp2OaDLSRR0x5DXqk6qv0DshLQ3Q6e5ZHTo+IXqkTy+RLV+K3LOOVaJeE9mDlSLychumuVFeIh1sDaZZ+rP00KAtEYmhEdw1zuIV62lTTVA5h9aXWOAtQ0OnvNkT3pMofpkL7Z4Pn7kd2Gbh8ZlX7q/NlLV/Jkpjr0QAcW8Yb8bHWYraYJXWl+09T+mbmBWdn1dQODcQS5hS5dULlQdf+T4e0Yvu2ZnHFUUsZl7cLRT1+xmj0T8zuybrCQABCPHsdA1AU+ytbFu+vt1qXH/w9yfp/yjisfQY4cYx6pqJSlGrd2BqdVNQpvfku/vy5jDM7FgexqD3QLv6s31yXXcfmVhFZ7xMr3T7zFD3zxzhw1vozBh8bNBGGXDMGv4Qi1oGcX+uN3VeLarxxEaR3uqx+FCkfo8t9kEgA8txxcM0rLJIE/EwA9GoLithnIXizhifqzC3Vbg+reVnlsdModziXfr6zXiXKMgZ8n1mPX/1GixQx03ZZN3wdyYKM+PD5jt4AHcAt6Y5Nu5upakClvuQ/koNkFtUSwzqQKZL3aNoyN+PjoDJ08q4sZ/SHiFwVyPUrquJtJkdh52O4LnuMU9PSh/LIF4dLK35RcXd4uD45/pxAACx7pg5RqvvwOjlWyzw4/pMXYQeG7QZADEYGYyMzOVbqVwGcTkBjRKQiMu8KpXDKXKdx8657PHbqD9NiklDMvpNrFc0z51Ztud0fqXY+eXXBHDk01rEUZpWV+R+EYYoosoZ1bnTEmmwxoSIQ8/jQEWrnfJwV9e1RPEuq+A5i32VnyTncnCnekIo1yRpcpPlEeDMDJiV5z4NYU0GoNR6UjPAzGtbNthtWhblOFMOInv6rJ/3FzkeVGxDI5GRoQSGXxdW+MbcO/cUtYvyFhtbEG9I6l9xVXgsaUcjoMsfKiDNxysCVJ8inVhoBSjP5Snx0N8btY8NKa4VVo9fp866v8LwFBR66uWjcUMlFCvyI1OEIAKx7lTRd2nHxmDfjzXaYfRmWeLNsCvH1WEyR984Y7OTNVue/BalPBjgtf8mTgO5fu/aYzmuW40Cg+7YSPLXO34OKHI4jp57bNBuVBaf7Zzr3JZ0L0PePnPZEmgrB7xr8ExScUlmVkxmN4gsiSLR9jSn5Jg0U27vMuUNQIfeoiou2UbWKekDnspzNd1CKI49TnOgCKt9To0dbajjEGnTuAq+B971Eb/r8uYDYxZ16O+vDJKZvTI3khoPrp2IdBbNKnm5EHqL1sBrvASKWJg1dZpvePNFeGAf+dZC1Ij0PpcAOAmCaxW6lK2dXD1IQq/NULLPyz5h7p6411M7T2dGn9FKjed1+bPoWG/oRHmJRZRhXgpdOaUmI/I9crW7cgGU3TrFgVIBlXz9w+imBQe9okw3oGa9VN7+1pVfZZWHHG6myMiRcke6rX+isjSndV5peMFVTA8P2q3OTmHknJFSwi77tZslXQQ055Im7wxstcHYdZgJmWmBUCxxyrHvgHiY3hZajPM+Ii90Z0LCZ/OdlSX37EpN/5xXlj68dqZtzoSKpuHTBf8z5Sf5nVGet5Att7tebnbpetVoTqwy7draTzRcANxqlMl3D1xx+nM188/reQdTQ4fVaLY6HugPmdDndFR1od5mqPdcy5gWI0Dbhaf5/ji6XT6mOZ0Yz+W2jEVqERob0RDHgwLZlXbV/msnHfSGeSsQENgZQ7ujQRuddxHKCWl4vNXd5H3LdNCMuqjnST00yz/Se7Py4rJcPPQOLHh40JYQjyihAsQ79lQOXNm2rTXOZhf1MJD3jH3fAdQXfCQdWqlIhirC1k52ZaV8jgc8qC3Rr+AcOsG7GT+I3uIxrOZoonKWght4jWfLlme6fBnd77cMOMvL0apSz0/fkcftssrLe8/i/Ubef6gA1JJVj03Y84DdZLs/SKgeO63ZBOWL59rz06Vo9e6NOeULdXwNx5hCHTybv5ar7ZPh8qwZlKxZgbpebM91fdzL7Pt52HC1iGkW+QBGUPHf+3xcG9VsOft5YTFjqHa2uWbAsAdH6p6N6lmMA32dcPkiC9qUR7/N1tehCzF7ndLVMzIK+7Uet9Iqmhik7sqb5RHlExkJbkjdwIfSw4M2UAdkzrheX7FtF+TLUweURAmUyrnjqR5jum0JV7E8czmS2L6MhVS7dWFjC8Zy17//mKgOguouzMIaR+L0HkAk9B5KyNfR1mkFwAOIHyjF26IKff5n6znzrImobRs8ss6HcGPJoctz4MclG/opqk/jrTxYvI3R2kspVSPUkNWzrjqtHBZF2t0MlUz5nBslkVEnka8+GiDTSyw/9Xkp3xl4tlJ9G+UunRjlnTdeoxPC1+ptaI9CM8VvHYBZdIiIwER1Wrnqo5q+1D0BKA4LkMq98EAVr7NkPjyYRqplWF6VH0b0VjWv47qoHOtiueZ4ub6VtGow3qfnZnrsDBiv8rtFl0Wc32N0PDxoFyseJtwjCyysZaYhmvaPRcaK8shgIG+4bH1DpapEysI0HnRfBKw5Z2xp6+7LYGnAz42BcPCxux4JwSycsxK6FUVO/wwQZ/ycKsfUKfLMV/l4zzIKkfk2iwDYPncr6M/CW9rXgEiJ9S4sB/YVfB6Q4NoHkGkH4wmBQInA+5z3dTvO62SvlbbTV4MelaP17fs3ajPx/Ah9X8lYHg1kyX9uUCz543jWcNXl7+91x7Qa3/I99ioRpi8X5t5e8Xx1L3UzBk2UJyU1sDVv3V7n813qITCKkaBGn9dzrQzSiAjByYwD5r49Cn+MwIibkOc7mt6L6mNyCHVApJsjWeruI+yym4H74UEbqA1kAFvOIJcGuaQN+76XWW3jbbcOAoO5vnYNG5IRXGkw3d9YPB8bUosEg4F+y0QDGNQ5Gm6yNwtzRQMhosi78e1j0y5yOhTwt4abmhe1qFdkqMyUwsyIsr+PDJvGmynvTD1X4cmqd/q+MXOqIj1eGcPIXr+gT27KvllGojLF43lh5rbVcaxf11pD2+QcGWa68n0wMIzX3I0JzaVdGcDalT08GfCixtCZsdEbTkehraEv/mDScufe58r7tt9tX0vf2ShSSYsegLn0Vu9A6EuZuouI+mauX/q6jGPR/kkZJIPI5lMN4lYK+dziCMpRvx7pTTuHf9ZJWhliM+erVO9t8vdTgHZTDFzf9GUaq4Sugcu24YILctoUuKFCxJxLmJwZG+wgAZrnvmjLobPUhDX3uIarjq3kEKCcx+Lvn1E2kQUY5eevn1FmK6/Eg1IExGfqP1ZIYWHmcUf33kL35NucbwFyzL0ouRaVNbQBCaia/ueyFXEEbc/r2mO114pMN4yW/wa5n/aTAf3MavjWrzrF3c219nmLl6WyUzPufHa0z9N90zpnbPc/0svWcuc7JCxvs99Rn3a6A2h6sjgXadqPzLmE2WnT8qrxOSv/qK5nxo/o7qZLfX1E1CH9J4bwrL8I6A7M0rzsp+fhrNMkeURj2F5fGfrWGHqL3D08aK/BqlS8gDThQjte66vhCFaJ7OA9g7YNW0rItCElTVNLquUBdquCfPpTqFi8aRhPGwSZf4uUwgoYbwHargXeSemsAHXGS1if0Jo/q1yjdN57HJ85aoNVpOKs8p4NzN6rMfnWhTlWyUQyA6hHLteJCFe+aplUlHD5K4Yrd4rfeOiWr/aTFDhZDeCWFr1HZo1Q3zYzOZGoiJTHvPZs7WpwSWvbJX5zmv0c28xHH/q+1XHsn43q86OotEe06O/2sr2OovpnT0WDkTkAJbpRDSzVaXr+Q+Qp38NXNOZsVEwNxdGIiiI0M8BueQc8HPEY8RcB8VkH41gPiekxpr/FiPwpQBsAyCgQewpaSgmXS8JGCTkBr5fvpeIG7HPOIM5I3clqUHBHPTzFWOSFvCegZQ57R6txqkda9grFe52zukZKLhIqKWP1zFlLMuLD01kg9wN+NofkB3UIqmpmnyx7TkeRirfVWadK7HOiQDuFVOe0bT6JxgE7tANYgZsZe5YFadQStefZ9zsfyqA3LiwPgzEQPe+A3h7iIluOhidpvCbjckg4IwZyBvwOpe5p8qve5/34I4D7JlldeGwRWfDz/Vu+9xENy5NEJEdj9H7gnjkpkeyJoUeI253hZbCPOPXArlvWbP5H0T2bzkcsZuTzPIqMaF3X4C98HPX9w4O2UAaXQ1O4vuWLCLRtSJcNxMB22fCcCE/Pn0BbwqVuB5N3HxdPKMvayLIwjVKzMJPRIDaE16z0er455bIKswC0UVANtNcNPvU8WD2BqfIGBuGKhNj/bvmdAK2ZwK4Mhi4PmiuJLm+2ip1lzZ5Jj6rU+2dkkAsPcte/frU9MHLSPls0xqw/sIab5UkWN+pJdGWd7dbSs+Ffy92kXcWbqTWSpV+EjMwaHdJ6idyK11oahYnK9h628ureXMU9LyuvYUXHAD15jqjjaZradqa5eBOPpQjkYU+ZtoVwcaCK62O2nWy73mYkTjjt+llZNVuwAMgmNxv/sJGMorMIzKnpoPrGcoAYlOpqcS5yLWfFcZW/AtjV0ajXwPW5Wr7lWesenyhndZI3wGegacetrFjf5QQ3qNQ0KKY8qJVeNxa+GndiEFhHzKgm+6Tt89xysa0v6crVgh2CJCpZLZ+w7RgShYzqcAashR4atBm6lQS0NesQREib7t9KVCzGS9rw9PwJv/z6K15fX/GN0KzQzAIMGW3vF4neqEGLOifSxj8XcSqC71amV40u4STpYK9wmN12mCCN0MyjntHKipwZByuKQkP+nvXsQzDgvh4Rf8zcD4doIEVqlkwa8nXuV72uVPSgNrn/bvV9pzTFU2Zvm0jbSNsFhUrziBFoFv+0HTtSVlW6uSrdIsJqqGVmcDb9hazoBauEtOAjD+I9w8SF7TouJiKojvnbypJ+8Lai9d66+ky8oAiU+/6NI1pnqfCo6lwM/GmUSVLKNXIcksikJJFXxOY2vppussZxsuOVFbgtuIVE8ZgEBl0QAZAPf7f+qU5VqWpqjc7SaOXhUn4bl1E/cNi3PYDaKrrdHsxmx0d1nEbrqs9TPL5mFBgnD31/ar1HvWqjHbPX7lp6aNBuQAhAwz/Avu8t9EMVwK95R85lz3baLgBRC00SlcPxmUujJGYQkhkwImyAffsXw3et0i0DOAIxyePomajco3QzT50SAWZRShT2PFOvLk9vjJjBfza8GhkpGh2Iy5091+7NFEzQn7NQfcTP0Ifl5tAm5R6bRI2BrpxFVLcrW6IKFrxLe/cLkARcPN9n6nPoQZ/gVeg43/4dzPdSsxU7XI4Boz0T56Sgyj7V+2wLk3xnUY/bDHX1vMN8RD6q4VcfaePbh8UF4F1pY/nVepjJWDR+ZvqPBLDLj9CAs3rgTBQzKidKk2zZylBnpJf0yyKn5UeRh4i/VWRiRg8N2oBawXt74fkOIsL1eq0LcsRKSvV+Cbg0Ky6VQCSThhm9Rd5UbAUcMm8PEkOKQENjzxSTvxeFlrVuZ+p/fH2VV8Tnkbdvv0ce9cp48EaqCfyi+ZSu+BlYti5wXsmhgiNj9E2MmNn1aZY+jQhIc1cas/pdL+pz3LfpOBsXlUdBffppkuoPYgUy3is6qm8f0jwKMVtuj0C5+ZsnclsdlKL7j8+OiVF25brwBRBxryfu9LB9GTPD3UeNWsSK1fiTxY2+ybSfci8LxhMnInAyTow/MAq17ieqeTT2ZkZw2IZUi6wGKMyuCIkK3Nr0Z4wfq6NUqtW4mAHsLP/ZmIoMmuZ1B7ro5wdtAtrBD1zmNK7XK7btgut1b8BdFkQWxZnBoG3D5fKEp+dnfH/5XrJqhpVRqGy2aMlByeCqcLxA93RvqOyo4yXNGbA+Usyz36u0vgxT2HEauRc8Q/LzhkiBGGyqVFXBscvb58kyZUFjO1mAXPWHvR8p22LjxUDR5Wu8GOvpq7fNZVsOADZgp/Utf/3q6IjfVuspHXneZ9KeJQuC/Xg5C9ZHdJ+3HhnRRIT21ioHsO/gZEvJYC5HKMsYt2NdeXLjn8u13hgswKsnv6mR0TxsFOCT8DihB+tubzJsjywqLDa3A5me3zI2/IJhT8LnzjWKREDmrCFiMVx8e9xAZ8EwC9+dbDCs/hGyhm9nfAdl+L49Ey04SvPYoA1AOozQC4ispC2WaLm+15W1RIRtuyDVPduUNsjbDDMAzlxe41nf/MUSQvJtxfpRQEeFORLC7lFnaUZewJHX2EI55pjUI8tvqWjJzfselNvzbE2efnHRyigYWRit2ahukiY7GNJQsNrJstZgLCyqnEZn2nIfsuDefPuO12jwNZE5oU/0eeq8wlgu4O4F22S0+oPCvAVjeh/jKN2oPC0wq6cC8/vdEM+VO+Z9OoKAwJsSMJL7AHKnnN/KMbnv83lffy0y4osOLGZeAezc64s87uO34fFR/oqnHpFEMhh7PQ861mtll0BpRG4T6WXRpD0lbdAr1thwaaIoX9ROuUVi56/y7X4zTOTIy5LyfiQJLkd8AAAgAElEQVRPke6Lfh954TbdkS59eNAmUaatMox937HvxdO+7lc8Qwfitm11G9ilvKYzbS38khlIibv+USuwrkq3CrOZrtWHWSjaGd3irczy9Z7lKu9VaIcDhX6GP7F6h2cm9Z6FnVeGy1AeVFlE+QtIR2DdAG58eTRkpXgzGDBa1wxgc4N/CggHGBEZVtbz6ENmyeyxpabsRq/riCILNM5iBtqDnMi1sPwZkLP5Lm0g9Z6yd4LOj7/w6ciQ5gmYm/LeGnnoqK7+92M76rmZwhd9OEsj19t2RLFGgvT+8RiI6tbYiK8G2KozyVi0TY+7PEmMTtMOK2N5RjPDekbcfUp6QAwX8fCH5wIHaYUHEWbMnBSf/4zOrIP5O1MRhmYPMiPnHft+xevrawHuGiYvaRK2tNW/Cy71jHCVJ2qeFrNaaH1TOSUZWLrvQZFw2uuNhYVwRJb47Pqs/Oj6cK/Lv7TiLOeZkXH2vt0/Kn0F8yl+dVOpJJayzm0m93KE5o13iMXhCXarnu7aeZFO0vpBK8rLg7h4e8uBzGdKnRP7v1gvdQqt+F/nZ7P7uk0KwFsA8O3jcB7hKq/2LaeDpVZa9YvRIn7dFBtOGlIRHzTIyFnZE8CeGcia39x7t7/ZGRCxPrG8mzZkBrGeVNldl7y4HMvbxm5Q1zgCMG8DS/F+8wUVJtzF2zrS69iZY9VFydy1e+jhPe1CDHmvJtc5j+JtF8B+fX0twLrJWc2lITdKSBTMp3QNKSXk6omqDyfmog0GjwMH3b0j62kVNo+sr9kgmqW5VRDOGiPFaLYe8Bgit7zI9yi0f8ZalXveE2bmYU+2AJ55snrjY7/78mvy/nlaeNaO19WhJDa9D7PaNkn1FL+cNTowDmpjcFQleA8J7rucxzSSrkUk4rSe4vFB4LYHd5TV8waxGgH32tDWO41qYxW/LHRtqazRxN3HafIeHFEa9MbKGJY8bCh1Fa1C85CpNV+sP9jwtjb2/fiNUhLQoheoETNZblmMZ26RBulMlY6+Dmf0RaSLo3RRmiMHw6Y/Knf1vP3t87plLPwkoK0eisoiN8C+bK/IAC5Pz6by+qrOjexh8LJAQhpKwsbcCRCzCpkM3BXA3uKJe3C1ArYSgjNlvEdEIBoA0ga9l1JCun6g+QNiVuV4QD4KNVnfQdJHZTJzfSGFGZgO7LoXymA9iI8AfCYPdjDmrIdH+DwLf2ERxhN/u5c91bAehKxXdU95d3vSM5p77bdTbLIUj1DLSoRiRPGxcr+Fwi6wfTsx/i3NjErvDMx47hexdUUPea2Bch5xG711QAyCCMzsm/F8HVdGtC/zTD+NOvecvvLPr/Kc8TJz/OT70XqphwbtMnSqL8O5eFhUrPZ935FzxuvrK9L2Dc+kg46s/mPCljYkJGTUYyApYc/q+RQw2GDPBG4LG6qFyqifFcyLUZpdoPZ4YK9AKcrDd7AFqpuVCANUV8m3U8CS8t8NTu6fQ20/SqninrOQA4s0qscMmCNFM3rQqGVSnQuznlzlhOUKASRLzSSdnphU9QcI1J3H3HgjFxJmMgdT2Dzti2nmRFUuQfJKRDnFrfJMqbaj8d5JwZbtS0O0OmjbgJzSiU51IpOMurRuCRL1383GitNhcsDKRD3BDQoKUXRo3obvBdY+v8CAah8adcsS8UnSDmwa5Tb+mgFMqMvIExi6RQtunESOQjNy60tBrIda8rcRRIDT2L4WsBVs7pktpe696OayVRFD/7dyidqiOdGrBMIuI9fJxhlj5uYatAiDBVAxMm7T5/76DKBXzxyle2jQFiLxkGr9Mxehu16veHl9wdPzM/Z9R0rXGnqRQaChJyKUVeNUlW8FhJS2rqyUCDnvKmwGN2xok+zAp3V4IwLYez3ilZAcC4V8qcpe4MtbhhPFroOaO2/Ag/NRW3haWbCD0qp8icHVmJvk2USnfTpFmAXcesUX8aCgbsHcaKaARHZtHVM1lJpcAfBr5hr/FeCtAeM4gF61P7l2E01DmF15kwRNThZt3KU3bRXdX8nKXG7eBtpjvnH/Dv0OIzv2GrRdnEnUlbfkKSivGQQwrxh2/HsDF+aZkkc9/VHGsOimyrjNs38dpW0PBfXIaAj5bs9Su0gU9aWmy2Adf+a59oYv56B4z72P+gU8TCiqQ8ln/ftenX3Ey6308KAt53zvu+1E04HMeH19BVFZJX7Znmrop4RbdgB71Tkq/FtVgmkY0KF3SDqv3UUxLaLLJc//DXW9ZV5jNldyC4nVP9SZY75XIarZgLL3bolC+HBhK3uSxcCbGfizMuyEJVcNPQtzr+p3TG6vZ4sDWj7rWoxU9/ImWUmuyrMzFDuU5f4bQSNDJ3zj45qc6z9JMyj1g7BilMfZtEd5nE3bA7oKRrlMSK4lo9DyrWWdnQ89mopjoHmr1sOmZjjF7WllW4zaiM70wzDmg7q0ercEBJFvO73FpCbtzKCaydQqomef9fdnffGeQL2qwy308KANoAmeDf2UFeQJ1+sVKb1io0sNi6fiiTPXFxcAO5ftXoCdvygaM+fcWZw5UBhlGNfBXHGjWdkczIf6QXAgEJG3sWqLSNjOWJf2mWk+AVw3y5RGD+qs8Es+R3M89ndrS1tW5TKCmtATPuBB6tYC6VH/vwmwMeVHPH9fh9lv63X0pCFy7zHncvsN1Fr/9BNWRqL6nFGsZ+7PnrnlnhqDBCBNyuMaCmHIq3dNBgBG4/02fnv5OmoTk7j3srsxbL7TOP4BPee63ItWlMfAeIsRNrR5YHdbYK5SM1yP8l2NxRX/0Zib6VGJtNxKXk+uDAgfSThq08fe8lU9EbEEZdCUBskVuPfu/cL7vuP1+oo9l/PJ5XoGOgFtAyVtQ69kcPsDLPg69tyAyay2ONf9NGdU3VnL25Z1S/qz+VhfQ3kDZv5axMe9lukZZVVZgQ5q7y2M3qdcJ+r3Rts0QFFu0QKQ1WCXJ4862UczumebsuzbUGTX1qstlgzyKM63ket3oXl+t3jMzPpnr9+T5/vQrC/sd/2TKAfVLVqp/jVncWJ0RhQBTZTc9ruXQRtljGpRxMkCuHk5zcLIt2Ml+r2qH7O+Orbo6DzqBRkqnRFhwtyQ+8dbVrtxERguM/5n9Z6XEd6app/RylmxxtOZMfDQnnbzHmp9C5CWa2Do+4VFWFJ5vVveK1BnxvW6Y2e7dUOFRQA819ctUlWUIlyiShUs9NN6NGqNUfvd3teJNahZ4Dvy8o7CZL4sm26mKJm5vEylzS3ZsowXwCvwmZctdPT2Gm9ttuu1bNnmJcDVlgnV1b3NAyLNz+a94pOZW0jOAvdhOKv2u7EjTmEmV82lhqgoWIZd2Ebcz+lJH8VERlB7I+A+GgHbytHZ0G6Y88QLWk5lnKDzRqzRBoGhU/iTdPaG0Qkir2Mqk+/In/eotC2o72sXfQs9y2o4yD1ZEZ7NOg2dfumNw9EgGHmL6rEGfe7qIg1jARqmr1tdqJ4FwHZArdsSQDUQ5rrVytXKaLknomPzkvzORBH9s2eB2tJDgzYAiJ5iqdxeVkwySoj8et2R0isSvSBReVlI874rcOfcr7qW7WAKqnWwkCh/18ndOFEQy/WzyJkBbAMowaFcjc4omTMhKn9P7s9CrV1aF57TduqVsz018kxkwAqxt95XYavhnlOetuwOuBd8zMmUx2iebfR81N41joNuJ3/fnLUUGGUlOxa6u2hJar7Nu6sJZ9tAxHN5K0SfpZUBOEtHZL1swANHuX4+PPh2Wuc/hMCBstLbRAsAC+5v4OTAw/JjdpBDcw/mHPJ2bwjdj0aK5n/frpTewNcDjqz8gihaAtT0injYEYB6A2bke01n5ekWT3ll0N8qx/9woG0Ds9l5Glw9rOv1isvlij3vSJTaVrCXlxdcr9fioWQg/f/svXm4bUlRJ/rLXGvvc8+dqJEqKAooRgGZZChAEQVFxQH12XSrn7OPxqc2Pnht2w5f292vW5+z3a20+rQd8KmNgqDYgFqCgMwUUAxFMVYxFFXUPNx79t5rZbw/IiMzMlfmWmufe0tO4Y36bp29186Vc8YvIjIychHPbnMEHS4hkbZ9UHKiCLi1fTgvUzJgK2atgV3TXM04/52IJs/u6TLm7uXUnukDQLqtY2VNaeD1PaNxKXdbCXYuCejmDRtjEPp5iXkCSsYoVi8XCEpafTp2ucCTaGODN1B9Mp9M9vfUqTQ1xhjbXTHeWW55iUCIcq/WWVImp5FPeW777XGeS+Xn+m8J2PVc1PNB9rTLPTZPsytq9jPSa94XNWmDfF89a0iYJKcyzjVekisQtd+neFGeR61/qngxYu3cpt0HH7QpTmwxK2pNxRgTJkXX92hg0PcM5KvVCl3Xoe96fgcNmqYJ8cmZXDJgxheaS9RpneSwlET68elgBsyoLNfGfDSNSW85jWndeZpt8k3MtRrwtTaZlTHXVFqb7GMmLv28dgwlTzenHkPT5tDiMJZHNGkX1Ifqe3ohWz8n+TH5L6QnN7K5ZPX+tmgn8Qz0qevbY7NVpZrBhCRdOrbDNHl+p8K096MlxpcBVhGcF+j4+2nLf5uqZP071yKX9LvkBQRzvknmVQ4mcTVs10YJeFU5luWnlEEdwHQ7twHNuRYf/f42SkPJkjJ3fuZCTD4+pzLPDzxoaxJzKYG1bjHhakmp63zQlfUam9Waw5o6wsKD9XK5xGKxAMBOa/n7AKXBWVADhmnvwPQkbkq1+VYCuDmTtCSZz5HydP1FOMqZKxEB1iaaYd72MUl1bhvyvLdh5vOtCLU6zH8//614qGrwKGUeJCq555XcR/7u90J9m6aB6wnOKlDJVDwNNCruzEzSc7U8VpPCmc5tJsCNaUBTZW8jjI5ZTbYxZ6ZWNp83jFrQ24O6MWl/jfGAPJ3xGeR1t8aoXaNpoZj5WUwzNvbDLFIANl6ToULimiBSej4HwHPSgn0+vvq9MatFzapR6peaApLzrrna9pw1c+BB25Lf1w6DCqQagQFg4RzQ9+y12HUd9lYr7K1X2GxWMA2ws7uD3d1dLJcLWAv0fQ/qO21859yMASi9p9cYYbTOM0rZr2l5cXgpPT4XLZsnryNe1MJsQ4iSZHyosBi2p1zSTUoIdcgmpEqvpe4pTar0vQSwNfCdq6Hn75YWlkmO62Tl8EvD/IFkr34OaUYgQt7c96RPuWo9AAsOBCSAzbGxrOWY+c75HXNiELbg9dAYoLcO5CJ4qA0N//9tYpcha4cZ/DIrr2y8IgOLP5c+f66oNB+LJwiQzqFcFI8OWPppmUQrlfnL5cvZfD+/ZW/a2rBnHWpJ+erlervSmgxzFeBmeaXERH8eYNxyNXxWbh8rOiZ8BpBESpP5kPcv5537EKQAZ2CDJaRWx1JbppxfS+9q4M4tEHn+c/Oc+95cy8qBB20AYeISGZYq49Mk3WbTBbP43t4eVqsV+t7h6NEj2N3dxe7uLprG8lEx53hSh31y3h83RGjC98iutHkT8NqVIzgDdZQoLm4B7DAAHrC12TzkVZGwx2hMIq0twjTdmBQbpf856WsS4lS9piT62ns5A2CmlnriUtBeWWASxRaJl4SvO4Z12MaMNklZk/JsAsyKMII8vT9q5NmitDfGCtAZxzm7pTySVrkAwHEdlhk7QWl/4XmeLv2c98Up9fMpkJ6PxTHAUPhLtG5TnrtJHib9m5c/0LAL9dNlB76RPUvTpeXlWntav7rAn9c1SSMsLnlPgDc2pLSmxPFX1aLQljJwzrEejrUx/y75pZHoXNJfpS26Ul5zrEA1/vd5AdqArJWUvQrDJdej6wibTYfNpsPJk3tY7a1AjrBcLrG7exi7u4exXLYslYaOV3G0+Qn/Ltqy4fu1Q/jTKO4iAfBM8wrmSyKIA0aqKaYLcsw0VqM5ppSSCRsIejSibJzmq496acY0VZ/9UAmQa/mVFmEkPTdEmyhYBTDs5xJDTPrLDM9wzzFjTaWP+afbDgx8MlZRG4OaP4CYPynMRprQieea3yTtoN4zxzhdHdvTXODedgwOMun+Lgm0Qx5SPx0SngerTszjrhCItPqUzxeDFLireSiBeyhU+DseTqHuYybsvA4amGPM9HGlpZYmX0djVkhdhzE68KCtTWzBiKIOSbuencz6tcNqtcZqtcHe3h5cDywWC+zuHsHu7mEcOrQbzOLG9MwMwbHHeZAkd6P0FAsCm8TD5AupgOElCP4XMXOF/8W2RBBMFyQLEHqyTDPf2kSqmZUT87JqSW4WKmabLf68nLHnc6mkSUxJtFHboDBAsQ0pg0vSzqiHBm9tattP+1JmK8+kDfAMVnkDJwIiVEL5LNpH1EJM+nVApwpyZiSPxKJRqO4cGhOk/jFpat7J7+Gc8CnWU4NprX9rddJAPRTM00+a8rjmGixL9auVKzaf4ntJ+vggBbBEfal3ZfbuGJX4nfzNBfLpvOaXq3lo/rz0eZv+1nTgQVtIdI8oREpUNIeuXwUte73usNn0aJsWhw8fxtFjx3D02HE0TQMDB2AD2fcGOkDOaJM3tVqlwRDA0YTkOk/HUO6vo/RTA8Z4g7px2UTUe68ElwQAMfGjpJ45kfaj5ZVNaxTqFim9PrKSof4CrbFTkv80A8zT5IyxBNDlfDLmkz8WAC8wmNIim5KAp4SqmDA+E8AWPs/lWOijZ3wU0QxYrTGRuVtjwXviYLCHau7pVj6NssYEzWm6H+bWg8JaGwqAnwvgniMMb8P05+QtazGso4LmNgrqFbDgr+Ma5rz+LWv0PO/qgFQCqLwO+zDkDJzNNNX4yja0jZWnNhdyIaoG5vup38EHbWPRJ6Yg489hdyDiAVx7sO780a7lYomjR4/i+Nln4fjx4zh8+DAH1PehTZ3rA3OUPA10B4fCYzXkchFfn8bGG8QYqABrW7+vw4PJ0qwyWXo8zDU+XXYsb3wwtzGjjz+P6pmWKgfmYlVfqXtw10uCUZiw+vSElf4umfXGNOyatJwTUS4wceUSDZuAUiCWGkOs9XEJ1Ic0ZIwc1If8yQfP8nz3s6aKeP0n4rwI/wqOOLUbIkcU7q1I50MicVQTm9MiNcyd23clTYF3ajXbLl9Za8V14PtwDiCpH9LtG+PHSc37stA+3sfcxmELw2n2kYaX1jDEZJm1QfPbsTYL6ctFSuXq90p841QsTnMENl1m7fmpCKUHG7RJPK8BcvE4Ut8T+p6Bu+97rNY+gIrhu7N3d3dx7NhxHD/GgL1YLNB3HQgGvek982wAWBCZbA9DrNtxcJzjO5CN4WNjrO0YtLYJoQOtNWhaC2ss5OZPaYRzrBX1vYGjfiCB6QhYUg/5rdgtM7S8PNTC+Ht672uo6RY1XPWXVN6kGPfYhJwCytqzuhDSFJ+Ladt/izLKjDqVmOSY5h8XoSkwtChQmDC/tAY9jIEf34vVr1FuWBhjK/vWYGczq0lbzZbFnjqIjzHbEhP9xxIYcvO0BusSuOo5qjVe4UOpLJ6mzed3Ncpe0k85YKu1v6XFQd7r1Q1p/Pqwr6e00pr1rqbtzxEGxp7r/EpjkNOYwD9Gc9bmgQZtAkfmI2Kgds6FwCliDnfOwfW8N22MxeHDR3H8+HGcddZZOHr4MJq29Rqy0qo9aDdNAyJC12WdSdGM2bYNCBQCsiyaFou2VVHVDKw1fPbbCOB77Zqkzh2c67FarbzwkR5F2C9TqpnaWGJX7NtY/oN00c7Ne7/mwDGqmVhLZug5/ZL3p5iinXP+CE2U8k3hnVpeY/Xe7j1gwACFEZNNxibte0lnEkDOxAWdq7fm5DC+v3FMUp8mTXqr8vcxF0rvzqGSdjtVHxa6y/O5BBQDC1YpzYy6l9aJD+6cgHmtDVPgFPPP2zVHCRiWE+c63yNA8BcsFTTjGtBtPXeVMJa/P1bOUHgfL0O/M5ZGaMyKOIcONGgDQNfx2eu+7zm6mQftruvRbSQ4CgNw2y5x7OhRHDt2HMvlDtq2BfwEAfEVnE3TwHZi2m5gTB+kVM6Lj9aISXdnZ4mmabBYLLFsWyzaBrZp0DQxHCoANI03/0I0aYeu22Cz3njrANA0DeAtBZRP2ILWVltc8wA1AneMqc16sZhix2i/piRWIsv7WaU6z9G0a/mMkWjYWsuO7GbooSp9Laa3vH6z+2PqZxJVv1A+9FghCJvFdhspjtR3bf8QG0he9rQFYVDU7LaPg8XEa76sLV8+zTTHjDp3TYyBo9aqBxpkgcnXxoxIgd+IiaMGUuPjDmCwdZeaqnRd0ryGczwCN/mjtvV+rAHsfhQcSSvOpFPtrlkZS3WqzZU5wl/Najc1vw40aDtHWK1W7GzWdeEiEOcI5KIGwoC9wNGjR7G7exg7CrBBBGvIB6u3IW3Xb9A0Dfq+gbUG1gJN22LRNJAAF4vFAsvlEm3TYNkusLu7i0OHDgUgIO8MJIye11vvgbkHQOzd7thDncvrQ/v0pLDhQoJMM8L+TI0entVnpE+iuBzemaMtlOqu01H2PXzOGE3+npSZm55GrQnJs/BJadrzF9JAU48eZEHzKeWXP5d96JxRqQSIWUfGBnk8BxAMPEel8vzQJscEEaezlgx0i5JPhfELAg5GcWN7omyTR+FZIqNsleWQWeZm1LkMVARDI2bmQloRxnJpZGp9aR+QLMdiGZxZmo5lvrr1IB3HoTCgA04FkFJzN+mnLG9psy5ZAx3nxQJHSagHoATuYX1rVOMXU2lK75S2D2JeJvk8ls+cZ9v8fqBBm8jhxMmVN4H3YYANbIhp2zQNDjU72Dm8i+XODow16F2PjnpY1/grHQ1ADcgRnPOX4VCLtiFgYbFxHYyx2NnZwaJtsbANljtLLJdLLBctjDHYWS6xs7OD1vLeae86GMPa+3q1hiPeuyay/tx4xyZ9DwAODo6cB3qCgb+tTIK8wPq/njMZHRBkPsUJaWDUnJcoS8baWcxOM7OphTD8PVskudZKISxIse5jgFsDTrEgEKXvaw1av1NiiMKEfSLAC2KlMahbCiJ/TgQZw/OAyGvTfl6S/7/1z0RQc/46WWG8HP6M9ywbY9Aai95YkHFJ9WKJXfIk1COjMgOrMCNj4jwqgFsAUhp6vxdy4xRjc5GU8Om3eMJ8HLs+r5bdiOacW1zGmG3xbyK4FQsJ4G4MwFHUegCNny9qvvoNkJjtuMXNGsO80d8gVxLE52nZTqpaBVKA+DbEUGOTGnWyLFlZiotCPpM1IDeMEyF1K/GXMYvdWFuHbShTedzT6JhpYzWoj8eYqFGtrWN0oEHbOcJmswkTl6UbA2MN2qZF07DmfKg9hMVyiUXLAOucQ7fpYMigbRqfl4MhL735Cdu2SzRNix1j0CwaLBYL1sSNRdu2OLy7i8ViAec6LBaLcKY7ml47WGux2TBIEzl0PR8p6/sOvWMPd3JxUZtwixj8d60N+wkhGkWFp9UXVPbdlCeyaI76+Zg0uo2JvFbfwNT5QdD4a+bxbSb+2Lu5tKw1j1zDyvuIO7BeTrlfou4bGaPXiIMEEMcHQaNRWnfQMFV9/FZMsNTkWpH0KVEBxLeW/QagG6wlmQVlMG/Up+kRLEA7xd/iysjqcYq0rSCaA0PN0lAvL3Zb9IORLToB8UQnVVoyMOwDXQ8/bxOtdNw6kLevRsU+ymvj6z6IKojYrmFf+vlqLQuBNLSqTfG4/HlpDMZAPv9copLyEBo9SJu+N1VnbUnM2z01NvsGbWPMxQB+H8AF4DH6TSL6VWPMOQD+BMD9AXwcwHOI6GbDNflVAM8CcALAdxPRO6fKiZ3BTKttF2hsg7Zt0TQt39plGzS2hcTUdY7guh7OWHRacpbL4T0oSwc1bYOmbWGsRWMtFjb+vtlsAACuX2ODVXBe29s7ib7vQEQ4eXIPm83Gm8l7NK1F2zZwjr3c2VJA3gktR2OT/FH9Czm/O8YY5k6QOZNhjE4FTPP3GMBNALISE5xrytbf8zqKAKfTzWUGpX6fw6DLSJUGjTDqZi6twTB4Ry94Ycq67qU2sHVGItkhAfz9j3g8zRDNr3xqos7MQgNnQbaUoykea/P5aGvFKZCu8xRgl9ZL3bIyXTOJKS55WvnnY8wbpOMrc69URqp1ShhQSecK7RzAbNLGMZoj3OTf5XMUSsrvE9SYFPKradfbmLpLYzbXqjKVpy47tfQN+2Isj7xOc+hUNO0OwAuJ6J3GmGMA3mGM+WsA3w3gb4noZ40xPwbgxwD8GwBfA+DB/t+lAF7k/46QQdMsAjCLx7dovQDB2gatZQC3poHWckQrDgvCM8+maWC9WUqc03gxeROcA1Z7a2xksVmAegcDznO9XmOzWQPg4wtrv+/ON4hxPYmE7cWIWr3rfZ24dYRQ3TCJw+CR6CFDyTDpoQKwlNLk6afSCZUk07F3tjH16LpMSdpz88zTiJBVKi9PX2RGFQl6m4Wm9cn4bswzrY835yOET4n7mxrAjJgoOZIe83oDF6pECHtIU0Rikg1vBh8I3XY7MY9C/0yXWKXiPDNDEUBHwJuibZiyfmeK6U7lq4EnfFbfrQY1AS+V95SAGfsq/xdqOnhvTPjbDxUteZX1JM+IMue5LC+dz7QVo1zGVFoa6edSmjk0R6ArrhfVX3P4yr5Bm4iuBXCt/3y7MeYDAC4C8GwAX+aT/R6A14JB+9kAfp+4pm82xpxljLmXz6dIxhrsHDrMpvDW34NtLGzDwCgLoIFB27ZYLBeAMeHObOkQYdys3VHQGGTicmexBrRer0E9oe+74FXemGiS6vueHeLIAdaAHME2CyyXrF1bawWqYYxF5xxc79BterjeDW7jYQr3fqk/42acEhAX+3BiQk6l0WWPSc5jZdbKqmkQ8jl3RJmnfcRnWuqXd6b6KryDikbpFReddtj++CERzBIp3yHdE+OEqWYZ56cxBraxgDUwva6vVEv8BOraVYl4XcTUBMB4KwCZcQuLaIXp26eHkvJIOaSZ7csaEzBKZY4x6cD1MQYAACAASURBVG01M52fnDbRx0XLIJpbZsbXXQTu4e9ja7u05nS++rNOOw9Iy+szX1PM6oZzrAaA2woaczTxMcrXeM5rpD1a287zHuuz/SgCp2VP2xhzfwCPBfAWABcoIP4M2HwOMKB/Qr32Sf+sCtqNbXDk6DHWhm3j9/X4nHVjmzDZ5K5sY0xxUTAgW9lZHCwUBuMOq1WPzWYD18U9agODZduiaTmcqQgEBEBcgBrD7m7WwtfD+fPZPbqux2a9RtdtIDfa8LGeTCL213qGuU6hb/lrBfhqWup+tIspmrtgphYYCROuaA5T9Z9iqpKmlM82UrOON24AHibo2OEpE0rGSm4/9No6qa+SxtpoJuf30zqWmByM1qZVPZJn22pQARJTq0BqaCgzFWOyt9I27IcGQt++c9qOtmHiY1TSiHNmr3nP0EuZxSgjk65Sj1ygHgqRYdYV+UMNJLZd5/nnMRIeXdK0x/Lfr1Vgv3wk798x0OV+5Fghfd9XFQoN8HpO6LLuUk1bVeoogD8D8CNEdFsmLZEx27l5GmOeC+C5ALBoFzh65FgRZDUwLzxgAwjhRTU4+7oMPIgBhLO86/Ua6/Uarnfouy4w7OVygWbRYrFs0TZNshXde7OkNTboTJwta9pdt8F6s8Km63zc8agxpFqXaDuq79I+KfXTtBaE+RJfjaYm0H61jrH8c2YwpSGVqMQ4a++XgF08ueXdsKjmvGtNokGE3wr1kSkpczatu4F2JswX+2kjMlVgHGXqBADpaYTTISzKeoD0e2n8Z3TBXSG4crX23/+l+VzT5rjpQ4FI1yPV9CJAx+/lssUSeartKdVJfy6tXbbQ+M/ijJZRDbBzYXwg4O2TH5XAck5Zurzcf0an0dg1pljM4dGnBNrGmAUYsP+QiF7qH19nvNnbGHMvANf7558CcLF6/T7+WUJE9JsAfhMAjhw+QjvLpZQlvwNAAtrWMGhrx62SGSPX7AjAput8hLUN1psNX8NJfKVn0zTY2VlisVigbRve2ybWsY0xwYxorYX19XKuQ7dZY9OtGLA3a3R9B15MXIUwKH5hGURtjOuc9Eep35O/8nlKA80nS/771PtzzTdjdY/1NoPxiL9tlx/gBR4jn/U74dPAelHKswbqqcFvpL6m3C6Vm0+mBUhAPMjVrahA4kVccEBTABa2fvZBOXvntqZHDsvjYpGvy9NFhHlax92JNMBqZj7eTnk+vpbSq2i16TtNW9P6a4JDqQ06v200xEqGg7xzy8FYHaaolI+ua6kP9LulcktAawwSy1wpj9Jd3HOUiJzKwWdnkOGSfxvAB4jol9RPrwDwXf7zdwF4uXr+nYbpSQBupZH9bIAZUWsX7GhmGzTeu7tt+LN4YZKftAzeHM6UpblQV9iGYzsL83Xgm7t657DebLDpOjb1WYPlcolDhw7h0KFD7Fy2XPgALDaYx43hgCzWAsYHb+Fbx3ofCW2N9XrlzeLs5SnenQFAmDNN2v/0xJoXLzh9t2SGmUM1sChJ03m62ntjeW1Th+R3b6MwxP+0Tw5bGCn29UT+kh+puoV+M+X6yLhYPz9L/ZKnL7a9Mj7FfBSwSxv3cXR5QLr7JikDBKZ9s5RB1p9PgA0MQW7+eizPIyLyJ720lcaGz6Jt1zTEHKhL9R1be5JGp82fl9ICqdKV07Z8qtaX3D+u+lv+vbRmS+0rlTcX8PP2lf7elZr2FwP4DgBXGGPe5Z/9OICfBfA/jTHfB+BqAM/xv/0V+LjXh8FHvr5nsgQTw0oCLP1bm0pJTdPwpSKGw49GD1eCsVoSDToO50TRqazz5vDWxxQ/tFh6T/CFV5wMjJWOFO/vTCIlPre96TYM2v2Gz2yDPB/zC9ab1LXRK5+2+ZhtO4GTeg26dH+ONPvRtHU9qpNRWx0yrc0Yk+4r18o2kUGpR7MYU17XZHFVnHtCXbyGm+RvUquEbn+pHaXPcb4PtVij5ndsaVLB8lc/4cZ6YQ5Y53Ngqn+1gYtoONel3JSi1QS1Mc/NAwWqAcI2NLZeahrTVLnpBUXzPIbTKnh+po75pWXwYNeE6DkgXK7DPEerNI/UssT1RlRiptbYoG1pXWtgnPOdOXxrSrPnPEjNae1z4pLxrOWba+tjwF+jU/EefwPqy+YZhfQE4Ae3KgOA84zRAP4eYSUVwcCgCVHKohYi5goCnPIQNzLZvUa86dGve1BHsMZiYRdYLFosdlq0i9Z7qet9IzZhWtsArvdl8OTjeOgbdN4c3rvOT0gXACT2hQnti+CdH2tJo+2IoKGpBAhz6FSAu0TLsx3u+SWrrAz1LmdQqklIkfgwK549EGCyRS4aWZ7OSFoqg++gsjWwm2t0DkCrszUKtfK+q2neilHB+D0/vovdSdz9vkfXuXB8MK16ObiK1G1QP1/3IHyoFFmPIK5EjvEH9Oo9AGSQnBtW/ZLUJx/T4rQSR6zhfif/fBrMCrNoSsyZ//zGDwLXXY6En3D3GBDx7YO12+oGJVAKzDHPPimfqByOcy6InQrYhS0fw/MiZkUg1wNEPgb5/iwq48KsgKP+nq+MoTY8FGxcwIwgl6t21OokWr4+uZIDdk2wmOrzAx0RrUQxzrcGrBSwuRPS98TkKZ3pehcYipi727bFcrmDxaIJWjeX0YdcGAV4ogmDcj5s6Xq9Qr9hT/FOvAgLilDU+qv6Uqx3+GHexJ4L3iWJeer3XEiQ347cr8MTfunWWeWeoTP0T5Xe8iuE6y7XoByPdkWmPgSxsvWMkvdqFo8cIPS6zTXxMUFe5y9aey2fYehPri8LmBR4cM6nSyblWr3y9uj+0zJ4zTI01kbdZ/sxgZe0/fydqTEbo7sBaMfBMWbYAXNMPdF0KSZqlvRc7+JeZNOo/es0b5GGxSTiswqe5+zIxgFXXMdatp60pcD3c7XkAPIzTEZ6kk2ZyadozPw1+H2fkvIZOkP/lKi8TizYoU8uCEkjqGmaso6J8jLGU0pgVFrfY9tr+Ts5n/Qpw7N0a0AAln9zToC2Xt9tno9ZRlLeaIppy6Zs36IMT8ZAekzgmKKpdw40aBv1/zgJ0uvVgvVRv1eZAJb49i1yjoOiWDaR8P3a+mx3OjlZu2fziAkaNpu3um6D1WoPq/UeutUKBOdNXTwZXRJ3fATcTLqo48DNH/T9TJCkCiOTbHQRn8HsM3SGZlFpHcVtEQbvWjpNGjDq+8nzyp9L+bvpd5P9BVKP9phOQHNUEZgJ4sN0qfauLQO1vGoavvD9nAfn4F3yTdh//e/moB1Mx6pheo8gSaskm9x8E/7vAV8GhG/d4V+tB26TlUdI90wJce9os9lgtWIP8d5fHcq3eDmYcKuTq2KaHnSTTHYtoAz7IKdtF+KYFr5f6fAMnaEzNI9yEJmz3qa2s3yqJH0pbWmPu6aZ17RyXQ8ROPjruJY7puHP3T+vmeVVCojmXrNo5r4jNQ05blfENtTapvOS/EpHwHT60vbEnD440KAN+AaaKJ1Fs0Y0U1cH0cZ9bI6IxhHOrAHatgFM3F+J52Z9h0ueXAufN/FeOBw2mzVOnjyJ1XoPfd/BdRs46sDOF7KXnU7IfBKldY5tys0y+lnezpK5ahvKF8HcPJI6nFG1z9AZ2opKGteUSVo+10yvRu3l6rRTeUp95mh9ZUGgLojo/ebS8auSZjoloNTS6rxS4C3lAehYCfJe/k5JGClZHHLhQ4Sj0tiV+iBXNMfowIM24Acvk+xyaUnSBSlS/WTD2dkQfspjv1OzPF7i4AAfm5yfg8RznAFZjomFfey+hwlem/4fSwtAwTwjA5PchJONVWkBbkPb7IedunZ9RjM/Q2doG9KMeg5YA9Om8NISrvGBKWub/C3t8er6R15cL2OM5rRfp9F9oI8Dp9bY+F7uTxTzTmoc+s4YUr+JpbN+XjvJJatbKZ0x8bje8DeLOWz+bgfaWisWs7Ux6SJw5ABjs06NLvj8nkskPwOgh4NBz0fLjGyWE2D4FqS+79D3bBJfrVdYb9ach+v9ERhKOj0BZFJA7CXT6EIeZkxSX03bSOFb923hcy1daZGdgewzdIa2oyEIEBgk8uAodRoCeIygp39PAa0c/GYbwYHrHOuZ1ycvdyzvKZNwzm/0OyV+p48clt5P6ypla5P6eP/l5efKWE1IGOYDAPl2gS0KXjkdbNAmQtd1HPksmMOt6ljpNJcMovyVPQUBZ4Av8WByyaAE/DRStAwqAHJw1MO5ns3ieyew2tvDputgPPhbq8ziREHZ9rX0mSLdM5dJjvrE1mTCVkB9MewHuPN3pvKYWmi3fRK4/gpu3vkPB866/1bVOUOfB7S6Dfj02wG7AC56ItDuzH/vpo8AJ28E3AZYHAXucTFw/GLAzjvCjH4D3HoNz8PNCaBZAEcuAM55ANAezrWsIXV7wI1XAXdcx2mP3Rs450FAs5wodwVc/Qau972+CDhyz3K6dO3wWWa5YYbXVn2NlSx26tfi2k2VlbrwPVbe8L26sjBV77F3NCCOvZuDdqxfetxsjjBSA+Gxd2tt1FcB5/nk/Z8LPVBHAMfoYIM2+Ay0MY0KwGDUqpOQk9kE8GYTci6EKu26Dr3bwBo+3iUC5+CKPLCJhFFXwNxhs9lgs97D3t4JrFZ7WK9W6MmhbSxMMK+4MF8YuxlgI0bHvWqxEBBFc44s2JziBBGhoJ4m3zfPF399EZYl+zFpuPb8Y5cBf/k8wHXAM38RuPSHh/X9xyTXAzd/FLjhA8CDnwXYAz/r797keuB9LwFe/SPA2Q8CvuPVQFsBsPBOB1z998Bb/yuD/Z2fZfBbHgPOvgR46DcCT/gB4PD5ddAlAm7/NPCmXwI++hrglquBzZ0MtkfvBdznUuDJLwQufGxZACACTt4EvOFngA/8GedlLAsMj3gO8OQXAIfOLpdPBHz0MuDPvhU4fC7wnZfN6SkBnJiHzjvX9ErrLV27Q3Nt1fzsZX8PJymIeY2jBloS2EXKrwv4afs4vZTHf/UzyW8bYWIIhFGpGadYt6EGnPLnvLwpKvHTaDofbjHEdKY4jjkdaPZF4OvOCBwZzRoLMtHzW56TP8xvyXAcsQ7+WJfDpttgtV5j028A9GjbFkQtmqZB21g0hktqAFgVwYbxkSP29L1Dv+mwXq2wt7eH9XoPndvAWove9bCQW4nUQJH/bPjYlzEGZBwQJq0FkjCEceBKEyRYFoAs5tU4TYFuKb38VlsYY+ajg0abk8C7/gfwD78IXPwU4IFfdQa070oiAj7xRuC1/w5Y3zHvHdcB7/sT4H89nzVsTatbgc+8C7juPcC1bwe+9tcZREt041XAK74X+OSbAW0l7faAWz7G/65+PfB1/x14yNcN3+/XwN//R+Btvw4sjwIP+2YG7Q+/GnjjzwEnbgS++peB9tDw3b1bgLf8CtCdBJ7wQ8Dx+5RqyBEcTQAoC+cEHISBR1OtUM78c6Ak/9whHk8Ka5O8fw4M7/hxNWCI+SXXw79v/Pqm+uUzXL5T9Uhj7ceyNfhE3iblxa3ENI0A7xC8xxWPbckYCdJV+10+1QWfsXL1OOVOanWNfh5fP9jsi2JDw41e2UXymgwA1/Vwjo9frdcr7K1XHFvcEJomBkRpGl48zhGsAUxjw4QhB1gvZXVdh9V6D3sn7sTe6gRf3ymu/MR73QLWwawFNXHDwkgvoZA97jnmG/1syjQ9N33tt5p0Pm6WO7h08ibgdf8BuPM64OInfa5r8/lN/Qb42N8Cr/4/gdsH9/fV6VNvBf76Rxmwd+4BPPxbGDCXx4BPvgl49+8Bn30/8OFXAa//GeCrfnlobt+7Ffjbfwt84h9YKLvoUuBxzwXOfTBw26eAd/8+1+32TwGX/QRw9gOA8x6WaraffR/wrt/jvJ/xn4FHfycAwwLFq54PXPGHwCP/BXC/p6VlEwEf/ivg469lLf4R3xKvXM3JmGgprK2/0juj2iYAWAvr/XZQAzMDkLfqIQMPUuBkVf10WTn41MzxpXoOAXLIf8b4VG4N0Om34Ufzy4vfx/jtmAUy33svmeRz4rDZ4204PVfy3FUU5pecrY5nrCWKWQLihjXXvmfP7tVqhfV6jc1mA9d1Xor1DhTOxQvLiQvTJnLnf99s1livVjh58gT29k6i69Yg18sOFAAg3uDlF4xcCpIPeEHKmpIWc637dGq1tTxLi0BLjANp8QCDODmgW02nO0P7JyLeO37nbwEv/17ghivnv9uvgTf9Ipui213gqT8OfO2LgAd9DXDfLwGe8q+Bb3oxcMGjWCN/7x+x5p2X/6G/BD7yGv5+yVcA3/InwKO/C7jPU4CH/zPgm18MfNFzARjg+vcyiIfoxJ4+9L+A9W3APe4LPOKfA4vDwGKXTePnPIgtB1e9Mp3uRCwQvvXXeFvg8c8Djt0Hsyy0GgST9eWI/yVmZSNSPr8jeSQ5WtaoKzwm6LvG8J3vxrB2MlK/Qd3C2rfp6Zd9kOYjmheVrHlztFCuZ8xbt6FU9li9Sp9L/VETGEr72oJd9brPsxwcbNCmtPHGGDStRdu2aNs2XJPZtg2ahgGb/JEsuR/bOda8ndzotengNj3IeWMz6b0FvyCJ/OUMG6zWK6xWJ9G7Pu4RA5DjALL/zYCdSu7cBErem5oscyXvsTx0Xmmkt3nOFnMk19w8d4b+aVK/Zg3zZd8FvOaFwB3X8r7z8ui89z/9DtaOAeD+XwZ80f/OmrLGqAsfDTzt37HmvXcra7z9JuaxOQFc8Ue8f708Bnz5T7N5Wudx6CzgS/4NcO/HsSB3xR8BJ2+OeZBjTZscm98PnRV/a3cZtEHATR/mNuv33vvHwLXv5Po/9BuGPECopBmKk2xwlqXyO5oo/pgJzwDBwGF4NIyY+YTvLAR4I7bvJK11j2+dsZYdzd0pPymZr2vXcNZoW0Eg8rYhDywpJ1OOtvpzDfjnaORjgkmpjrWyNB1s83gWnIQByMA2BtYoILIESw06kX78BOWQotFLnPqegblpAAlfakxyRzaDtyykPmjPcn6vsVETj0CvpMFMAitJvUQUvOE1nS6TtJ4Quh5zJl5JQpwrTdaoXwHXXQF84GW879gugfMfwU5h531BeY8wlOGYUX/2/cAn3gDccBWwdxPgHHDkPNbAHvCVwNkPTE2mrmPv3zuujfubmxPA7Z8E7JKZ8s4x/u3O6xkElkeBQ/cATtwAfOiv2DHqxA3A7rnA/Z7KDHn3XJ//huv0gZcys4dhU+xDn80m0naJorZFxBrbTVcB17yRtb6TN3Ef7Z7D/fGAZwLnP4zBIucDq9uB1S0ArPdOJtZsr/xz4Pr3cb3ucV/gki8H7vul3B5TEM03J9kcTcSOWofPm++dremaNwB//j3Abdcw2N7ri4Av+XHeG77u3ePvkgM+9RZ2OjMN8OCvBXbPHqYzlsf4+MXADe9nk/md18V945M3RuC/6AnAeQ8vA+eRC4AHPYsB9s7ruO4P+yb+zfW8Hw0AO8eH7y6P8d/uJIO2zLU7PgO87UU8h5/wAynYV9td0AjjXwRtOXZAtp6tARwV8oxWQ7k3L2RRAViAQRoK7PTWnT7CxHWOZ4nHt97mmZ/1s3GFYnyrL1S8YuKYIwTkdatpvvnzoJTNFDRqZvKIP3dj0BYHC20C5wYSbOMbCYvWxmMNYe+7sVgsFuhdzwBuWKwUkzr/bWAbG270ErOR81xe9mGCcIDUxCT71mEIiOKcIQIMwZBBuG7P6HcRNO/aZD2VveOxyV1yZtHllYSMnObWrTsJvOmX2ZFn7xaoDgTe+P+wZvWUf80ANLBSEPDRvwbe8HPANa9nIB6o9YYZ/RP/FfCkH2GGawwz0//+GC5TzKBXvhz44F/wMaRn/jzwxB9iAP2jbwA+cznwhB/kvdTLfpKdqbQz0xUvBt79B8A3/CaDx5t/hb2UT9yQtultL2KN7kkvGO67EjFg/P1/ZFNut1duz+t/BnjUtwNP++lhv7znD4DX/F8MDt/xGuCqv2Tz8okbs3r8OnDJ04Fn/gILSHnffuwy4KXfxoLMfZ4MPOfPgCPnjwxkhU7cAJz4LHD4nsBjvgu49Pk8Hq//z9Pv9msGdup5TO77JfW0yyPAvR7LoH3DB3l8j13E7br+vdHp7aJL2aRdImOBCx8DLI5w+k++CfiCb+Q8bAs0XnjsC9spmxP8t1lGR0bX8ZbAzR9hx7YHf11ZQBrUIwNh4V1EqfuXGs6EiBGRT84owAgAS+LoqgRyDKfafP4StWrdhpLAL/WYa34uAWDp3eDMm+0X+1wADG/32pa2tWqW6j7+XnlE5+ztazrQoA1E4M47xFqLxvAejrXGxxEHNn0Hu2hhyKGhJZYAup7jge+0CyyXy/BvseAbvWxjg+au45MTwF7oJBHRMABm7mAxL0UQl7CpueyXSJWzjiaktB+JERifkLl0WSujKkxU1gf1wHtezF67rgPOeyiD6uYEcMvH+UzuW36VHYW+/jdSDYcc8NG/Af7iuXzm1jR8Xvfw+Xzutl+zhnz7taypvvFnGXQe/zyEDncd0n1L4u/OpIDsek5741Vc3k0fZmA+cj6nu+Vq1uaufh1w2U8BFzySgbVZsKbf7jBo3vJx9nZ+/c8AFzwGePDX6P5nweAV3w9c9y5m7kcv5H/tDpd/4gbui/XtwDv/X3bK+rJ/n4I/OU7b7QFv/W9sKgb4PPzyKJuIb/k4g9JHXg28qgOe8xI+qpSPmev8v2xvdxvaPZeFny/8FywctDusxc+hfsNH8QC2CBy790hiA5z7EP64vp3H/V7+pxs/xP1iW+CsS3iuFLMwwFn3Y614fTvPq37F340Bznkgj8ttn+T+FfB3G+5TGOAe/n0itmy85w9YgHrS86fPcQMI2nBtbxNE/oSMaMF5G9j/3NEwJGiaj+80g+AYa2gIFpJnjdK4GJyvAXukk9IMkz1egypvmwLTmnWx/nzanFyjuf5E8nk8vYxnPbjKVF3mauoHGrRFE4Up7M8SIDOIPMA6bxYXczf8+0sAbdviyKGdZC/cGF6kaWdZGAdAIqPJISuK0qpXsMOeuBCJWSmcfswcNZSmrc9BlvZD5g5giUomnjlppdx8ctbqNjXpyXGQlSP3ZJPpw76Rz8uevImdfl73H4BbPw5c+TLeD3zc90eGu7oN+IdfYMZqW+Cx3wc8/l8C5zyYzcabOxlk3/lbwDt/m5ns5b/D6dodBqmv+S+skb32p1njv+hS4DHfzWB7UcGT/COv8WV9L/CE/4PLIgd86JWs3d7+KTZDf+iVbI5/2k9xvZfHgFs+Cvz9f+L9zfXt7DD1wGdGk7Pr2FnpuncBMGxqf8qPRrCVY0nv+5/AG38e6PdY4Ln0+cCxew3runcLe1Wf9QDgqf8WuOQZfD745M3AVa8AXvvvub6fegufH37YN6fa9gWPAp71a1yvI/ecvwed0/2fxhr9fqar61jwAlgYmzqKd/TC+PmOa9Xnz/A4tUd4i2GsLrvnRnDdu4UFDNmeueTpPOduuRr4+GXAA7+al+wn3siCXLNkM70xLOhc/tvAzR/j+XLRpfP6QCyF+rtR/E2OspKsPZ9uIPxjeCwrrN18TfOPBX3Z500+d6IMbE25vkSA8xciJbyA/FXaou6WTcFz9oLHKCo+dd42leccoNd1nb9taLzGr9soZU6Xc7c3j8OkDgyJhx2ixg1/O5e1bBIHgKZtOZJa02CxWGDRtmhD57HmzFHOXNZR+dLQUmYcQJMPDvEkNrLnFJogwOfzCwBen6zbTOJTNaXPmSRT5eahAzUtj3GAlS/81ghgRy9kU+rRC4GXfjuwdzPwrt8BvuDZkTHfeBVrtgCbb7/iZ1nzlK7ZOQ7c+/EsBFz3Hj6be+s1vFd5j/uyOfXR3wnc+gnWfLuTrEk95nvq0bmoBx72HOArfz6a2QH2Pr769cDbf501s8Vh4OteBNznSdEceu4XAE/9Cd5bveVjPqrXTdHkfMe17OEMsMXhmb/otUJfxvIIcM8v5Ohx17+XBZk7rwNu+0QZtEHct1//G3z+XOpx5J7AY76XNf/LfpI17k+/jfvWqNV+j/uyAHOqdCpn3smxcAZwf9eUTyFtiZH3AL/HD6BpuR/HaHkkzsPuJGvRQhddyv30/j8FXvlDXohsGZxP3sSm9Eu+HACxMPS+P+HxvfT5LEjOpVxY19oqEYXgUAK0WhpIwIAfBBO7T5AW5vE45OAIZCh0dlFhqNQ3lingzRcrBS3RRH6SCxmSz5QJeQzA5mijc/mh9pPSz2r5ldKkv0mLWcgZ1rNsGh/bHq3RwQZtIJmUru+Bpk2ONYgZm83kNmjYLVi73t3dDUBu4SOjbTp0nUPfy73YQxNLLgED5H0/DCT0oCwUIwHqkZqFwt61kV9F4DBhIda02W1pyqxUm8Slfe4xYaLWTzW65MuBh3z90MnJWNZsHvAMZpLXXs7ajID28YuAp/8nBsGHfXMKopp2z2HP3k++mUF3bkCPEolGf+ge2fOGHZze7ofwfl/KDld6/9IYFgp2z2HQ3twZ90EBdnp72k+zM909H8Xm91J72kMM3le+jPmvBqecHvAV7PSW18M0/Ntrfxroe95zdt0BDCpD0RO7WaCsBirS5mftwd2vOS9jp9toVTmuS7dJFoeBZ/wM0Hd8pvvv/h0/3znGc/Arftbvh98JvP1FDOSX/it2HgT4+wdeyv4CJ2/msKkP+xbg4ieLCV60aT9OBQtWbpXTv0XyHE94k3NsbSxY2Kw8Zw1DMkvyFkEhLdcANByQaHEUAQOQuyAccRRKnc0cE3xel7zd5a2+9N7snGr8UKjmzV4C6SlAFUuFaP6xzdI3aUx4PbglAeVuDtoEDg1qYJzliD7E8c/4MwAne8hA42HTWvYEdwBc32NDnKYhg816g67jf3yxCMHY6DUOKFOPd6MUqHXoYfyl6ASCtSRJvLk+BzA5guC/kYVx5UWpqWpu3nIB6HfGytHSIzov5gAAIABJREFUfv5baRENPlfqYxfAJc8oe+MCzIQf9DUM2m7DQTbEGenovTnk5JNfgNBXYVjA5snbPsGOXTd8MOZ5KvuzO8cZMEsk4SuJ2JmpBA52wYwfYAFC76fvnMX77Y9/XnwWupYYPO74DHvZX/uO6faYBrjnI2N5OR29MIJ5t0rB6UDRNrKqmoqJw9c+88gPvBrD1o9v+n12fLz+vZz3BY8E7vvUaEb/5JuB97+U0z72+3kunPgs8MofAD74Ch4zY4CPEAdreepP8J53UnnD4ZetWoPCdxoigAKyZ2tO2kBw5GMxmqgq8PZdH8DGEQMHEYEMg7gtAYQC7qAlRz1D1d1r6gYc4VFv84FABaDn7Mtm5hKVrX+U/UUGhOn7ebljZUm6Eh/UN4mVKIL6sL68U9Fn1uI0Vcm34e5tHkeMDqM70zkHZ1zYA+LtmNQZwjmH3jmsVqvwzHQcQ1ycBWxj+fiYtbCNmIvkfQrOHgLgRMRHvowFkYMhkTgBIO4HpabwuDjGtGqi4eX0g96YCdZzpbYx0/iUqUhLoLUSbAuc+9AqpgNgjXpxhDXTW6/RZfFf17OJ+8ar+JjUTR9h56WbP8rOYes7WPOJFauXNUXi5FYiDRKHzkLRS1gLaKXfAAbP2z/NzlM3XQXc+GFvTv8wM/71HZm1oNIe2/IxrVp5VrVjnzsndzkZG4GwW03Xs9uLn7U5ut0FYPgYoNbAS9SvowDTLIbClzFsQn/QV/O/nPZu5lMD/R5bZc57KABif4UrX87OdF/6k6xdX/ly4B9+np0kz3lABBkbFAFfJvR6M4BNja1irjPGsIDHjCeAs+Z7eqsqaNgVsspEXk7nzRcDE3VqmdOAN0VTJvKcb6UWwGFeYzRlXRyrl06XtzPPX7ZY0/QAkauA/ni97+aatgc7xM4QchRv8TIecPW+UN/3WK1W2HQd1t0GfdfB9AzCbdtwgBZqYYyFadKO5cWgzTwMyI0HYZlAxhh/R4hWYyKI52cagbJkdarS4n5I8s8n1dyykjpXzenAzoiDkzFAs8Ma9+bOFHyJmEG+9deAD/wp8NkPpPuPAGubcgQn/20/1O5gltY251hPTkQMxle8GLj8f7AW12Ve1qE9i/Kxo7wOY97KJnD8g0vGsgB02yd4G2DKGrB3S/ysz3PveiuI22QCXIFWt0cLyPLIPI9vIXLAh17FWvj5jwAe+a3chluvYbM4OXaWfOz38ZbK2Q8EbvoQR1+7/HeAh3yVrButmRnovWD4X1JTeaYBBv4SctD6ZwLkwWEtqM6SZWply59HxbZkrnYYA15+rfz7XP4yJ92YKT1v11wlZiqNFiKmqKS51/LLn43RgQZtA6AxDSxitDLn+MyetawJGzLe2zuCtvO3em02G5w4cQKr1Yo16b4PEdS4Qx2CWCt2bk1ecu17x+e99b604b0k+FdTBimd7vPP21VaJFvQ1IKp0TZ71Tr9foUGojRyVYnk2BGQAvzeLXxT2JV/HgH50NmsmR+9F/877wuACx8FXP67DOynTHchyPVr4O9+CnjHb0SNcXmU97aPXsjtOffBbHq/+nV8DnyyugcclKfItqyZXn8FO91Nacm3fZL/GpseDzt+MQDD/XrihqCYFunO62JY291z69sLJdq7BXjzL/N8fcIPxuAuN1zJnvrGcvAW8d9od4H7fznw3j8BPvNu4OInGF8vvX6hTpmIlc/A6n3vBLCZ2ZACbtGwnY/amJBhBcd4U3z00Ykke9oD/qC1f+Q/jYPgFF+qaebb8qhtyp0DynnaMV6bWwOGeURLRgT7YVm5teRur2nH4PUeBPrea4d+MhLf0CVhAPmiEI47vre3h9WKLwwxvUGrvLotfOATKPNGwxeIcHnOg7bXkMGhAIt7E8meRi6J8SIrTdL9AvaUs4YuK9eipxaLnmDpZBtZMJWfZJ+23haOhrXx2tGxi+Jv7//TCNhnXcIBWC5+MgP3zjEGPLtgZ6/3vLhexkGhj/8d8K7fZWA57D2OH/RVDBw7R4Hlcdb6qGfP5H8K1Cz57PVHXs0a8i0fB45eUElMwPXv54+Hz+PoZjKNz38YA2W/Bm7+MINqaZuDiLdVNifYqnHOg+Y757mej/Nd927gXo8DvvCfR4vLyZu4/u0OH7sTMoa9+W3r4wpcF43exiDwMdYFmIdIoBXV7AiZmUmaiLyVj/1sjGGFJgcBLw0k7w33cnU/6bjnqSE/B+s5W30l4JvSZqd+G+NjNR5ZKvdUhAFtrSz9ps36tfbqMZlbnwMO2ga5ppqbPHSYvRy41+s1uq7jTiCCXSwh+8y8OAxc16NZsDTL4C35AFGrBu+dd/COHWJ6irXUoQdL4JgDqQbEvF2nk+aYZ/LPeb0TBoDhGNSu8XMbvtzhEc8pm5SpB675e28WNcwMAWaQH3y5v0/5KPD0/5uDdyin+0DrO6IGRjRtYv1cEDm+oWp1GwsaT34h8JQXMnDk7ek2vG+v3/18Jbtg7/dmh8f66tcBFz2xrCXfeT1w/Xv487kP9SFcPZ37EBaEbv8UnzbYnACaewzzcBs+/tadZC34PpfOqycRm/Df8RsMwE/6ET5+qH8HAaYdznPxFOdgNiZRWon0jYBAvp3m/L2dOQCGdWj56mDKftPALELAmMIQ9spFM+KHIc/ElF94v0R6n3eMB40pBXO0zlw50Xgw990pGtva3CafsXenoshpOtAXhogpRwdLAeCBOQbadz3fyCUXhYhpnJ3O+OjXYrlgx7PW+oWlJjbFgP2iabMpiYOrGFi+P8fydZ4kEzwAtXYsKU++baXNqT7RgWa0kFCTCHOhIZfGcwm2JHDU9olqRI5vRbrhysHWGIj4fPWVf87fL3hkjHjVnYz7l8tjfHY5ML8s/49dxpdO8IOhOd4gvrdPK/8pU7+J4U6bJZvB5VIMTUTsOf6xv1XvTpiM785kDFtPjt2bx/L9f8rBdvJx6jcc+e32a1nQud+XsrYttHOcA9kAfHTwY39TFnYkRjsAnH0JcO8nzK/ru36P/RAe8JU+wIr6bec4R0/rTqbH/ADWwl0fHQcBFNddACgq3VWA5Chp+hsfs5Irh/Xa1t+B4doOvIRt6DN2hxjAa8pI6dnYtlv+OW/bNpS3aQ5v3baMnG/OrY+oddrimvfbNheqHGjQBtREQxqEQCYp39y1Qr/ZwPUd1usV1us99D17ictFH9YawPARLyICrOo8IFGbo3Qoj0z86+tiVdeJeWlsMHOz1lSbx75r2mYi1d7X+eTP83rkdZkq+7Pv4/uLb/5o9NztVhwZ7FU/wpd6NEsOviKm0fYQn3cGGOyu+ku+NMT1cZ/85E1sFr/sx6NDF9HQuQvKYevEjbEO/5gabLPwmqHh+n3w5dxu13GdXcda+IdeCfzVD3HbuEFDEPh8o3Me7L20DYd5veynWGPuNzxG6zv5GNU//AI75x25J/DIb0vP/Tc7HABn91xOc9lPsTC3Ocl59Gvghg8Af/NjPsLegq/tlEtAxoiI333PH7B2/sQf8k5wahmcdX8GZNcBn3pbFDpcx3vZ/YqD2Ry9EMnEiwx9xIqlfHniM386pnOQ24DZLA4gKBURKLblEbX0Ja15UnCfUe5cXjNFc4SBqfdqv2/L+3KrR+nffuoKHHjzuA6rx1CpG8wT1cF4b8au67BaqX3s0NmcgwPQoGQSNspUxUFYRCgQLbqxDZztQX3JHBw2ptTfdCHWTOFj2rGuY01yre0pTU2E2sKT/q3tSeWm8jEyDTOrD76Czx8/+GuZcd16NT+TUJQP+Ao+vyz7i6YBHvHP+KYtt2GGfe3lbM5cHmHA+8SbgE+/NTqxAT5+941pHZoF7zPeeR17/f7tjwPH781hTO//ZZNNOD1kOGzp5b/N4PyeF7MJ/H5PA3bP4kAcn3orm3ZzoUPCfJ5uuvmjLCT0HUdce+g3bOeUdbrINmxuvuYN7JAm92U/+Flsgv7M5Rxedn07g+aTXxAtMkLGcJCeR3078Jb/yiD7kudwm859CPfhVX/BIUcB4JKnc7S8OacA+jWbxW/5OAuWF3/xMM15D+XnN38UeMuv8PfzH8GhUN/3xzyfH/UdgL9cEIAyuQblgIG4aRSP86DunGM+SA4ExxzGb+GxpZB5oexny1/WOuMec23t5vd2a/P6FG1jgq7tN29Dc6yUY3WvgeWcveQpq8Gp0JhlIqcDDtre+YtkL4ji3gvElM2iqHNsMgcB1jZoW29WsgYgCatnQjCCoEUbuRiEfDwDA5CFMQTrL3pvrIVpW/SuYw9NB5AhmAykjTGAIW9Cj/sgcu2nkDZnh5aaoZOHpE16pPDb3AGfk3+J8vxzs16NmiXwxT8KXPH/cfzmt/6X9Pd2F3jo13PkM71HaAzwkG8AHvdcjq+9OQF85FX8T9PyKIeePPuBwLt/l528bvgAQM+ODHl5jM2ZN1zFgPi2/8bPn/jDwH0LDPiuIGM41OiTX8jex3u3cH984o1punaXQ7Ne/MXstLa6lYUd1+/v2swx+uz7WfPcnADu8xTgkmd8bkAb4PH7+t8EXvmDvG/92ff5604VHTqLPbYf9y/LzmPNkuPbb/YY+Pdu5rmjyS74itWv+qU0jvkYXX8F8J4/5PSPf175Glnb8jy//goWOP742ewweef1XI+HfwsfD/vgSwCx25HXiB35a39BoJ4DpoSY2iZ+NpD9WoI1zK86CQalrI75uiTyVkCkazfwAM8biYNdDNpWE+5znlAEPRNVrrG80lfKlgexIvhs6/l4s2lIPsHepC/yfMb4Wt6O/P1t98pzmnr/QIO26LTkTdxxf9KBfTS8SchYkOFQfrZpsTAW1jbshGYMByMIezEGRDKoXgP2XuSGSJm9+K5tS4TWWmwcX+vZ9Zt4Siyk5Ti8fORSHsZQVjVnkLkLokZTDh46TW7a0s9rmnRtb0rnVZKcbRtvTrrnFwLf+LusrXzwL9j0uTwOXPhoDg35sP9tGDYU4Gdf+XO873jly5gZ7t3C+R6/iMOIPuhZwAOeznudH/pLNitf+w4+iyt5LnaZoRrL5d/5mch4RUtvd/iZ1LnY1z4QiNwmVaPG59UcQmJCFQHmgkexEHPtO9j0bxe8LXDBo9mb/IHPZJD++OuAG69kIeSOz3CbpW8Xu6y91W6zElocAuDKntTGspBArh6L/VQo9OmMvG3Dwtdz/pQB90N/xdddbk6wg9lFT2Qt94HPHM/v6AXAV/8yW1CufBnw6bfznGgP8cUsD/k6Nq1XPdQz6vaAd/wW1+OR38aWntr8OP8RwDe/GHjzr/LtdLd9im8Uu/SHgcc9j2OUX/y0Hk//xVWGI6xK5Oeow68mTcs0FJiJYghR/TKvX4IxHazd+G1GFMKWsnJUcirNsW9QyxRF47M8odexhs/VO3l6bcDUjnBI45sn9dM8q4Z/UqQvQJS6YG4t0Pp2i8t/4Vh6cyCGPHM/AJ5bY0fTnoqp4q6mI0eO06Me/oTQkNaydyXvUXNMV56QDYgoOKN1XRfOancSUxAM8ouGLxJpLLBoGrQN36UdtGwjw+hAfYe+W2PTrbHZrND3HdabPWw2G5APZ2qtFf3dF0N+QqR7V+I4pp+V/urP+SSomcLHvk+ZkfJ3dFm6biVwlmdnP3qFp73kpvC824tBLnaO++AnHTM/1yEEBlnsjpsovUEF3V4MxWmMv/t4yQBp2GrI92Y7BsGdY2m+RIBb8x6nTIdmx2uWxCZric29c7xcp34d44AvjtQBfu9WNunblrX8XEMm355+FesiQVUkTyLWsl3Hv+0ci4LCRjk7LY+UNT+A++Lkzdy+ZoetErq+/ZqFG1C5z06FdP3H+rRErvPjtPFbVU0UhOZaIsVvQvdxs2QhpeTQONqO27guiyP1e7p1+n7tLyLpWVhaHEbxlMAZuvvRiessXvKUC6qBnEp8uqRYzQHmq6/59DuI6PGl3w60pi0moaZpEhkrfDIG8PvcxvCVnFpDjM5kDC5ty+FHieC5qQnHKqLkBQ/cDODWNgFwiaz/3gcvc4nXxoKlDmIvEm7diaH0XAPl1D5LLtFtsw81xzSjhYZ8X52IYBrg0Pk9Dp2f5iVaq6ZmUT6GM15PAIYZ35jp1tjouFbLp9nhf8Mf2fQ6Rc0y9ViuUclqkNdlsTsOAGakTlPvhjxsemY4p2Y5/vup0Fj9p8i2LECcUvl2fj+N5mOmxzNP3+7cNZaLM/S5J2OBo/fusTkBnPzs0Mw1R6nKn+1nT/xAg7beh4ExAcDDMzH1+IbLEYdcSwwXxvcdnGUgBhAusRHTSAKiBrDGwjQNiBYsvoPQ9A16a8OZbvJ7UiIcCBmjteq0XWMOabmppZQu/30/VNPm56QXOnRej2e85vokzvUZOkNn6Ax9PtKh8xy+6bXX47OXL/DKbypLvFP8eQ6vnaIDDdqMphz1x8IqIPT7EJkp1wYw1SDH+cjejt6H7Xv28GmCg1t0dOB9HwML1t6d62CMDZp36HznQFYcRlIhIjYipVSbdWw6NDZq75U97W08NfX7Y3vkU05pU85rpjl9ZtUzdIbO0Bk6qCRbWTm/m6tNj3m+bwPkBxu0/Z41BwCAB0bVOGNA1nBwAAxNy9ZavsrTsoclO5zx0TFQdBCTd6zhG8P4TDf5azjhTe8LNH0Pah26jr3Tnevggglc1Tl8Fre0ktYc3Oy4PvJ0pulkDGxLpvfc83tbLX2OtzgArG6yeP8vHOd0klScSCjYTiqF6PTyUX8R00jMpxR0IibnwDk6XQghkZVBIriNuJsOnPhQdtyJ+ZtYP+PjS8uPyuclDz3JKcRRaNg+p4JpOIrHfFxw6CHf3WNj7MfH70EYv0VESC+D4HGUExZZAA8gOO2Mjmu9BgOanJUz560hxQdkLRgTruGtzhsTRii0sVainoOleUDqg6wH5xwcVNAT0m+a7M28ZEo+DuplYquS9W8RTsE0jQRm8luHJs5FmY81En8LI+t5UDsaJkYaw8JAvzvWuxJERNbtsIdDEZLboPK6fP1e5MVVRcaPy5F793jsC+4YnXa1fKb47JTCVKMDDdoEwLmOjzgEV1kHY+Qe2eGQC1gDHpTJeWcUIzIAO4z03ixsDcgZLz7pU+Gi2UuAFoemaQFDWCx62N5iveHnsXCERR/Wg7EYBlSQCa6AkBwoi4Y06I8t9qynaMy5bSpvShh1St2dBte87DCoL0/C/ZiGSotsbv0lrGHsd5Mw/pqTXaneU2WGPISpGZlHBgiXQuTR6Qz6vofrGXQJDoZEkLRJ26U9vXPoXB9C9Doi9L0O6etCHVyFKSbbL36uc17doL3kTDhS5PznaLECC88TDHi0vxSdlvntAU0sYnkEwTnRp4zfjqv9NuprEkA8FZRdx5ccOepDf6Z9ln8esdiVQBuxb6SNxhjAGjSNxaJt/A2H0VoIq2DUFyFtmzrxkqzHQmVy4c+Lh4M8B340kk6VQYq36rxLTrRTik9t7EttPfcRHR77gjuK6cfeH/j/nCYtGzjgoA0i9H0HCwPbxLCiAJIZqxutgwjIAm0AuL6H9dJT7lQlf50jv2cujJ4ZlpjFm6YFX2reoOs7X1YDEzzGUzAT6dDmky05gubJS/9aS8415pqWXDJ/l7RvSTs10Uuk39N1K9LMffKpcuR7Xtf8+RilPhBK01Z5nuoeU05RgYlSZQmwcybNcqXlY4qOYBXzBLxm5LmjU3O5Ni6EMiOCej42l4Kgq+tc7K/5/Xc6+npSeJ3E9Jomm6Wxas4nvyEKKhS1cia1haeREEpx8LlEX5i8hByw9fN6/xXXirI0xLEt9WGat56rJaAe8C4T86yNMSkemeeXpqPgEBx+I3WftshD3lIRq09wBdmxxOvHBAedtkYDQWOmRr1NGTU62KANjnjmXAeSG3E8sCWWIkolTOmMpmlYkuw5/qUV0AOyCey1Glg0xsZ1501BFg1guS7WtmjbHl2/Qd/rAYkm2LA2TbAQZQN3mkHiNINOjeZqpTq9ppKwVEpfWlD7bWMOaNaYAHal/MfKmqOdEZRgNVPxNKaJV83K/DbxYtdgovaCpfZ9cCEPzdFCzvPaQNHyk48vQUXY0q/oPtpeyT5lKjHKMShOmGx4tkV5SV7qoQHIFYTgfPgJydyvT+dapeYDthRIYrr3TEhwTipuzPDOhDHBv1iWmufbWu10GUGo8Dw35e9BMlIgDqSamzyrT8bcUqfrm/tCxXTTbRgzc2uedjq0bOCAgzYRa8g9ERpjYdDCWIDIxD0r1eYgGToHGIu2aQHXMyg3BAtv8rKsPScaLQxHPjPsXc6dSUFbsdQAxsE5jnDWNgsQOXQd4FzvQR9KiwYYrSMTj5MmCgxS7zEcLw3smHSXmGlFaIBasPFLmOIiKQ9J9uspEY4k+yIZU5jshclMyeDVMgOFvxE4NIMOwgTUIvHp08Wo6j5DeIhgFvPT9SrrbCYoWGGkw48lZu3nhRFBVAkT/psjPvnAAqbj0xCIzD9tg+Z44wCu2x+0xYxZOufY3EuO+18hVqmUU6VJLXpmWuHhaiiLPTDHqlN4ibXLMDeHmmJcA6kAVM2Xsg8FEM4SplYjATYxP3u/hqgwqAlpTNIxFJBS9UH4OfUb2VY+S3gfaDhZDGL+JK0yXuHJ+3UIoun6VAl1Abr2asFqy0BdoTids1vlOkNJqNGBBm0DAD40n8MGDQAQn6+WKzuMYW2anzD4WfJDaBlIrTHoRYPuO8hAWOsZL/GdtGwCl+AqQA+Ck2VpCDAWtmlgXYu24SNgooUAXlNysfIcnpApkWBdLpWaZNHUroCr9lPBhMUfUjk6WY/K3DmeeVpOkn+FJMBrFBhSAUFlmGhwSsZQWgCHriETtQWpg4CW8b+LQCTvEgEmCGBlzTdn1HHxiuQvdVfObCpNYC6qP8Pid6SYpsSKVls8MGwKB8H5/+R6RiKChT/GCMRjiwLUALweDnE4G5poZW7rdpp8FCBzV342iPvWTH4flhSjg+eg7HAy7NgKzQbGrci3yR/LDMKbAJT142TAYY23LDsAD9RyIS5X1pIWxo0xPjyp0uT8+Dnqs3EqAURRvEg/G8DfpBDaLL/x+DAvJGI2INqqTD8t0Mr2newba6HfaIAHgsCSfMd4fya/WRPGJ2jWIQ1xXQsCvoysXv++tbF3jIElBMuHjFnMP/asNqOPbRFtI6LMmVM5ry5p+FP5HGjQ5onVB8ZuYNA0Mkytn1DecUcYndegLSyHP7UW1jk01qHvRAOOK8/q276MeJ0b9ESA4/y4fA6lRE2LxnG9HHltnhx6F2PbCcMwySpH+rtuZ7bApwZt/n5L1A7HNMv4vDBBFdoPBYPyhLbGeD4uIKgUAZWtzygUEUdFAWzgHxVPba9hR3DU7UnbVxM2ZNxrjkeSJjcdWmsT7bNmGku2axCde0g12hjjBQzfJiL08I50RMFLnMjBwYAwnEPJ32Sej7e/VNfSd+O1N0d5P22rf51eEo02CH1qLQPZeptZVaM+aU21CKfZuhDLnbwvgpMeo222mepEKIH+gJ9ACc61In2/lIT/0loqfS5930aTFPHDqDWR/qqF9fH1PFlflrYSS0BZ+Zk/Rrpu+lme96mO/cEGbSJsurVndmzeNp4528YAkBCiWltzwTxkHfhIlrV83Kt16Hs5IsOymyxDrcU4Je2xqdz5EhwLAW0L6zo0FMOnAj2iZ6RTi7Y8wccmVk6a+WiTTilN7d2cGcuzWp7zTJSVOpMwUOU8MqxY6H3ud38cJ8l5KAEPJr4ZMtLSIo2S+SBbhHlgIlML82mE6bAzWIlpmUG7SbQeYYwm3ULQ2ytsifHe3F5bljvf481zBQceaJ/lGqWoVWufnhe1EqI1RL//uQDv2Kaktqr+rHVFzXia8kNhNaExTSNlFTdOMiEi6fd9dRtV/opVh/kmJf2jCtL1KPRJaV6UwDIxgWdrb4rPDfQaY5hne+E15FnSJwrrPK+xAbdNyiGFw0a9W+Op1e0XxVfGhJhSPacEnSk60KANInTdhhvVAh0AGK50b/3RDTbmMSjrTibAGEI4KGYY5AVkRfuTs9okRzBMDKgSJc/IzY2xsA1g2wUaf3TDWgvrGtbOgxYiTiBpk0L1woSOk610HCKnhAlNaM9D85tMslgixJwW1m2J2cTneiFWp1pBQB0uCgE21kRiezzcZwurtGir9aC8V1UGplDr0KfWa7kCspXFZpSwMaiYyf5GphTyVO3kdrM5uzFA57V9UmUKYPfO8ZWMfl7lY0HANpbqIuXagv7MVihgaI6XGnyutG0/d1wKElzfeNpXvKgJdS1SZcmUz2P5QHH9iIAZxyI6gHF/ekvO7Evcp4SgkgZYaoe4MsqlxFoYNiGbMQtRCcxqwKTnTD4O+r2B5SNvndH9Kou5IJ3X6mNU3TlBZo9gC2otD13fMctkrkSM1S1ZqyNWgjkAfrBBGwBRj75nlmQaz5qI0HgtzhjAmgbwF4hIKHFxNAuMknwecLBGmxt5QHtjeL/b+rOyNh7BYmLm2vhjIOQcjFug7x3a1jPajd4HjBM0SrfxDlxuGwWTo5QRPs0wZdaecR1i+4dpFCiK+T8IE2PlZIuxsopKLEXyCwtX/T8ciSPRRMfBulhmzhgQwRBI173ILMIcTLIHDA/cklLA3jtjkXKUmahLUh/D9x7HXL1AITdYeEc02QYwxu/jedDuVWATx3fDRqamNbhMMCrVMmeeMi46vkFuNpTneg8urqvPLcXpQxB9WmplvV9L4kyl2rZdOYZvAoTMISXg5uCWZM3APS3IaqoJQdm8nGFbScrykl0QUCUXYgtOSTPOtcrcglEqa46FL29lAmYy5xJ+qua3iUKwkfRExfxqdSjVbxsz9pRWXcqvBNx5f04B94EGbTbs8B3Zfb+BBd8l2xsD44DeWZieNWpjWg/UniWS8985LytL2UBQHcaHPQUR70lbgiULSw6Lbc3aAAAgAElEQVRwFqZJHZ/E7G7IobUtyHa8pw3WhKxp4AwBYqIXkNOLG3oRREbDAmVBEi31S2GiaSppESXJV9LkE7s8aQr77kXt1+dvClqbJNB1RAb+lP3Nyqib8ZVGHWWAAICiXfB8UpI3hf9FIY7Khaf9HC0F+biGO4xJ18PCOApbAPKb8/M01MJH8cu7g9MSOucvqyHwHPZ1kvPoaX2RCImx3sPxzudSznjlKKUxqZNadLjaDgDvCtJtkX/hvoKwfsHHOitrp6Z1ym+UCUbllTIEhUGaHBDyZEY/zPt2fl/rcRxqkMG10jdpngCm+7nEN7bRzpP2mEr6uHwHGnPg54hLWdetVO4YME4JJGOUCzT5M5O3S9Vnm/IONGgDHpA9Q+y6TRhXaw1sx2FE+4ZgHe9zEwHGijNIekSF32NzEVEmgRkEDZpgwpWKsUN9ucSAD2vRtqxpN0Ro2x6990x3+blNBdJp41SaWMXq4I2ZVaZoDoDnz4rmLJVm65qooRCJWI+O0T/qFKn6DxOUjbhYYyjbmJSCxhyBSjwZAChw1EIFWIwqrekA0pqdRi93XXjIS4ZWQBbRXCrMXYKoiOaQ93vQtsmh7104sSCasT5tkJ48oCAQ6DF0bjgH9HdrrffTSBmcADdRjL6m4yIcBNICo46CZixz/KlZmzN0mRlaRqXwT4NuCifx//JzpY9qXUf5F5M/3FpOKgInwDt6PtBLDdDGgHhMO83nWbEfTPqBXDmPmlCgBTW5U3w/c3LKgplTwo9lfrkKMFO00CFba07VeQ5/P9igHXh2vD6z95HIBCCJWlhj0bsO1BFs04Yz3A4Em01+6ZPo1CPACoAkNjBf88l7ZAjSNfPsyBSapsVi4fWoboOmaWGIo7jFfdq0QfG7LP1YvjCabYB5jjlljtQ7nU+BaczgGkEgggc4AjMIqP1gP5cdVy4CuJH3jT+jAd9PNgo8lVpwl6YaMLhohHEIj/0X+Y0oCf8ZtBApVzR1KghihTKZkfkpTC6Cn0E8nSAV8u2UMJd932O92aDre3R970E7mqi15mtk7mhBlfIjJfBxp+tjnc9DYzjUKreXA8FIHQ3JOB4ETdsLcJkQEkjibWO8tkPtGwguhyxp+dUrkzDMXk+OeYaepLAgHyI2lIPh/E3EBT0/qxUurcu8PXHNs2Co/VrkNwOYumaqqQYuNW26ZPkrPWceVG5N8VlBuB2rZ6neU+0t9yz5OyeicA4arvmQl+/fWqjXXOiZooMN2kBg7dww1pAZsCP1fRM1F8Me341pg/acLAryy80zplwydOTgHND3DNzWNr7TI4dmLdOym4dI8z4gP2wTJh9Tbp5SE9S3UMyLNUlvTOMtmYDiOyb7Pk7jGjbXMc1nLqNOtb8gUZv0KTyQJYq0/1K1PqhlNfCMHSxSAeuUM5jw/zAiWdt8nUmNW1hkemwjAxRrS1yM8bx0DPCTjS0hgPJms2HAXq+x2WywcZTE/C6ZPUWoDG2m7Lu0JuvPknZf1MSNQRPkpS4KCo4wY3rd5UQyvmZ45CtoYjNNwEkqycur28IOSM2jICZlUkFUCEiOpbBSQSG7hGI+uiYy9yr1GwVuFjdsVlCaf8oX5XsNDJOSKxp46d0xZSTJR8BQ94+SbnIzdA6yplDnKUtjCdzr9TWhrFS4SvlRsFB5oQ9EIJvypf1YTg80aBv4ACh+kcg+j3M9D2xHAFp0HYNviyV3TgM0psk6JJp/GGjJO7jxb6yUsIjgjEHX9V6bZjt52B833rHMm+05IMsCi9aBPGO1toFzMvCE5JyB8ugOrFYvxsLkGoKnpJWFrPOPAkOeV26GL3wZmPTmLNyc9HZDDoniaKUE/TjRjfEBSRggCAQrgRKQ9oVoryFznU8h7ZiAoQ6o+dcpCdDAeXCQE5v1bzC4eybMWyxeEyOXpJUtBWMsYE2IESCtc47QbXpsuo3XsjsP3g5d7/z+d0Vz8HJGFHTITy0xjwujLmsfuRYiwoVYi7TiyGuo8Zp2KoxqIBuQ2W4ejVFJa4rfU7Aupwk5ZfnqxINSk99ZziLFtyn+C1JnxGwB+9F2qcyjIMXzV4uUg/fiEoJ2x9IibWxD6Shmuu0Rq1EW5HPNMO/XPGhIsa2Jhl3YD4b3wtfVr9QrJ6NvMeOEA6tGXhe9DoIgW8xfBpwCX6JBXWJJTvMqpIAtPEO3a6rfDjRoA8z4DCzIO3eJYYoI/ugWH2sQJr5YLEKscCB1oLE2BtBgRhRXUTRRc8AMYfRaK8nv85YoatYS2tb5Yzk92naBrpOB6H0ddGSqXOyVSTNcCOVFIVGzYgYl7SmnJD9pheKxsjhqZqS5UmHoVWHSNFx4VtaDBwRHMS44vJwjdYuAH+tCPsMA/oay9ZUzY5d9B8REb/2YxKhjUoZL3ufY4AhlA1LPeIZaeJ7eepE+kP7Tt07Jv2AO3zhsug5d16HrO/QSEZAc8hFN5oaob0bMdjKwNra3ILyUAFvyDtppKNjHRo/RL3ge+YEiw/+SAxGF0agx+v1oHf7N8FeunQyyzCQTHPRqNX3CkrWgDb0nGQXMuAb92ITngA/PWCjEd54uwKjSSQmnSkYN2BTarQQKOfkV6sQWS1XTsMb0uJfN12l/JQCHWEbd+ofB87T5KYAFYYjS9CnwqXcSkwLFvrIq8ptq+RQVfVvIwPQi+ERRSvNgiQPiwh63L5U813Ii/BJg/NFlo+dHnQ48aPPUSs+zGopMses6kFsDQKJJO9dk2oKBZnuRIaUewywImPDZWuvN5OnVigQHS/GokHMWbdug7xu4vvGaCAdckeMUWkAYMiwMfit9jpNUNKA85GSd+SULS/2N0n39/W0BW0QDUjIKeXDlL7E/SvUzA8mYJ3ccK5MEN4n6R+4BHp6GcoMwEAA3XkcJ+C2SnmPKOx/pTs8TrWWQ0QDN/wSARRCUean/acAW6jves+6di9duOhdYT81yIoLg0CQ4FFbGKDc5au3H2gYixFpHYWvI99hgDur+5AwjM9o/OKvsRvKI1oG6j0hkpEMLw5gWNwCJXOhRrzg9D+VPeDbBmU+VMsEpn7fy1ybAM1InLyxoYJH1Uxp3CtJ0fFbT2uWz8LKpd+Zq8GPrJQq1KKYRcoU5QOG/8MALsjGsdYlfAIBRERHFx8f1EphrXvjqAw7a/txlmBw9WGQ0cIZ/68gB/SbEEbfWYL3mTmpcj0W7QNM0EUwMR0kLriQmlqU1OGNMAO38Hl6RAEUgIGp8uga2YWGhsRyNyDnt0jRvbznpAZ9emLs2C5eAehZDVPxlqjZB0s14kgF4f6aQOSkJWefPXetBy/eFpOBqp21ooBYgAFAfVIkA1n5hdyqMLPPE1ATv/CFpMXsTYhrRQjmISR8XnjgrGv9ZQFigqncQ0SJq5zwvnZjGA1DpQDdiGh8GeJCyQ8xxJY4IlWLTG4r5JRreTI1ibF6mY5AxTyVsksyTuxiPhHKmr9entSY5BjfHCjX2TLRoEcByc2qk4f5+WLPWS7B+rnh1OL7HpY7WKa2fLlXSe4G+8v4ASJTVhJSaLmFwA//9/9l7l5hLjuxM7DuReR//q96sYrGqmg+RbLFtQzIstUYYQdYMBA0wHtgbGzOwYXhhYLYGDMPG7LywF17ZBgzYGGAWtjeC7I0NSUtbnh7Loxm11C1qWv0ge9hks0jW+/E/7r2ZGeFFxIk4ERmRmfevYvMvNk/hr3tvZrwf5zvnRMQJDurmKQusNlEp4HEdjLM6sT2LEDbrcZqcfl5rDjXjzGN+lwpkRaBM+skYk9Wgc4JnySFOZ4SaYMJymsxbbnb2+SIoX1wuxT5GTIeRLgdw5kEbqJQz/TpTKMs4soM73YJa8pOjqjrfodoo198Ed3jMJswXHXRhMgJ9CVJ2QpDgbXlIMIW6rqF1h7qu0c1m0EQwrfbmkTHNIJVMt6GSKYt/5wA9J+3GAGsEV5BihwxUKK9XLkg0KMe3Dej7UDtHN47/h/IGN56sptmJEfLUmnfpGrRaAKpxQOy+GOMmnxOuJcAyQHrHJW6S6c6ax8NyTDoe8tpYTokysildy2jt9jtE4YIEH2nXydiRVpfoz1DmMprtqATebDUAkTctKqXssgYf+zL2yhN2FPOzJHLlUkRQpKAovseeXNnhxnXow/5aqkswYsricW/Y58DGpilOOfiseS4qMb4ABtpU2+0LDlxmUSB4cTcsFPh4bkyJse7LDC32biigJ/TFaYW8Y96RAzsuk3wuRUjPn9I4hbGrTQcIwOMlJcnncncHFDV1ZgSCclaDtu2naYxB24aLp3LxS9/ZApRaDHgMad0vQ0pnHrS5cRkotZHD2g4DpewA1KaDMgpaA5vN2jfWbDbDbDbzEq4fwCYwZCAwSE0AjIZKGHpULDcCiQhVpUA095Km1h1aY6BNDd219mYfJBK6Syec83W/eh0p31kgjCaNHJROkA9TQ+xMBzMEN7EF9+H/pZJEXoyWGvG0dW3eF0Bwzjfcc7+m5P1nO2bmwd2GszuvbZt3xgDkNE/tgNdt9NImnLfvxC1YXRcmmvfVnTAtBiEG+a7T0eSSXsHgNMh4CHB80WgFMgbWMuQFl7LQxM2eS7IkiEV9IiLyudAxJhCNf5Q0nkwGSJgQ3673Oanb/SUBRN95pPsRb8I5cgmWmo+Q+ljpV0qEVjdPM9obU67tpMAVzS2RdwlUguYa15mFD1YseH4HIVL3NXCjYYyKxrZNUIfVKmhYX+X5sZlbMpDl7JEo+6AVR3wvmb6N4wH9sTe8lJF7HkA7CJZpn8nxUgLtpml65UnnUTo+WOlLy5MbR0N05kGbPZu5X0iBDRCQZDp0moFRQak2bEohAqlMdXNaFwIgVpXyz7uucwBt85OMUymF2awG0KHunNZtZmhVA4JGWFt0E4yCdBw+KPo0IRBDpo3N1wtC8h4SA0OAvQzE/JQHrZM4o3KI9gjFJX+XnTEspcNL5n0iwDM5vorSZW7xGOzV0Rg44NXuO/x3rY1d/nCSLUuiFlC5nNoJcuS/d11YkjAs5HlBTUw1Y0R9rAncMzFD8YQSc4mBmgW3Iom8nKIvWicFDWbw+TVC37LJmMs9Tyl9JplSjgnLfSChP7jCPhHZq0kz5AWSMSAfskiVTKjSeUyO6TNwcv5+POTSBQu2fSEGYGErL5AQUaT5uYchPoUz+a5kkMLkUL/FQpkcdAr9ddBQPmt9cEK06FfXEvBXBxsXb2As56x0OQrzJQgsxi31+DQyQk2uvlHbUFjKnCqElspvAw1PXSapAMj07Z6V/Luh35QZO2GZdZqge6ZBm8B3XttfxriNE5RU3QRA6brOm1SjRiAFVQlGpw1IW5/OHqzdpQwM2mGjDXwYWR547ZAZhnJHwCrUdQ0YYNbN0HZ8ScmIpkpB0yLA3yEt68mDvy8FswYdJitr37EJjtFSNLLJDDbWNgx83bw5zKebJ+PXuBAxC3dEEbZE1jzI7W+9IAVvX1obNG0LA6DTHZqmBcQmD+3CsOmP/XQDQbsm1yCptJ/ODW5Krd0m2wlzRwjqmBZFaFAIfSTfA+MMKS5DrB1MvYe9pEHJvO1eDCtwsTMOZvdeaBMMmjittGGSfLepnyxfycrAn0RuHVaRvYdAwW+ClFiR0yJLJDVdNqnKMZWvn/juRRpEoO2tNzC9dpd5FwoFZv05zVhrgjFd4BHerXMsjNl41kIpBfhSG8R1NNF7+U4+Z+9k0iTf68dMWrkxaVlcLEzlKLVSFEmM05yVgyl3W6/UtEv5lfsvJJi2xZcCtOE72YGSnBRgTc0ybqVq7/6OiJxmJpyfUGMnka4s8JIBKQNoDW1adylD6/qxgtzZGzpFgpAoh7ETkJ8pB951baC7mU3f935fEmOt3rDkC7g13kRTKQjDzFCDJJtMJtalU0mVvI3Cp2MFh2CtCIMy5Oc3ZBU2JmtjDwdZYLVmcas1d8I87ZY6nBZnzdPBTWfX2Q1hre68ZzBfSEPQiDd66Xj+g/sjBWvJJyLB3yDanMJCi8clET6EGZHWhRLtH0ngToKzkDVGPUtTojXLcZCmNwYQ4budcz3GCXgByYi6+VjGvp+ixeTqkj4rWRDCc+XHaXg2kif6gFxq++h9Mg+y5SaEpSXD44bgN21AMuj8WrDMW34C8OZx2/554QXiuXFmrbygD9i9Pok2mIwnn1ZBwOCwqeDI6eScWHGcnGUk+xwmbJUY6ANe8pTp5ermLWWQfKNfxhxoh3TH15/7EUP/cLt73jaRzjZoA2IQjkgihqVW22Vadx60rQlJoTIA1QDfgMXatD3SxZ0AQFWo6xnquobc3WizsaBdV3xLDg96yyFZC2EgJiXjs6iRryevHEfB+wEtUzBJgALDyTeV2+BlHKAzcxDtzO3O5zmNA8kIyLKSObBpW7uz2oTziux4ptMdjOkAo3obwORZZ38+mbURzaZs+H7m/OT8TsuUvndN2AvLS2b+kXPOkDK0EEE0ucS5bFjy40gypFHQx7B2yu1m/NgXGmHCGDj80HfJWI3mPo+P+aQM0ccxVrMaY2K5+pS06BJ4pJ88j/kzV8fot5QwRL6l/jamv4Mf8KqEH6Mp0LClLoC225w2VLakPfjTC06ujHbfSOn4E7cxX0EZlhB65TRujhMA9I/HlTRIb3UroJrs55xQOeZ8RfYvKxC2ZgNzEgCRVQTSdPrlYl8XwxYqpeRtBfJ57HsjHfblulHE4AmwR06lgD/CFM48aAMZDccwQAJwpqJOh2svDRl7Q5cxaLsOoAYGwIxqGANUprabogigyl63CWNQVZU74uOOb7kw7DRCGwMyxvlulibCIKUT2eNe9nyvA26nDZTOzLraQEGJDqN+P/J//ocb2K6R+Eyh3Q5E4FXHwGxtPQ2R8/MNJ0oaEA9cE3vwCWvNfXCo2tidLPfNyXqFrgmmMStJuvXoLqyPWm063jTGgKyd3/fOsGbE6cefQHBL7ttCNCxxPRF/599GxorAX7alTag3dSPBqT+x5bq1EWmmsUzyLS3DGPUAWFS0L8SUBQBJSpH3wEYIGgybNAPIuWEE0RzGxO2aUKrx5bTp6JnnczzeqRePCJFTFZlGDyB9nTmMA0WhpfqQEufTpnNxCUJYMIC79dKXOU7WJJ/9Nsm1QRiPTrg2QdPuh+e1c+PYRXzKwJfEpxn315ipVlofWFgqmaPTscm/vafJtFUEsOcEGR5bkfoj8/DCdLAEEcX9ZwC79CjyKtVBqQ6xX3nH46sKfMLFxs2fIIjKHtU0UFXVXoBganKOdxy9IKAdDzSeaO4JDKxbSHLv7fEAi7RGA6az51216lCTRl0bEKyv8ErV7rYnA6s8K1gPbAjMmoDO7SSqHBPRws1Q6HAASM4PWm4iQDvd+WlNyQYAGYqOqTAHCtto5K/wxHhECRK2bC/+tObnzgI8p8Y8XncAKbtRy51JZqasnenaWi8CGJh1f2AZo3F0eIyuDaBtXEJWMzSijxwoijJy2v6TgUGCbcIbGKO2WReKE5OCkEjT5UvO0pCLmpf6Oc2CyGyiDzfOhmAuk0RSz1hzMaI+MTMqAVmf4RrP/GxKYS07WDosu9dCsOUx49MYACP+njXbinfsuIKtP/5fD9Rknfr1EQkn4cgHUbINwf0bxkhJAPA8gC9jcWMjZJW2d1+gGqKoXVy7U+6db5NQPaXskl0E3MZEZc/llZq0JbhF2n9hnJdM4n1tPwH2XJoDlgmTMIdojPsyqkjIMabzeDFEVrZoomdEQFUFiwmDdq8sURx+30W/0+9MqwxvZTrzoN2XgFKzSzLJDMeD09g0+HIDkPYMvqpqVLMZDLkz3YZAZIKTCqdNk2LtlxMOAOTNawzxxpmCZb8ZOZFCWQOzcvqYOGIlP/rMNR74cX0FoLovqfmUN2/5zWSG15Vtprwzm3dhswkWxkC7tWVr3jLoDiIObfPWBicnK2jn1106HYjC+d9xv+Wory2WwknhxrVLlEv/GfddvC0sFZwMgs/4GFwjid8/KZktRVnjXE5FOYbqi4z4HX/mTJY5k6gkfyZWKRhtbylr29hTnLSYlIB6ioadvreatmx3Po2Qm1e5/FMwj0KKd+lxHPsuNX3mNMBR7fAUlPK90ndWFNK4/KmUXaKrVLwkyDH4PvQ0faacwMfPZbjSurVML/eOLTlp3B5wFwSANF2l7F3pkWXC2NkWWSZMBaLY3XCO6gxCEshuNE6fUhCSZZpxH83Q50a5vFfZ8gAvAGgzBem+/yyV/mPJm5x2pwGjYLRB1WnUM9tZdV2DagvOii8Z8VJpcDjgxQMvCcrNaWGTWdc5H9Jt582/RsfSWNppEYsxQrr3GmcAeenfmk3WbNrudHw43xgD48rA4N2xpy2XSAcD4y7I6KR52m0IAwDjrmVkIQCwlotq3R9uBkDbtFZxz2gT22gY24TLXXvH5YnyLzwPT2NGzp+U7uTPpPl50hAAMCNmE60NGwQxfpYCtDRzpoAqxxzgNnRWdq+HBe0Wm00T3LUiJ2C6vCNAdPs8vHWjX4+ckMuMN2vezVgJ8t/TZ8YK5sTfpTYpy2XLnctvTFPLCUm537l6DGljQTBj4UKGC2DBoAiITbkinYrI84+0z3N1LAl5LNiVxlRWw3ZlknyF4+pcuwjlY6itSgJ6uCNeAcYK4VWVXiwVCwN1nRMoFep6HoFxtGM/024hblV8l6tXjs48aMeVk64gfYhI24zI9xiDUou2bezO7sXcgdncNnYFoFJu8wj7ha7g14eMPU3CbMgguJjkdRStrZOPzmi0budz22kLgF6blZtREDEurQFvuPb/SdM73I5sYb42Bmxy8UKC06j5mkejrU9rg0TjJqAzXbj0ojO+UGxa8pIqCxCieXXBgtP5cAIA/cTLx+mT6TH10C4JJUaKoST5IzOK/DeSJtMokxxw58SC08N4Ki5YIBGpZ5iV1KDCxO83SklLlCApn/F+BCLCcrmD/f0DzBcLB9gbHB4eom3b7DlTa4J1reEua/CgwOCr4rJxHVIiUFirTDVbV0UDNz+zNzyUqdy2fdaf1lGSZPQljTUX/jQUa9nl96kAxAAux0qqpZasHhwu7R95jCx1ZDOlHsxfemDulSNhkUEA/5KVSTaKNI/LdvH1KdRJpl9VeevArK5j0dDErqZzcVzNiu+mjokzD9qWCLldl7Izg8TD7xC4vOsEvoih04R51zqt2ILcbDazzLy22jecWUk5Ddmmbs+uEtxmLXsvoZMMLWC2nUbbdWi7Dk3jALuzm9sMOreb003wtNzkrtx1VgJ7tEpbr2COmJFagcMIkHZnzJ12rLVG5xiqNF9y+2ln+usYroxoPIGXxuQNOAZ57dbIT19uSpDSresPIjiFzJ8jRTlm0w6AZ3rhhgB7quQwjaZM3xzYcmy2mIwx0CFtju+T393ZxfXrr+D1N95AVVf46KOP8ODBAw/sR0dHaJrGa1uKgVklgJH8QZysSMuRmkZJdoYTMkFuDZoIaoBBT23HMSqBcGpp2Aa4ti1DCJ+PL9suAE/Va9+exj9SHu+qNiHp3z0Xr2wNifl3yRLhfkQAn6uH/51mIvtGjgkBzGneSgictcq7Rl3M5jFf5XY3jq8J+Z6tSrZ8/XG57ZLKCwDalomaTCPniTvJNhaf7TPG7lZu2xZNp9HqDuvNBvVsgfligd2dHXRdh+XOAqqeoyIFqpR3MmFNeipSHDlNvg1Ka42madC2G2w2GzRNA2M0TKehKueoggh8PtM4oAy3AVEAXvdcmh+9A5iuQ+e0Z35vYLwfb7j6mi49suOYObwOb3f9OlTu6YgFzZQBuyQYGrE+T8iHM6wiDdJAJv0UJz3iZNMHFL3YhoE+X7CWlGuiknky/l1Oc0hblGHatgWRwnKxg2vXXsYbb7yBr736Kp48fYLd3V2sVitfjtZdJQpYgZfLWKkwX9Lzu+TA1jO2jLYR6mmFvE53zpwq60H+Tu9hIdAn5eP380HvmVxmk+/knBxKZ4gkP0vn6LZppeUqxS/Vm60YPW00k9aYxSarWJWEKBP32iC4J8LcUDt5YObyUNjk6+PkNHZWXvy4zI0pA8D66gjD2lkphEDZK5OzGLl11iQ9Ltf4GH5BQDsmOZisdG+ScO44AvpN0BlrNm67DfTGgNQG9cmJZTxNA601No3VvOdzC951VYHdWroCeMDunE9sa3q3dyC3TYOmacRua4J26ymKgVNr8HUBrDFbkG6dWTuAMhOb2T1QG74+Mpb047YCwGZ8FgCF4iu9MnorhWg32arTL3mMpeQJobJkJoUaTyH+bZLXbhalQMhfBrN//kC9DeXAmyc+j7uUUq1QpiPXNGezOZpNi4sXL+LKlSt46aWXsGk2ePToEYwxWCwW3vPfZrPBZrOOrDnS4YlcRZV5GMoDQmo5mM3sOjq1bQSS8DUkwPs9D4y8eP42Gp7DAtAQlUzeU8Azl1YKmNuYmdPvsp1ji2R4F+UxoR1K5UnN1TL+VEtHGn8bC0k0lu2LQnj+EpbAyOsFxt5x7RLxvDCXFuWXcfqae78oRggBxTYb4StnHrRznS87OVjF4gZQSrkDvGENxDIJBVIW+JpOA3Am867DerXCarXGbLHEfD7HYrHAwjlZqes6MjMxaFt/1x2apsFms/HafNs2Pm9og05bN6bWD68A/a5D21rN2QOyDj62ZTvk1nMYvL2/FW4jIPLwJc8yG/FXUlDTYeNLwgPaDCiy0pMcFyaXyVSahu6ZeKnk2rMlfOFUksonx53wbFuyY1zhwoULuH79Ot544w2cO3cOH338U6zXa9R1jfl87ueI1hqr1TGOjo5cCsEndgraIf0gM6WABQQNdm9vD/v7+36ubDYbrNdr4SHPClwps07Ty5mzU3Cd2nY5nlQynf8sacjMOqTBushARoPOpbtt/U5jNZgar1SWnhAAABSsm8n2X/fJ+44C5e7TdiH9uDOAO3Ukx0NwwXrYdXwAACAASURBVB0pmSa5QliWcWI7nXnQZuqZMchdmE5gZ0P8FswFWW6xjiLsLmulKpDSznsTvFm76zq0TYP1aoVqtsBiscByvsB8NvNMajabgapwAQY5M3fbtmicdt2J3doWgK12rNvWmfha977z6+ld11kLgHE3WXkf28yHpETIO1uNr6MOP5NGC+2VaphDt0nx856xJh1TE805nztN1YZN8mTCHCkzKK+3jCeSiymEHuP2XWzD3KQ2yuMt7B6X5e5rMENM174HdNfhwoULePXVV/HGG2/gJz/5Ce7fu496ZoXXxWLhwwPAer3CarVC27b2RIbwVW+MiSyCQbvr10eW8fr167hx4wZOTk6w2WywWq3w5MmTsGRkYP0waMdAiXpjsqQxPi9g3UYblhpuLu42a5s2rXweuTQpCZcrH0R/9d5lfo+No6EliJyJndMcEjhyZZuy3BMAgvlmDNw5DX1QoJYWip4QIF+nu/HlMV2Kwk6lFwK0406hoMFxQxl7r3Iw/wCAEYMQ1nxmFBSF6x3ZzG3PoBKM6dB1LbBpsF6vcFLVUIqsVjGbYzafoXIat91pGdbz2qZB17X+NirWuDl9PhbWdW3QmHmTmDFl1m9CnXgQRVL9QIf7YSrS9ywtQuVw7CWNHwZc/8hd/0GIOYUn/uzhPkzYmE6jgW9besF4AERbZoxrZyPDuA4Sfc5Hp1IGTO52DGOsEw07WFS2SqUlFN7RTVDYbDaYzxe4evUq3nzzTezu7uLevXtYrVY4vzzvNx9VVYX5fA4AuHTpEtquw2effQZFCjN3jtUfs0HQoL0XrUxP2H0hLW7cuIFf/dVfBZHCw4f3YYzBvXv3sF6v7Xo6XEMoeDMQewqLlwhCO6X1nwbcZQ01Tj98hsfpBsFpeYY5VxqTbgSZsGu/BPJ+R3gGCAfXg6PsglbJuZtg4szOpt73NKwx4m2uHWMhJ+VPcZ1FX3MHpO2cmp6NHX2+HZjPhgIHQTBD9nkQMgP2xAIZUfzcyFvZpOLk/psyIs82aJt0kMdatBw4MAYa9jytNT+TF7qtAwEF6M6bO1Qyjo3u0JG99xjO+1eDNRQRNps1lFKo69p/guymMdamjdOeeR27fA93fI66RDxY02nBZv4JTZdn2pmwiuB2+gbGKvPblk7JCz9/ygkmBa0nBHiumYcEBXcnBKYRNMVYWPLMzISyhnVrcqko8TuvaQ8XkdC2HQ6PjvDW9Vfw67/+63j77bdx//59rFYrzObOH79jZmwe52ezxQL7BwdoNw102wWAdeXtHReCEfsz7JzZbDaoqgpvvPELmM3mePL0CHt7+zBG4/Dw0OcX5le4upe91kktNNVu+1UecoQj+M2oliwuESokNwaw/ecxMIQ68JnmeEe3LBtROPPeB5KhOsd5SdCNWlC2Z6FOuRyiZwbubgbJF0vaOdeB6yk37InfmaUY30ZiHvW0aqRa9ZjgJPrGl4//+hYDlgtY2JSKE8EJC35fxjCdbdBGv/JGcjBwM6Xmh3BWlU2PGtYVqTE5+T7KEADZ86kINxoRkd8h68/jAdElCZaRBH/c0mFAVP5S1ohYdebZc8IQCqOGFTwpKfa0A5SHbp4mxNimIp8TwKcMb3Td79lyE2YxBO06KQf5cBw4vAHxocM+cyrlWSLZx0rxhiWgbTsoRfilX/olvPHGG1gul96aNJ/ZJSIWXlnLns1mWCwWuNhewuGlQ2xOVjg5tps71+s11uuwSY0/67qGIbgTFhaw27bF06dPsVzakxyPHz9G5faTPHnyGFVVYWdnB8vlEsYYbDYbwTDtmDbJLBkyy+bMt/E7fgYBDv20bNR+fxjTz9t+8vu0DFHo3ncblu9QyztC4XDpHz/PncVO24TDsTUw1z5x/ctlKO0fsKRAJM38lGmTHHCHssi/dHklLW9K06wexdgAZPsbP6fT8vlyhSoIYUjUsTCOUjrToG1gb3lSJvZSpJ1XL8bv6DIDjmtMcKEJ50kMVkvVMOF8ci9PJ0MROZ/kiBiO1JT7g5Ilf1kOV5O+ghVNXpa+SmXankZ2zvoBYlPv0qMrpHgc5kthzGkLdsYoMOfPPackG9vtJp7BrkiBFagoMsviPZ0sYdBxLnlKNV97EqPD3t4u3vnG13Hx4gUslnPcv38fALBcLlHXNXZ3d7FcLKEq5ZeAeEno/PnzaJsG9+7cxWq1wnq9xmaziZyweM9cLj4A5/yog1IV2rbD7u4udnZ3QUQ4OnyKk5MTv5a+WCzc0coWXdv6CZWzLg2tkeY+Y4GVGXPahiYTJrcDOgCz/a6jMWA3KuX6pw9UuTBB64zrJj3j5cCb33HbBNCIwSabawLUpfPbadvK79Yrm/MQScx33NKP54lli4QEav6d5nFamhqf+9T9iropLU9O4JE0VNccnWnQtizNXmLBrJWxwhiEyyeEKdBPHuPCGnuns9bWU5k/ppVrQMO6eay7c6PmdnNH0U1452vQYyKD1R3+vQ1NlNryokKYxJQ+Yy3Qv8vdEp9JslTEkZJ9nhS0qXJJckzx2cn4wWzAzD0cy4uaOpLmKbKKcHlyf3Z86q3GEG+efO2117C/vw+QsUe5TIvFco7ZrMZyucTOcom5cy6hZtZNsDY6uLLUGlVV+SNh/FyCdl3Xdh8JAAXWABUWix2sVivcvHkTt772Ndy9exff/tMPoRQ515GE2WyG2Wzm9pK0CFckOgilAGg5sMq13fAySVkjzy1/9fMLItgQQ89p+ZkSuI9YcRgyfec8o+W+S2Yl9Mc4LY7j+XCw+shsTfoAaZtF2oPPSdZH1otN4vy9d/SvIJT4umVo2lzOWRGiWgEw3smPf1rIWypt25Uj0BkHbcBdriXMtwKs+f5luEYy4TC98Z7BwvEpTYEx2fPVA9KP+wz5Dptb5KDicgKBkQx5D3tmRe85AEl/MFHynbUZDyVAzvGAmVadibj+OVLKNH7WFBrK710IWG4p7VeSzx1DGzHxjUn5kjabDeq6xuuvv47d3V1sNhsopXBwcIArVy5DVTUWiyUqFbxgKVIgxUKysUcf1xvPcOdzC7TsDnU2mwGA2MxJ/nnXWR8KN27cwK/8yq/ga6++in/8j/8fnJwcY3d3B4DxgM8nOrTWaFx+fNOfrXd8T7IE5xyIl02ygXKm4aHwIV/rMULrOI+0fJyHNB8DiMyq9oE7mpTR4lJNW7YxZfy6R1bBpK4loUeJZccyIMZLi3E97Z8VFEKYnPbMz+xVxyUgpGx9higXbuqz3POc9UuGDWNHaujDeZToTIO2MQZN17kzcKw5sxtP4793mk3YfUnMGPIex9jHtjHsInS8sYY6Y4i8mQeTsjkD1B9MKcXr3IWdASykPM+iPVdKhZEvnkzyGb5PKB9lGIhg4EToMcTUlEvOKtO2LS5fvoybN2+i6zpUVYW9vT0sl0scHBw4KxfZvSGtY+rOPKqNXZNerVY4Wa18fCalVHRUTGrgVVVhudzF8fExjDF455138Pbbb2M2r7HerLw5veu0A/g5FosdaG3s5TRV56+cJQoCZgmct2HOKY1ZXvpCkmTWIWzOOYe/TS0FNhPSsT8pSjmXPwM2g7ZSKmjJIxRaMJ+24UCIlZNYa3aCZbT7gthI5wQRyynS8Zh+n2p+H6yTy0P6Bx8bB2G/Qi9ULLS5eOxff2hJpjSn0zYYorMP2puWf3gwjs5Ca22BWadmWhNM6dxOWgANm2gSbcWbddh0CUSfAG8FSUzohe/Pn8iva5YotRJMSTP+nsbcska5JM4EbV+o52MOz6aM1CRoSZVb20uQfeBImVjQkkL6OcCSJuK6rnHhwgUcHBzg+Pg4MnEvFgu0bYfG3V7XuvIqo/x8PDo6wvHJCdq2iS4R8aBRVT3GWVWV9X/gyrW3t4fXXn0NFy9ewMnqxAH6Ajs7u9hs7GU/8/kCxti027ZDx+vqvv4E62aSeu0h670t5eLk1lNTc7X9BJjZlwBHasZSyw6cyPUXWGgObzjdyBQOZPu8VB/KPO/FJeY97H/Oga4Iz0ZHZQJw8/KPbSD7nw0rgT6mIUETiI8PDtUrfV6aC2k+PH9GyQtWfdCP85bv/DfE6DLOa880aGtjwvV/rDk7oGZQ1dod9RJaNhAaTzvwdnIrgoHXUiRVxqMq+RZrkLapTRQmrx19Hkw/PjMpaXuBYQto30Ia/IqGqKDLTNAAia3q4nE65n0cAfApI+6ZPJXCbDbDuXPn/Aay9XrtQXtvbw9HR8fYNLErUXYo1DQNVusVNs0GbdNarYMdvhC8z2V7UY09yVFT5W/TY9rf38fOzo4vz3w+x87uLuq6RtN0qKoas9kc+3vnoLsOR4dHqKrabzQNmnaekW8L1v111T6lYNAPp+F9U6PcF0HAqYIGy7yNRHhDMKTFXp58nzLAT6nbUL1y6adhslaNQrhoVz3HMwow2nPn9JrPdL5I4B0SgnJLGEN1nrLkkUsnrWu+bQVekIwz7Xw205kGbaMNVqu117DlEipL1qE7Y0bo10RcgxgiVHIyUTKtxWQ38ien54Ox1OgCkHzP3CmmacdzniMVMKEceIhSEecrej4U22nCBGennyYTmq1D+UUbBl/+joTZp2ElGWNQ1zUODg7sjXfGYLVaOd/iDdarBm3b9TZj8i7u4+NjNJ21ilVsMhfHu9gFMD9TSoHc3dxsDdDa4PLlS25XNWE+nwHgO48V6tp+Kqqd5zV71Ey7S3vIhFMlsk1TIJ0ifJbMtbk0Us2tz6xZy+qH479YO1cey+wZfhOlxJodIb4SNU2XzeOG23uk7FM3XcryDrUr+bVvOH5LfkjaLjKej7ufCBy7XA7ZbmPguo11Jf8+H0fumjfG2vxLVh2ZvhS0eqNqIns926BtDDZtIx5kwvjPnHkhNiMbUtGACBo2RZ99kJUexeRRCxWt7wS0z5fxeVEvB5O8294+PjGwZT7psbavaDvKmfy8whEx4Jw2bsedIgVFFsRI8XP3xwJpzO8HzYFd1/nNXVVV4fj42LotVRWOnh6i2ayhnSMUjsNLVU3TWotXZ9C19v72SlWY1dbsvZjNMV/M7A12XQeQPe5UOVCpqgp8HGp3dxdaa+wsFzg6PsKsqmE6AIpQqRmMDnfGz2YzzOYztO0cBgZNuxF7W8q7xscAOe2boT4spdkH8LxmqMhuEIuW6IyIa+B8+UcaC0AEhb7zlOx6alKvtNwpaJeEHWOM3XhorP6v2fSd5XC8gKgA4g3CzEkD2EX8EwZwZnS2nXLK9oYuUS6w6Zoyc6dfv2006DFytXL1c2eNSGCRL08I74WW50BnG7SRsK1incvaoGwoO0AK55dziSeNb9MQ5rIJSTx3Ms9fCPAJI0yMQDkTTy7cVzSVcowjMNu+5tIL7zkdQVHlnKPYoZ0O75KGnZoXtTE4d/485vM5Hjx4YNea6xrNeo0HDx5gs9lAO85kwRtomxZd22Gz3qBtOqxOVjg+OcZyPsf+xT2cO3fOCwHWfH6MtiULOM5szmuSVmiocPHieewsl6iUQkUKF85dQF3NQKScA5ZOWAX28eTpY5AiVHWNTreuzeJ2LYFvysiHNM3SBqOUyppdLEiwRUS6GfXl0DHPSgUAAw2YsMVrzIoCJHadzPp+CdRybePzdYBtfyfHaImgTb/9jNEwSIR+oW8pzpNs2pqXDEITRi6r++3dPwqWDxfKlX4vW0xEut5eEADbLsVmxonvt+fDuc80aAPIaq5fNH2h67oTmyMtIaE/KPOxpOm1bB77ip4vlYBcflpMJ98t5BhbXrMbz0tqWEop7O7uous6HB0dYblc4smTJ1gd28s6bAR7DW7Xdv6CnM3GHvE6PDzEer3G1atX8dprr+L69ZdBRN6V6aNHj9C28wigKlV5Lf/4+BjXrl3D+fPnsFzaaz93d3ext7fnQb3TrS/rbDbDycpa4aqqcj7O2cFRXpPOAtAW5tOpaZbaXAI2OeDpm3opuiWPN/SRkMYM4uNjslwpIPHufFnWknlekWJGEcodKlCsV9rmXErbH0H14vpJVcow7rmxDDc+OHd5B7bRJr7Old9FbSAtof2yTqEp8ymdm1Lo8vEiC2gGuE8JI2cftM8A5UxQXwSFAXKKuJl0hsF7UkrbF+QrisgyTdkncpmHwvfA3bw6PXUNcoyMMVjM55jPZmHN2gCr1QobrP0Za1IVGqfpbjYbNE2LJ0+eomka3Lx5E7/8y7+My5cvwxiN1eoEjx8/xnq9xtHREZqmsUBdzdwxMev4hZTCar1CVVe4evUqLly4gGvXrmGxWMBojbqq0HYtTlYrt5fEApAFcI3ZbCY2zFVomnC94tjGsW3n8qDmNQH8U9O4/PN7EYQVixIg4CUESswpJQ2RBZw0v1wcRdTfTWHCKFS+HAWLZNKMxujIxXMog9u1YfqAVywf95M7h09ufV5mqXxfZgqD7eZG1JcD4aK6OcuHL7dYNkjN4pFQeQoe+hVoT6SSOelnRWFj3TOlAqA/iMbCS/p5UbI/D2tCDmTHgGVonBGRYKbDxOnlvPppbaBUjflsab2OoULXaUDbtee2tY4tDFp0WvvNZ+v1BvP5HL/xG7+Br3/965jP5/jkk0/w4MF9HB0d4uTkxF8IQkT+YhH2lwBYLXm33sP58+dx7tw57O7uAgDapoF2d9wTEZqmsReFmBbQGmitBrpcLrHZrHFy0kR1HTIBn6a9n3XOl0zWDNjxe+3mqNtI5jRZUiFM5Y7PhXPdcV7ymaIgCjCkKXHZyNAISt/FWqgFZyBeNw7g2QdAvvDGLzM6c3cvrLQCuDLzWj7Q50zGFUgCp0xrW/J1LLROSZPP9UdpWeW04+lLAtqfL5I8L43mCyeirBOzryimz6t/p2pqAPoMlU2LJpiXIUKENcPhsZpajay/A4PlYum0W2uurojQkUHXwfsHJ6XQOAcqi8UCr732Or7xjW/gzTffxN27d/Fnf/ZnePz4sb8v3p7zDmu3/MdHs+SxritXrmDvYB/r9Rp37tyBUgqHT57g008/tXfbu0tC+Ew4M/TlcomT1TGOTsJVi7JNZBuMmcdzlGO4HD/nd3usj/2faJMongAmD4Yg2Is1lF8X5vy5P/tLKZwe/DFB+Qe3jSq21g7vp5BgzIxkSFNM26KicAcD11s7k3hO+ORlAhjrJtQDczKGZfkURdb9YthQn37YKWCaCnFy6SN9lsv7WehLAtrA5w3cXzSRmMinxV1ymya+3C31+dGUibet9Cz7NX0e5eYOOqdrZexeI2jNfaciQ+Ujsru4z587h73dXcfIYw2OP5umQdt1uHTpEt566228/vobODo6wu///u/j4cOH0FpjsVg6MK6d1zO7MayqlL9NTCOsS/OOdQB49PARZvUMTdOgqir89KOPcPuTT7wntfV67cygVnus3J3dRNYNqm47GGXCHd6Jxsn17wPRlP4JjDrnzSwXR4JFTovkMMrtHrcnU5Q4bw6AjNipzGn3ASMnnNkvQbudChxpv/fShPUtLU+39toxBTRy4JzefCbKn25kSwMGbxz9+oS4+baYurw5FWintOVYmFxZpqT7AoD2VxAjiUqoa0akXnzVks9K43sB8u9ObVZl4HbatcxDambsGUpqW6kGVzLRVVWFvd09XLxwwZtRKwFKnGbXdWjaFteuXcNbb70FQOGP//iP8f7776NpGly7dg0HB+dQ1zN/exWXUykKvsYVUCuKzm4D5M6AW8v30dEJPvvsDn7y4YdYrddeK1dKwWgDUgaVqlCpCh113quadk6YHGb32im34pnTrkr9m2rYpTaVYUsCQg7IeU3Zn2cmApmgXcuLjEo7x3N1sF8Ta0MoVO/Z6Gh19dBybTYd42LIyvztzm9566Ezfw/NLRYi/PJeJogP1989Lvtpa8tI8W3ZcjNFEHyWpZavQPsFo9JAMmRAp3ZynrKyLyed1WUNSk160Wff3CaZhf1DD0T4ewlYAqAq7O3uYbFYeGD1Zmzvv98W7sKFC7h+/Tru3LmLv/qr7+Pu3btYLpe4du0a9vcPsLu75/KKTbgM0N4Pdh0EDGtCr6GU9bw2m89Qz2o8fPQYDx4+QtO2gGTsQjAhItR1hcVijk2zQacqdKqy67WOeZMoPwqMcptxUTJ/ljS53No6A6V8riB2cbuSE5Svc0UVjOlCusis62b6mkHR/cgILDGAc9olIohNX8JaHtVv5LsBRQJILowXWN14Ih0ElVDcMB6YL/Jc6KVXoHiNfroFJi33M2Dw1iD+AoD2V8Q0KBU6DXxIY8gPDKmDf/mB+4ugIW3LPY0ZnH+vkB7xst6yhrX5IXMpf/JGpqqqcP78eX8sSF4yIdO2/sfnuP3JJ7h77z4MAddvvILFYoG9vT3sH5wLG83EjUzyes66rgEif7mIPYtdY1bPUJHC3F25OZvPsX74EE+ePoU2sHHcDnZVqXB8xhhcvHgJO7s7aH76EdbHK1cHyh6Jkm1R0rjGNgbmfmeBOQnrhaSBvnG/3LOwXh36TjpZydvVhrR/Wb/sGErCFNPgMCKJkjBTovx4FwKnfeDeO+B2YXnjmtHpfROF9LcoT2/5pBCew53WxF1agphCZx60J0kg8fixjwptcVa1rW1oiGlPMd3GbZqT2b+iIQsPnwV1v7ZLNds/vFZtnNYtHZ+EHAgAKbeJy7m6JJU5JuN2HpNndMERh0GIo5TCfD7H/sF+pA3ziOiMAZzXM2MMnj55is5oKAJ2d3agSGExX2B/fx+7uzuo65lbT7ZamF3HZq9n1vOZNga661CTgqpq1LMZZk7DXiwWqOczVHWN4+NjbDYb65iltbvW+a5uRQp1rTCf1bhy+TJW6xU++/Qza9qvKmhdA7CuTW19E49jxX5IAF3Ok9yabYHx5jbAeQuZYPQeIIwFIuPBKTVt85iwvWt4/ZvXtn0+ZRALaeQFSGmZSeuQ8mBNXI/QZpKylh2fkf3PKulO0UjKKH7E5Xf1l0uBKXByG6VlL5mycyTboDS7NYS6Q7Gjm2HMii9BCYIZ52nDDNGZB+1RytTP1/s54XPJvBjl+Sz2kVOUZUjSHyrPNhtvton3rPQswtTnV7ahMlkGOxh7snAlz+kGxuv7WvwOGptdH1YCgH365ICaCAqJKVYRlLgyc7lcel/jfBMXKLgpZXDpus7v3p3V1pxNpLBcLrG/v4/ZbAalwq1gbAK2oE1hE5rW0M7bGTnQrqoK80WN2WyG3b09PHnyBLc/+QRd19ld4ycnwQzKwEaE2awG/PooeTBWqoI2OphYXbl9GwytxcYdGIWVPRaxl0QjzsUJzD30ZbBoELwrOwpOV2w9Q/gISIFEM+mDU6qpy/rmxma6HJJ+9/UuWAsGNU6vWHm4dmGU9yQm4/TSI847U6aovHGdtuEr2fJnorvh5sok+31YMAqxpWCUtmO/Dim9+KD9FU0emDkGVVrTeZFoaJI8W53KsyfkEzQgm1/4nksvMGHJ/Mht3krOzyYMOGhsFphARmiywuuV04K8dgf4d+yYgzdTzedzL+lXlQK5dNihSpS3i2Pzst/39vZwcHCAuq5hNPmLKbxwoZQrJ/m6Ebkz2w74q6pCPVNemLh//z4ePnhgvaA5LZ/LDLde3ratf88Wg1k9C2Z0pbymnVJf0y1rVCXNKTdnCAlYZt5Hgpeq4O0gQkBjcTAaRaKcXGZQ0NBCDrKvh6xF05YBcs9K/GKKwJ+GYJuQduH4LHrOCjCuxY7TmCVySGCRZY7aQBgrx9rEGkaGedLY+y8daH9Rht7nMaCeJw1Le/1wLypgp/T86jGlL8O6TJxtmckDwo0lxY41rAYdA0rf/BdAPmiy8XlfxZ6jknxZe7NWb426rrFcLkFkzcqqcpc7GIrHhVJ2R7n73rYd5vMaL7/8Ml597TVcunzJucuc4fjImrW7tg0ChIK7oYt3p1uNHKRQVdYsb9D5tnjw4AGatsWsdlduat5UxpoPeY2LLQTz+RxVXYE2oV2sqVzbXc4CmFUy5g0RiE2iyADLBE11DMhkX0sNmwE7ikdk12tJLI0QYBSbw+0DcppaSZvji0eMidecZT1kOXNAn6tvqa65sFktODW9k/UtblybjN3yNfS8JDRvww/H9gXIPSbRs0yyUvDOlXlIICzRlwq0o+p/ARiUdtBZpp+FkPFFCgLb7CAdoj5gyv4l8PlTFBgZU0UqYoy9CyPgwCSjXffqlIB2pIXLPyH9e6ZNFvi6rsPMmabr2p6phnIaatcXMhhkVVVhZ2cXV69exSuvvIKr166CvKZPaJo1msZguVzAXvig/Sa0VFjhW8qqSoGUNbUfHR/jyZMnqMXZbLleaR2MAIAJPsedts4AWFWVPUrsdrBDuwsRC8xY8luv5W6hYaf9k4bL/6kIsNN+JtdPssw5Aa6/P8V+2uccrorKN6RNj2miOUrH6thmN1u1pN7Eu7+53CyglcuQX59ma0xfY57K8+K22EZgGAf6FNhPw4e/NKD9RQM28LMB61EpcCAekJeYT03F+GdHaz9te0nKaU+egbrNP5IBpZ9KKX+kh3978CLygKKcNptl4PI3Ys0tAkKlBBMVt3Oz2dYxRNZOF4sF5jOnpfq8w+azYH6vUdU1lju7uHLlCvb396GUQtu22N2zbkiPj4+toxRt/JExvj+4rgOr8dYBqnxZVGW9m/30449xdHQEcvHZA5qM23XWRN51nd2sVs8AwB0ds22iMzuLc2Nfmt7TOClIjo2lsXEWjxHALpfEfuRzwCzjS/N7DEx8JWkv16j83Kc5kH4ewF0qsyuKLxOS9pfpAIAhYw1ZA/mNlTUt8+n484Q4TtJLhQNfd2UtW6TchjXRH6WyDtGXBrQBnAmseF4a3pR8puTxvASJvIZSWheDn5QvEo2Z4VJm5LUhr/nGDk3sOjVrlQXNy6WXbhyyyYYJLjJ2aQsN3ZvI+2mTScaAU2KqqsJyubRr2oC/7lA7sywDeeJZgQAAIABJREFUWNCSa1SVdTm6Xq/x5MkTVFWFq9eu4dKlS/7ijp2dHewslzDabmRbbdZ+HVyWFwAqVYOPNu3uLQEAt2/fxtHREeq6xmazQdu2wctboq60bWvDzubW9Wpd28sk/Lr7DI3ZDGozOYY+pEWX5l3WIlII5//4HnTTX+sMAtYwL2Eglpp1lEZS7lS4lN9LIJK+ywmxZWtUWeNmSxVbhAJgh53ppToPvM2WKSccTFNgJggF7p/FY+FSViyfhStMRTyKTfFTefWLD9pbYMPnDaSfdx7pRNhW2nwRzPY/E5LWbQbGCBTgx1UKsvzMBxPv6rr2moykVCMGbF+qDNPo5ZPpN9aqw3cCLznL/Pgca5o2X9jBY0KbEI6ZP4Os/bPma1UprFYrPH78GFevXsXbb7+NW1+7BW0Mjo+PYYzBYrEAgbCzXGK9XqN52KBpWzRN4/2M83luggKRwmK5wI0b1/HTjz/GnTt30LYt6rqOtGze4Ba0L3uJiDYGs7n1ikZuZ3zXtaDKnnGX7V6aP2kfcP/Iz7H5MwZSZTKChzFrL68/p1pztFTD6fXC5sdXWt6p5c6Zw4cEmWK7EaxDKAY7J+zn+iGXbjHRiTvp0/Sm80jKp5cIXoasP/whk3jaH1Pyf/FBeyJNHZjbANtY2M9D6y5pAc+zXl8GKjImg7DRxfNLchNOhKv6Vxr2LncAIPFZOigB+ibPqByUyt1xOVNTZg4U7LtQbgazUt3z8cmbhqVpORYy7LOmadB1Hfb29vDOO+/g5s2b6DqNk5W9zWtnZwdEhFllj291XYflYomT1SO/8Y1djgJW057PF7h8+TLOnz+Pf/7P/zkeP37stWwpdHgXpq4qvEHNANAG/uYxa+3g+hJACjThlpyUcaZtPqapy3j8vK/dhvVaCbo+DadhEoJ5n8dqKkSUPkM+oXxKVcmyyfgYGaIxIB3iNWk+HJLPYE8t11B/5MzUaVpjWnaIU6xKCIO4z/335CibXdoatpoM1Y3p5wa0v6KfLxqTrNPncgc2EEA7t24cp9Pf6S3DpFqJjyu+50CCf+fMjvHktkw65JOvq1y7hTtWM5/PI0Ejx/jZfO1N2lWFK1eu4Pz581it7D3Yy+XSp1NVFWpS0J3G+fPnYYzB06NDHB0d+YtBuK3raob9/X0cHOzj448/xl/+i3/h18XZkYoHbGPQmQ5Gx/Xvug5tp7FarcIuc5JXV3ZodbhAZGhM5DTvnOA9pKmWwQSAO/Jnm9L0AMUKchR2zFNwB8tUAmuRkyuHFv1WVljGwItpir/1UrqDafcNBINpjStCebN3OseeVZEa08oN8QKAyDMXbiJQS/q5AO1tzT9TaEojP8/8SvmXTFQ/L5p1qf6A24RlRDiyk8lZ4bwZkpR9Xyk2HzMA8jqx6jHXXBlSs3gKmD2mQdaEbSD6awRU8lqD8hqms/TzC5sHiXZQdieCUgrzeoZZVQHawGhAVRWM1tZ1KHjXuPU+RqQwm839xrP5YgGqFHb3rN9yLp/dxW3rs19VqGY1jlcnODw8jNanq6rC3v4e2q7Be++/h+9973v40Q/eQ13NMKvm9opQtK7OgGXGBhrWaUpnbMd1Wrtd6h1XtyekEFUA6cG2zX2eZo6nfRz/hT7i7uF8Yq0eFqwjIY5/2vvPud9z5eDxwG2RgvYUoWMqOIcy58On1opSmlJI7WnjWwgLEJaJWJhO3f+W+naasNEDbYrXsGW4ENZ6vTP2hVuWsoKa5wHUL0NKXzrQHmpk/nyRAS0HzlMl3xe53sBwH/Y1WRJMS0we0ha0wUAH59bTeDeeEIxWxs23cxnM0zJH/cYxSR51iSe5jJPrZ9akmDFLJu7z5jguLb6Zqa5rzGczVM7BSdCoa5i2hTbaa88Ap293eB+cO0A9q7G7a3eS13WNtm29NsYa72w2g9baOj4Rx8uUUrhy5QqapsFHH32ITz/9FB9++CGuXLkCIrLnvHULdqISgRrBaaCuvZQ1f6vK7kCnLrRh8K9uYHQb3Uol+6ZEQxpern9yfR7iy3dl4bpvkjeif/32CxiT13774zD+XQLWdE7lgDOtfxo/R0MC0OfBkyKhNc4N3IYcLhtqCz3LCxoFvwxsCu+3DwsoiN77thrZsf6lAe3PU6s9azQFqL9MWneO6Qxqo2DQ7h+Lslq0PSMbXd7AjL9n/s7nN2WtLEonKSOnIfOhJE7pe05gKTPt8TCVuCSEXZfa9wqAQuXWRJUD7b29PZw7dw5Xr17FwcEetIYHYwYRpRTW6zW01tjf38f169cBwO4u39kBAHzyySf49NNP8ejRI9R1jQsXLuDw8BBNs0HTbLwAYIxwsJIKUATUM8vGVierXhmsg5Uu0XimUQmIZd+PCo9FYa+sQYa82MtdWAaJ90sUNkRlyjFGQ2vEY1TK+7R8Z0p9SssW+fLmL9kZS28s/LPULzeGSn2Z0pcGtIfo5wnQUypJz0OS81mgIeaXDuwIjBwj4zuhJZMnIkBcsEEmrH0CgOORiVltxHJjI/DD2ATrfvuWFWtbuToMaTpDbZPWcyx+Lq5y5dPauI1L4RYwBUJFCnVlPagt5gtcuHABe3u70NrGl+ewbZo27oULF9C2LYDYt/Xt27fx9OlTXLlyBXt7e/jJT36Ce/fu42R1gvVm7c+JB+FBexDvurDOW1cVXn/tdXzwL/+lb3veWEdETtvv0CbjZ4yGwHhIIN4GHCTjLwN3Ou4BC9ZBU0vjDJmTh8bY0Fgfa7Op4D5WpqF8pwBrv37lOZzGO62gk2vH3DupWafhtxEov/Sg/SIB9ph2PCSxb1vPMTD6WYF4TtpM36eTvbdpTAKzgWfcPe1ShUsl+Lm9C4t9OgNsjiwJCVE5C9K+JwHSuTqV2iL3PAfy6e/c9Yg5YSBtG/tcgaCgCPZ4l1L27LM7+qWUgjYau7u72D/Yx7lz51zaXFXjz6Wz8X+xsH7N2YkLb7DS2m5Se+WVV3DlyhV88MEH+NM//VM8fvzYp8MmdyJyN4eFfIAwBl566SXcvHEDf/nuu/6IGIcJZR/3CHZaRpqOsXQtNUfSapBLK9eX/TFoLUXabTgbA/9S2cfCTQVjptwyj/wt6Vl4TLlcPP7s99I84PxPI+SGfBTL5YC4VyAnaIzRNm3xpQdtprMO3ttqVtu8P03+YwLEEBkzLkiMMTjJvHJaZHrns2I3oeI9AOeFyG7wICJokwFASOYl6xEzwl59BHA/Cw0JY/Kojgyf/nH4nJCT01hms5m/oIPX16pKQcGgcmekicgKNcagbVss6iUWiwV2d3ZBRGjbLjouZtcTuc1s03SdxnK5xMWLF/0lHwCw57yoKaXw8ccf4/3338f+/n44wy2Yflofay63u99v3bqFx48f4+TkJGpLthIAYYPgEAiPCUxpuFDnPtjnlj9yaUgvbLkxPVhGAwR/dwRQl40zlNaYcOGzKtQjLdMYWG2rXJTyGlIsyFkipN913knfD1ueI+MU1scDWIf83ZMt0ptOZx60nwWQThP3WcDqWahk8h2jMUlxaIBPKdPzoClSfArKzMRKvrWzmrZIk4GYVFj7k8/tdxGOCAZ5N5ZT6pKj0rrbWFo5xp+WKQfOY2nJsaCUvWOaTa5Exl71SeHazqqqoGFA2tiNa/O505rnWW0xrLMGBlZVCvv7+9jb28N6vfbpzmYz1LXC8fEK77//vgfZtI+7rvMbyFjIMwYuvvWZ/sMffh8nJydYLpde2+bxMZvNnHl+CsPPz/1cG5dcgco2z2mWab/JC1+GgKUvMALWt4CbB0bBGF30ojZlHI+Nx7E2ydV3Co3Fm8I/ArGAlt8sd5rlgWkULEzxM0nPh5+eedCeSs9D23zR6HnVOZdOiekkEftpAV7r8kHIQ6P/zQOcJVOiFLjD+eDcrVg5MIpAzBiAYsB2OdnfJple1i6cBUvyYeLd2TD5fZ6lssnP9HsujaHfaZpTNAn53QopvhrOUYnBfD5zWrbdVd40DRQRFrW9BYxsRzmQ5T4icQwpKgGUYneugFLW+Yq9Ecy29aeffoIf//jHOHfuHGp3qxeX0Y6jDp0GtLG3dckxsbOzg88++wwPHjzA3t5erz1YCLBm9u3my1DYlPFPEQBK6fFmue3ncmp9sCJoDhiGBPsxoT8HfGn8/Ppt3hSdmqRPqxgMxZX5nFYZCqTGgyRp5/I9zRJmib40oH2W6XkLFKeREIc0jLE8cpoa0JcjmRSsq8ycNugBg3T0LqeB2N9Vz892rqw9Ruq/p2GN42spszL+CBa/Nda25o4VxXUwwRaWpdMwiiFN71kZrnxG5M6HO4DURlsbgwM6u4mLzYpAPZuBqgoG4RhX0zReS9fOz3hw5MHPNYwBwo1kMTPTWuP27Y/RdZ13AcugbMsqtHkigAxI2U1xvIHwzp07WK/Xfg0cgKiDBezNZhO1YYmBjmmSpTYthSkJbHKs9+YUhfYT4mK2bEanZQmgPcX0PTYuU+16KMyUMT413LPyy2xbZZYsnpWmCh1DYU4juHwF2qeks6LZb1uOsfC5QZSu3QXmk9Uze2eds8BMYZ25FMY+628oy21uSdd+S9UkwHoEM4D1TQ3PG4VO8cyaVtxOw1pwKWyO8ZaAIA2bayOpfWgjz5cGzZR3bVdVhfV67V2lAsaboxVZbbltW8xm5IA5FmweP36K9XqN3d1d7OzseN/oDOKABe379+/7tV12bxr60Xo0M22T1Nlq2icnJzg+PsqCC5vWj4+PfZ3kO9lG6fe0rUvr1iwYTCHuh9RqlOYVa8rB3CrLEvo29WIHgLi/+vXI/T6NQDkWd8zyUIpTmufPQlLrfZ7LnT5d5zAF3kXt9P08Y0J3ib40oP08zQ9nncY0hdO1g5zs/cFEzqViBAAqN5GtNuacCVvmVFdg394M5vBg6UzjhiesZVTKH83KlaV/XMbuyyFfCHIbdfrmQtaoYdewXVq8xsv1H9NSZFmi1AsmRH5XSiMXJzg3KWuBQ31uRR4DcuvAtt2VrbuzIEApVLMa9XwGqpR3ktIZDSjCbD537aF8O2mtAQN0TYdK8VliBaoIptP45JNP8MMf/RCXLl3G1atXsVgs3BGyUGbjHKTcv/8Qjx49itazjTHQnUZd1WibFtAVoC17NKYDCF7T19puhmvbFqYzgDagyo6bZrOB7lrM6gptqwFoaOe/nNsjZ8Ys9bFk/lJzG2PC3G4Kyo5zGL7cy12E4sYe8Z4KCv2F/vjx6RvtpoewfI0M2RQUB8dPAUCnCP4wxp3MsKSFIBzL+vb0Riqsj5VtW4vHWPlzeU0W3OEuOzEI/E2WL/2dSXsboeKFBO1tKlgajFPMPmedtpF+p6UTa6mp9C+vnrSgAhA2vbTm8zmshz57zCrSginAqJ/ECJvIxiYP5x1pOR7sISZNXqOC6aK0ZJrldhmmHChPTS/VLtJ3zLxyLlJl/FwaFrqYIdon2oE1X7axWC6ws7OD2XwBGbFrO+sD3BhUFMDcuim1TKjrOnRuBznVAIzB7dsf45/8k/8Xly9fxu7ODpbLpRPAmG+xAKHQNC0ePXqEk5MTHBwcoOs6LBYLbDYbzOdztE3jlzIUEUDkTfH2L2jQWts177brsHCm867rQADm8xmqSmGzWSHsbi8fo0tNqTkqCWY5za43ztnxjxdKw/zjfsrlIZ/Z5RkfEvIjbxXrz6cpfHAK4OUEauJlElj5XW4AZftBwLmy0JQKTGPli8rwDILIZD4qmt4UhatkKW0LAShHLyRoPw+tehvgP2tUAomxCZUd3OBJFSZWGNhAPMXiQV9VuT7gKyqdBi08VMGBtmdRjpMzE8uZyNKy8/ueyV4pX1SSmSCdGOVxM8QgJHCWzG1puUvppZM6p62l4XLm7vR3j/FEz6y2rAjonGm7rq0r0v39fdSzOU5OTkBE0Rozl6PrOsxmM++OVGuNzcYKbLy+fO/+PfzTf/bPcOHiRdy6dQsXL17E/v4elFLYbFpsNmsoVWGxtHdn37//APfv30fXdVitVrh8+TKqqsLx8TEuXbqEzWqNw8NDEGl3aSWbh9lLWuecrVjw7rTVwqlSMJ0VSmaLOZaLBVarFZpmAxYapCkTwKCpO+3nKUCX+0QkQLk+YSh3c4WIInerp+FRJYAeC1sKty2vJWLAJr99hPuuHzYG7hJP26YdSv01VI/T5FPKOy13NH9tZkWLzpT8X0jQ3oaGzF0vGnA/q6CSphM0VTdBHDgr/96iYIkJZPaE2XeKIO8yDi9iY7XUEoY067TsUiMK/UcAsYQPoCDEcH5D61ylzW7p93Si5wB1yvpeBLyZEqd1YQGLrGHVtyOBQCasg1qFWApErm+csYHPTM/nc6gq3AXO12hyGx0frTCfzaLjSVoAf9t1ePDoId59913s7e3htddex7WrL+Hg3AHarsPj+w/wox/9CEdHR3jnG9/A9esvAwDu3LmDu3fv+rpduXIFH3/8MebzOX7hjTfwg+//wG5wIwUY5zRFa8C5NgUgtG52v6q8FrppNri4fxGXL1/E3bt3cXR0FFkpUxN3+nyo/4YUh5Rh27kFyNEfa9/uvbOxlrTAkpCYexflMZFvTKnPFLKatnwAz2O4b4C8cF0SGtI5OaUspwHiU2vcmXSy/TXBkjhW3hcGtFNt42eZ3xdJU+o6BnJAzJjkJ1GYOHZyVHZp2DHAoBkkcQBUVaF9nAAQlUuRe+60GvfPJIwsD8jxe/k9Be7SxBep+G855xj56tAgI8+BfFrmMW3blT5/wCRTRN9tJv4tzZDy2KjPx62Vdl2Hk5MTp4E2MJvWX84xn1tPZqxBE5G/C9t7o3Ma+6Zp0LQN7t69i0uXLuHll1/G1ZeuYj6b48GDh3j/xz/GRx/+BI+fPMbNmzcjzfb+gwd4+OgRlFJ45ZVXsFgs8PjxY/z2b/82XrpyBX/yT//Eb4TrWoNOa19hblc+IsaNwevbTdOgrmvcvHkTN2/ewL1796w1Rse3Zw1p0SWza6/fCv0q/wB2hSLfy7zi3yWS45+tA0MAn86FnslejM9cfbahKB3+4GE3gXdLIUfO67G4U4SXZ7VYFMtciJO2Zyn/nPA3lu8LA9rA5wPWZwmctxFKZPjUJCPD5L7Lnb7yaJY8M8ruQNkUyTt2ZVpVxRthYjLG9Eaz1zWkmQgxEEvtNzVXpvUrMZnxCTB9guQmXqmPcumUNHCZ3jZjOtfPQ4JNaVzL95vNBsfHx6jrGYwx3oc4H59q2xaz+QzzxdwLXhoWQKsa7npBqyXP53NcvHgRSil89tldfO9738MHH3yA5XKJf/Vf+ddw/ZXreOmlKwCAp08P8d3vfhfGGMzmc7z66qt4//33cfnyZXzzm9/Et771LRweHlorgNvow9u0lFLQXfCuZozduMZmfADYbDbY29vDyy+/jPV67esDBDeiubaVbTTFSlJq+55gDJ4Dybg1wbsaURBiSxqnLG+pDKVxNcRfZHmfF8CNpZK+T0F62zxL7TM2D05NRDn2V8zLz7vkXXr73Bi9MKC9LYPbhs4CcNv8x44BZCa9+J4bxDkmEvnuJnJXU4o/WLegtjys+1FkWrTpFCrjipmCjHYXPSiRFwNhDrxLUyIVWErt1QNzY6xKmqTRB31rXZA3Xm0z8YcY4Ji2oEMRe2SEOVHeUJZqdTnGHQE5BU9cHG4xX2A+n6NpW3871/HxMZRSWC7ndqdzVYEUea9jnNfOzo5bH9/BZrPB7Y/v4rvf/Qt8+umnuHDhAr7+9a/jrbd+AYudpdOENd577328//77Xhve2d3Fj3/8Y/zO7/wOLly4gL/63vew2ayxu7u0/UB2fZTX09M/30ZuPLVti0uXLuHg4AA/+MEPcHR0DGPywMDLAtv0bYlKmi0A55ynAqBdHxPCHgy31k7ltHrpbSlYDAm3ufRLlAqFWYEU4+M+qe4kQTh9l+Mhg2N/Yp3GwiPDb0sCdEkYSd9PpWcGbbL3x/0pgI+NMX+HiF4H8LsALgP4NoD/0BizIaIFgP8FwL8B4D6Av2uM+eBZ838e9EUDNhOPgTJg8/O+BpcD6NTVYupdjJO1v513KzF47dlaNwENoet0nF6hmIqUN4uVypXb+OPfC8DmyW+7SDAsfuYfxWu5KXEfVySGfIknEAD0fUtnhaJCEvzeQAicxibO8kMIJwojG5UDcXtMMJ/GZeU/Gc+4Mljw3d/fx+uvvY71eoPVagWsVzg8PARgj1UtFgtffnuO296yZTVbYD5fYGe5xGw+w2q1wk8+/Ag//P4P8PDhI9y6dQuvvfYabty4AVIKDx48AhHw8OEjfPvbf4bNZoPFYoFXXnkFP/rRj7Czs4Pf/M3fxO3bH+Ojn36IvZ1dq0UbbTdpKYKCQqs7tF2HpmmCj3QV73C/ePEirl69iqZp8PDhQ7fr3MCY/nicYqIcArkSuPeEVieQ2bnmvKAZcjfPAUQ2vKZ+OtP6e5wkyA0t6wzlMSYol5aCColGc+hZlkDHLAzb0rZlKPUVt/U2Vroheh6a9n8C4K8AnHO//xsA/60x5neJ6H8C8B8D+B/d50NjzJtE9PdcuL87lHBOe5TvmJ4FdL9IwI7rxh1qvwcNl3m3XB/rg3bqvzh9J0E7fc/kTXTGgI2RXB4g4x+5NNgoTp8nkxy4pbICEKZ5sbHM7UYV23YQgziJxrIazNBan3zGFK3HUSy558ITwpUNWTKsRZEXfnw5/MF1mSABwvd3aioVIx4Q3sLkX0oBvC0ocPUAa0m4cOECLl68iEeP7A1bVCkcHx/jwYMHAOAcozitXAP2ChGFrjPoWo2u1QApPD08wkcf/RTvvfcejg6P8PbbX8etWzexs7OD27dv45PPPsWTJ0/QdR2ePn2K27dvY7FYYmdnibqu8Rd/8Rf4m3/jb+DWrZv4vd/7PTRNg2q/QtM00MbddV5V6NBF2jWvs7PXMy7r5cuXce3aNTx69AhE9h7w4+NjC4pdk7RPHmSzXZpZE+63d/+7MdazPZEVSv0xKOLTE244uM2fEoByYCDLOwXoSuWaSlMtRkM0FqekEZeel6wOQ4LO1DKM0ZCgJ0F6W5P/FHom0CaimwD+LQD/NYD/lGyp/yaAf98F+Z8B/JewoP3vuO8A8L8D+B+IiMwpa5OVaCCYLtBTMiKGWYibrr3GbG6oQMnvIp4RvElMPh8ACGa8NgxL6zHgDV2uASTXWTozsZX0w3fOX7qjDBoseU9WAVBz9Quado5RFD99u6AXJ22jnDQvwxt/rKcvEBiYXh8P0TBDJM4kfZJlIjlAiMtG0fGXYj3d/9yfOUFMjhmuh5Vn7BhqmgZVVWF/fx9PD5/6Y16tttr38fGxK79No6oqaKM9SDZNg/V6DVKEdbPBxx9/jDt37sAYg194803cunkTWht85zvfwbvvvot7D+5jZ2cHXddhZ2fHpq0smH7nO9+B1hr/5m/9Fg4Pj/CXf/kuzh1YX+RN07j+tH981Iw1bPbixu2gtb1V7OWXX0Zd13jy5ImN13VQIHTa7s9gYTQFx7RfRsEqsfGWNW/lxU1yk1gbN7MoNRSnccnKaYWd5dsA0bZgOzYWgXwbDZmCc8LylGe5dIeE8KF4uTRSIatMMR8q5c1e+fo86NnoWTXt/w7Afw7gwP2+DOCRMYZ3ffwUwA33/QaAjwDAGNMS0WMX/t4zlgEmgWHJmIEwHUxvFQUemzi+vSnndGUISfaZrBHh/IV6RD3mwGZqH9cDVdjJnYIxg3Z6S5IP55hDEBYcszKs7TkGb/plBwgwytcrrDfnwlqyvsfF23RAU7wlJy5bXqjiNhqagNEElp8smKQvC2TzKd97LJ+x9hSFI3fWVvat4rr5BHqGaxaSgmsK23EByDkG+atIc0SuLzU0NDmpX9tZohxgVVWFqqpw//59HB+fYG93H8vlEovZHNWegrms8fjxY7SbBl3NN2UZGHTYNGt0poWGQdM2ePjoER4+fISqqnH16kXM53N873vfw+3bt/GDH/4QIMLLL7+Mc+fOoarsWFqv15jNajx+9BD37t3Dr/3ar+Gtt97CH/3R/407d+9j7+AcCEDbaSjDSwoGm/UGm9UaXddhb28PIOCosZozuza9efMmzp8/jwcPHvgd8p3WLFECpvJrK3bs6SIY2DZmjUkyXwIMOYGi6zH8viBgAOpgL6UhQCNZXnJ9r01wuhKYUjROxkDoNDRFUx0CRaYUxErry0PpbqMp9/lnLGTk4j1z+xEy/Zsvf08YOX2unk4N2kT0dwDcMcZ8m4h+6zmUhdP9+wD+vvjdCxNtFkBGyR2SJhOp2IdPlPQhKmvDpTzJr09KDSjdjc2UmqFZo8hp0Pw9Z/oOwE79ivFkcn/9wZXU0ZD3pEWAcwTR34XLGqARr0oTCyPtONbOJclfvhub5L3SUwCIIZJm/iSBXKL5NNJgAqy9QBMxmL7AlJ0fHJ8FC7FRSxt37hl2h/Xt27dx+fIVzOo5ZrMZFgvrIa1trbeyzWaN+WLhN+XZCzjWUJ1d3z7qNA4PD713ss8++xSPHz3GRx9+iM1mgxs3XsHNW7dw4cJFaG2dqCyXS6tB6w4P7t/D+XPn8Lf+1u/g+PgYf/7n38FyaU3mbdOgqmuga9A0DTabDU5OTqC1xvnz53Hu3Dk8evTIa9q8QY43oN25cwdPnz7FarWyY7KqnKbNknp/w1SeqD/uEgAfmv9hHAq+JTRn32vMgwbGdZquLFP6LEcly8LzohK/HgK3XJlOaxHIPRtrm0EAzrlqTso/Vo5e2Gds9mfRtP86gH+biP42gCXsmvZ/D+ACEdVO274J4GMX/mMAtwD8lIhqAOdhN6RFZIz5hwD+IQAopUZnVF9b6b8fo22krjGmL8PI3/KPN1qVAJi/p+Zu66cYkfmagZdAzqlJpgx9qUYcMUEWtK12LQa7E2ziSw4G6k/J74ntVPq9rUQ7Jb6kqYwyRynzHCrT4DuLwmD/AAAgAElEQVQEMLbWgXz6AFnwzZwzT5mDfJ1qP8fHx3jy5AkODs5ZU7fIh2/yWq1XWO7uuJMCxj9XzrnKarXG4eERTk5OcPfuXWw2G7SbBsvlEm+++SZuvfo1X07tTO/z+RxHR0c4f/48Ll++jLfffhvvvPMN/Mmf/Anee+89LJfLSKBrW3vxR9u2aDYbXL58GdevX8ejR4+w3qx9m282G1y6dAmvvPIKlFJ4+PChX0fno2x2PdxuSLPzB36zIOcXhErXiNnlNG17iwDpZ3+IvBtgq6pBA6h6Y7SgdRK8petZaQxEQ1meD423S3+eZpc/R7T2tA/lXCzlObZHoYQgY8JFarWQZR8SFKe0+6lB2xjzDwD8A5fRbwH4z4wx/wER/W8A/l3YHeT/EYD/w0X5P93v/8+9/79Ou54dMTFp20a+0kGWBXPGbJrpoJgKCKUypmDsNV9SUBSvSeYAPN3p7eMjXh+KGI2sbKGe6fey6Y3i/6UcYEoZuDRSTb2Xdr+dON0UXEp1mAK0pxEYBoXAAtMYYxJjz4nImUEt4zaAv1QiYyYpLk1E+bguKrUhn9E+PjrGye5JtMGr6zpnvbFrxk3T+Pdt22Lm1rVXqxMcHj7B97//fTx48BC/+Iu/iFeuX8POzi5eunI1gLxYvlmtViACdneXePXVr+E3fuOvo1IK3/rWt7BarXD+/Hl0ztGLdXF6DN21MLrDufPncOvWLbRti8ePH2O9CqA9n8/x8ssv49KlS/joo4/w4MEDbDYbf51omC/2AgvjnLXwmjm3SxhfbPkgwOgMs9XgY3glJp4z0UorSZhFhf6ElwlCnMJ6b4mGgGWbdNIyjD0r5TlWvmc1jadpnKZtxupzagFnTMucQJ/HOe3/AsDvEtF/BeDPAfwj9/wfAfhfieg9AA8A/L0picnGiRpRDmSMm7mI4j3HsWmqnxf/ljRlMEkQjYBabBRTpFBlNo1xuDRdH0bUVz4vkaKBIx1O0k/LzwwwrF33mRG/UwXTETPG3PpWrr3iYk2TunNxt32fC8emT5N5lxsPpTJOyXuwXsEiDmO0N9P5uYDgL1v+5Rhx7pnWdlPZZrNB0zY4PDzEZrPxILterwEYzGY1uq7zZ7eloHh8fIzDw0O8++67+MEPvo+/9td+DbduvoKu06gqhaPjQ1R1jcq5SOVLPuy92hqLxQLf/Oav4ubNm/jDP/xDfOc738bXvvYqdnd38OTxE2itsVqtsDo5gTEaFy9exI0bN9B1HT759DaOj498e2mtsbu7i7fffhtKKXz44YfeepDOaSJbltbdFKYqy0nDuK7AgpMxxgK2IRjE9bfp9pdhlPODLwXXEIYiFDbGQLt55j0RehNLWOoYEwrH5srnTUPlGlpbnhJH5lES8EuUA/JSGaYoDGOULssN8YhS/DF6LqBtjPkjAH/kvv8YwDczYVYA/r3nkBfATM216bR1qSiVopQ0VWJMyyTXk/k777QF+seuKlK9yc7hZFmIyB/PlWVL749Oy1PSrkrgkjKFUvx4c1ZJO8iYGjNppWUuvRuryxBIDU3ynDBotR+73slBx9qo9Huo7Nly28i98MjlY+LyE4WrPNP6R0KYEA75Wde1ODk5Qtc1MOhcP9tNZoDGen2C2awGEdfd4MmTJzg6eor33v8RvvsXf46vf/3ruHb1Kh4+fABjgLq2l4vMFwscHBxgPl+AyOa7ctrxW7/wBl597VV88MEH+IM/+AN87dbX8K//8i/jhz/8IZQCmmaDBw8eoNmc4LXXXsU777yDp0+f4oMPPnCXm7gLNjqN+XyO119/HTdv3sT777+Pe/fuxZ7/jPHtw5aDtm39ZreKz4FTDXYm24mxbi0MGiBjhVU3/o0xqIg3tllBVnc8j+15AK2dmmCsHYWvuE0tacZYB0YKcBs5Cdp0kMNkCNBOQ30hZJi2FYRPC35jgmc6rtOyM09OBZ1o7g0pDIVyDJUxzZ9JLmPx5UylsFPozHtE61XIc9L++8mDQ4BgjqYM4JLUJ82A/JnbJFapqjhZ5MBSiflNhkkZcw7IthFK8gBH0diW6RbbD5mR+f9T96ZPchznnfAvM+vsY3oOAIODF0iQlJZS2OtDshySLHEjHOGVHd795Ih3/6Z3P/hfkBzhb7ve9a51vTJD1MXXEkkRJAhRAEmQIK4ZzNFnnZn74cnMyqqu6m5QWgWUQXBmurOysrIyn99zPy1zWnewP+2B6XrGLmZgaf071nwT7r9rbqs+s++MPqzfj6ka88CYToAjm9Kj9mQ2a2uBpf29uoymCe9inEHOddY67XQopURRlpCSnL3C0IeCRJLOkeUZbt++ja2tLVzYP4/FYoHFYoE8yxHHMeJeHwMAbDi0ErvU/3Z2trG7u4PbH3+Ef/iHb0FKiS9+8Ys4ODiwUv3Bg/tI5nO8+JkX8IUv/CmOj49x+/Zt8lTnHjyPHOOKosCFCxfw/PPP4+iIipMURbFE5F0iLqVEKUsIzgHFUEoFAV4zEVRMUVWQRCljc4BdE8kUPAh9prmlAUZrUeQ5OeoZ4q3IOZQzbr34zZozxsA8r5q7pvJtdO5RiH3XeVnFqK9TD3f1a5NkH5Uh2PTebt/mvVZK1i3r8Sjask2FDrOf3DO6aqzfmaT9u2ptD70OqBmD49wDS4yFw2m15SLeZC7u781/nud1JzVxnNDansGOA2fuHfd1D527SZvA1Qboq56rOgAAjCFGVbHZWs5Yu07N+3c986O0JrOyrt+m49V/rxzxuvu0z2ndfTqJA2NayqPvTV7vZl1w5bwHV1pzbZ+OIqqTOQQoXtukK/WEgCcEhYX5HpSis1EWBdl/laQseVAQgmGxmGM+n+GpJ5/EpUuXEEWRljw5er0ezu2fA+c+wiisvNHzHEqVyLIUN278Gm+99UtMxqd44YUr+Oijj3BycgKlFG7fvo35bI4//uM/xte+/he4d+8ubn34IR4eHML3fPh+gLKkzGi+7+OFF15Av9/Hz3/+c5ycnNj4bXO23fMnhEAQBDRfKWtaCwC21KdZQVMCVHNVgD13hnboDGMBh+/7tfztvhDIkgSz2Qy5rlRmTWXQ/i0a5M21xnGuMqdVqvlHbesEk5XMd8t+/U0k50c5q+6926Torn7rhIrmPNp+34TRaM6hSd9Ma0aXVOZGM05dU7yJqfexB+0aF6IdcNZt3toCOlK1hh7iXM2YLarE5u+bcKJtG8YlqK460gC3O9/mvd25t63HOmn1UUCk7bloPrRilBiiXh1J77bW1hoPv2Ium0rN64Bzk7HXEY7qfr9d6b+r3/LvjlpNdaRRVcuCgnRdmloIVtdzl2VJkmBeIE8zKM+D7/uAIs9mm8VLp9osigK+7yEIAmRZCsaA569cwZUrV3DmzBlwxpEmCYbDIba3tzGZTDGdzTGZTJCmKZJkjrIosJjNMV+Q1/n29jY++eQTlDo16u3bt8EU8JWvfAVf/epXkSYLXHv7bdy7cxdQwKA/gAIwnU4huMDlZ57DxYtP4OrVq/j4449tdbJmulxzDuM4RhRFCIIAnvAgdcWzXNu4C80M0B6v+3eYdVYKOnVqCZM9sCxLgDEyCwQBGGModarVyWSCLEutfdp9PxzESJhKap5H62vGAUTtfbv0bRPpcJVwsOq6Tdsm53oTgcHt23bu153dTe/BWCWw/TaZkFWMh/1sqV/DqZS1W8jc9tiDdjfX4RIp9/MWr239OxTAlILiWp6x3M6ys8ASYBuVr8MZNTd9299N0Lbfof3AmL765p0boTlek9Nsm1PbOPa5zf9VtalrDm86prU+fuvQMCEt9c/qzRCvrrbK7NF8xub7a1uLtnG67kG//+YagXXXt82vSQw63x9o/lJRkhzJuhk6d2x3vYwk6mvJEIxCyaSqclNzRk5jjJHkX8ocjFOc9WKxwPZohHPnzmFri7IYF0WO4WCAra0tnJ6e4uDgAJPJFPMkIbt5UQCKJPxMq8GTJMHpyQlKKfHw4RG2hiP8x//8V3jmmWcwHo/x4x//CB/d+ghhGGIw2EIQBEh1RreLFy/hD//wD3F6eoqbN99fOnfGRGWeWSplpdqzZ88gjnuYT2eYTqcUA64k0iRDmueQRd6IcVfghollxk7ugXNACE5Od5wjiiJcvHgR/X4fp8fHUEphvlggOcktE1AbF8ZmXtg5m1rlJsOb5wk0GclKCwa0cdCtTHzTdLWJ8M4cJ942RGGshUV/tLZOC7fu7HZpDdrA1R1jmU7UzYHtbbUDcOdVHXS6bV6r2u8BaC83A8SWJWGuKrMurdZAidH/qg2MWl97T6OS0VmkJOTyRBSWimK0AXetmpJRizvfA6gczbQKwMClO76Zl/u3O9/mc7hMR1PKbzyG/c2lAUxPjHgdUgEub7T2jecqhNxlY9iMRphn6WpdWoVHGXf1GKrTLt92bdccXCJk3gdF2GumpuW9oawKRnDGtela2U2iVKnBlfaHLCUBbaO2MmMMSipQznjNOAoOIbiVQDnnyDT4ScbAPIG8KMCVRGFjLIAyK1FmJfKUYrBlUcJjDHmSgoNByhLj8Ql837d5wCfTKU5PTzGfz1HKEnmW6nKaBZSSyIsMsiwg8wLJbI75ZIqiKPDFP/1T/O1/+lsMBgNcvfo2vvfd7+HmjV9jb3cXg8EAUufA9wFsb2/jueefA+fAm2++TnZiXtmHpaS0YwrkVCY42ZkZ59jeHmFrOEBR5OhFHoToI+4FmC8SMMHAMwFVesjzDEXJqUCKlbIVipJqwoe+byVl3/fhBz76gwFGoxGCIEIU9TBbpPjwo9uVbdOcb5hzVu1JYwOtQu6ICSDmgM5xlmeAqswhDICSOkLFGK0cX4jmfuQtijAFWH8IPZnaHkXLXrZ71vRt/G6erYtuNb834N9FI1xa3iaYmTVcK6oC2v8DTvIUw6jXzY2tIzl0WUEzzsCSKXPtHBo0uvl7V3usQbtG8JtSgyIwoRcI1HdhM+5ZLymrb54uYm8OjvH0Yw1nEAYG1VFxqQu4zQPxxr3bZlDj+1aA0yqprAtUlp+5yrqOjsPldG1w1esPh0uciJh0P3dzvpvYlNaB5fJY6zQ3loNqnY8B7K7EJqueh5G4CkDvA8YaDAADODkfKqUAxinrplIAk1Y6LooCZSn1z9KqdPXCVPcDgxAePJ/s1AICgKhpI/I8J3Ws76Gnc4P7HoVo5WlmJcM8y1CkOYosQ5okSNMEZZHD9zx4QkDpECopJRIkyNKUEqKUJQByGJOyJOAuSiitfk6SOQ4PD3D+/Hn85V/+Jb74Z3+GIIrw6qs/xPe//z289+tfYdDrYzgcks3XD8GFQJIkuHDhAi5euIhfvvVLHB8fIwxDAKjZsYmG05qkaYrZbIaLFy5gd3cXnu9BqRISAiHn4IKjKCUkgCAEiiyFl3t2nckZTTvxlSWUUwfbAGypAXexSOD7ISaTCW7duoXT09PlPeX8bO535WgEPG2yUIoSyORZXlU+Y6yWt8GGcbrSIFumEXYqBmsb2sN1p6V2xlxBoXH22syNKxleA9wrpNFVtMNlgta1TShR6xyWFqWbBpnfu0x8n0YAeaxBmzaz/t15GIqDVIAkNRXjhsEzQG1CPQwXZkDcLFx1h2pcU1ABNi2iVOvrKZu2iZ3dHE7T3xBWe3D0GK63YfPZ28bt2uCbXK9ZENi1sgyQ4QKdZ2xy5xuIzfbwO8/TdpCXrlsDiPXvXaJk1hYwFZSspMqqvqZf7UJnvFXr2bz/RlI3NO1kmgF07kvVGWm/knTMwDint8Jp/0qlkGmVcp7nNmTJSI5GwjDey57w4fkeuKg7Qrqe0UIIsu8GIaIgxLDXRxAEiOMYJycnmE4mKGQJ44helgXlIs8LyCxHL4ow7PcRhwHCwEei51bmBMyceBAUeYEiy6xDmywLZIsFTsdj3PnkE5w9s4f/57/8F3zmM5/FdDrDm6+/ju9///v44IMPEIYhdnZ2EIYhoihGGPeQ5zlGoxGefvppvHv9XVy/fh1xHIMxZs+ODfdSzCZ3OTw8xNbWFi5dvIQ4jpHnGRjjUCjtufc8DxHTxTz0egrh6ZKkpf0XOCl9laKc4RIlFBeYzWa49dHH6PUOcffuXXxy5xOdwa6iNeYdtJ0Jxjk8z0MYhQjCAH7gAwCyPMN8Mcd4PIFSEtzYwTmH7/nWec2YBGBpS50ZcKawLAw1aEabk25TEnwkW3LLZ5/Wruze/5Gvt9KeYdbravGK7q8byKzZsja29idzE+nULrcM1joMMe2xBm3ApaXGlqQXiXEwbsDG9K2rqZlRRjKmQyyqcV11cY3DdQ6UKkmS3wSwXUmsTV3tvrGK210tObt9a9c5B30deKwGu2Vu01He6zHsYMvXd3HCjEGhSk6xCtTauNBNJNj6ZwxgTpiOAW5Udvi6/NA+j9p4K+7bnK8772beeALTymSgNGC7/gGMsUo1yWEdLi14K4XFPMV8PkOeU4UraNWdUgoCgOd58LwAHhdOnnrALTHqzisIKM+473vwuECR5RCM46knn8JwMMD7H9xEmsyx0M5iFLJVWOZACI7hcADfD9CLY0hdUKQocm23JpUhh0KWJkiTBFKWKPICyXyOh4cPUcoSn33xRXzu85/D7s423r76Fh48eIC3rr6NhwcH6Pf7pAr3fURxhMFwiLJUGI1GeOqpp3Dr1i288foburZ3tfbmOSkfAqnLDw4OAAAvvfQSdnZ2kOcZOOfIFag+uJQopQFg47lfJVphWtOhCM3pHsIjDUNRaF6Mvp/PE3h+gSRNcDoe69KiQjOKEi5T3NxbjHMIT3u3xzHiXg++Tvs6Ho8xnU4xm81sDgjBOQQXVhoPwxBhGDo0cPlOldJp9bkz37m5GX4TcH2Utuo+bTTPnkvzzI0+7XQPLoGrjV9dsw5IqzVuCjXuXJsaDP2lY5JUdWZ+RXu8QZs1gbgCYfJo1gkMTD/HPsGZqL0szo1EqXt0SKEMDNIhdKbPo0jay2NaXq42pqkbXeu7Agg3kaZXAV8bgDb7rVRLNT/vOFfMFAxRqnWdm+tZMTH2g400F+7vRivSOVfU16bLxt/29zq1nunTrBFedQQgNSGgGXS+B2ubZhKckzfxfD7X3seZBQ5zued5iOMYQRCRPTlN7VwUpE2X6wKZ8U6OopCcnUqJRUqVsPq9HvqDHvr9Hra2tlCWJR4+fAimJW0OaPBR8D0Pvi+QFznyPEOSpShKiTzLIDip5mezKe7fu4c8owIhgnMM+n1cfuZp7J3Zw9mzZyE8D2/+4nWMpxOMJ1NMJmNsDYfg8znmiwWV8Oz1IBWlKv385z+Pe/fu4Sc/+QnSNEWv1yMvcOWEUzFyDsuLAtksg1IKL730Es6cOYNCllCqWossy5BlpL0oSwnfD6DKyvRgHMI4q0wXhGOUOIVzMidQ0pYCUc/HcDhEnucIggC9Xg/z+dz2Nxx8ba8wgDEOLgh8oyhGv9+35UyNap/G0WFppUSJijaYcDHjvOb7vqaJamk/Kpp+pf2TFbPbtr+b+9Tt454j92xt0ppCziatjcZtQi+aAkc1DuCax1xa2WZdNnhD8gHT9KdZa7KdtrY116ywSXu8QRvNTGLCqsFpuXSMIzfSnXkBFYECKnVp17I0N8typqLN1BZNIFCq7qCwBLAt925TmbnftY7Txkk2AKnrGdr6rAPu6jnbHSaUqhOltntZRsZdK/0OmbOJJZbXqHkNjVe94EexE3WtXdvfZk2boN/FAJjGNUNZMZCVY6Ah9taPQqutgzC0xP74+BhZlunRiDRwzhFqVXYQBCgKicVigbIoEPgBAbcwdaNh72v+eR5J5HmegzGOvCyRFRkKWSAMA5w5c0arprfBBcfB4QOk6QJlSZI0SfwFVKpw7+5dcEG5yBdJgmSRwPeE9sROILjAxYvnMdraQi+K0O/FGAwGCIMIggscn55gOhnj/r17YELA9zxEUUj2YZ1udT6fY3d3F3/x1a9hMpngF7/4BR4+fIjt7W0nOQmza+N5grQDizn6/R4+97nP4eLFi5jNZkiSBCLggPIBMMQxMT9RKSEEMTSz+RyhH6DQOdCLglT+gQ9ICessZt6jAejBYIC9M3t4+plncHR0hNl8jkWSEPOQpvZdLJ8xBjATQx6i1+sjDMlLfzwe4/T0FNPpFGVZ1jLfmZ/ESEj7zyRt4eCVZqC5542TnlJoI45t9KyrtanRmwDu7vnfhsT+KGN0AT197iqu60wOW+EURl3ahb+2Z+0S/jYV3Ex7rEGbMYp5NL9z7i0RSQZm7YGcVRmPVGOcNtDuWkCT8EC2cJGr5trsY9U1rEWytNxd1bdJ+Luk1GbbFHSa/bs20apru+blNq65UIMYy+o5pSW2lmdF/TrW+L5zbqxubFgH9O6/pjmjS7pugvcqcK995oC1AV3TpygKLBYLm9mLcY7hcAghSAI8PDxEmqbWHkrOSZ5VgUsprRQuhAffC2xyD9YwHQEETmEQIAoihF4IwQSCMEAYxcgLildO0xSjrS3EUYj5og/P4wgDsp3meQYoCcEApiRm0xmyjKT0xXyOxSJBGATo7e5ga2sXo9EWnnjiCQSBb2OWBeMQHgckhTWNhkMM+n1ivPT7EUIgCiMoxlAUBe7evYuvfe3reOmll/DNb34TN2/exPb2to2HrpKfVKBtpOitrS2cPXvWvjPjsKa02toPAi0xM8RRDM45ejMyC8xmM3L+ynNIX2dLk8xqPcx7CHW61tH2CM8+9xzOnTuH+WJBzFUYIk1TlEUBKRkgS0hWqZyVltw8z0cURZRNLo4hpcJ4PMHJyTEWi7ll6Ow+blA0BSArcohcoChySOmBcbHcr03jtsYhq62tootdUnCb2rrtjG0iKLXSn1XSrDu+21/BmrgNEG8mqK2mMetMg4+i5XTbYw3anHH4XkB/rARQQyyB6hd3G9YlvyaRro3HKoexNiJev+fyohtpyfZqk8AqlUAroe9S866S5jZV97YdoE24XwY9Z1YZGdbtL7OOsoWJah6uVhWZmVPLM9Xmbt91NzPR5HbddWjN995BPDZhpJbepbOnoJUIUkqkaWoBF3peQRACYChLiePjh5hMJjZGNwxD9PvkLFaWpZUapZQExmEAwQXAlC0WY96rSavJGcP2aBuxrlkdBAE834dkgO97SBNKQzroxYiDAFv9PgLBoYoCaZKgzHLkSYI8S3Hvk7s4PDxE3IsplemFC9h5dgdn985g/9w5DIdDbG1tQaHEyckJFlKhgCSVo5ZqozDA1tYWOGPwBIcEg6e9pqUEZLLAw4cP8bnPfQ5f+tKXcHx8jB/+8IdIkgR7e3v1tQapx4PARxxHmEwm5A3v+zg6OkQYxnZNDNj6gQ/hCasGj+MYghHQHh0d1c6FOdt5ngMc8P0AYRgi8HzEvRiDwRCXnriEJ598Eh9//DHev3kTi/kcg8HAapaSJEHplFU1ceNGwu/1etjd3QVjDCcnJzg6OtKFUer70KjqTUw9nRMFwRm4oJzlRVmAcVYxcevOd/NcqdU+M12fdwFzG43bRHDouucqtfoqqVYpZWmL7eMIGfXru5kA42NVaQmX6amrDXHn2kaHN12Hxxq0GaMc3QDIgadlQ1VEFICxb0NH1tTCsgi4N1ETS7PJeD1fcX0jLIOOrVG9dkMuv7Cu2Lzmi+/iSrs2bvOgNOe0TmquzVMpS3xWt0pGVs41NQXaGubC7dd2QGvrYO7QMkTbIWlKzM3+7v3a3kvXujb71NX30OMREzKfz21aT6FDpgCQtOwH1uGIsmRx+L6Hra0thKFvU4/OZjMwxhBFEcIwtM5JnDFdqStDGIToD3ro9fuAktgaDrF/bh+e56Hf72MwGCDJUpyenkKVlOhEFhQ/HUYhol4fvTBAqfuUeYbxyTFOjo+xmI5xaf8cLl9+Fk899TTO7+8jjmP0ez1EvT6KLEWepkiSBCgkPAZwRs8qpYQXeOjFPZIQkxRhEAJcQDHKBZ7nJZL5AgDw8ssvYzTawo9/9BPcuXMHo9GoJnVyzgHOtEd8D0kyx3w+p7SsnENKhel0at+PLdzj5P6mlK0l7VUpsZgvkKWZrX7m6VA4Iz17ngfheQi8CFEUYrg1xHA4xL1793D9+nXcvXsX/X4f/X4fSkqbLhacmDBiAqRlqjzft+Fsi8UC4/FYV1szu6dJN3R5UeIIwbVDGuccRVnWtAFuGtf6GM7InwI821oXjWn2WfX9utau5m6fR5dQUgNshVop3OqMdzAq7ues+ZnBGlkX7RQssK/TTqxqjzVo1xaa1cGa9iBJLrwFxKn8H2rcD0k5XeBQLXrNBu0Q/Vb4XcNF2uFNH4d5a+PEanthDaC2S4HLB9z93l2jVZzqyu+N5NjtJVCXkFXdqcNVey9fWb+PuVenWN9QeKwCzzqT1621WEdQmlJ7c8z2dau82YuiwHg8Qa4B2zTfJ1tyFJGUmOc5SXKBj1CrgdM0xXw2x+mYJPTt7W3EcawlzABRGGqHqhKj0Qhnz5zDaDQi7+LAw97ODgb9PpRS8H0fZVEgWSQUpiUV8iRFMl9gq9eDLzx4jIF7AoM4RpnlCHQClXNnzuKzL7yI8+fP48L58xgMhjqfAQNKicXpKZRSKMocTEp4YKB0JAx5SXnMI52q8+DwEFEUYu/MHjj3MJnPkSQElNPpBOfOn8eLL76IyWSKn/z4x/A8gTAMakxyUZY2n7iUhV1b4XvakazUaVKVzTxWMWQmjwIBIFO093MN2FmeWXA3aUaZoIQrABD4AXw/BOccDx48wMHBAW7evImTkxNcuXIFvV4P0+nUxlwXSkHJksL5TCYdEKM1GY9xqrUwpoY57bHlfUoVwLR6XTMgJqlMkefgjNn47lYmkzU0Xs7B3FRV6wy6JKmuv6TbrPeoEngl7TrjrRinRnvdiCGXQKOb7LjrVJFcMx60gNOQ5N2f7u9L5HX12j3WoNyd+moAACAASURBVA0ApSmawJqxgfSTMVRhNEqBG2DWP10PbekmGQCDsuUXleVWlVJgsuK6TOYc61lpxXjUXxyWpTo37zF9sOxNbQmHGQuwXvBSVWrOFVjsjOdy09VB30z6bx/TNRvU9hjnACvbrtLhS46E2XKYwNqkZwU3boI1r7FvpP4lY6b+8ernalPVNbUVbaC+au3MXjO7kwg+bFpRxphO1MMAxqGkwngyRprlkIpBlSbvNMfu7hlcvPgEZrMZylLZcCff8wnssoxAW9uOh8MBtre3EUUxylJiNBohiiKkaYqz5wJcOH8eO9s7CIIAJycnpH7tDyAhkWhJrsgLAqY0BdOAlmUpmOBgHkchS+TzOWLhobe7i62tLcRxjJ2dHQyGQx1yxKDKrO6mod+jYAAgISHBoSgVapGj1+th0IuQzqfI8wSXrzyHMIqhJPD662+gSFPMp2MURYY/+8IXcGH/PF555RW8e+1tDLcGCKMQVD6VmHNfePADH4oBk9kcYBxeEOpQqBCce/A9IE2zWl1wpRRKpXT8eFnbB0VGzA/9zQFweB4xGowxiIDU6oLT30VOnvY3bt7EIknwmc9+Fk8/8ySOj4+hhN7feg8Lnxgid3/leY7EJs8pyYHRORsGF410rjRzLDTz4jqhMd+HVKr2zzxXxSbAhhpyLeB04Ej3mTKve9P+jwjGv0mzPEjznk0BizEt/5lwvKpJuWquVSobZUK2atoL+kwqTROVgqitGP0z4G4YqXXr89iDNq1vGwdWPbwr4RiQtlI5HM6lheDSQsnaZ2CswQXDcqVG3Vvr7zQj8Zs0kUoqKOZwgWoZuO13zGXaWiTvhli5zJEpu14GuGtjNdZwU066TdVF6vLV160bv85ZwzJOFeFvusfQM9ULkuhn4WZ92qVt05o1ls33XZJ3E7xbgV3vO/caztnSGFJKZFmG+XzuxL6aPpw8qsMQDx8+RJomtmgE17mo8yRDUeRIkhTb2yM899xz2N7eQRCQdN3r9QDAJk3Z290DlMLp6SkWiwWSJEGWpciLDKfHJ5BliTAMCbjyAr2YqnQlSaJDiyQ8ziCzAnEcY2s4xGh7G71eD6OtLZTaRu77HjzP1+lUSzBok1IpKTxNAUz/lFJau63wPMymU0RxD/tPnUMY9fHmL17HnTt3kOUZxuMxzp3bxxe+8AWMx2P87Kc/xXQ6xdn9c6SqlmRXVArgngdAYT6dwePChlwJIRAFIYTnIc8LeEKglAJKOXH9Ujrmiarmttkv5v0YSdbzPERRZL3+Bfds+tajoyMsFgtcuXIFly8/g6PjI9z66CNMxmNbEczEYRtbMwDkeYEkzeweE0JYWkHntVEutEH3yrKEQr0mgVte1bQlE1v1zbKWq6W1nmlHyl0HyuvU5uu0f23fddmEXbq/iVatGs/5fcUcmqbSOmNQ0SPBODGGtqtJxFK/TinY97yqPeagXXGXbqsWWjkSt5Gu61Ksu2HrL4hUdUxLQDSWs2EcQt7cDF0v0gC2+d39zHC4bQBRqVjqIUTuzQzvsnozm5/dh6b5PI+kAtuwMUfSXt8PcG0GNbakhSkhuG4o5u3iYGld2wDcfN50QOu6bt3vykxVM4zNJAumX1mWWCQLlGWlnjUxxZ4n0OvFKIoCh4eH2ut5SKkxyxJZTrHQWZYhjEJ89rOfxb/7dy/h/PkLmM1muHv3bkXsQeB4eHiI6WSCRbIgSbAsAUV21DzL4Ak6/iZs0vOonOV0OsPJ6QnKcoA48BH5PoIwRBBF8HxyXDMFOzzft+r5LMsABUprWkoUUkHZzGEMZSERhzFGO9vwfR+zxQLc87G7u4twMMDNGx/gRz/+MY5OjjGZzbBIU3z5a39Bmc+uvYtr166RI55mNLgQ5uWDAUjSFEVR4MyZMxgMBjg5ObFmA8/zoSRQihKeEpCSOSU4q31h6IWbUIRzoc0UgWWkTCUxIQRkCb2+BRZJYmOr33nnGm7c/DXm8xlJU5IkN3J461l1OdUPX0B4HKUkDeByY460zbSEL3RSGGlB3I0flyZB/QbNmG5W9mljaumLJTORaY+q4fs09KjJhG/at2uebt/O6TBHhFJ1KbuJG0bQIzrhakyq4ZTWhqx7B8BjD9rMgnAX8QXKKkNl2wgWyVAj9SZbGvWBPQwAAC1luwD7qCqdSipz4r6xvCnqdvsWSbHOvLU+W5tdfV171OdqHbtz0VEBWMf49fGqF6iWvqv6GFjnDakWABR3tBaNw7PuOZrSdJdT4LrPLa/EqhzzhmkrpURhUmAGpLqk/LughCODPqQscffuXcznMwwGfYTaPm08xIuCSlfu7+/jmWeewcWLlzCdTvH+++/bFJzm2ZMkgdIE3cQUA5SxzBMCjHNwTwCM6fAokiKLokCaJphOpwh8Hx5nlIucMRQFJfkIdIhUGFJ61TQvyGokFRg4pK7iSjWxJBQYcqngRxG2t0fwgwBJsgD3PAx6feR5gbvvf4j/+T//Bx4cHiAIAhyfnOLs2XP46l98DUVR4tVXX8X9+/ext7cHoVO8SikBRczPYrHAdD6DlNKumYmdLooCnFf2aIBs7WgAiiuZcs71PqZKXmEYIo5j+75dxzQGYniOjqeYjMeYLxa4d++eZb6CkPwASJtKoV1x3EMURbokaFVIxRU6XA0NSdBVMikopTPBGcDVG0//VAok0Mnuqnf1M2HY4fXScONiKOkWhq2uaYvd7r4/tU8jUKyjY11n3r1fF2PePWglLBsn6ZUCFajUrdVKOP3JXENam6IsIWWb2bFqjzVo0wauEp0sq0FWO1XVX2Qlw1EBeuJKK6m84TUsq0QUzbq8m3BD1Ryqu9c4UcMfGGca157kStnMGaS2Nptvsjbg6lIxrbu2/nnHdyTyts5zWYVUmTCUoTRO+lnXQsSq0WtjM1B5Q/NF19oY4rVUmN7ZX5swP22cvX2HqhE/2+grhIAX+Fb9WuQFAJL6Dg4OkGUZ+v0eBoMB0jTFdDrVCVDIUcn3fZw7dx55XuKtt97CycmJBScj/aVOVjSTJYtpbYTxLob+ngkOph2sGGco8hwpI+92ypgmEIUhCiWRS4kSDElekENaKYGsQCnNmaIxS8UILPRbK8DghQGGW1sIwgBJmkIJD/FwiNl8jpvvf4DX/u3fcO/+fWxv7+D+gwMs0hRf+vKXcfnys/j1r36Fa9euUf7xXg+uGUlKhcVigdPTU5yOxxhuDZEkifUMV0rpMpcUOkp+AgTcAMClslXS3Jz/jDFKTAJY0Dbx3cbzvt/vaylZ4ujoCO+//z7uP3hASW50la4gCKgSm049G0URRqMRtra2LHORpimKorSSv6VlOhLA9XQHFLIstXnnrfNU87wpk2yltGr8erKpdqnZnkXn82XfE1a7pik2tknXn8aPppuW1/s3f99U4l7XbxUdqJkvVaOvVhwaFx2SriuGysUtQhMKz8u0A+k6ZuexBm0AVopm9n+1b1FfgI4xHEnWEugV6+ISbqPGbHvJzc/cA2f+hlLkuMaNl2cFaJoroXfcun8U/bdC+lt6RqzevF2btev5as/SvM/KGbXPqWJ8SsuU1GzRyqy/87wMlZpP1cvYVdcuS+nrpO6uubkgvorzd/s3Ve4uA+AewlITUePhzfQzzedTcC7AucDu7i7OnDmDO3fuoCgKAFWMsEnU8cknn9jvTP1lI2UCJqSJymYypiwAMCbsvIIggK9DyrgQlB+bc2R5hslkBs/3AAZ4vg8vCBCECoWW3kulIBmD5ByFUhD6eWUJcMEAwVHKklS0PhW/UJ6PWZpDgiMe9CGCEPc/vIVXf/Qj3L5zB08/cxkPT45xeHSEi09cwl//9TegihI//elPcXB4iLP75+AHVZaysiyRpRlOTsYUU81AcdaC1NkmYQ0xO2XlXV1KHUpH6uW8LGw9a/P+POFBcE/Hv4e6prWHXq+HMAyxu7uL4XCIDz74ANevX8frb7yB8XjsgGv9zHDOEUcRtre3MRqNkOc5Tk9PkWVZVblNltZOL7W6gguyf/f7fSRJgtlsRnunKKxKu+LtVUVzuLAaHncvdpl+GLRZx8zZHCqn3ypGnxla1kJbNrFTt7UmLV3FjLeNv+6+Xcx3rc8auts2R1ZxPyBQrhwA6UwSPSA/hEoTJsvy9x+0laKH5C2x2qaZCl5LYIlKorWW0JrEXsVgM1Zt+DZCrxijMngNrpG0Xcx+br6TUlI4iGw4rfFlr2X7XfNvOFJ6K+As21vWjWnmt24Tt33eygG3ceusLoV3Pa9SDGjY3o20at6V/RwgpkfBcdhzQujMZy2A3XX/Vc/YRRyaIN12fbOvWx85yzIkiwRZnhOxlRKckdanLIlgi5BAgnNOiTi097I5yEbac+stm31spHeSpg3l0BKbEATaet045xqwBYTgZLP2fSgdnwzO8fD4BPNFgqIgCZALD+AeIDz4cQ/CDwCTOdCqnoHCSK1CQEInduECaUFVuuM4ht/r4eHhQ/x///oKbr7/Af74T/4EM11IZLaY4W+/+p9w4cJFvP3WW/jF66+jPxwgimMrMRoP6+lsiulsgiDwsb27q4ugVBWvmvngdSFLeFxAokqykhcF4BEDFHi+zjwX2AQqVBilh/MX9ilhjFJ499138b3vfQ+/eu89TCYTnD171r4Lox0xGR1930e/RwVQxuMx5vO5fb9WGpVSR4xUTrRGMjf550362EolXt+Ddv/aMauET11MuQEU0rUva4lW0gvnvLhM86Pastvm9WmbO4dNz79pTQBvu0phGYcaE3CYH1bJHKqi6RaoFanDi6JAUZYE8av5hMcbtAkAHGchzb00VaxNdXUFKvQ/pe1AtQ3Eqr6ux16Ty2lKb60vy3KrtWnVpLWuDdDWrKMVa9tsFSAqY1SB2SernUFa79UB7G3fLfddpbJallrrfQCgffy670FdijbraPuwRseOua46tOtAeml+zjOt5Ob14XVB21ToIq67qm1t1KBGaj48PMR8PreAbcDKSHxG9etKdlXOaXJuk9LsO4Iqzqo8/m7MsR9QGU8/CFCkKY5OTjBLFhgMBlikqQ5XE1CKIy9KlFAI4xiiIGc0SopC4C2VRAmFQhYQqMqByrIkp7VeD2Ec4+jhQ3znO9/B2++8gxdeeAHb29t47733cHR0hAsXLuDLX/4yJuMx/u21/x/HxyfY3tm2y2rWzEjHJvGMH4TIspTylpcloijSa0Pvi5gaDmty03HZQngAGEIRWWczCqMi80Iv7qPX6+PMmTM4c2YP9+7fxbe//W28+uqrODk5Qa/fx9mzZ9Hv923iG6WUZRyoApsHWSpMJzNdc7sqrVqWJUnZ+vmkKgGm4HuUW342m1n7uBAmWoL2VpsaGw4DKR2v81UgpoxTLzN/owbIXc2e7Y6z0hSENmlN4O9iNro0hu593c/cpkfWQoBDK7V20yGzG82X1N/S0qclhkpVeRuVgtUCSSmRF2ktjz0Xq1H7sQbtpjS5LAkpq05tSyHnUvxNNk5TmqwVDmHLnK1pShNhO1lnsz3SZm3+3Ig7rK5iDDbUyD0sbRJk60iPwOHSunRnceva8fYequ6tagGZMZj4W9tfG4cq5qeFAeLL92vXUHTPaVkbUK1dpx2wcY/m+7aaF626Ju2RgJSO57JzHQdDlqTI8pxsoVpKsrWeNWib+xpJzgC43qoAqvAlM0+znw1Y26ISnMMPfPT7PUzLEgeHhyQNByG4EJhMp1CKQsHOpHvItcS8XVCsNvd9MO6R6t/aUSUVjmKMPNOFQBTHCMIIt259hO9+5zu4cePXeP755/HSSy/hrV/+Eqenp2Cc4Rvf+I/Y3d3B1Tffwo1f36Ca3doje6Hzefu+r7OFAb0eVSQ7HY9RFAXmc4HRaITz58/r/O0P7RrQ+pv649DATEU6jJQeBIHt7/shdrZ3sLe3hzRN8YMf/AD/9D/+Oz788EMEQUBgPRggiiIAwGw2s4BtxjHvwdRBl1JCobRMhyHecBhvIQTCKMBsNsV0OtOSO5znqGhMk9FkqPas+33XHrYq9U/TjFTZAtx2Pg065N53ldDQNtYmn23ajNZu6cNWYWn9aBVtq8/PfRelVPadl9osI0u61uNcJ8n5vQZtWK4YMNYBoCZpsmUiaa9FFTtovrO2YdvNqGM1YXPAmetFZFJWkjNNaul+hvCaPtKqpdy7mGfq4gCZBf8mt7a0tyqmutGrhTkxTIU+WG2cYG2UVVK65oVWOeMZ4uhOjRvGp8ngoJKaa7Zt5r5p1KQH3liNam1dDq8+tu3ZKhC3O7+476mNwLSBvPt7RZRLFIVEkZe2MIW758w/o6o19i3Xi9SoyQ0YLJlwlIIhHGZct48BaDOGJzxbg9kPqBTk1tYIH936CItkAT8IyBYc+MjyArPFgvKlZylOphMozhH1eugPh7TfAXBPIPRC2h8lZeWSSiHwfUrE4nm4du0avvPt7+Lg4QHOnD2Ly5cv41fXr+Po4REY57jy3HP4/Oc/j5OTY9z++GMACntnziBJE0x1LvELFy8iDEMkCcWy7587h7wokKYpmF6r8/v7ePHFF3H79m0cHR0TOAuP8EX7FXieB+5RnvMwimy2N8p7TqVHR6NtxHEPN27cwH/77/8N165dQ5LMMRqNMBxS2lKTRtYAshnDOLDmeQ4lFcpCaj8EBQVZgbXZY6j8IjzPw2JBdcjLUup3u0Yta3d5i2/NI7bmGXXHqWmcsJqW2PEaZ6n52ap5/raEjaaGtvlZkwFnpMZdvl/jnsbcunQP1LVCSinkRUllao3zo8EkButbsu55HmvQdqUDMFK9GQCy3As4ZM332jkAgF10Mxbgcnj6wABWejPSo/F99RgjgqR/WuBhZMtu27TGHlVKQIFBgoJfFHRFMifjmWm8eUAa760y3Zp5Os+qCTbgeik662ie2ewt/uiHjbIFOeo3AEB7aAKzUozDZWuPZcNtcMYr7YgD2ssMjbTq467D3QTsOgtQ72kdd2oE0BBFbj+vtAUOgWrcv0uqJnVnFe8rywKyTMFYCagCstQhRkJAcA7OBDjz4AkqklEUEmma6eWqDnwQBAh8H1EYIstzu5/dUp/LjEVltzWSOdfJQLjw4fkhfN+D73mYzmeYzGcolEKhJBZZCi8MKDFJWUJlGeZZhkVR4Kmnnobn+wBjEIGPMKb6zcL3IHVoWJ6lYIwh6MVIixxX33gdP/vZz3B4fIit7S288MILSJIEDw4P4fdjYDHD/vnzyNMMD+7dx7VfXUOGEpOTUyRJgnNn9xH1Yjz73HM4PT3Fe++9h6cuPYEoCnHz5g2UaQouPGwPhrh08QJkWWByOgZTgO8wO0Wh4Ace/IDytftaJU7e3pHtN+jFyNIUP/3pj/Av3/42bty4gX6/b8uWMs7BBKyEnmUZGOheQtvdpVvGs8z1+6w8u92CH0wxCwh5ntuc55xzMFkHzTbp1bx7sotDZ4qs08VOh1bGWhna5W7LDHObhP27aKvAreu7as1gJeraujYkpfZRGARzIooYqzJ3clMIpjJLGP8LcjJDLVpBylL7YAjtiMrXOh0/1qANoOaJyfQq1heZWYB1Wxc31/zd/M1hQoxa1OxuPyNtO4C9ass2D5oBAwMczixWqn/sfAAonVrPdbJpu8b+btXKsB6iqjluy5rUQapVRG1/aFa/3tybOdmaaODl+9Xfl9GCdM/NDrWCY671Y5Vz4JJasfa3TUzaPo4D3K4K3Hh/lvpAGy6apCeqe20JMSMTg5k5SWFSe0dLsltqvsjYoYmx4BaAjQe0G67kNs6rOHKbN5sJK2WT3VUgTXMAqc1Y5nqig1HOc1OAgkqHUmELdXqCUkmMx2MwxrRav3KSi+PYhkNdvXoVk8kEg8EAg8EARVHgvffeQxRFyMrCZgn78MMP8cYbb+Ddd6+jLCUOHzzAl/7sS/jMZz+LQpbY29vDG2+8gcFggGeevYy33vwlFosEANCLY+xfOA+pFD7+6GMq0uFxCF8AnIErhiAMITxhi7MEuviHKQRiEp+8ffWXeOWVV3D16lUsFgtsb2+j3+9bJogzVCmN9R6KoogcDTU4l2WVkUwBNoGGIfKGcTcCg0KVH70Gyq2alfp+NJpE874Ns9esPNjVVp0p9/t1Gqe2a9fd81Fs313zbJPmm9fVJGQ0rtNEeVMWpMk8NVuNidcRAib5jdJJjoSuaOdqwn6vJe1mozNCEhFUlb0IoBAu8xKajEpzY5iFdiUU833zOlc9785jXathk91UXIOBEZMrlZdJS0y3csDDUeOb7dS0W2+sHnKl8+pTVDmR3Sc0QM1gMqxVKnk9j877shpTYLhR99r6U5oP3AOle7DlLpZT1j1dVfzKtWDtB355fzjvqNHPBWtjjzKgqczEFYNgQmfsAoQApJAQoqhpapQyCUmAEiSdM1SOZYILSCFrc1wkC8zmVN3LhB8lSQLGWM2GTYSb3qshBmS/pn8GIE3MNhhDkqQoS2nVuq5ns6nj7Xk+hOB4eER24iAIcPfePUdyINB3Q6qSJMH9+/cxmUys6pgyhr2DZLGg8CwlEYYh7t27h2vXruGNN95EmmYAgBeuPI+/+Zu/gQJwfHqCH/7wh2CM4etf/zp+/m8/x8HBARjjCIIQ5/bP4czZs1QFbT4DE1W8NgAI34PgtK+seUATTQqtGgBg+N//+3/hO9/+X3j48Ai9fh+7u7vWf8A0U1LTrBXjHMLzwCzgVnsHUDbRjZlL6fyuGIMQlDuilJQIx4YH6bEoD3al/THn1NCMLma2TTO0KUD+32jrGO5PqyZvG69rDB2IVfU1kvdGd1ieq/ndvbcxjxnANoVqgIoJN06KbqTD7z1oN9OQckXShmQSjCmHm3RSEHIi7m45OrMQhrA1F0Zq4GwSZuPVuwQ2HZurSdTrB8aAoKMQZgCYqnI0N7ZNm4agi7NrbW0b2OUmW1KeWmIDx06qGpy26jpEjCREk7fdAWysmXPreEwtfU8qOed+rHpMZfq53LPD8FStAvumjbzZmtK0BWmpAJNnW68Hd/aXEMKGZklJ3tOcc5Ss8rVQiqR/KUtwxiE41wAAWwvZeIWnaYqDgwNbwSvWIVDGPmvAiTG3hnIlfXHtEe37gf2bJG+y2CRJivl8ocNPCvu97/uIoghxHNla3kdHD8EAxHGPnk8zRCY7mXl2NybdtfNnWYbpdIo4iqAYxUX3ej2Mx2N88MGHJHUqCp368pe/jEuXLuHar67jlVdegRAe/uqvvoFr197Gh7c+BBhV2grjGDt7e+j3+wBj8PwAoiidM2/2BrSmoiKYvu9jZ2cHSZLgm9/8Fl7511egWImdvR1EUQzOiAERet3Iy5xAPC8KKzEbn4Msy/Qaw2peFGeQhlFzCLzneZoBpixnUpUwRUHM3qa1NfvRLUSk7LMZEw9JcYBSVWSMu4ebWq2utjGN+S21VXStKeWvYzhWaQmWrl011Jr5VKBf17yZPW/8HOraNbbkCOq+k99z0NZJUOyDkNSnmmDo/FNKUYU9TmpkUjvp67nSG55bKQCoQKipZrGcU0PCtPfF8iZwD5NSy3Vzll6Icr9tPH2LdOr+7drom9/Zz5jLJFS3JDsz/bWJuos3gZq14n11PTOe/8tq700OlHuf5mHuWm9zgXu/KvWEdtBymUDTv/HMRu/gArWr6upi6lxptznfQDt22euMqUCXk6P3UcVjC8FtiBY5RtE8JtoZC4BV5xqO3cyrUqWbPAfckbINUFdA7gnyWF0sFkjTFFwIeJxMRUIIRFGEwYAqinmewL1793B6eoo4jhGEAZTSWgX9yO65MuBtCJUxH1AlMwLUqN/DaDSifOSzBeK4B2gpaH9/H88++yx+9d57eO2113DlyvP4kz/+U1y9ehWv/+INpGmKXn8AphR6vZhykwcBpEKtjjS9w8p3weQQ9zwBTwhsb2+jLEv8w7e+hVf+9QcQwsPW9pb2AWAQXDusads3vUddWIQV9vnCMLSMidlNhoYwVTGISpGHuaFbjIEYmCjE6fQUeV7YPU1mMV7RIzTPBLN93cyN7tk2+3OdvbStLZ3J38K1rmTadbbdvqta1/VNGu3+RG1eFY3fqDk0yWilDHdlaIRrx3a1VeZMGAm7SeM3WePHHLQphrLuTEGEWOlDqBQlMnEXB6BEmJaMM2bjGjlXYMwc4MZGApYkSMMUcMY63K7am5GkKhCtCH89w5oLNmYW9R3UBXJdnGn9voZ5cOdGtUdNhSR3THcMd3xmQM/p10oAGCpmAFVYWPO6tsPcBHejxNrsmauna9NOME000fKdGdf8lEpBogq1MiBZ218GqMHBRaXaqpVSVRTeVcoCTDELoNW6LXv5lrLUEnMFuO4zG9uyCU0qdaUuygde31ucC63OFo4KrnqPQnBdmzoEZwxFURDQgdm4YWOfHQ4H2NnZxnw+JyczXe9ZSQXFTaKYKu7crJl5LjOHTJcXnUwmFMrV62FHl/ycTKZkJ9fXp2mKwWCA+/fv4/6DB/j617+OP/zDf49fvvkWXnvtNczncwwGQ3iCPMO3dQWyc/v7GI/HmM3mpNnQczF7yoCrUYvv7e1BAfiHb30L3/ve9xDHMba3twFelUcN/ABhGCPwfeskZl60S8ANk5Wm6TJDrxSgI1H8IACUolrmZYkLF85j/9xZKsZS5rh9+zbG4zF8XxN6xmsMpGmUt7y0JjP3+yYQuJrH/9ttFXP+22AC2u5j6EdTTd02RsXuaK3cI0ylJgjqZt6NG8LnngGzP4yEXTHWj26meKxBmzFAeMYe5UiukoBHqhKlLGBieInDNzFxdSIvhAB4pR5SXMf7qgZooF672x4C5RB+rZ/tCnsy47gq8rbNxlh9AzPLhQNN4DYTYKgD5aoD0KoZ4MrO31XHNMGwCaCV5Orcuy02GhqU7d+kQnbn0wbA7Qe46RzWdbKMNO0+O93XMGIGzKta4dHJjwAAIABJREFU387bY8yaVyjcSoKKMxgJXcBEGlgnJMdk4gKxu576IQHGKTc6FDxPoChchzxpGRuS3LVtRz+Tm5zDSGeGGBiO3hTFMLZiM49KRe6q40zRCWaJh+/7yDMqCxlFkXaYIuIzm82wsz2yY5+cnJBXc1lCKaAoSlAVSe0IJagMIdPzBmALbRwcHGCxWGA+nxMw7uygN+iDMYYkSXB6eorZbGafDaAY7F6/j7/+m7/GE088gRs3b+BfX/kBxuNT9PoxqaGFQNSLUUqJ/f19DAYDHB+fWht0lmUIggCMMcRxjF6vZ0Oy9vb2EAQhvvnNb+G73/0uer0ednZ2wBiDVDnCIKjFxhvANgyOu3+NKcOsLZ3/shZrL6VEHEUYDoY41lXItkcjXLp4Ac9evgwuBD6+d8c6vZE2gMPTkr57PyklaUb0Wk+nUzx48ABjXQbUlaybINME0E/bmjTmNwHkrusMnWgCXJOutgF4s+8SSLLla9fNp+3+rmTt5oU3e8E4nDVphzuRTZfsMQdtpolVZQ+ToHSitc1rJCMd/AVor0wDjAw6r6+sCLeuuOOGWZjxBHOC4fVBa3K4rjzcvtHq6lX6rLI1Se1sUr/WVRk11oKbu1Y33oRLM5vXMDRtErXbr1313A6wqzZ07TvVJkV39G183ny89mc24y5/ajQENR0Mo3dAa01aF/LypaQgSlF6Uc6ZBVLGBBhXNfW3+685R1drwwAUjMHzPQShj7zIUeSuJEpaH1sZDLqsImAPvAlJMtLhcDi0qjmjirXhJtrz2wCNKSZiCIYpjmMIiud5KEzazSAAY4BUQlcXo7N3dHSEw8NDnJ6e4uHDI0S+jyIvHHDSUr5mNEykgEk5enBwQHWys8wCY6Bjm0tdrer0dIy8KJAXBabTKaIowssvv4wv/tkX0e/38c477+D69etIkgVKSUTS2NsBcorbGo2QJKmVeM25FUIgjmIM+wP0hwNdHjNGEAT453/+Z/zLv/wLoijCxYsXrTag14s0gHPNqBQoiiq0BzDq8Sp7Wq5D8TyPwuhII5ghSwvIssBwOML+uXOYTqfI0hSD4RCjnRGKssSRLv4ynU7R7/chpbQqeYbKN8GV0AyjBQAPHjyw2diM93lFe5zQst+BpP2bgrc7RvP3traKFro0sBW4V0+i9SOrwdRrnee5BW732d1ERlYb52goqauTi6RDk+i2xxq0AabT9pFdTLlICadeNpckAXO2JHSRkGVsyyZtHbQdURPLBiNQyrrdsvUf6vdxGy18PQzIeA6a8nqAQ/hh1Jl11XC1DHVmYVOWzN0AJP3K1kvbOPAuznwTydcF2y6g71KRL3HKDuKu0iYoVS6DJ6qlM2thnYJU3bnMHY+hsv26hI5zZvMCNzUU7u9KKasPoedhtohF5VE6t3WYdU+Q9+oycyOEQK/XswBsykQyRqFYNlGIAyQ285Ym6jWnM94ugZm1F8IDB8PW1hZGoxGCILD5sufzBRbzBYItD5PJxHqhm39hGELlwHQ2Q6al99PTU6vu3dnZsSFjJJkolCVV5co181Fo4P6jP/oj/Pmf/znKssDVq2/h9u1PkCQJ5vO5rZW9u7uLQJf6HA6G8ISP6WQG3/dtBS3P8xCFEfq9HuI4xnA4xM7ODjjn+Md//Ed861vfwpNPPo3PfOYzuHv3Lu7cuYMwCHSOcYqZr7Qbsva+zXoJXZtcKWWleDj0gikg3h7g/PkLUAo4uv0xvMBHf9AnbSIDTidjDf6+9dK3ew+wDFSuTRbmO+PnUJYl9vf3dXKaE1y7ds2G6bl+F+s1XMtncdPW7Ns2xqPcc5VGwP1uFdjV7fyP9jxd0G4EOkPbXYezJkNszqbL5NP5axdK1rXHGrRp/mR7k0pX59V1gbU8AnAFJivbXye3BcBkF5E1EOTWM9rdBFJKKy001SmsqV41TVW2bIPosqwyHylJ6lFZlmCM2wIiNkZc1UN13LmbbElGdW7A28B7bdMqZR4YXTbe7jVfD9bVd12D1EGXpE7WyuRQH1jGpRqzygtsNCGGAatfa76vq+CVUuCKVTtFSUCC8mJrKcS+5wZRowPnVyFUmrPmolJhrWIg7CI4nr0eBOD5UIFEHuTIkgxZkdfXGpUVnzjz6oBzrR71fc9WfTKq8uFwaPNeuxy/Ac1Aq3gDLUWbcaGlYqEL8hhmRsoSnifQ6/corCyKMJ/NMJ1OyU7MOIq8wP3793F0dKzrcVfEKUlTzJMFGCN1slHXBjoGWmhPcSEE8pyAKAxDCM/DeHxqw8ZefPFFFEWBO3fu4969e8iyDMfHx7hz5w4YY9jb24Xn+UjThObb62N8egruCQtmxgHNEwL9fl871O1ge3sbr776Kv7pn/4JV65cwd/93d/h3Xev4513jiDLEsOdXfgeaUVsuLxl6smLXNo9VCLPM3BG/hAWtPVbVQroD/oYDCmH+WQygef7GAwGiOMYYRQg7vVsdAG0Jo5Mf7SvuGYagapYjFJk087zAowB/f4QzzzzNJ544glcv34dt259BKUk4jiumUp+V82lSb8pA7Dquk3G7GIGVl6z4hs3jKsoCl1iF1XCJEFn1rMStq6yp7MhtmbP0iRynRbgsQZtA1BSSlIPQUGxEkqRZ2Xbsi9JdqgWQmnC7jU4ZfdaqRRKpnTWMgXFQEp3BvpM6qxareta2VAVUXoCbQVygFM5OezUQnDIwY2Ic1kDDjMnIQQdZEUQRJryunRqpVIYxoEenLK51aXamjToXNe8bxuXa9fNFWOXXlx9XDAGGPyzY6mK+dGaC8YNsLtMi4ltB62ne/jMWtEn9vbWj4DpAhalRJWFqpKqXaB234dR79rpN8ZvrkmzVXvPMFEAUxw+42C+QBECWVCiLOaN9yIAW9RDONw4OfQZ04pSwHA4pPzgvo/RaIQ0TZEkiQVqo+GZz+c2Z7lxPGPMJ76OQccFS+TaRmueOAgi6+zm+T6CKEIv7oErZotiTCYz7RGvEASVh/t8sYAEMQumVGZsGYAYe2fO4plnnoEsS4zHY81Y+JhMTlEWOfIsw0DHRpPT2gxSAkmS4NatW5BS4tKlS+Ac+nkltra2EfV8JNkCfX+ANE2gVIkso1SgcRxjd3eX0o9ubeH69ffw93//95BS4hvf+AaklLh58wYYA86eO4eLly7BDwSOj48xnU5tJT9pVM9C6BAuhTxPwJmEkiH8ILSaDvKop/1LTKCPQsdzb21tIY5jRFGk/5Hd39eV1opCAYpDqirMDDAhfQJKSRRFjjwnSVpKiSDwEMcRJpMxptMJzpzZg4mWaZOym3u2jR5uss83Uematu7+S9qyFZJ21zzanmOTOdT6dHosUchelhnAziFlqc1CAoKLWjEec6bqKvGG5rS6qSMUdrfHGrRhpaLKwUyWEkTIncQqjme225rcLthy7PbSZlDabqmUtYG7Hqgrm6l6DsdJgbnetDoel1eFG9y5NgHEbC73hRsmxAX3JkdKf2tgdcKImp60xu6PxoFepeKyv9Pr6VgHWOnUApiqvrSSc1MVbu9lJGj63Z1P06ZsrjGSuqvyrswZdNCMjbWNMapA2zAEjrNIh2quqZarE4NKy2EkpVIpCMCquLMssyUc6R/AOCUHonkYmzsDQJy7UvT+dnZ2EIYhtra2MBwOcXp6alXObjatoigwmUwQhgEAqSVuqdWv5DiVZZkF9jRNrZRvbKfGZhr3+8TUQqHIUkil4AXkXMM4SLoA0PeoUpmpQ03A72EwGFh7thAC49NTAkTGcHg4xdHRkdUQDIdDmzWtLEocPTzGgwf3sLe3hwsXLuD4+BhjXSDEAB/nlPzFqI8XiwVm0xkuXLiICxcuWMeuDz/4EP/1v/6/+OSTO3j55a/jqaeewnvvvYevfOUrmM3IUe78/gXcP7hrS2jKskSW5UjTtHrvnPapkjopSikhNFNeeewD/UEPcRRbRzUAVq1vCHwVzy+1psVbolWu+pUc3EpbN9yoah8+fGilP2Njd/fmKg3RJoDXbK4ZsXk2NpGU12usNptHcz7NuWwyjj3HIDpucKXtHlmeVZkLGWztdaNlactu1jSldc2pm12g9liDtlE9uQkCKsAmQgZFnuKypAoqUFptDr3ZHdW3ktXvLjDavg5AKtRzgzdt3OaaVRygAQylAVQpiVLzFQqSQoEYsx7h7hzcn+79jWTZBBxX0obLcfIqg1oN6KFLNQKo1NnolLxNcz+Tsv3ZlVSAKXfKWFVInlW+75X06oyhnNSwCrApPjVzYZ5dw3qlQZFS5/MtlwDbZDdjDYatvsYut+7mo7cP3UqEGGAzvzX9B/RLrhL26PG4qNu6bKpQd1WY0UBU7921V3NO3tZxHGM0GmE0Gtnv3HCTQhfRIGcxio12w8KAar8bYsMYOXAZ043r+RrHEUpTTjDPkeelJlQe4DhKGa9mc22VPpWhlDk++eQ2Dg8PUTo27NlsYiXUPM+xv7+P7e1tpGmK+WKB/f19vPzy1zFP5vjud76D6XRqHeUYo3Spg8HQglqaphifjrG1NcITl55Ar9ezVcK+//3v4/33P8D29jb29/cBAM8//wJGo228+eab2NoaIY56uP/gAWWbA1DkBRXvKIoqHa8k7ZA1o+m3aJ37tPai3+uh14v1niwRBj6CMNBx2pSLmjMyA5r4fKJN9TBWFwzJj8GHlKUOk4NNwJPnOZIksQk+3HjgdVLmOprW1Taliauu3xSYTXMZ5036PdK41tbZPtdc+ygZGhJ4QW2fNyvsbfosm/R/rEEbMPjhekBDS7PVC7PSVOlIVzrIBgAE1x7DQI2wNjlZ1y7uboY2tUv7whq1rgv8EoyT5AITIys0pjGjhin1HwSmspQ1hyQrdWvwcrdfm7RNK2ZMAnVPdGNfoVSbzMXoaiy9Xub3mqTv3MvLl7UPSilSAapqTa3dmDlSvWTOgdDMluFEnbEsc9J4Ntcr1vXwZ6wSjE0CkToYLmsp3DVoSvYuoWRGS2BeLqMiMl0ctAKsKV8YRpEBoqxyDhsHluqKugRv/hnvU1KDBtZjvNfr2aQoAGXXGgwGFgAHgz6CgADZEHECO4kwBISg5CxFkduQFKkkAlHVgjY25zzLkGe5lW49jxiAMAzhedyGdpkYZTdto2ueSNIF8iIjZlUpW6LQSIu+7+P8+fPI8xwHDx7ixRdexPPPPw/OOX7y05/g448/trXJJ5MJLl++jJde+jyyPEeWUv70xXwBBo4rz13BYDCAEAKDwQA///kv8NrPfmbt25x7GI+nePrpp/H222/j3r17uHD+Al577TW8/+FNRDpN7GKx0J7hlL1MaY0chWQF4Jyh1+tjMOhbJ8HFYoFeL8ZoewTfE3bde73YMklGM+TG7lbMFHeS7QgLBK42Kc8ylIWE7/kIwwgMDGVRotSSdlPYaJ7lttYEkKY0/ZtKwuukfbev/b57wIqppwFau60b3/1MoVqvdg2rOZ9VHL+vc/i7Zra2e9foQwcjsY7BeKxB2xDTysmIa8m7kmJ1JNMS0EJV0o2Uykq7FRGpVMYuELUBtAsQNVAxP92NqCVq4+quGGWmEsJkpSKO2r2Gxic4MMyJUfm699c3sxqAZjINd85co1epSuvEZtbQZFcyrIWRNJv/7ObjFdhW74aBJ+2bPk1TcFThKRyMHHfMuIwTmDmAarQjzQ3bJBR1tbda+rvSotQlSbfVD25lZqnWEkvPyowlwSEfyq7fsmaiBrogzr2UUr8L2AxpqQYZ6+HK2p6lSjlqPLRNBShjxzbjWElZ3zuKwirdpo4xTpLEAiqFZBGADAcDHB8fATrkzTgvybICDt/3EYahznJWWLV6HJMqnDGGwWBg84gnCXmGc60CNnu5LEsomduzm2WZZT6MWvz69V/huWev4MmnngIXAjdu3MCPfvQjy6BMp1OMRiP8wR/8AXq9HorxGEEQYD5PkGcFzp07h+1tKq25tbWNw8OH+O53v4fZbI4nn3wSOzs7ODk9xfsffIC333kH7167hv5ggFu3buHGr2+CC4U0COwzmGIrRVHA8330+330ej0EQWSzxlGqVx8HBwfggmN7MEKkk+BIKfVaxfXz1dibSpK2SkHabHLMrlllaoOizwSvQgHJKaoEAwdnCmEQLOU877p32xlpU3/XmGm2rIVq9nfHa4LmJlI/czlx93P6oz7fFc+yrrnPanM2NEyuekBdlYvZojuCebXz2kXHVrVNNQKPNWhTq5y+iFuvg7N5H23cYPWZfud8OTSgni2pg/vSg9ixsZxYpb6R4YQGKWsf9H3P/jTxfJUGoQ4WqpRLYysN2EyHthmZu51jlBrgG7GJqgTTmauYs4Z033a7F2NMKzfqoC4W7aC9WCzgCd+m+BQ6p7a18wBQuqAGYwxuKFobZ29+moPUfFdN0KT4au3855z3NsJD31fvoY15I1NCy+cta+Wumb2X5syLsoqnNqBt7MVFUUAq2DSrrqratYWGuiLV0dGRTiJyXF0vK7OQAXjjgAZUKvDxeIzJZAIACIIQgnP0ehHm/RhxRLHTnFFUQ5kXkBoYlKwym4VhCBNfavYP59wmLtnb20Mcx7h69SqklBgMBxBepTLMsgyQVeYzw0zkeY69vT3KnpZmmM/nuHnzBnpxhB/84Ae4desDy3xEUYTLly9jMBhgOp1STvM0R7IgiXZrawuMMfT7fURRhJ/97Gd47733cPHSRbz8H/4Der0efvH663jnnXdw584dqh9+fIwiz8EFagltkiTRNccpPv7ipUvY2dnRmpJKJR5FMRaLGcbjMeIoxGi4ZfctQJqRfr9f2yt1Rqbyz5BldYYLmdf6m3dM75Bi+LMsswwcGIMniHkTKK3Jwg1Jau5Ttz2qOnnT79u0lW2A39Q01Q6y+cycf8OAKGMeXT+3LiZEKTK3FSX5CZgwxObzGFouBNExwURtjK57rWuraIppjzVoKwWUpXHGIdA2tYpLm2nIyR/ePRKwAuCq+y3bR5QFu0bqO1SOUquc/Rir2zCDwLdJH+rz0Ry22bC+mbnSXLeRLJWW5hWYotfXTLOptDMLOINwAMuOrSV6A9p0XZVsZGnzMdjwK/NMAJBlaom1NaAtWFaBuw59MF6wQghIoOah3eVd6UoI5qfb14Cbq3Wg3wFjpjDJO5pEwmWyjEOJeeCKkSHve6klG5epIK0BrDqtuW42jwBgnYNsGT5OjBPtDR/zxQJZnsPUD2+2PCf1da/Xs6FP+/v71ulqKfmPnQsV9YiiEJxzPHz4EAcHBzg6OtLFPgSCkIpfBP+HujdrsiO5zgQ/91jvkjf3BBIJFFAbWQXJhlRRbDOyKZlMUjdND5Jp+kkPmv5P3T9A1jLrMZOG0otGLU2rJVIjthZ2SxSruaiqwEJhSQCZyERm3rxLxI3FfR6OH3ePuHETKM0LFFWJvBk3Fg8Pdz/nfOec75i60gzX2mdsBe9FUWTaHhklyt0ziiLcuHFg0rVKnJyc4PHjx0jSBLGBmjl3GkYwCUE54WmaYm1thDfffAtRFEMrUGUwARw+OcT5+ZlBBiqsr69jc3MTW1tbmE6ndn9ZkE+c51wcx+j3e3j48AF+8IMfYGdnB7/6q7+CX/6VX8ajx4c4fv4cAJCkKWbTqYsx0Bq1JoWlKivs7u7i9u3b2NzcQpyk9j1QjjS9+zimYL+zszMAwPpoA2kaY7FYYLFYIIoi7O7uWnY5fm8+g5bRaG1/1qYGt0/OYeeyAEJOA6tqlHWFWiuIQEJXRDYVyAChdDA5ZxdwsKLv737VrVOpX2FZt49po1Grrt/ZprZwBzuU3PdtRf5VtrYRR/EgJaq6tnEX7eNZUbJz4wohsKp/Pm+/8/ZaC22AfTfOYlaewHY/HcJW0yvl1Cuylt13K6EIA9fxO7BHeJCMBmvDr/AInhXCVYWCQCIIPf5xDZBd44ob8LmcC+oLLj6HrX+a3LUV1sx+pmFS1pSjUaTjAxLc3rXpR8BXcBRDv0I4RcBsnHfe0X0EK3nKlJQSC8CyjEkZQAZNeM6PMWhD3+4VLAsQu4jxdYSJZDbpOAQ30vuUxpffnjBWOEuPBU36DGImOAjNyeZbLQI8bpZjIwoDgyeGiISOD9DvUzGOKIoRRBGm0ymUqgwXAUGkSinyUSrH/vXixQsrBOq6RlWWDd2JqFBhhW+/P4AQwGKR28Way0pypgT7yBl6X7Wo+EU4qqo2feXGcp7nGK6t4c6bbyHLMrzz7rs4Oj5GVVYQGljkOaIoRhIniAwrGfOAz2YzuGI+NQb9NXzhC1/AO+++iyzPrOJ769YtrK2tWSWG713XNVlIqkSSJDaXXSmFBw8+g9Yat2/fxo2DG8iyDEWxwPbODmpopP0e5rM5BdqZ6ygTCDZaW8O1vWvY399HaRjRZrMZBZqFIYSgtKo4JsKZ8XiMteEQaZoiSWJUZYXx+QU2tjbR6/W8POumi8wqo8rFglQVBfn5lKlkuaslfvxmwBkFZtK5oR3fbHH7a8qqOs5dSuDn3a467/NeswtFbSNjvkJ+tYXLhoswfUXuq7pSqKqaZEpNCn9XuxspokJadMQ/pom+Nv++SmF52fZaC22taWHgz2xt+wK7VrWtaew6Qnu4+apr66s/a1J4bUdfAXm0B4gvBHxrjl82BDG9NQYfAgQiXLo+t8E9CsE30LDVzsi6rAGr3JDFDEGe4rqubP/RswBaN4V2I+oaigQenHLjB8HwJh3audQ3NsXKKBTcL9QnVUNA+/1G/aXdM0AuTcYlga1d8Ig0+fV+xSz/+tzHXZOa8yp95cD65Vl4Q1jY3z9Gwyk5/MMlKBeLBYIwRGRSfOh9O3eBUkBl+r8yaWB1XUNBoSoqICRoOw5jzGdzTMYTREGIyDCXqVpZAc1jVUBYYgfn985QFIUhNxmSQlEUmGcZpOxZOD3Lsgb1aYPP3CAEIoohRQ0JCaVrCA3kWUZjUikrjL/0pS/j/mf38fTJU/T7faQyhRTUNp/0YzqdoigK9Hp9zOdzBEGAO7ffwt27dxHHkSkAMsMbb7yBnZ0dW5u73+9Da4qjqIoCqqIAPCJxoWjq4+NjzOdzpGmM3d0dLBYLfPbgAebZHAIUZLc2GiEMiM5Vqxrz+QxCCqyNRtjZ2cH6+jrxNfjjPwwg6hpC1UgTcj0QMiCwtbWFfr8PCYKpF4vSoi1+ZHFDWPM41b7ynoDJcBzDovnRlX3vXIylriuEIUWeO9DAWepxHFsWva4KVO358jIL+mXfX/XdywTYVdvLhJtv5HQdK7RZB0FrFb+buq5RVC44VHadC9hxC7ARt/r52u1qI32fd3uthTYLKG3wWaU1aZg2L7uGqitw6hedwlayswwZQukaGksDputAK1i9C646dvkRHLRujg0E+Xkh3AUocMRFhtuJzPArfOVB2zaxwBUITFQrYIOrBEwqFAtkjtwmjURY4ejD59S/taoNDM/XcxopQAtKGKqXugZ8yAqecmC/R1OD5k6jjwJUUKOl4LQWE7Y2GG5XBuK3XPPmGCkEIRodGrkQoiGwfYHMgjsIqI+FETrSWIXS+IwpO8ApamVZ2trSaZIiDALyWUqBQAr7vtNeAhHQNRd5jrKsTLCV6y8pA1RVjdl0hiAIsLm5ASEFFsUCVV0hDE2tbrMYCyFIcZnOMJ1MoDUQJ2SZ5vkCZUmL1Hw+RyAFemlsrW8pm+QQHLQWSEkBdTXXqCaEoSxMve88R9QfIDbBaoDGnTu38Y1//Q382X/9M7x4cYZr1/YIQaibFZHYdcBjsN8fYHd3F3Ec48mTQxwdHeHu3bvY3NzEc4a0kwRCCBvQV1VkITM8zoqbkAK7e7s4ODjA+voIeU7KS621sewlemmKQa+HOIpx9uIEWiukfUqpS+IYZVFaxIX9nIyeIQjQ6/Xx4sUpJpeX2NndwWAwoHElBbJsjjzPbNlQO+6N28tXDLXW0LWnpGuOy/BpM2sEgQJkZOc/c56XJVnRlLceoCwLb24JxHECKeeoqtyM1drcu6mBX2Wxtq3blx3nz9Ou/V3b0tpAOzuv97JrtgW3E+hm/axrVB7DmdbKvhcuOtNqHNiFZtdO4QKH/TatauNVAv5lSsxrLbS1BuqKFt6ahY/283BhTFFjxUE7ilIj20z3MlBurtttZfPfdiByI9AcRE5me/l8rWvY31boClB0moSGBNiq1i5KuN0uhl7stTQgpDBW9MuhoCb07X2v9NJz+VHYEAKVYlKbZvQ8G68UCbucDiEAYseqvD5otcff37aY3bGA7TnvGIak2wKcFjsvSM0EMLKyw+4MZTjKfTiNrR0btd8huF1pS9n6nhdd/j6w1+R0rl7aQxKGiIPQ3jMIAohAWqUmjkMMegnKkizFvFhYzd+hEjXSdIDNzQ30Bn1owDJsQQCQAnXl8R8roFgULkXL1K2eTKYWBeBc7jwnSDxJiJ2L+4T7XEoJEVDamIaz5iUk4iBBFFDcwvr6OhG5aBIGt27ehBQBHj54hA8//BBlWaPICwgtUJrAvL5hK0uSxPiIFfqmGtfz589x9OwIt9+4g/WNEU5PTzGdTi2bGPuLtSbSl0VZIopj9HopwpCE6v7+Pt588w6gQUpUGJs8WwkpFdI4QhKF2N7eJth8kVk2OEYMuC/q2llVEoQ8REmCRbHA02fPEMUxtne2EUYBykWBRVHgcnoJGUrs7u4iTVNnxRmIlglqnFuF4FlheBRYwZGSAjpD876VN3cZVWDkRpi1pqpqY92zUiqRpj3M5xmqinLcy7KGlKEJ3LzaL9wWPO357B9zldDqWnf99aD9GQAhg+ZzZ1Q3lu0of91mhVtpjVqzm6Gyc4EU5Npm+EgpIcMOEakd8mvbx5bhiu3zoAovU2pea6HNlhmEsNZ11w9rOLzgruwY89LbmuJVHbk00MyhbAh2WX/tF8QLX3tgkhXoBpMvTPzjCPZly5sJQ5rtW6XF8b0b+z0q+hE5AAAgAElEQVSh3eweqpMGIRCooCW0Sf3xnylNy6VrSCnRS3tQtctz9K1rfpa2kL7qPVylofI9u7T/9jW67umfz8KWr8MWq68s+P4/Op9mK/tb/XxqFpbMgMaWIYQg9jAW4iYFLwgklKKCEAruvbGC0EuIWhSCOI795+AIZa219eNKT+lL0hSpiQzXWttgSMrnphKcXIIyTVPMZhPr27b97D2/UgowCnQYhoCUiJMQ8/kcl5cTHB0dUaUqDTx69Ajr6+u4e/cuWfZmvkZhhK3tLbz99tvY2dnBgwcPkOcFer0Qg+EQ8/kcDx8+tKU1p5M5Li4uEUgqoALA5j4HQQBpctOvX7+OKI5RFAV2d3fx/vvvYz7PsLV1D+fn58YVIQx9KzHShWGILMswuby0wYL8TinqPjAun9LGmQCw/Xh0dISqqvDOu+9gNBoizzII7ZRhUmaSRnGX2KAjYRTSmLBKUgVGxaqqAgJtItkB7cXzVN789OcPB0nZd2OO4VTANKVAuvF4bAPvKC1wOVXJnztdf6+aty+zfLuO71rLWge5YODWWnnVxvOeV7FaKVTGd11VpSUiAhznf2Dij8KgeOm12+1f9VxXyZlXfRbgNRfaGgR1Eu+2gcT5BXh+bQmGcI15bc82Fi5vog1g8O5mh181CP3zuzRSX9DyMW2BzfvJku6GSVZpnPapWgO8fV2/DVw+0d4jEA1Fh61RDVg/d3MANdVIngRpupwDDdCiUVcujcVPeemytoGmNd/+7iqI6aqJvmpi+33U3s/KUde5bWifBK3z+3I5TIbU4jhGL+0R+1UcI+337cIsJUWNc3+4PGDTLhMVzP7PMAwx7FPt6dl8hsIwhwGwkdN1XduqW4vFAiIIEAiC+PqDPqQUmM/n1rdpix0EElUV2trcJPS1y7E2sDsrCnZ8CTe2hBCQIaW/nJ2f4e///u8RRbFJTzvHYDCwkHFouPDjNMbNWzexs7OD8fgSWbZAHBO9alVWePr0qbV0rSUJgcFgjdpfFhgMBkiSxNbpZotUSgmtFK7v75tI7xJ37twBADx5+hRFWZhgSoW6qqCVwty4Hnq9vn3nHN1PirIJ5ARsXEMYhjg9PcWLF6fY3t7Gjf19KlFQER81R/1vbGxYhY7HSBySciDDwI4BQmhcmigFkTEOS5W+qqpEWZWAmVusXPhzhcckj0UeH6w8rq2tmapt84YC1+at6Jp3/t+r5tc/d/s8wv5lBlf7mqyIV1WFqlaoyspG0wNwiFogEZgiODLoIFd5Ndn60ra0t1cV3K+10AYI/gNcji4Lcl8YCuELA09wW7+oUQC861rv6QrruL193sFh90lheZ6FaFppjBK0052uenG+b2fV5OoS+KusTOhmEEUXfN1uF38Xht3tZIvUnwy+MPSftS2c/fvz5660r/a1pEm9E/7vVZvgX8KhJZrpJMlvC7EM/bGF2dVmIrkIrBCPwgi9Xh9xnCAKE8RxYopCCOsTZmErpbQR1Da1x5Dx8KIbRRHiKCYLTjSRhXYKHFf6Yst/tLEOKSWybGYoL5Wl2SyKAlEUWoUjSRJSumqFPC9sVTG6j4D2rDHqNoUwcO82SRKUZYXxeGIXRBYEzJXeT1LyZYMKLxwePsXp6amtyiVEhao8Q10r7O7uIjGpYtxXURQhDELEUYytrU2kaYJ7P72HfLGw6IaUEjt7e7h16xYgBNbX1/H+++/jo48+wsnJiamulZhxHFpLK00pj5rbTmM5XBq/VVVRpbIwxMX5OcqyxJ07t3H9+jVcnJ8jCALLLc/+ep6LHOMQc1UvL2iSlVuq6EbKAgd1KqWgamWUJwGNooH++EqlL8zb45jH23A4tL5wCsZSCEMKku2cNlcoxu3Pr7rZK/pWNGD9+fxdx43pKHuIn4njXxg2pqWqKlJ2K8qtr00mhe/+ovxrmn/MMdHZ7lcQrlcZgq9ifa/aXmuhrbVuEN4zo9QSVNOwrtuWIkUg8zUANyhYWPHCyz9XaY7W5ux4IQ1hbDXxCHGcIDHQJvmOPKo7tfwyX6bpaiy3sWvCrEIA2pa4f+xVE9NP7QGAMFw14KiXGHb0F4uudq6yrrtQirbQ5GOlt6s9WVb9ba9j9ZdW+yRZOLZ9AAIpDPoD9hhQQJGm76IgRCQDJHGCJIqRRDF6aYokSRHHiYUyffiSBbZlVzKEDTJwhSd6vR6gNMYXFyiKBSmhyhWnYAWA/ZpchEIYf+xsNsV8PvPGuBP2fq5wEATY29vDeDzG8fHUWLnMpxwCwmOJ0hIilrYsJSsj/f7AXpf5zmPDLLZYLBAHhAQUJmWqqkrMZjPLVx4GETbWB7h58yb29vYItjZkMH5aE32WGI8nOD+/wJMnT7C1tWVh/vfff98GfgkpcHR8jEePHgFaI00SCCGhpbZIAs9RvrYfXe2PHxZ0/X4fR0dHePbsGfb29nDz4AC9NMWllxnBBUeGwyGiKEEYxuj1CHWIDNJSa2XdFpRupEzOfGJgeUfxqgKFQAWkVC5cnzMi0+ae5+dhxdIfM6PRyBZocRz4pMgErZTMV92uEtxXGSTCHWQFuPa+W1rb+F/RWn8bCiVJBu67oipt7WutKROJFW3LnxAEREYk4MmVq59TiO48bf95//8I6fb22gtt1oABK5Ltd7wJE2UMdAkDga7ub3cxa2ld25J1CCfw/f38t18kgQR2YiE+ElzLZPKrBGz3Md0DZNV29bVW37NxrIYtIsHCdPX9YPPQ2+hC+7kBrBTE/o+/r+s4qY0rwlPMLCLROrZ9bqMvBEWddx3Dzx2IZvobL/xxHCNkqk9DVMKWaxhHBIOWDlJn65NJTRiaZuvLH0dhGKI2cF5RlJCBbLyDrpQdXrxnsxlmsynyxaLhl5Ym2l3VNfKaoPHNTao1fXZ2hpOTExMQRcexski53bB5wqpWqHVt+yCOI2RZbhdLtjaFECTE+TnKGr1+H0IAZVWirikdKopDbGxsYDQaNfyzVA50gvl8buuIz+dzPH9+jPHFBeq6xs2bNxHHMW7duoWdnR17LiDw+NEjjMdjbGxsII5jzGazxsKuVFsBZzccBSexYlQUhfUJf/LJJyjLEjdu7GN3d6dBSsOCkyubcf8MBgOqdCYDEurFomHJ83EUANcU2n6qVl2XFn0QQti8dR/9abulWJCzcqi1xrlBCvh4plnm9vjz7/NA576R4M+Xxn7dRLXA+7z5+6obtQ2AWQeoLC+xmlVVhbIqURqlRkrDThmEjXiUZqGPl9/PPlerX7rW4659/xzF6LUX2nahFStlKphAxT+HP1uhbV4mDxTdvIDdJMTq+3QItPZk40WWLac4TpBEiVuMzUYQZ1P8vszaNR86Uwu4fY1ztRt4q67Z3u8/j5tchjxAaetiqE0+bNc14ziGFK74u/Ai4K9CCHzhyJ99uK+tePA5bau8cyKw5t2hBDhozYwLKRBAdIwl73ItlIIFsHv3IcKQyWSEpRBFGKAsSrtA+EFqHLEspbT+Ylb0kiTBtJyYZ1Q2ypytRF6028FzJDQXlpaxhoPUGQbPsgx1TcKFx/B7772Hqqpw//59mxdcLErzTJTuJg0PAN3PcZ7PZjOUpYOyfUteCAFdUYGcJI4htCbymLJEYKghe70eev0UW1ubuHHjBqIowunpKb73ve/hyZMnKMsSW1tb0FrhxdkJLsbnmEwnGK2tYW93F/vXr+P999+340cIgcnlBD/84Q8poK/XsyQoab9n4wxovaZUUgDGdWXWD1O/ejweW+Tj8ePHmEwm2N7ewu7uDnZ3d23MAN+bucb7/T7CMLQCPEkS5Flu4wp4I9+0Nq6ENWgNLBZFQ3BXVQmqFe4xchlUi9wTpY1PYF82uwD4b16nRqMR8jzHfD63yI/Wxo/uje+rti7E7lU2e54/t7RbtNprY1vJ7rJiHVFKbZ+1NNZ1rYielKPw2c1iBbYMVl77qm0letBxrbax88/pu9daaANEWAHALrpdm+iwvski9iFl+0Xr3Na1hOi8jxCCBpPgak0CUpsawkIiCEOEIQWt0IIdEXVnEEKKyFg1TrgLAwG131OXxd3c7zTTVdYyPxf90L+W3ax1rE0PEs0odWH+09DQigJgrCAwP3IFW1CcxBDaLSjaqzHut/EqdIC/833j/sT1j2lb5W2IrnkftXQN+qG+1cZiF953/nFSkgLDqYec9y2DAEEUIkoSREkMGYUQQQAZBdDQVkAX+cIKMy6+EcexFdjWrx1IW2EtTVOMRiPMpjM6N4ywKAv7Ptgnx9YVAKRpaqzHGlVtIHCzYFW1RiwpLaooSuTZ3AaxcR3s3d1dzGYznJycIM9zwylOpSSpPKd736SQkv+VApsqC6lTvrbnGlEaCKmf/TTD4ZBqXe/s7eL2nTt47733sL29jbqmyOxvf/vbePLkCVGdjoZQusb5xRnG4zGKooCUEtf3rmF9NMK7777rFTWh8fbo0SM8e/YMGxsbKIrC1B8PybUhtBclTkLaokOQVElLSpxfXGCxyLCxcQ1BIPD8+RHm8xn2969hd3cX169fx8XFhRXQPHaZUGU47GNjYwQpgfH4AnmWIctyQAoL+zOdbhzHGI1GmE6niKIAWofQxnJcLDSIdCVEHKcWWhcCiKIEcVyhLAk5YLgdaEL+/D6Y6nWxKAAFhEEFFUbQkvLbzUt+Jeu3bWH7+/y5+HkEuz1WU5aNFk0lH/Dgc2NhVyaNi5WXqnYBhGEQENFRSDEiloNBSJttYbFUgSUDiW6MlnIhlvrlKkSz3RdthryXQeivvdAGrvYtOOHsoo+tdSiMOCdcfVlA8ytpGqfuexYuAMCCml+ylIiDJqzCsKPPrCUgrZCH8IOG6O8Vw6Jx/1ajO79rDxIJt/hYdlIsKwI20tafZFoDSlu/KVtK3L+14jzxZUo0IQRiwxvtw2BCLNcu97f2gG0LXV+xYEXDP+4qK7t5zWXo2y9C4u/vFu5df5t3bhbAwKAqGtrCo8MBWbGZqq11zelVDFeyICdiEAkhhYWsF4uFJYuRgYSoXEpQXddI09RaUhsbG9ja2iKBu8hQl8TX7xZAF4wUhsQCtljQuGYfdBRFuHbtGq5fv45Hjx6ZIh0BqoqUQJ+Mo50yR5AtfR8EgQuykwEMxV9jLCRJgvX1EXZ2tnFwcICN7S3MZjN8+OGHePjwIR4+eITpdIbRaA39QQqtFRaL3EaLc2raxsYG3nzzTayvr9uxwEjEhx9+SDzkaYonT49QljX6g6GZT5QCF0YhIEXD/cXBX/P5nOhJDX3qJ598gnv37uHatWu4eXATt27ewptvvonDw8OG370sSwuJk187QpZlXvEYmp91zbXFSxsMxRYwKXR0TSr6ERnFj/qXi6XQHHNlXzlanBVutrZ9hThJEgqoCwLMsznl2MOtSnbe8Txcml3Nrcv69eewP4de5TreDkJKzZ9aO6ngz0W/JntZEn+4j4Lyc4dhZN+TbK9HLDRWuksJKW0kJnW0fxUC2jZC2kGOL1NqXn+hrTWE6T+rUUFA+yQqRvI6i2nZkhPwBLixVp0s0zaSmAPDSOA6y5oX5dCkAoQyQCAc7MkDA2hFS9vodd1JiQdPq2vsQvNltz9zG21bW1Y0YPw7JiCMA0Klpz0L2tG4Zl1VZlEl3l3lVSMTHnc4zKLRtUkZuCASe7s2RO7y1MlfzouCsO1ky6P9zG2NXmuNwFT2ArtDdLdW21butNY2IEh7/Q64LAV+R0KYMq/aQfWsLEgZII6jhhLHWvSgP0AgJbI8s1a2HVNeEIxVMk27wyBAEsfI5nNMplObPRGGIWRZgKuZMQ+51hqxWYSF8b+6EpwBohCoFaUicRupnKbEdDpBWVXI8xyTyYRYxQyc2+v1jHAsEYaBobitGuPeDzJkP3AQkHUoTQYF1aJ2yi8vpGtraxgOiSf82dERfvLRRzg+PsKLF2fUfinRH6RQurLFRurK+XeZAvXg4AC3bt6id6goylophR/96Ee4d+8e1tdHuJxc4vziHLu7eyawDoiiEFEcGR5xYd49jSlVElf35eWlXfSfPXuGn/zkJ+ilPdzYv2HY1m5Y4pTFIrfICgAMBgOsDYcYDoc2NSsMQogkJa53W1OdLa8K4/EY83lmrzMYDKAUlWLlOQZoG0fhXFWcLkaR0FpFqOu44ftm4h8uLVoUBVVKm0wJVq4rBHXgWBsZdfCsS39eXbXxms1rrYcXuu+vOFc0jvXmvdCWF5znJAvsRVGgMj56Hp9sYQchFy4KEZj616ygXSVo2y3z2Su5hV2GSNfnNhLRtq7/xQttqYV76Rrgohq0ta2ytsbElhUt1sJGkdM/ypbPdPCGCASkZnpKZ0HLMEScOD7mQJJPL7B+WyMkrTJgFAOjyfsvRgpB9Zm5nWzuCzfAV1uMLXjfG2zLFqxnUbOlzXfVsAQebqFt5VMrZVmbePBzV2lJgTrdW1uBaLbV9IhBSIQpNaodHOefp1z/8f42WQzl6mujbAjbl/QcxgLUipAVb5K4cbMceFMr5Ug0BPW71uT31F7KIbeHqSA5qIUX5zRNMRj0yWcrJGTo3CO+z9o+tylYEkURUWYWVIZytLaG+WyOJE2QZXNIAURhgFrBLsL8jvJiQRHJdWX80IQAyEBYa51/1tfX0ev1UBSmPOZigbPzc5y+eIHpdEqCezCgcSEElCbIlfOPA08JITY4rqxWGaWC9lOfKVTK+NwrN/Yup5f2+XWt7IIbBQFCKVHrGrPZBEEQYW0thKqJklcrYgvL8xx3797F//blLyGIyE0gJOVpf/rTn+J/fO972DLW+737P8X25q4ticrkN9x3HMgIYQL5tEJeLFCaAK4sy3ByckK+6fUNbG5sYDhaw/7NA1SqxJOnj5HnGbSusVjkIOh/aPtKaCA2Vh6PN44FAIDZfIaL8RhZRnS2rIz1er1GVDhA6UhJ2sNkfImqKBGmpqgNNMIA0KFAXZHClCSpVXKyLLP3ZqWu3+8hiilHWWkiWRIakJrlNk38VYZEY/YLb83257L2yK1sPzuksWGVm+/4PGheL7zzWfE2PmwuTVqy3146+mEyuij/OggCCISNcppoteFlglPwOq99VeTqra3gtIX3q26vvdBuwpFmGHjvfJWWQ/sAgDTStuXlH9TgnBYSYRBZy9paTaGzngAjeNEi+29ZgdaibLWPBAErE66tGl6+ccuqdifDft8tqPl6TQHoW/lWQGvyTbMA8n2AAGnzYSPQzkFlQgqiz+zQlWmCd7fF7uMJaH3nTU3atpUVmiueLQgCqkPdcSwLbecz6hovyxSyUkrKR9BU4rD5HuhvDgRjohSCuSP0+wOkKflUt7e3kaQp5hMqHwlDduIyCZzQ1yCGr9FoRBbYYmHh0SRJGtaEfSY4wgi/+IZSCuOLMRXnsBSsoQ2yYmie/Zz9fh/T6dSmVz18+NCOheFwiKIoLNMaQGOoKAriU28tPEEglgqOKEUKD/tUCaYF1eoOXV/QdVyaTl3XgKSxOBqN0Ov1UBYVqqogLvYZpbF9/etfx87OjnXjhFGEp0+f4q/+6q+wtraGqqrwySefoN/vY319A1pro1AN7DunkQAzrkkh4NrdLDwvLy9xcXGBtbU1bG5vYWNrE9vb20jTFM+fn+Dps2coysKktxVWYGjTpjAKIYw7papqizawi4Te5QtkWWYjwRliB7jEaw1AoTcYQikKJGTFqTKkLlbRDohbPY4jKJVaV0Kv17OFQ5RStuY4Q8zUjxpU2KhJ3NLerrIw2/v8NUu3LPeuNc9H5nwkzDcylK5RliSwazM+gyBAZNZvHv9h6PgPqFaDq871KpD9qzz7qu2qvusS5ldt/0KEtgtmop38gQXcqrNF43dDwMIs+KGzqIm2LkAURpBhiEASPCQCnyXICC8AXOaRr/UqWxvebfy2kLanrXYJvJZF6qzg7jawRsgT0q/lW2tn8vupSNYa9IQg0bxTn1s//RXP2fXZXcz4pNivbxAJbcX36n5dPdDF0vdWcbL9yQqfg8NduqCPjAQGDpTQQlgLjGF0rWtzvLOawyBCIEP0e+S/FAI4OLiJk+fPqT1aQZgIVT+9hP+uTfTu+vo6inyB2WxmBSpX6uIoX4eKcJlMU6tbCEzHE8yyOcqixMAs/AARdlRVaRZxIkxhq4tZxdgS01rbNEUOrNJa24We4dhaSlsYhRWjKAoxHA7sPQFhyDscXSQr4YEMoGoq2am0G5tFUZACHYVIohhr/T7iODbBRcre88WLM3z5576Mt99+G1oLVKVCGIWoS4VHDw+xPtqA0hp//z+/jyxf4M0334YEWbej9SECG8BHY0BpQMMoR8ZyY9/nZEL0rBzhvrOzg62tLaytreHi4gI//OEP8fz5c8zmc1u2lPtYSnJFQLALRIKUP2FcKwSB10ohfH4MwNGRTiYTW/+cCpyQwjXaWMf9+/cxzzPs7OxQ4QtVc9gAzwz77tgds7Ozg7qucXp6il6vhyiK0OulWF9fx+UloR4k3GPUteMB4Pe2al53CSZ/jWsLR19w+/NVesdaxdasDHy6MmhYWZcoS8oz51RNhsNZcfTdN7bJBhW1vvGG5bzc/q7nuspK/jxKwOexsoF/MUIbWLK27AEstXnRbULmvpBsWNReehbR1QUIQxP2H3i1neki9jz//l0Ce8lia1nDQtB8bQulrtdm9zWsaYJrnTXs/IrtdtjoXOOb9qlfrULgBRH5P/a6rIm2LOdVFj5/7yMbbQ2arHVtZmDLKvdiAAgGe9VB3Qzoc/dsIh+0EPCE4/bIRnDbKkXBLTzCpDBpO2bCMEZoLOK1tTW7sI8vLjG+uES/l0AKh1z4ixJHGWulsL6+hSAIMJlOMZ/Psb+/DyklirJAZni2bQ1trW32gk9DWdc16rJCbKxD3k8pQalFTGwRCqM8sCBnkhaGdtkKy7LMCuderweALGW/PjNRZ4ZGwchgFSnqRNuPhApIQMNadsoEmC0WOcKQcrXTkHzu2vjuAaA2vPaEQsT48pe+jDhOUCxK0ybyZ29ubuLi4gJ//ud/jtPTU3z1X/0rrI3WkM0zK6yEdPnuNFcoaK82zwWQT7qqKhweHtp+3N7exrVr15CmKQ4PD/H8+XOMx2NcXk7IxypoXHMwGY9RUkoArUvUpuww+a0pFqH0UrWY2W0ymaAoSoxGkaFUJSXv9PQUZ2dnGI1GWFtbo/eTZ6aoi0HujPuOU+62t7cRhiGOjo5AxTIK9Ps9AIlNheNKV0LQ+G7Pqa5tSZhfYVn664G9Jq9nrXs078kpXTDR4QXKsrCKJBtd/prOQcMNI0IzuudcIX6g7qsIXDrEaQBXLVEN2P9zCuiu7fUW2hYOMcKuq0OFB21JTzB6wlmytiVcUJmDTMIG5zPnyNJ9XQqR7Wz++yVNt4INLYEteFC7ewgJo+l5x8ITPP79hbYDpEtQ82+b11lVJLQb0dUcVCZp0TeRyn67+bOU0qTFOEF6lYYpQJWftNFkeZ+GiZLU7OvX3ntrCrJXQS/a34mlNgk7bnh/+9q+9d2O4PT7CiAnixJ+3yrH9R3FlO8ZhEjTHjY2NpBlFIz03FjZ/nj0xxpb3HVdYzAYoNfr4enTpzg6OsL7772P0doaxuMxMo/GsyxLlMYCZCWEn4UDl1jg8LP4qWCkuGkDzzrL18+p5udM0xS7u7s2n/ezzz5DlmUQwtTZNha5rQFulMI8XyDPiVZUKFf4hyk7oygiP6WZB2y5h2GIXj/B1tYWer2efR/cfrKc6D3N53PcvXsXb775llWkhGj6iL/97W/jxz/+MX7mZ34Ge7u7lL7W62EwGCAIAyu0LfMitGUIE0JYzvTvf//7mM/n2N3dRVmW2DXXmk6nKLVCysxrhnaUXR5CCEqry0kZkTIwPn7yu0Jx9oJRkk378zy3bpH19XUEQYTBYGiuVyDLMhwdHSGKIty4cQMAcHZ2htmMyoCGYWDbUBoym9FohL29PRwePkZdV0gSR09LgWtkcU+nU+oJ3aRA/VwCp2W5dq0Zjc8dc6+t7PPY9CvU8bgIwwBRZNxUHBkuZeM6gKcUtK/Pu+H2MarWtWltPZXmdzOyvf18XX83r7cawWhvr7fQZgF3hYgUnqXGL4gp+MKILWgS0IFwUI/PBdwkPRFWERBCIBCUGwivFf4Aa5zX+nu57SzIW8IRTmBbC9o7RjWuaZA1b/OtHP+zUgpQpsCBlHZRZ5YyP8rdfwb/t4aJ1Bcu+r2tHbdeiKksRRqKCz3QjXdFx9pQNHuu8A6hoJXuXPCG8rbKjfA5Jo2zvpeP9RU2LQQUHAwXSMr55DaRBZdgsShRliQQIxNVzgU3WLAJIWz0rtYag+EA4/EYp6en2NzcxNbWFi7HY+SLvAGJs9WklIIMHFOXEOSrZGY1HsN8PPu8HdGJtDAuCzsuJ8rX5Cjjt956C/P5HOfn5w2/Nl+X/aG2CAm3saqhFUVgV3WF0uQs13UNVWsjxCgXnapP9TAY9q0l32BE1C74b1HkqFWFmzdvUrqbQR54fl9cXOAP/uAP8OEPfoA3bt/GzZs3kec5hBAYjUbWB1xrN74o8ruwyEQcJxgMBnjw4AE+/fRT3Lx5E+PxmJjaksQKDi2Fx+Ft+L/NUKqqinKxIQzFrESSpFbp0UohqAPkeYYkoViH0WhkffVMZ6oUoR79fh+Xl5eWES5NUwRBgM8++wyPHz827oyedYGwS2VtbYjBYIgXL06QZXPDN08+dHa5RFGIKAohJbkz+Hl8mLo9N3xFu6EUo1sQXQWhX7XVVWVJUjj/mgW2lBJBKGieBZGNCoe/jrUVgVX31yv2LzXafSB3KYnvlS7NFcZV+7u2ktG1vd5CGwzxOJgTaAkXs9Bz/VMbuStdvjRP5FC6gJcuYWX+ALBM12dfvE3lon+F9/K4PW6Pt5+fhySRvb7fFiGEqVjmqC79zT1vM+qbf/spPoAZzAFBkAyT8R/naIcAACAASURBVG///l394A9utiA8VXLV62q21/xo0awXbifQKpeH31mCddlmu5qC2wyCjmatmgD+QvOyYxvt87V2M6ZCKa1i1+v1kSQJUW2qCr1BH1EYIpJGGYTjT+cSiZPJhMphTmeYzKZWKH708UcQQlghXBRFA4omBZXGN3OOs8UshCsg4fsS+RiXCiYbbiMee2xpMrFKHMf4yU9+gslk4gX1URaF4HQ1I2T4nlVVQWpHp5plGQrDfAYAURiDo82DQCJOiAKVc84tKYgMiEUtcn1/eTnG7u4Otre3qB61EVJBEGA8HuN3fud38Jff+Q72r1/HF9591yosGxsbNjceAijK0qISBLNWdh3ZGK1jPB7jL/7iL3D9+nWkaYp7P72HGzcPrCLFeqhfzc5mN0Cgrp0CNJ1OvTUp9PjGK0gJDAZ9DIYDbG9vYzab2VEXhpG1mjmvmuFgIQQuLi5QFAX29va8uBSgLAu8eHGKJElw/fo1XF5eYjabNYrJcKAd5e3H1qDxY19ehn51frdCYC8p3PBP6T6HFVVuKyuWQnBJ3ABBKC0XgORUtQbK+XJhCMBC5u68joPMwkbGlzafnUuwyy/epdh0oRjtuKuu7V+A0CbrxheA7gcmilnYoA1L/B6FDYEYSIoUbEPKXcFpBH3opUWaWoCGn9UXPKxdNoWfu27T+m75jvk7T6ttaIb8gi3LVWWsFWVvorVCwFa7QRsC4UOyTmB3bV1C2+kkvjVMAlKKsBMDIRh8mZVs1WRdNZFpv4sK5773jrBNE7plxb/kHu131NXX/nFuH6XCsNLBsKIGzEIocXl5iSzLECcRBoMBvW1VL5WVLYoCJycn1krL8hyz+ayRetfr9bC+vo7FYuGCv0y+Nsy8ECB0oy4rSAjEYYQkijGv5pZVjYPHiGxD2ZQtYnWjtsdRhDIIKKDJwN2X4zEePniAw8ePcfjkCQAXG2KtebTnEb23JI6RxokVAvP5nBZhXhhNxJQQpr64F0XOEL3WGrWJQIqTBBACi0WOy8sx9vf3ceuNWybXXEALIkH53d/9Xfzpn/4p+v0+bty4YdoRY2CIUXq9HoIgIIY4I/yUQQPCKLJlGcuyxLe//W2kaYovfelL+OyzzzAcrmE0GrkoddMH/nvVWkNZHm9CVy4uzlGWC9v/a2trkMZCLxYFhADWRmsYDodYW1vDxsamnbO9Xs/ehzMD2DhhutL9/X0bnEcELDUuLy8xGAywv38dVVXZKmocCc8KH5P6cLwCz4WGAvISgXeVH7hLiPF+0THHeK76yE1R0PgvqwqqNgI7CBAbdMBm+bDV662zK1oFt340uc8183Zc8UxN/cSkyLWNkJay0r5XV5++ij/9tRfazgrlz56vWpoo5tAFH3B+tQy4bjEACAgJW+ihSzMU1moWNldWSHr5bW3zVbQhd30noN2P46T2re1V0dhaUWoWsTNVUCywlasYBcBy55KPWkIDCBrC303IVRNp6bfrIGd1m79XzWNWfBoIQ8e1u/vLe25NUdzt7+ygb5zc/HsV9NT13F3NabfVnmfcXwEEiLGGg6/cwjebzQFoxCnB4lSzuTRDQVrYkRdga9mo2vq205SIN3q9HtI0xWQyaSxmbEnXVW2sCwEYMhG2xrI8a0DkTFHKFbfKsrTzZW04RBzHuLy8tFHai8UCi8UCn3zyCYQg5jKOtvYj3zmtzFruki3pAD2TB13XNYbDIWpFXNC1UhBaU4S4l5pTmYpX/X4flSF7KfIFkWOYua51hK2tTayvjzC+HGN7PsNgMMRiscB3v/td/PVf/zWINpQITTiyftjvI04dNM3WK+AIatJeCmHg+r/967/B4eEhvvnNb+LWrVv47n//74iT2FKktrneAZqrunY84UFAJTonk6mBwBMr8BMDsRdFAQ2N+TyD3JWIohjr6xtWILNAYiHWjsFxqWKO7Ww6pappw+EQUxPUyMLeT7tL0xT9QQ/ZPLPpYL4x4b/ntkHStpwbyu6K+da1mQQSq4+zAsRQOLkhKEocoGpzzRoPoVM2qLE8iWFXCovuwRpd/prkPyOfIsQVi5x3jrHyVuoHVxkM/5zttRfaFrqz/mhKxRIssKXjaCZfthF+GuCelMJBsb5F1X5h1i/BVrB9aZyK1Nzand8NxfjXYMian8cpJHx/Pq9RIIADfLQGVG2vBWE4r0Oyr/1IdVYYhFFY6NrSDkatm8FWrr3sGjC9Zx/bH/Cma1cFaTQ7hXzBbV8PwRLepOAebg9urx9b/dxeJLreReN2cLdrC3V3uOknLPvS/fcoTBAfhLCWWRAEyLK5rQKllQI0VcEqi4pgZOkWuKqubXQu1/rtD6ieMy/Mi8XCi/wmYSGDgBSBukaJglxDASFJVVVhbbSGwXCAi/EFprOZLTmptcb6+jr6/T4eP3qE58+PIQSwvbXRKBYSRTFGI1M+0yzkEJRmUy0KgiMDqulsySuMCyoIA8tzMOj30OulkEJSnwwHNmCtrCoivzC+4/6gj16SIs9zZIscSmtrGU4vLyETciWk/RRKa6RpD0VR4Mc//jGKosT29jYePXiIP/jW/4UXp6cIwxA/8zN3sX99Hy/OzpAvFlBaI4ljw09g+tHLceeynnES4x/+4fv4u7/7O7z99tv42Z/9WXz66ac4fXGKr3zlK0bp0hQlrgAuo6MBqNqkItnAOodmsCWcZRnm8zlGo5FTuIMAWU7R32mvj+FwYOaoMtSxdAe2Jpngp64r1DVFexNdqUJRLDCZXIKoUDPkuaPuDMIQSmucnZ1juLaGnZ0dzGZTjMeXZn0i6F5rV9QmMAGkncryqr87FPDl6dRcp4Wg1ErFzGYGXSrL0li9ZnzGCdV34LVPOsu6cRth/+lq4NL673/mtq0Wr21rfPn5uv3bzqUn/NMb318t1F9roU1+lsSzrAMbuMId0o7IZYEkBajSlNUaAf9Fdb4wPoY8ywRV80Bgy/GKgCVusy8QhCRBKY0VTEVEmDrPnafB1KHON8Z+PfusQpgULdiUEp+kQwJ2oAnDjUTKAA8eEpJOETUD3Q4Sjkyn9hNVX7d17FK22puZQNITrKzhNi6g/DOMMtzS1CWglS+4W3di7d+c8TL9le7jE6VoOy7sPTTcZ1/HEJQrqjQASe4H0rYCyCBEaKKHuTgEU23mWY6qrKBrjdC8dCmBMAqJbCMIqTRmnkNrZf3RjuACViHITcqX1iBmMWhAKNQqQBTGJn+5Rl0riEAgjCPoqbDXiKIIO9vbGK2NcPbiBGVZQBnmstFoDXlO/vIwjJDECYIwg8bMQvUElQooRWlXQUCKhD/3pAwRRiH5pvs9pL0eWeYxua3mc1JqwjgmX7+Bq69fv46t9Q0ieFnkmM5m1srMZnMMBwPESQylgSiKrWWdZxn+/n/+D2it8dmnn+LRwwcY9Pv48pe/jG/866/j/HyM07MzHB0fQwYBojhG2u9BSIlAOBieq2/duHEDP/7xj/Ff/viPsXf9Gn75V38F27s7+L//yx9Da23LfQpQIB2NcTdOlAYqj1XQWvOCOPkZjTk7O0NRFLYK2GKxwHg8xtHxMd64cxtroyEW+cL42/0sFhB7XblAVRVQyrjLqpJcSdCoTJlTIUJQHjgZM2EYQAsgyxc4uHUL+/v7ePbsGWbznJj1jMEYBKEN9OKgRBp3yiB4TaWZ14YGpwOceLrKL65Z5WH3gtYO5s9z14fSpHM16s5LmzHk0G3hrOjmBLa/HWrWbP8SknCFZeIlBJvLLGkLjc1Z23zPZrPceaJ7WfW211poC+F81S7BfzmAzBfavBCzdS4AS8XZJYC6P7PQko0XbwedbDJotS1sHz6XUtq8bw5c4nQn6+fVRO6ga0d+wr4kvoYLTDN5xkZoN1KIAGiuf2yVD3oeFp7tgarMIOlWSoWF2f2v3QKySpg2J9Gyn1+Akqi8Ptca7cuRutG0gv1rNN6Bdz+3tVI2rOKm7QRyxr4LJFwFrbP7ghcyjqHw/YsArM+Uo1y10gilm2psNQtjQRc1UTD2+nSen08PAFmWYTweYzabkfKg6oaCr7VGUZbI5kR9GacRkiRCv9fDhRgjCCSGw6Hlub6cjDEej+3CPJvNcHExdn5z7aDDdnuUqk3d5h6Gwz7CMGrAssLobCxw2V/Mlj7Ds8wF3UtTbG1t4eDgAAEEsZStDZHlObIsw/n5OSQEFjnlbtdmEY+iCGtrazg9PcWPfvQjAMDxs2e4desWvvKVr+DGjRtUezvLsLu7i08//RSPHz+GlBJ7165hMBzY4L2yLDEajfDGG28AAH7/938fWZ7j17/xDbz99ts4Pj7GvXv3cHBw4FjDlIJWTSWdIWd/DlcVW9wB9vf30ev18OzZM5ydUYUyDvjjcaU0rQEbGxsWbeEgU14DFnluo/79KGqtnHBkGN5vW23iKkajEXZ3d20bbHqadw1mROP0Kg7kuxLu9hR1zb/N8Ve5FDnYrK5rFMayzrIMZeEY5SjmInFMlWFgx5q5SNNYgmfTtpSF1bEtHcJ2pSngyyHAR+a67tO1uTWM78HtvPK011toU9qF4wUGAL8+MwDjX2v5iyFa5zBM3G01rrK++Tp8H6BliHmCw49K57awv5BkgS/MBbSmSV0WVCtXKw1d66Xr+dcCQIEWArbUZuPHfE8NbUH01OAlmF94+/kavClOyeJro+nHWi20RWPkrTqu3ffdEJr/l28ZMyWp54MyeH5D8126NSMXzS+FcJOH2sJIBd8Z7GxAIAVEFCAMXDU3TttiSNGvZczl/kjYC9s/bFHnxqJgBjJfodNaYzab4fT01PolWVBLQcUSyOenMJvOMRgQoUevlyBNqSY1R0tXVYlnz55Aa225tIuyxGQ6xfHxMaSUJLir2kLqViEMAihdIxAS/X6PuKpNxZi6doKDFLbQKiYc0MVRv0VRQCuFxLCsSSkxGo1wfn6OfJ5h11iyo9EIayY1a39/H700JV70i3OrXBRFgfPzc4xGI9y7dw97u3v4rd/6LRwfH0MIgXk2R6/Xw4apkvbJJ5/g6OiIAt4MnSXD2Ddv3kQQhviP//E/4N6nP8U3v/lNfPBzP4e1wRD/9R/+HyyyHOtrI6p+V5t3oKhwsNJNWk2KpZFWGJVlhX5/gDt37mA+n+P09NT6wxeLhY1tYEG/yHOcnp5iMBhQudYwBISjW25SwRqO71qRO8akeHKQIV+X4xdGG+vY29vD0dERjo+PaUyC1joO8OL2s/HD9+N1iJEtdrUBRvD6QtO3WFsC1c5EL/OF0+cyw/zHc4nL1YZBhCiKrXtAwhE0tdcb/z5+IF2zHZ2LwyttK1Y9+ND26jVPtPrnZccvb6+10BaA1TbtPsHigzYpaBGVHWlMLlJamFNcGTTdMcCaApDMxfbxmrF3NK1IX2izgOVz/WvYVAqlrO8GRkHw/VsrrXcBKDSLXzhhuzqoipWNJc1RwMCs9mDf67L63QhxxZhf7p+Xbe1J3ZxcS0eba7fuKNz3K+7S3VqnrtvrLik85jj7HlSzmhsLLT6OuaKV4rrEyvzIBlyYG9IU8mNHDYQFgI38ZopRawWRNgWtNIq6RFGQr7goFigWBaQMcOPGDezu7uHi4gxKkf8zzx3RSmJqbk+nU0hJDG6MQFha1CAApCFSQYjICGM/J7koClxeXkIpRQFwJoKZ04vyPHeLq3mmPM8hpcRgMMC9e/dwcXGBjdE6ppMJruc5ru1ft1W6vvjFL2JzYwOHh4eoVI2joyPMZjMLtT9+/BgA8H/8+3+PMCCaztFohKKukGcFptMpNjY2cO3aNZyfn+Pw8BAALGHMjYMbSPs9/Of/8z/jz/7bf8M3vvENfP3rX8f6+gaePXtmA9tYgJCSrex8ZuvYF9p+ulRREBf5bDbD8+fPURRFIwgtyzI754mYhljUFosF3dOUAOY5zOOOURC/4hlnlNQm8LCuCdYuyxIHBwfY37+Bk9MTnJycoFgsrCLO74XnQRg6TnlGkIQQlDbrrZlauMDdZTelm2/++ukHUvrBZhwdzgF8sakxT0xnkVWI7dzwBLHwVisXTNYWkG5+ttePz7u1ET26b/M7X1Fo3tOXYZ+/Ea+10AZokAjp4Dr/O847DoSGn8rEA6Kd3uTn4K2yrq2QhFh66fa6gVt4/ajZxqLuXdPPoVZ1bekLGznTcNY1T+AuGNr5iL3gOji6UfjttcoKPX37Oe03PnLQ7H57WidkvEpqi+bA9SdwlyBf5e9qPHPr2Lb/uwEytQR/84HYGvS/47O1N6lWb13jRwhHYkILtilJGQWoqwq1gg18UkZhqwBk8wxSECwsgIalxj/z+dzm7XJuLxPYKK2sAshWu6orpEmML37xC1TZ6l5h8quDxvUZui7LykLvVPUqQWAEBfmRKbipLMhFoBQVqSiKArPZDE+ePMHpKeUDD4dDm0PMKAEARKbSGOdxc0Bar9ez19rdImrQO2+9iTtvvom9vT1i8bp2Dbqm4iuXsykODw+tD/izzz7D8fExfvu3fxtKKbwYj/HOO+/g1u03iMHt/gNbUOPg4ABCCJy8OMXh4SF2dnZw48YNHBwc4Nvf+Q7+8A//EF/4whfwi7/4i9jd3YUUAh9//DHOzs6wu7trI+9ZWeBxouGIZlig++lfUlLp03/8x3+EEK6cLyMZnIOstbbuQBZmaZw0KoKFcWTrkzMKyUKPWNcWxigAtKY88aoqrPA7OXmOZ0dHWOQ5AhnYDAGG6YNAmndnjIqiQGaY+DjDJfAMJGY+5LWvgW6umONsXfO6yPcnZbTJWmnz2k0MArw1TggyzDjQT4Dchhq6Mb85y6bZFvfZn8fteb7CamhcyzuD97a+dwqLL5Pa69PL4HTeXm+hLTyrs2XZuRB/6/lsdDynh1ntXgggcAPK/21v51mtHDkuPcvLt3p9rdfdjzYelKyhkjbs8gsb7efBLoiowm9H12ceAv5zuVQxT8iTCm37rC1g7cBBc9C2hbJ/r1cFcARWw1XdEPiKCfMq9zICvMtj1n0NX7xzb7YVLeCqp/XfiQ9ju2IYCkW5MAt0CG2Cheq6gkRoFiyNfJEhX+QY9gd0zYAUURt8Y5jDJpNJg1SF28DBQX7NcyklyqpClmXI89xj94qd79Ncg4XBbDazdarTNMXm5oYl/+j1qYRlXVeoBD0fC9zpdIonT57g/PzcVgxjYcQWps1VNu+pGdQGy3UdhhSt/vTpU1xOLnF0fIx33nkH+/v72N7cxMb6BrI8x6NHj3BycoKzszPcv38fWZbhgw8+wObmJsqqxO037+DGzQPbBuby1lojz3Nsb2+jrCucnJwgTalIxvf+7nv43f/0u9jZ2cGv/dqvWd/22dkZPv74YwBwhCxwFc6Iez60iAC/n9qzuLlgSlXVlpq0ETxqBJ2v8Pn7qqpCbBj3IAXCqnRlUU0WQVmWqEpH7VmWNaqaWfuEjbs4OTkBAORZjrpWtiBKEARI0wSAQlFQcJcAbPYACz1hBDYH9wKwsTX+s7QFdntt5N/8fDye+FgZNPnC2R8PDUvpLE1EuxW+0DD/26nbZenzPdpWcXt+23m29G1zr4/IuXv4Qtq2oLEkvur61rW91kKbrU8eCP4LaWh0elXnSytwKSCs+UL4fP83DVjd+ttVv2poZi0fuR/17aAqgs9CD9bhc3xryioK3ndAd9CEL0R9qMoJYr8/lgNBuq+JpX10j9UCu2vcsX7VnhSvEpTR1ojb7bkygERrd9OX3MdZ6/5zuMnnx0zwfa01L5oISINQQykEgURZkQXKBR+0ZuHuL+zawMakmAYhpT+xf1QIF0Ge5zkAx3BX15RuBDiFgYlbeCzNZjM8fXqIIIisdecvvgAszD2dTm2KTRiGuH37NoqiwIMHD1AVFN0dBgFypbAwgmGxWNhAps3NTezu7tq0MR6/VVU1AqpMZ9p2sv8+NcFoa32q2/3i7AXOz8/x8ccfYzwe4/reNWxtbuLBwwf46U9/iqOjIzx69AhZluGrX/0qvvjFLyJJEtw4OMAbb7xhXRNZnqM0UHSSJLi4uEAURdja2rJowA9+8AN861vfQlkU+Lf/9t/g7t27yPMcL168wHxKsQQk1FI7HliRCkMS4gGayhsLbFZMtKaI6DBMGmsFWbaBPacsS+s2cBXNKizEgvy4HhLno3HQsAWB6poEXK0cosJc6Jx9UJUlVVVTypUn1QqTySWKxQIZSGDP5/MGNC6lhJJBwxjg6ndtpNFfn9trj6/k0rMrg0xJhxR6Sp5SCoEIiD7Yh+ClV28CFHCszB98jfZ6z22g2Ba3JnQZcFp3JfoCV7vZXuaC89tw9TGrttdaaEO4gcoWsC8o2wuov7i3B4uUTprYoDT/pUkCWKQQNpfWXRcEQHv3UFoTNKldcQ4/8MPeNwgQaBi/D9E1Cm+As1UqGhZz8xmW/L0v6TPbV7QD7ZzjtkLgV70SBnKi71fdgt9Bd0RoF6zkv6tVW5eisureS9srQktdULy73/Lk5eN062/enNXFlk1gg354QSb4TpvhZ/zAiwXqWtkoa2qHstZzXSu70Ob53AZb1jVA6XLeWPGejf2YRVHg7MULrK9vUrUvpaANnMq0lcwCxgQhzJi2sbGB+/fvYzab2VSxqqxMW3LrTw7DEAcHBxgMBkiSxDKTsSXJdaAZxmVFlvqJBNOg38doNMLGxgb6CUVmjzbWcWgs+M8++wyLLMezp09xfHyM4+NjC49/7Wtfw3vvvYfFYoGDgwPcvn3b1Z02bG7k2z+wroD79+9jc3MTe3t7ePz4Mb773e/i9PQUX/va1/D1r30dm+sb+OjoY4pebkHWjBpw8FgYRhZ188cSo2yMqJBy16yyx33An3kMKKWI9UtxsY/SrgFdax2vj4Che4VA1aAgdT5tbhtb15ubm+j3ehBCYpFnqPt9ACSwsyxbiq9gi7fLgq2qCiaj1MwRaYNbuY2+0siKLoxzD5p+lALKkuB94rKoAUE1ICBAfARCmPNIweZ7BEJQ8GxLaLf7afm5YK8ppVPmWdle3q4Srk5wd69VLxPM+qXHvNZCW3jBWU67clqYcCPECKqmIPfPBZr+C+kRjfgvlLS9ZroVb35KRW2KH7RTtBrXQcsyAyx3eeOZBEdkriabd88Kp2y0vwNWCJeWhe6dU+saDroxEfN8HbPPt5K4H6/SKv1x3lak/P3+QtR+Xj6n+RxXbCuOWeXX7rofGgEiXbdYpiD0c1mjKEIQSis8WZhLKSlHGxTtXVUVtHDBRAAVRKgFHPOdUf6eP3+O8/NzW9Oayi5qQ9vq6DO1USJJaFdQqkY2z9DvDxtpaexHZf8nt5HfRZZlePjwIZ4/f24LiJyfn2M2nyLLM0wnU8tYxsLa8v0DjWdi4d2G9YUQVmAzRScv5FVVoVgQOQ0AG6g1ubzEs2fP8Mm9T7BYLPALv/AL+OCDD3B0dITbt2/j7XfecQK7qnB2dobj42NUdYWdnR1bmGU6naI2ytF8Psd0OsXOzg7efvttjEYjaqsiUpzSEMv4PuXJZELXqGsURUloimf1Witbu2yBqtJYLArEcWT7iI/3/cDcj9qMBxovykLIHOnO94NuCkUhgsacYqFNedvONZKmKYbDIba3t6GVQp5RxPbx8bEdb4xE8Fj0BZ4/Z/k7rTVVc+N7C1fOl/uEn705P4GmSmzGdF1DwM+aMainZ6wB0gYguz6tbeVCiKbl317//HWl6zhuz/JG/cprJm3C+655TpeV3b2mNXkyVm2vtdCGAIQMGnC1tSG9TrfftLSq5Rdg1nbhvzhprGtWCkjjs91mIBJVKxPUUTpIB93a75LlD935nVU0zFHOtdothGGv4R0lmlatvU/Dn7JsQVrFRsilISK8gWifoTXGNLSFxpa2ljz3F23ZobS0j2tbwu1na2/ag+vabfR/c1+3FQndPsfzw3Af277m8wAbUKa0FzkL0tRVrVGWFdhHHYQRlGZBryyjnzDXY0IOhkmLosDpi1M8Pz5GfzDAcDgkH7VS1gJw81vYvNiyLsmnWlHFqqIorKXLz0tRxxpFUQIgAZplGcIwxOXlJe7fv28XdvaNX44vMZlMoDUwHA5tNTEOGqLrK0BQqhBHMNdGaeFIXwhhg9JYYJVliYuLCypTqej5lda2SMo8y/D06RN89NFHKMoSv/Ebv4EPPvgA9+7dw1tvv42f/8pXkCQJtKb+OzxkP3sPd27voz8YYD6bIc9z7Ozs4LNHD/HTe/fw8ccfYzKZYLS2hjRJMJvOoPo0z8uKIGYIIAgDYjmrKrw4O8OiWKBWNRbFAvNsjjiJISA8qmFlIWlaKyoAkVUA/Ajo5pgWkJLS0XhsAbDWthDC5k87twwNy6qk+u7sQ7fon1ao6gpCgMrHGsXvxYsXOD4+xmw6w+XlGGdnZ3jx4oSCD+PYkuYwQxmPfW5TW5jzlPdRH//5fGHrf0dj2bkRQPoSlKDgMkaBuCQxW9dspfNmSbfARoiztH0XKx0r7TrQKN8p+DpGLkiJqi6X1xWtUSua23wdSkFzC58PvfM6usrH/gomSWN7vYU2qJAAeIEym63iIszipR0k0vXDGi3AlrWw1J5MRcmLN71QB1tZ2kXz2/dVCW9QtF9KW2C3rUwh2BcPB5163y9pY1Ja4SNblrMT5m0NsdtSbbSlwWPk9rZtTirc0rreCr6EqwLR2lZ0+xj/uVdprF3nUpWtZepR3ytFFmqHpiubiwkErDukc9POGlCGkhNaEze2CYAsVQWtASlqBKFEJYgRjTR0evfQzpLi5yrLEuPxGBfjC8xmE1y/fh37N27g9PQUp6entja8qtmao4h3pbRFfpTWqJRGXpSYzecYra9DmEhgZ1UrEyEeQam4kXJUFAWGw6G1/IqiwNnZOYSgspa+dezHZciAXEncj1prCsAUwsLkfJ/AWOCc8sYR3mEYkhXf6+Hi4gJZluHi4gI/+ad/5S7mcQAAIABJREFUQr/fx//+7/4d7t69i8PDQ3zhC1/ABx98QKxrSkGIAIu8wNGzY2xsbOD27duo6xoPHzxAkiR44403MJlM8P0Pf4AP/9f/wvHREaQQ2NrcRCADG/UtJEVdz7M5ojhErUjwFWUBIQWKknjkNUwwYcYuDmEUB0dBXNeVsXQju06w+4QD9+h9wBP0TRid1y/2q9M4KVCpCgDB9iEthiaWgATrYDCABjBfzKEMgU9RFijyBSaTCS4uLnBxcWGUAVIU4yRBkrocfV+R5oBa54ZpQuWMOpGf3Y2BVXOaOAeWrAGr3EEIK7SZnYyMLN2Yr1oDUtY0cVFD6bohkN00b7lbvbELs/7645mi64vONaWqawgo69KUSkP7qcCecuHbVSynbD+0UUm9vF63t9daaDcEMVgA0n6O7tYAYF4S7/P9z752BbQLdZj7mJemlAa0oLq/pvybTyVqoU6TztKOlOwS2sqn6/SOZSi/S8Hg5wXcQCKtl/csC0H/t50kHZB01+cuOLs9cJggxJ3zEnKVlirQ7qeuc6+Cytv7lgQ6BGDoZ9sR8d4NXjohbFtb2nHj3UhpF6+6rlFXFUIT6a3yHJGxIgEQFSsCuzh1WRvs/+YAr8vLSyRJjHfeeQd7e3uYTCZ4/PgxqqrCcG2NrPm6bqA9ft9xzmsYykZhEP84Ij/h90FMZzzOsizDycmJhb/5eK557YpYRIgixykQmIWONymlTZPius/+e2ZBkKYpdnZ2sL29jfX1dQwGA5yenuLBgwc4OzvDvXv3sL6+jt/8zd/E3t4eHj16hDt37uCDr3yFIHHzXFrROvD+++8j7fVQLBb4/ve/j42NDXzxvfdQVxU++eQT/L9/+Zd48uQJdF3j9u038NbbbyJJYpPGBRORvcBsNkWvR24A7te2y60sS8znc9snWhtXh4nytpYiXA1yjmxvKIpwPu5GJLqxbP2iKuxfl6Gw/RoFEXJDe0rsaSEo5kSjUpTSNx6PURYFKkmw/t7eHrZ3tm2q4MJQ6XJOetf6xoLbpznl52rkinvP0BCcHtKmFDHAETrlAhRhZrHFILUCe7+11qhRt66noRTD/7UzlHQrkMwbd1rrptCml0ryQbj9abYstFWtkGeZheaDIIBQ5A6whlwQALadbu6HYdRoAyO5/rr7L1poA65KFS/Gzro0gkQ48dAYZNrPe6YBzIXdeRLxteqqhoKLVORgHsAJYoZf4AlbLvjRXoR509oNvGUB3bTU+RgJ5vx2G39mLnC+wyoB1yWw28es+nvVPp9hzaLRenUgWlsRaAvAxqU7oLSXbd0KAAvWZUpUG3wi3OS35+nmNZs7YScWMzBpYw3xOdanq8naBYAkjaF0BUYWtS5Qq4q4xpUrKMHjii0uKSV2dnYwGAzQH6R48OABDg8PoZTCYDBAICVqQ2FJndxkeZISKA0vNZDYSOitrS2b+sT9FgS88Lq8ap/Y4/r167h+/TqiKLJR4FEUIwwjhGHUsMaE0LC1AYRAjRpJkljBz0oDzz+GYNfX1/HGG29ga2vL5h4/ffoUf/M3f4MHDx7g0aNH2Nrawq//+q9jfX0d0+kUX/rSl/DOO+/YCmr+mOCqaJeXl/jbv/1bBEGAd999F9l8ju985zv41re+hWdHR3jrzTdx+/Yt3Dw4AACkSYrZbIqLMdG6TicTzGYZhClUxAQ3fmAoQEJ7IRemP0mBYR801ckWCMNmJS5O1/IrjdF6w4aEy1XmjWMFmOAlCALEaYRe2rOR42EYod/vW0ECAHEcIYxCPD8+RiCo+leauHz5bJHj8vKSCr1EEaqytMWMpHRkUVaY2vWxbigYHMPB45oVsva88oV2bRRPWOEqrEFGfazsnOZ1185OzX57r168h1b6x9n5gaZhpX14v7U+8/G9rEJ701pjkS/sM4ZBSIFy0hmIsjXeeY5XlbuHe87l61+1vdZCW4AFL2tezTQCR2lad1qtAA92/hxCEvcjamWsJGVStIzWxzCVv5A2XqT3QoVYthrawqRh+fJzeZacf12qItptoWrvPH9orhbCTri3v2ueI9q37H4XniJh9aYrznuZ4PV93KuEeduiblrwywEfjWtowCtR5r7v8iCZLm0qF85id2g/7VOm0hqMohcExCZGflVSGIKQCtwIKUx1JZemk+c5wojgVKOPQmvdsKam0ymePjvExcUFlFI2PasBQXIfaAWtnS/PX0wBSv8aDofY2NjA+vo6iqIwQWilEUZzzE0db/ZVsx98Op0C4PSwALEh+/AXclZgWRFNksTmiPNxLJw4KIwFft8Eo11eXlL1sceP8Xu/93v4p3/6J8zncxwcHOCb3/wmhsMhgiDAV7/6VVy7ds0JEc9i5UpnWZbhRz/6EU5PT/FLv/RLmEwm+JM/+RP80R/9ES4uLvBzP/dl/PzP/zyuXdtFHMd4+PAhhBCGoazE5HKC8/NzSy/ql8X0U6AYHeGANZ7nbG3S2CbBxUQ0g8HAIgn/H3Xv9itJct6J/SIys7KqTtW5dZ/unu6e6enp7pkhORLJBjUiHyQZgiXaxgr7svCDgDUWftg3w49e+C/wqwDBAhb2Ut6FCEmwBAqiAQOUobtgWeTSoshhkzPTM30/90vd8xbhhy++iMjIrDqnl37oSWLYp/ISGRmX7/fdP55zAmcSLnyzFkvVUkibdpWdCeM4QhIR08Ke+Ovr61BKo99fs/2VUmI2m9i52NhYt3br2XwGdaZN9TgFKSMUXB9cKbueuB+8c3wHNdZE8rrjMSjLsgZWTtBxmdY4QoJt9DyffNS1EbKGyEopUKkRK0GYeXGaQ2ZsRdCeEHZDNwQunznxGQ//UIqSCxl+HpGMnRAmTTtm3VPaVYdlUtK+ioRbv7xHQie9ZccrDdoQwqaAtEuGARvOJtEG1nSrLx1Sfu+qYDtTSU4arFaBb5+OahNo2+M+MOAggkJlubwQpNukS9v3Fq7Ov6/W/xYJsI05CAavbUDroC7c+VXqbn6r/87l71h+hN9Wb+t8DtPva61vXt8Z2BnUfAm2zXxhfjSurWQIDFhGhpB2u10Mh0P0ej1KpqJVjbgnaQdrXm3n6XRqpa4sy5BnRU3NSLbcGbJ8Ye284XdCaEe0PBW5CiQhBpE8zzEcDrGxsYHd3V1MJhNMJzNkiwxFmZP91iQPYdspEyeW7BxgONDmv1kySpIEa2tUgnMymaDb7VqzUq/Xw2AwwIsXL7C/v49Hjx6h3+/jzTfftFqAf/qnf8KDBw+glMLbb7+NX/3VX7VM0TvvvIOrV69aHxMu0kJSphujZ8+e4eHDh7hz5w6klPjWt76Fb37zm6iqCu+99x6++tWvIZISw+HQJoYhNbRCrDTGoxFOT06RlZQDu9vt2hAoBmPA2T/LqoI0IMXjxn1hu/Z8voA2JpLT01O8ePHCmhwIRFN0uz3LHLIKPTKgHUmqY8DzkKYdpN0E3bSLtTViyNihsKo0Tk9PsVgsMJmMMTo7RVkUGA4GxEAZjQqbA3xaxxJ4lmUoi9LRM28PhJEx/LdP83wVuwV9plPaaLuUCZsVusZocps+42l4U2+fkO06lOZ5D/j7JdzbNSEo3OsNpqHFT8bMK3WKwswcM2DC+TwgNtZXRDKCkIUB8MiGr4mSmJk4clEKq45XG7ThbKn+omBg5dAHgQpc+hKoq1sth1yQI0lVVpaLZG8r5zHI9u64NqE16U3Xvaa5jCdLWEBTemyTINsmhj2Xlz2zHKDdPfXfYZ512Xqf3/6ytsI+LLunrT/L2g2BMSQCTQncJxZAqAwLmQJNRiY7L0IIGMeA1r62zbmvTrbnQHNMquJOLfSJAE9b7Q2ksKC+vb0NrTXyPDNq6DlJc9XExvOyNBJFsbWlMsdflKX1yOa89XZPCGE9WYuiwHQ6xfr6Oo2akdCn0ylOTk7w+PFj7O3uIs8oW1jScSlGE1P6kKVF3m/0/bKWscufH1YFc8pJHkeOD+b45u9+97s2Nno0GuGtt96yVbaOjo7w5MkTpGmKr371q3jvvfewWCywvb1N+ce3tmzok9VYGEaC+/P0yVP8zd/8DW7evInr16/jW9/6Fn7/938fi8UCt2/fxi/90i9BVRUiKXF8RFqMy5d3kC0otOxofoTpdIrpZEr1z+Hsm0qVqKoCWsc1sNCeNzdAORy00cJwCB6viRcvXlBJ0cUCURRhMpkY7UaKyWSKNO2gY8qYksSrAZMUKpIM2Cm2tjaxfWkDnU6KTpLWfCL29w9wcHBotBc9r2AM+WEUiwVpWUoFrQWiKIGUBZKkgySJbf/KskKSxG7Ne/vLt7/znDDIMlAzs+cng4lkBCi3VytVUXiYB7ZA3amNxsE56lmAhzJj6/aIVtr6efjg7c8X5U0QgE8XzH1WODlHgGBGhoGd1jsz0UBZFCRUWmGNTQPOfOBrq3x/hc80aAvApkAEHJcnRQRhOBUArUDHRMfPTlaPF6x7CgpuC674COAmx0k47RK0gCDJZ8l4+xJ1m1StoQHBHC3bcKT3qw2UVjuDXQRkl0m/F2EM2u/heVj9Tp8LXtVmK3PjqblqgNx4j/QcGIUbyHBDBsxQ2zjX3q00pFF3J6ZGMhErANAQkUQsE0jzHBd2YIelJIkhZQ9CkOpxrT/AYpFbqYyInESlyhoYsAMQEVwK54ljp34molh3ruFvmc1mePjwIc7OzjAajQADpGmaQunKthHHMXq9HmazmSXELl+5q/HNxJmJNmse8jy3nuHMLAC0H3d3d/H9738fn376KbTWuHHjBu7evYsoinBwcIDFYoEbN27gnXfewc2bNzGdTnHt2jW8++67WBsMMJlMbFIXJsSbm5vWFrv74gX+6q/+Cjdv3sS9e/fwJ3/yJ/ijP/ojFEWBr3zlK/jiF7+ItbU1jMdjRFGE+XyObq+HOOkgTXuYL+bGFk221jiKPZsu5WYgRsZ30BL2G8kLWVjnU6WVTWkqhESeU9ISX3vBGojZbA4hBOZziTSlePNetwt0tDW7SCEQR8QYbm5uYn19A0VeWBp3enqKn/70pzg4OELaSXH50mUMhwPM51NMp1Mn2OgMZV5SeU9F62CtPzBMWYl8kVGctEcPQiaNpU3Oec6VudicYKtzGfU/CVcCkaiX5K10ZYCyrqr2/6X1J2jNe07B5MhmbOKakxjRfq9U3UnOV93rqjI5yutx5rV9boB7mcaa7vW1dew1792jFJQdQ1a11xkTHgdeZ36xqGXHKw3aAINPZAPmBaT19uY0pVFU915k25OfmQwA4iiBEHAx2YJU7xSTx7GmsJvSt38QKJ8jZRqvuKaEWPsiurUGPAZ8rEAvyKdBkCXff5QXP7dfb6OZM/c8oF517mc9VgFweO08Kb9NKjdXVkrI8LzKKd6r+Y4w6iR8Z6gdEGYenD1So6oKZLmAiCPERlPjckxLZJmze7KPRZp2sbY2hKo0ptMZ5vMFsmxu31lWua0ExZnIqM5wYfwzJKAFIm8XCyGoVnUUUclPaCRxgslkgvmc2u50OugkCQQItKfGns3cPquLw2xcvvQNOI0SSxlFQap6djKTUtrsW0IInJ2dYX9/H0VR4PXXX8ev//qvQwiBg4MDRFGEO3fu4Nq1a+j1ephOp7h79y7ee+89lGWJw4MDZFlmiWySJNjY2ICMIsymUzx58gT/7/f/0YL+H/7hH+Ib3/gGOp0Ovva1r+HLX/4ypJQYj8cQQlChjCLHPFugUhVGoxEODg5wdjbC2WhswqhovURCQmgBVVZQZQXICJQQSdgQQkqYA6PiFCgr5z1elhWgyaP75IRKi25sbCCKIuzs7EAphfF4bO3OaUqajvXhEBg4gu5XDsuy3MRmK0wmEzx69AgHBweQMsL9L9+HNJqIosjR6aRI4g6yjJLLnJycIstyJB3yU0hiV3jk7GyOoihJcImbtE5KidLkEWCJnPPiCyFqxUxssQ8z/6Zocm2/SjihjPdXDTyhbVKrKnZCl8/MAk4yF6b0rkJT5c4qbaEBLV1uA58RCN8fx804bbf24dHiev+tNpAAhRgLAfjqdl7LQtT9ID7ToM2EkQkgS9oQnMiABrrIMysVKMvZepW3BOcONwPihGaaIMFSrbDx2/x+dsAIF1u7zTMChKbSmS0g4kvZfE4aFYoQVCObZ18LfzGws8VysG0wEy0geBEp9qJHqNlotnu+9LxM2uaj7my0uq/LTAdWwgYxaMz41O9p/QrH+LAnmt38CtAl+n0gSWJbha5UThJladBX77EkLQSrwihGnj1/k6RCVRVWPc32aS5zeXJyQuFbMkIc07eSyjMIXQGQZxnGMDbD1Dn9dTod9Ho9sxalVV1HKrJj2O12UZYlRqNRq+TDNmo3N2TP5r3XM2FIBwZoGRAePXqEvb093L59G7/5m7+JN954Aw8fPkS/38fly5chhMD+/j6EELh//z7eeustAKA84F6lM7YDc6Wvp0+f4tGjR3j3nc/h9dffwO/+7u/i937v95CmKX7hF34BX/jCFyAEOZoRkCTQAljMZlgsFnj69KmpwU3MVVHkiJMEkYyMNiNxmetsBjzhNDQmdpt8nSMQE+fVIWCBYr4gByYhrCf6w4cPMRqNUFUKaUrhdMMh+QToSpEd1GMAy6LAfD7HyckJ8pw8vx89eoSqqnD//n38wi/8InSl8OMf/xhlWZImRSkcHBzg6OgIJyenKIoS3S7VQ6+0QllWyLMc2YLKurIjblteiqIokBuw5hh7BmYyGSU1Cdvasj0p21+n7HYXarP8v7Xx34hiAaVgQdzf45SPX0HoCkKQt4fSddCm6yATpyEL9jpcFjuKHyeATTrtNJf3N0XQ0Pqv7weSrn3JmzPG+WScMYDX1iotJx+vPGh3Oomt16q1RqUrU4aQSgqWZUkhOOy5bUBaRs7DvOasZiRmsHpDOLUWAArI97wPGX4o25OvFq+DjxPsTJYxf1HBV4+3eLmz5CK8TEm+zYXZBgZuT1oMAdAH7VWTb5+rnyRgan1ANsBtafPC/3bqu89V+n04D7j9TdB+ndtqlkRt6VgNbNzZoE3Ux5+/gzQtEkoDqiqhAHS6qc3HrLV20mllMpdx3wRHJETg8EOtK5SaMmiRxsAr8agVyqLCfJ5hdDY2RDq3aTP5PyEEirJCFGnExv5YqgpCAVpU6HZpbTJBtbWwqwpJh+5PuwNUqo+z01Ob3GQyHgNAzXua81hrXWdeiWhyKtcOZSCbzTCdUVKPxWKB0XiMg4MDXLlyBb/xG7+B27dv49Hjx1gsFhiur6MsS+zu7SKKJL7w3hdw7+17ADT29w9wenZmAcKv2HV8fIxnz5/j+PgYX/rSl/D667fw777xDfyv3/h3SOIY/+y/+A382q/956Yq2Ams1sU4BqVpCoDCttbW1jCdzjAenUFrU3IXgACppQmUKA6b/A94/dB+oZCtClVU1saGGZksy1AZxy4Gv9lshtFoVIvblpJU4NL4D2RZZoGQJW4IqtT17Bn5RFy9ehV37tzB5z//ecznc+yZeuNaU1ravf19nJ6eoihypN0U6xuUrpW95UtUKIocRZ4BmvLk8x5Rhtlk9XeWZSiMlO3KeUZWsnaAnViGg7aSSR3t7WsAXg0Izejt0QmK1CDflMjsJQ0tXf9YTR1LY1PWEVN4UxuC2lTGEVkwzZDC1o6w/dEwEjozKxrdtF2Y6KY92h9a2/Yt7TR4oLUp5KMYb6gaoVbKjLChqdqrHMlEY8XxSoM2BEm+gEZRFq32aSEEhJYmXMIQawmbq7buAa4Zp60dRYDCVXxlqnu9udOoRP2603w4FY1R2wQcIAF/HahaAaUF0MK/GfAZVleGCLyEdK2989p7tvkcjYdoGQd3IwxBC7jMc7jHtn7WuWmnGanfyj/aZrDettbkh0Zj6M1FoDWxLXrMAv9NCXxMTL+mCATOee1LxxLkHMa53JOE1M4+UChVQCtOOalsbG+e58izHPM5pQ8djcYoihJrawPr3ZukHRdyoyujpoVti/w9yA5YVarmEORipml/3LhxA5ubm/jggw8QSYncVHgSoDrYMvIlJAZv2nsskTlTVYwsy/GjH/0Io9EIQgg8fvwYAHD12jXcunUL77z7Ln7wT/+EDz74ANeuXcNoPIbWGr1eF3fv3cOtN9/AIptjf38fo9EI83kGAYrBllJiNB5jPB7j+PgY0+kUX/rSl3D16lX8z7/zO/gP/+Hfo5t28fWvfx3/8r/5l6iqCo+fPAGb02hencMUx6CXZYnDw0PMZlNAAzKiPNaG+hrAjC0x5zwPrMkhB1ZqWymX88FPQOKPGVf0YgmePMgTpB74sWd6VVUoqwplVSLLcxRc+U0Ar712HZcvX4ZSGh988GNyCssLnHE2ubNTZCaVbbfXtX3O8xxJJ6G0uCYhC2kGCgtaPoNhQdswT3ydGUFWi0cR17+OGoy0ZXO8fcWgrhXRZikcUy2kMQUaYNYa5hyDbN2rXWsBXRFgRlJAejHcsSfcKEUaN5t+GE56Z7Dneztp03tcygj9HuXGZzW8z6Txs/65UCOljfaPK1TyfZH4jKvHAW0z/HDlG9+hwErQ2hUpAJi4OKewNkkulHYFhPH6bJJ9+9wSKdH+hqYctKEUF0jG/Ewb6K4C7mVq7qVtLWm37X3nq8r9+/i7W57RMCqj1d92Xr+W3dME89XfBW9GfXxuG2df6mfpoG4GcQl+hNDW1sy2YF6DpBKtYMpPQwinaeDQJPa7KAtlJPQSWeYkmNBeyB7qUkp00g40YPZGYeyWHUjpa2o0oJ2KllSVbr1yrG2SJLh+/TquXr2Ks7MzvHjxAsfHx1gsMiQJ2aa1Nzb+HPC/XPazKAocHBzgk08e4tmzp+AqVYeHh/j617+OO3fu4PT01KrNkyTBYrEAadQ6GA5JAvzkk08gpcR8PkeWZUg7PaxvrCNJEhwcHGBvb89eu3fvHpIkwW//9m/jT//0/8BwMMRXv/pV/Nqv/RqklPjhD39oKnKZBEvQEJpjcCsbL16WJWazGfKiQCRkzdmtUq4qF8+b9fwVnrYOqIG1L2RYps+zWXJ7/LuqKuOQStWsFDRlZzQpVDkHupQSlaowHA6RpinKssTp6allBris5mKxQCdN0ev3obVugC17WxMDWRlmQ1nNDO0JZcG8qiqUxgzJYE0OZx0kcWLH2DfV1G287SIk03Jol1gl1K5Z0UdTJrPQRClgFNTSASE7SvqMPjNrGoD0/GE4qoTV5ABnr2tCpBTC7gs/42UI0I3/lIaQugbaUHWveZ8RWXa80qBdFlStR0rpwrs8sLb/wlUTAmDLbPrEGGiX5qSgsA7i8mCperjAfDU2//bbV6ZcooAjaiGhC59r+x32cxWorbJ/tEmQbe353G/Y11DSdTqK5vjU30EOUjbPUaPd8O3L2hEW8MK+h8DdDuSkkmJ1PX1j1Hi+7Tk7fALWs99qUzx1+GKxsI5X7HfBNmmYEpkaACJpAZ4dtIqiQFW6bFJ5XtjwmcViUXMcYxUp5/0+PT3FYj5DZjyeSSpOICMXr8zOZKRSptzczDREUYQ8z3FwcAAhJMpCYWN9CyfHZzg5OYEQEkncgRQxZOxKh3JYF++9JEkwHA5xeHiI4+NjHB4e4uHDj7G1tYmrV68ijmPcvn0b9+/ftyA1n8+xubmJJCEHOR7LPM9xcnKCsiS7fp5Tta/h+hCXL1/GgwcP8PHHHwOArft9cnKCb37zm/jrv/5rbG1t4/33fxE/93M/hzzP8b3vfQ/Hx8c2FSsgjIq7tE5fLBhMp1NkWUbhSlEY8oman4FfMcsHY/+3H5rkOxkxs+SvOfYRYJBhVbMP5qxV4XfxevNLq/oAwVqdPM+RzakeeydO0Ov3oaoKs9kMs4JCYaEIEql/BOYKXHuBcnoLSJR5ZtdjmlL7HZMhz3nZ11Xgyxhse978I0NzlHC0RkppqtEaExX7mIh6W1IAWgpjbuJ2pNWCkJbI04iK5rsgjNuqdqFr4SEkg7ZGpajaF41/XcJmoIb/WzCom5epujTehgfh8UqDtgagFU2Qc95xtlUC7siaUEnarbvV83n7rxW8uMKSAyTa147rss/zsy0Su39XGIhPEjxqBKB27RxwXjaBPqi29ccH7DZJ2u/LMoYhZEra+tTet8Ypt0A9iZcnYhX3fV4f2+6nOXRx83XzxLJ2tGUw6IJZJKxzDu4nAkt/s6MYqweZ2JZlSd7GhuDO53MLpM4TGNZuySUyWWLlbFa9Xq+mWdJaU0nJ6ci+ezabQWtOaJEikmQThdYecDRrOJdlieOTE/zkwQN88Ytfxo0bN5DnOY6OjmpJRCLNTkX1ggtSSmxubqIoCnz88cd48uSJ1Yx97Wtfw9tvv40f/OAHePbsGSaTiQ1z0ppsxpubm1BK4ezsDEIIa4dVlUJ/rYcoinDp0iXcuH4DDx48wHe/+11orbG1tYXBYIDHjx/jz/7sz/CTn/wE169fx8+/90V87t3PIZIRdnd3AcDOC2lPpB3zypOYR6MRJpORVZdHUtrsaiKSEJVEpF2IEyd0iQJBgvejX7va93IWXAtam0JFUhiPYo28LAApsL7hCrLUQlKFqDmGkZmksuuGtTis7WGmUAqB69evo9frWTv61FQ8o6x1Ze0bSGuUmCpWpIGsKvKa55CxXreHTpoiMals/XGg/e7Sd66kUXw4ItwiYZtzpi+hVszf+7TDyWchbMfRYC4KE2onjaOaYMey5fQXECYGm80oRm73aAWr75msWAZGGKc3xRKBo0/8/CqBCHjFQVsKsmMJQZuHF3A7R8IqTcCBQyDRQjonI7hJEULYZO/8uP3bDD4xBE3AsDZsAQ8cArsNHLGv9acFIC8C1OG5NvBfBqyN88H7lkvcvvS6+qC6vrCg6dr272n/lvMOH8BqaiVB9iLtdTFc+zWG2v9m68PK570b0RxfDvPi/hfGoxeATWQRRTE6SQocCX0YAAAgAElEQVShYapulTZLGEtSJD0VFqT5+/gbu11ng2RpnEB6irIowQk8OLEGSYDaMhSqUlDS2VV9wi8E2SqTOMaTp09x7+13cO21a7ieX8eLvV18/PHHUFojKQt0yg6qxKRYTVhad9qPTz/9FN///vextraGGzdu4Pr11/DLv/zL6HQ6+Pjjj7G9vY3RaISBycjF74+iCMPhEKMRlf0cDoeYTCYU9tTt4vXXb+De3XuYzeb4i7/4C4xGI9y9exeXL1/Gw4cP8Zd/+ZfY29vD1tYW7t+/j5vXb9px5fZ5TLmvSilUJTnH8fmzszNkWYYoIuHAVmsTEYSRgpVSFmhLVYENEX7NcB5TX3Li8WYTilOBe06RIEYlTVNsbm0Fdu66FscBonnSqK/ZFMElVq9cuYJbt97AcDCAgLSe+xxCyCmcOalPPYMXJa+qlEAnTqzHOyfg4URCXCSlbY8sOy7CgHtXIVgA003AXvZs2zv8fUXqcU9l761HNpCuFEzMeYo0YrCua1qkIAExBGDO5eEEmea9n2lJG0KYRBTSlk/0iZK5BawGZYIbSiZegxBiyQLzcKkNxFhq9l+soZ1UrpcMtgHtVRJlG2j7ExguuEbfWw6SMJec9znUlv6EbS9jGMgpa2kXWvrIaqHm4vS/eVkb4WZ10rWob8LWd8Op1bxvcalA65I3L4hQ3UcqM+eYxe/kkMM8z5F2UqytDZF2XLwqQGr1RTa3zEZRFFhkmVVxsvMRO7YJQepnDm2yqvP5HLExGSUbMXJTzpPVyeSsw1IdlRBlCSM3ebIZyPtra0g6HTx7/hyXd3YAIbCzs4ODgwOMx2MkydBjKBSU5kQi1L+DgwPs7u5iMBjgnXfewWAwwOXLlzEejzGfz7G2tma/gat9sXTI6Ulv3bqFvb09e66qKgwHQ9x+8y1oLfCnf/pt7O3t4f79+7h9+zZ++MMf4jvf+Q5GoxHeeOMN3L59Gzdv3kQnSY1zkavU5KsqVck5HCooBeQ5ZY47OT21vgNSch4Izo7oxUebdcBEX0FDqwpJlFjAZrsxzTfNsy8BMzg473SgYt+C167j6pWrlE3LgCTHcwMuaxZf49+9Xh9KKZycnCBNU7z77ru4ffs25nP6tpOTU+zt7dl1VmnK1CekBKSCiCQ6nQRVWSCKBMpKQyCCjKNa5j3Orx/GX4f7zdFh1XK+uTdDelfbbyIye3S1MOOdgQxK7fr7Wph5VcGeZzu40soKYnVhpfYKwiDhrmtdp90srHFBG9sXGRmBBag56lm6db7w8kqDtjDqB2vCEJ4KFABPAp0Pn21bKJ4toeVd9hlunQEuAFBhwao+Sa3vp242+tPGKa5ayOdxsm2A1VjOQTusdmpKzxwWZzpvmR13XTDFafbEGx/7JvOsW+Btm9T/BgvG50jjVsoxJFDI9hAxIrqht+kyzlbAMYEt7xIRyEbsHG6sZKUUlAKShNSy/X4f/X7fSsKdToJKOZV4VZWAgLVZc38YvKQg6XA2m9lc0QS2fSqTmaY4OjnC8fGRp7I1a93kFmJvZj+GnNthyfSjjz7C2tqaLSpy7do1p6420hyr9hjcWLWfpineeecdXLlyBUJQUo9/+Id/QJqm1uObHb2Y2LPWYGdnB5ubm+j3+3j27Jkdl9lshg8//BA/+tGP8ODBA7z//vt466238ODBA3z7299Gnud4++238dZbb9m82wARXYm6Otn954qpcN/H0wmyPIfSAuQB7zzLyf5t1NxwGeTY58C3UYeJZ1jKZs2MEOwgRcurUJRSuSoppWq3kyKJY8xnM2sWuXLlirVbC0G1zDudjnFeA+IoQq+b4vKlS5hMKetZt9vFeDzGxx9/iDynCITFIqup1pmZIBW7K/8pTRiUkBLr6+soigJHR0f2G5gBDdNtttMj3kfLD0fGTVy0tzfdv85D3yo1a+/jexutBn2p/x1WUvRp/PmwKUwVLz+u2kjNso5F5N8DS085qtfHoXAcP9PqcZZ0zlMbrLIV+885laoj8va6L2QFz9rB9H4T4NV/t4G3r69tAGbLN60C51WbpNFntC3f5ndpEdhzXadBahzPNBA4i+jAdyBsnzUjfp9bxyh8+xKg9p8N26mHlyi0Vfiq9yvczMy8tCfOCd8phKxJUL4WoFIKi2xhbYRsOyUQSwEBm44ziiIUeWlDZVRZYgZgZiIm8rLEYjbDzKiNhRBIjD04SmJAaJPKtK5F0ppCZti2zep1vs7EW0ppJDCF58+fAwDW19exsbGBjY0NKsxhVbMu53qn4+pPp2mKwWCAS5cuYTaboSwLC/hcLUxrbR3xOKc65w7f2NiA1hoPHz7E7u4uer0e5vM5fvCDH2A2m+Hu3bvY2dnB3/7t3+KP//iPIYTAl7/8Zbzxxhu2+hcBJM2TD1BWyjYeu+wdXZkQKlu5S8DktwYAjShiAiyMY6tjptjzmjUGvvnBt2Mz2LEd31/1DJy+vfrw8BBKKVsGtdPpYDaboaoqdLtdbGxsWMYL8FTuZYlsvkAkJKaTKZ6Xz7E26FkP+KJw48HPu2QxbOMltX/S6eDyxgYA4ODgwIxNHbR5nS8DG/5WZx3mHtuNBBjNhRMGHI1t2KMhKO2ocvvWATg3uoyOam9feLRawKrFAdg59lsSQtTqw7u2m+3VzWn1b7YJu+w3C/s8v6fNLLnseKVBW8D7wODDmBvmv+Hf6/3dWAAhqAf02Xon8r3wJtHvm3AqWX4Pb1TbVgNY6oATXmvr87IJDM+3SabhfW1MAH/DeW21LahVfWMCTxLp+Qux7ZtDE0E4Nm3jSETaMRjha0MvX1ZrmZ6DJez6ebfe2D5JbUU1IkbA4BX3MIlFchMnqzWF8Fy6tIVer4exiU/OohxakQQ8M6Feo9HIqloXi4X9ZqUUut0e0l4XRZnbSkzhvFiwMhXH1ILmwWZygr/mJNKUKlmRNzmpX7e3t3F0dGTzUwtJxL7f7yHPSxuuBcBKoADZ9e/evYOqqnByclKLXZ1MXJlIjo3e2trC7u4uZrMZAFgwjOMY29vb6PV6ePToEf7gD/4A8/kc77//Pu7cuYNer2dBk9dyxXHyngbEriXNjlVGMg5Ul07Sk6AMfKRKjeIYMkgk4odz+aUVfZrk0tyad5hx5Gd4njhU6+zsDL1eD+uDIaqixPHhESBM0aSORjancqdFSVnxSkHfN51NbKggOT3OIKS2OQGqyqWg9T3gQ3ra7/dtCluuEsb9ZOkaRosTahp5PYX72T8cvjY1apZnNtf9tWzeZMDaS2RVb5XfbO/jBDitwk8LTeI3SeEx7ktpnBMU/G9pu8//4bMG/vPn0Uf/eKVBG0JASFd/lYgmUOeeAF/ICsHlPGlVe57DAuQR6N5hmAXApr/zmQXB9xmQEJJVITCNNPuwSorje8M+h3bVlqfBebWFCU3SHrvhvjUYB8Pt+bancAHavuimP0D7Qe+n20zCfQFAGyuS8G475yBCrMCxq2COVjC4+t/vOF5h9JB+V33iRFoSnvOQQEh73naVpSSTUYkqarnCMky0SYXMz1SoVIm8oHap/OXUqMFJ6p5MJphN58aznOZ5bAp6jEajmicwvyNNO1gbrAGCIieiSNvY3LW1NQhh1JwKIDs2pUaNdIwyiVEWBYGQ0QLwmClFOayZUF++fBnD4ZBynk+mbOFHWSocH5/i+PgYZVni9u03sb4+NMBDaUJv3LiBO3fuUFjRbIaTkxPL3HA+bgaUvb09qqo1nUIIgcFgYPOKc03rS1tbePCTn6AoCly9ehV379613tC+mlZVlBnRj4uurSeeUxOeWRUlFcYAbFZFWh90XemKSmLGEjKWQEn2bnbaYkfCNO5AJomxc4LicbUpz2jWijJ2ZI5xFkKg2+1hscjBe5BD9Bb5ArP5FJ00sVK9kMBk2jXOUgBUBVEA0+kMcRQTYGtF9upSYzHPTFIdyoXOa8SvyMVMIZllyAs8yzOMxxMsTJ53+q8CR+Uw3WCQbROKeHv7c9CmidTgKo40O6tUg25vN660/hae9N5Gs3weoSYlB38tgWwjFHBNA3PWkCbGD1/L6AsK7pt8TaXDi8+4epy5mVD10DIJSzi+835broyUMN5LnM2D1DPmHtGcViv18cLTtdlb2Qdfwl4lzbZJw+48g1ntDbCi5pI2IASEXnG9fnP9/Svu9Bcg/9bBAg651KVvtSDobY5aV+qq7pBZDzUGvmqcroWJGmjc/BXAkjf/Dc3OZ5QRrd/v25KJLMWwlqGqypq6tNPpmMIOFKu9mGeYzajqU1EUmIxGtt42MwKk0iQ1eK/XRdolwFNKYzKZ4sWLF6aOcgWlKgCJY7CkhsnAawGNmQFWj7NJgEKAKpvKlJ2dZCTJuU1K5HmBvb09PH78GF/72lfxpS99CdPpBHt7e4giiY2NTWxubkBKiY2NDezs7GA0GmGxWNhIEAYNDhc6OzurxSoPBgMsFguMx2O8++67uPXGLXz7T7+NXreLe3fvYnt72zpH8bwppQDlNF5hkgvOfGUXiFY281xmbL52rWoFVQEqjmh/wBSHiaisr/Uuh0aRZ4g0pUtmTQiMNobe6ZwZWSNANccHmM8znJ6egUs7Vhw/PesiSWKki9RqwhbZAvPFDN1uj2ztQpic4QXQIS2D0s4+XRi1NqXKlDZcbTKZWGYHgHUsq6oK48kEs9mcUpt6Fd4kpwgNyYOoM73+/loqPQb7UTHtDW4NtQC8Z88/2rEhPOrmCsNscb88Urrcwu3u4IQwzozCe+s8n5yaGGX/akuU5R+fAdA+f6aW1Ylepo4+D5waAAltg/99NW2bKpfbX7Zol2kClqk4255vtC2E4RXqHONFwJ9ZzvMYnQYOrzh8kKPHmpvSXlkxVtzBUIW/SnOxasy5PQjdGPcaaHNiGO00Ov49UkrkRYEszyAkrBrUqhC995YlhXqxVMu1rllNmuULlFUOjQqL+aKWLANCWEmHEjp0kHQ6gCZil+c5ptMZAJJQOae5e7+EEPUQObavE6AHSYoklWaczWY4PDzE+vrQhgj1+z0URY69vT3s7e1hZ+cybt9+E91uitlsirU1si13uz2rEu73+7h06RImkwl2d3ct48J9YY9yXxJhKXRjYwM3btzAm2++iT//8z/Hxw8/xq1bt2wsuR/+aROeGNNEaVTAfkggv9uvysVZ52opkT1J0QfcJIpRxRUKk85TSolIRtAKloGAcOr4NkacvzNNU2xubuHk5LS2TrXWmE6n6PVSywAyI8A+CUmSAqAEIpEZx0pVNScuyzyYwy+mlGWZLe0phLBmjjzPURrv98V8Zp3f4jiGMiU8eaxtrH5jp7nvWLUHw/1b16Q2NY6rBLKLHuE72+hrG11Z9jopRK06YAi0zNQ15SSmjaHUzQwmIJb44/DxyoO2fyybMIGQ8LY/17ZwmoDRsuA8wAoX0qp3ruaymhu7jbm4MPCGbbeohto3mmiszLa+StZze5nB2uejpY+s0fal5kAtvWz+mHjyc+cyF1jO8NBFYz7QzbGx9jKWFuD+Dt+jNIyTDiU74bSOXI+apeTpdGqJJhP7ygMVJq5ZliEvchRVSSpOQcVxClWgAiXTSLopoiQGFRtxyTA2N7cwnU5MNSpiHlRl1G+iTgR9qV+a/9iRjaSyBEJoTCYjzOdTL+XoNRwfH+Po6BDXr7+G69dfw2QywUcffWQ0DRGUgkkO42LOh8MhNjc3reTMGgQ/wYsf56y1xmAwwL1797BYLPCd73wH/8/f/z2u37iBW7duYTgc1lLB+vHQUEClKuPBr+wa8/cVpxkuitIyJE7jAMCoqrVSpDpPOPd63fEriWJ00y4WyQJVQWlrq0w19nQYXcDfyBnYwqMsSxNql1hvfo79XiwW6HZ7tn2baa0yYWpwYGPNNSiQ55SmNE1T3Lp1C6+99hqiKMKzZ88xGh1aM0aWZZhNJyiK3CSZiXB6cmLMGeRpzqF+gulGyzZrCD2B9H2eMNN2/8o9/RLHKvtza//b+sr3iCZNWiZQ2PNa8qrku+xrbArVcz7zMwXabZNOEqb5e9mAeUqONqJfn8AQ5EgUvQi397JSn/u7KYk2wHYZYDe7DQBcudbvnQs5qZ1tt0kta76uRF7SFdF05HKIDWdGwGp1moaGaEmHaq+v4OiXb8o6iDU2luctTOmqKNrAJ7i8sUjyqGxqTpZMGMBZmvMlQp/R84tJWC9kzfZDoKrKmuc5S6GseYijDtbWBgZ4tAUvUoe7ZEC+gyR/A0u8oWTDWd04rGl/fx+9Xg/9fh9FUWA4HKJrSm+Ox2PLBEwmRPi3traMVE7Zt1gVyzWy2YPdl/zDNJ4nJyf47ne/i48++gjHx8e4fv06XnvtNQwGAyqZabQUvlNVZWzTykosHJJHJhBagcKO+3w+t1K2n+XNX1tKUQW2OEqo3C6ASFKaUxWTej+JE1QFhW6JyGSQi6IGrfKXI8dzsyqb5ySKIiilsFgsyN/BZLqL49hjUDzPcxBwoxT2nTyW2mhipKwwHK7j5s0bGAzWkGUZjo+P8eTJU5yenmE6nWIymWA8HmM6HSOOY+zs7EBA4GB/3zNjxLQ3jM+H0tpWFwjX0IUBseX3quM/RcpeRiPahK5Wer2iLwIAonYzH7XFpl2Pxtl+WfHGjR8E5AU+8TMB2m2E2A76kvuE4QIF/0+Y8CZvM7WDMHGQBEpWvAZQV9+s6qd/rFQVsQcdO7ZdxDsLLeMRaAHMRTCz4Z5rtiEhVgRu1Q8phElFspp5YS50GciufM6/D6SCWmY3W/b8st/h0WwnkAJEbRV4z4GqLpUlZCSslzhL0gAwHA4taDMxDb+PQdZVWKoXmODnkyShkpymbQI3XueoZfcCyNYdRRIS0jIAIXPkS2R8nhzdUgscx8fHmM1m+Pmf/3ncu3cPz58/t85MAKwnNanM9zGfL3Dt2jV84QtfwO7uC5ycnACA9X7n+Gx/bubzOfI8R6/Xs8DD1bvyPMfNmzexPhxaeziHWrHdn4GOCaKGUzUKX0XmzbnWGotsYTOD1QHb5Wbg+SHVOzlNMS0RQiCJYiRxjFxGlA7U2291iVvYteVCxHStWIg/R2xCOTk5wf7+Pq5evWrPZ9kCnU5KDm6SCojASznLB8eQb2xs4N1330Wv18Pu7i5evNjF6emZLShyenqK/f195FmG69ev4fabt3F4eIhnz57ZLH9h1jP7XZ6wFO4lnwlvEwjC627O3FyEzKY/RucdIX1fhiHh2IfvkxdkFMK2auY2q31URNNaAP5l1P+vNGg3pOpA4nQf21wcWmvjRGLulatto4AnyQcbvY0L958PpUR/UpZ6fgvKuuT6DGtbXrbI2sbHth0CvuBGmZQJi9ruMaNFaOEnG4uo1rzRDCwF3/ZrbZu07Z31+883e7RtxJCIXURLwjbM5qZzgKc1qcaJ4CvIKLYEmN/LoMLzGGaOYhDnKmH8NwMi28FZauJqSt5H2j4ppa10T8S17iegdXMNMnBQZTCK42apbzab4ezsDJPJBPP5HDdu3MDNmzeRJAmuXLmC8XiM/f19m82M7aQnJycYDtfxK7/yK3jzzTfx4x9/gJ2dHcRxbMG+2+1ie3vbJk/xTQVssz08PERVVbhx44Z17uN+svTItmhfugzn3E/HyZoSHrP5nDz2ffusWx/eOrJj5WzxLPV2kg7KpECappjPM5QlpSJlJqKeQlXU2iXp3oULogH20oZd9ft9rK+v22uz2dxEDUTUWVVBKOE50rmDfSyOjo5wenpqypwuMB5PcHR0hCdPnmA0GuH69ddw78tfws7ly3j+/DmeP39ecw6kdcbOfXVTRus+aqGL5zHqofTr08E2mt2mmbvIEe4Ff6+09XVpv2GoKmuzWwSixqGdRocZEv97+fD9EdqOVxq0gfOlJ8fJut8M2G2THrbRvNYmW7X36WW4I76PpFABP07NB+5ljEqDy/UO3QK8Ak7Nq7VR8gthF5tntV35jY3zDUV5+11tbZynirpIX0KiEF5vu3eZ3alNNe7bmd2YS6MmpzH01dZcJY7vZemJVJOUhpeK3STkzMOe2vM5JsauKeBUpgxeLD1yBjHuL/sWCAFj0ybVM0v0oSmn7ZtJhU7AkiYJIATGJuyKGQdylqJMZYeHhxgOh7h+/Qb29w8wmUxRFLlti8pqDnDz5k3s7OzgRz/6EYqiwFtvvYXnz5/bePTbt29jbW0NDx48wGg0sup+Ichhj73Mv/KVryBJEozHY+uFbTOZmX85e5yfclIrZRlhny7UCKLx0OYCLr6mgZkcwJVvJIB1HvfsRyAAm4e72+2SlkS7JCvcZ45+cWtQ1zLShaDN/WXtzenpqU04QznIE3ufn2ueTPqGdVcV8lwZE8UUZ2cnUAqYTqfY29vD06fPMZ1OceXKDt5//yu4fv06skWGD3/6U3z66ac2Xt4HGNZIRLFExGGRS4Cbx6mNMW9bk8vAso3WvczRRjNXaj5xQbokgmfgmQ1bvsVqufwmWA8uBKACoescHflnDrQbhzcJdkJYLe5NfMgdtrVrCWKbu1YL8T+vz/6irS1ABu7a/fWQsnChrWRedFuSFAEBVms1+1eT0e2i8sPWAB+fbb9MT1cdRAyjxrkmg7W6jbYjHJNV0vpFuHwdrJ+iKKzdlUOetH1eQClt1aosKUURF5lwc0ZETpoMYjGkjqElJTgpywrZfIHx6ZkFgVhGUFKhQNHop+8kRYAtIU26Vh/UmbgyQ6G1rmV6CgYKqihRaCAvSxwdHeHk5ATr6+vY2dmxyWCKosDJyQnu3LljbdPr6xvGqYy+J01TXLp0CUIAf/d3f4dnz55iMFjDs2fP8OGHH2I8HuONN97A9vY2Tk9Pa1XE2AxASVv6+PznP4/Pfe5zODw8dNnKgvm10h+0W2tGPQ7hAJsB2M6/pvj1oiioJGWwFngf1tdH0ydASglVEePARTSSJAHY+Q++tOTC6nzpKsvy1m/j6/z8dDrF8+fPsba2hvX1dQgh0e/3TZw7Sb6ARqUkKnbKK8patbmzM4U8L7C7SwVDbt16HXfu3MG1a9dQVRWePn2KTz/5BM+fPcfh4SF6vZ5linxnPwCIk8iNR2ByCY9l++4iKmpfGm07lr3vPMHgIpL6eSBuESK8j5fZEvV3rX92Teoa6l8EXz5ToN2qhhai9sFSSlKLB4PA2XzaJrWmxsH5A7eKmwp/twNHc1Hwe0Op+iIqJsLZ8NpyLja8TwhWD3sL3/IXDOIOqqlQyPINJaWoAX37RmraG/moScie05rfVutGWPaFSwiD/7zWsHZEBicAFhSlcM+wTZfnioA3Rpz4ucgrlCWpjpXSSGTHqsmn0ylOT08tY8D22lNTojJ0EHPStSAnM8nnhe1fp9OxqmYNBSkTcDa60FyTJAkEBI6OjhDHMRZ5jkWe4cqVK7bONYMG26EfP34MpYAoSpCmXTMGJOV1Oh1sbW0BAB49+sSov6c4OzvDfD63tbH/8R//EUdHR9Y5bT6foyxLGy63vr6Oa9euNdXflatfzXOpPPCmE2au7XxzyI1dtdDQtmSl0gptqlLeD26tCMtY1NaTcHHuNp966Rgu0gxoRJGvfqVrzIy4iIIm2LCkPp1OMZvN0Ol0TGhWiaIoMRwOkSSkhYiTBHHiMvOt9SjfPfW7MCFeW/jKV76C4XAd29vbmM/nePjwIR4+fIjj4yOMTaW1OI4xHA4p+c90gkorVGVJ4KKotnZ7eFNzr4XHRZlnN/ZNmn8ezW0Tbs6Trl+mr/51ITwvJFp4De1eG73x27ehiJYOnW+zf+VBu01SDQdDwEl1Jvc8XQOsBy39juByUtcL0Uvjb93Mw10/LsK9LVNN2r8FwL30/jTcFxOOcHEKe0ujDxoQxkbu2tQQUGBHPPsSf3AAcLChAKxDXI0LhDf22vVZawHZArr8ecLEOddzswFAZb+x1p77WLi50cwvuPbtb20fonmD/f+wP3yXtS/C1LMVThsyn8+xt78LpTUGwwEA2OxRURQhjiJExp7JIThVVSFOaAtR3G5sbY0c+lSVBbKsgBRzKz1MJhNIk8u50+kg6SSYTicoysKZLoSwFYKsBKjdRucqQwzCJL1RVjStVa0eMuAqRLF9eDab4cXuC2xvb2N9fQObW5TvOpIRqlLZwaOMWsDR0SmiqIPLly+TY5zxjle6QhLHiKMIyjA0nIxjkc0gpES2yPDTn35o4ow7iCJK26mVxlp/gF6/ByGoj0dHRxiPxxZc3Sow827mk8oZOg0TRxowA8tLhveilMTwZPkCWZkT6EJbRyMNhUprRKwuByjXtdCAUnW6QK+GgoaIJKIkhoxjRFWMqizAyVI4Ix3FyktASHoGQBxHRip3tnSfgSRwjIy9v0KeT8w8xohjcnzr9ftIOgniqkIPXQwGa+j1+hiafOxxHGNtbQ3Xrl3Fzs4VVFWF0WiEjz/+EI8fP8HTJ09wcnKK2XSKvCis/byTdlCWBaJYQhbC9A1m31TQKqEwOI+5OS8hSH1PrrYjh/euasef45dp40LCEF1sPgtAhxqsoK0QrP2/fZCuYQNT6tX8wqsP2qskKSZKbRKducH+qc1OExYlRW3RuXbchn8Zlc+5KhXR7KcQfnlLUnuau72/nZ1y2WGTywSqZ+HIHdhr0b6bmQBtrrL92zYQtojGAgsBkg/pe+2GTII9aSiBB9xeh+rf1/ilvX/daQFRP9XCdSsBqicCl7y/LEscHx9jMp1ga3vbSsRsRy3LEoVxbMrz3MYWkzq6RCmctBVFVGQgkhGgjcra2LlZciSQovmoVIVFRgVGFJz2oqookQdLclJKE8rFjBXNKTlCzW14lZW2tbImCnZUA5ztfDqdYnNrC9dv3MDdu3cxHo/x7NlzSn0pKQuahvNCzvMMh4cH6HQSXLp0CWv9NXLoWkxRsMOSYCcrIE5iJLKD8WhibNpAkpAzXZ4TGMfVJWgAACAASURBVPd7fQwGAwyGA5QVMUjj8bixV+ibRTthrK0Vu6pra4OdzSpNebuLsgxWECfRcS3RPjElOL10kzVCKx3hjSKJSJr1VdNy+Y5ydL7T6WA+m6OqSmtSYU93IbhoiWPWOYae6mXP0Ot1EScxoiRBZKqMJXGMtf6azazHnvWU//0Ue3v72N3dxeHhIQ4ODnB6eorZdI48y7G2tobtrW0bysdpg2ndxFDKrSmnQWjfY63j1HLfeUAa3nsRCfSiKu+LHiJcFPYCGudXaQBW9an2nMktcJ5P1WcCtC8CniL4i0vsuWxpfM0HbM+e6dmUlzEBbZzZeTaUZd8EOA9X11YT3Jvfr4Nv8b/bt9+1b5Qmh9fiLQ80wI8YgDqpWx6iVt+sbWYND68bz9I1l02oyYsttxGtnAFDRDmMjKWnPM8xXywoSQiDryQbodAw0jUR7zzLQBW+GNhdvDHbEXlO4zg2BN8VkxBCQisOJSLnJSKyzFiRg9hiscB0OvW8wuvfz2wHO65xaBJrAYQQ6Ha79hkm5Hz0+330ej3cvHkTt964hR8/+AmgieGwffXil1k6393dRWyqjKW6gyyfY2GyZ7GzUreX2v4v5jnStAutYbUTHHPeTVMCFuW8rtmnQGuXHS2K6urXNilJCAEo46AnKDTRv8b/hfWu+bxNO+lJ3zzOvKjCzGna9Lcsc1BebhejbbhmC3JamzSrSmFWlDg9PbWZ3Xjd+8u0vr5dH132MhcmGBvNxWQysXH2AKyzHV87OTnBaDSyaXR73R7u3L2DgYn1z/OcmBSlIURkK8+5RC2U3923cTfX5cufa5O8/eMi5q9VgL3smYtcb/1OCISmlfPab2NgmhK4NMzjZxy0gbq814wR1uBiFKEKCwCE9Lho7V2AAGfHEkJAaOcB3CZpv4yzxUUWUIPL0u3nw3cQHanbKpmjr9uiQzm5+W6ttXFiN/KGoU9W/Ux3WxU3t6vdpaXt88XWxB6eRNwYJ20kYA9U2xb5khebknuweoBlG4qZOlaNCwA9k0M8jiJDwM33lwp5kVk7JAGNq9gkRVmLF2bwkpIL0AhIEUFKA/TgJBka0M62WZTk1d3rdrEwIUkc6qWUgm8GAsgUVFUkyXFCFI7rXltbQ7/ftzZRdvbyw6e4NObxyQkW8wUGgwE4LWad2SVAk1JYD2QpBbppCmFC0rjoBwAcHi5wcnqCOEqwvX2JVKpaeBKnCbNSNPZZkaHTSSzwczlKzukOzzvfX0fclj1vzTveLjf3WmnbAJ3vFOaWXp0BDA9eL0opdLvdWnge73nWOAjPTl2BcsKXBdmyCxPq18agM97X123dwbEoCpRViaosocoKKnZ5AvzSoVmW0fiaGuXT6RQbGxt4//338fbbb2MwGODZs+d49vQp8jIn1b3HpNF6lWBNB1WMK1AUrp52KHhc5Gjbx23S9Crpte2e/z+On6U9/xvCefXvaWMy6Dxaha3weOVBO0z6xr+FD75mzbRuQLCkyDvZWxym8L0wXLHHBtjnuK2LcIGhBNg2if694XEx7k/X+lT7Rp9jRRO0L6S2CcVs3sj+iItwDoImrGGWkxO4/vjMlfSKhri+sQVee/e797bZh2w5Eh4TTwnhjwv/VkqZ2rzOMSlJEmsfZoLkZ7ZiYt1GSJRhAJiAW2cvwe+XFBoWMC/kkOQSbUwnE2xubuK1115DmqYYDocmpzh9QxxFVmLld2ulUZkYYQAm/IqqbnF5RcCpyBk4+fmPPvoIw+E64iixMcjafBNpc6VJX0ne8UVR4vj4CEJo7Ozs4MqVK0jTFB988AH29/epBnNVYHt7C8PtDZMwhkKfmHGwmcDMUpOxMHnLu9Ba28Qpccwx8F6+a28f8hw5LYawObL9pcmgwlKq9iTFcH+SrZz6a8Le69K1GXsOy2MHNe6LUlSbmswnZCqoQCYBlWvrJ0HMKzxLUVPDFwI3rxk20ahKeeYQr1iIl/yGvc6vX7+Oa9eu4a233sLGxgb29/fxgx/8AC9ePEdZlYjjCKyCt2NhgDuKYkhZQSnyvvdLki6ji22gdS7T3XLPSol3hfT6Mseq/rzMtWW/a2bJ4Ltq9zPlO+cbXmnQroEEf3iwcYGGCdQ9w9dNGmIJVls1J5vbEWgn9P79ITCH7z3vun84guC+xN3DkOV9r2j2r639NsBuZTqE+27/kWa/Dei+5KawVsbGGC5b0C4veCjQtzEqLLnzaXuPB9y1d3D2OSmgigqZSWXJYM3tMggALj+2i70Nx1Ebu58Lh6mqypRqpY5UykmYnPnMpTUlFX2328X9+/dx8+ZNPH78GE+fPnXZvlqIOqvNKf0pAXa327USr+/dzMwKE3a2wY9GI5RFha3tbXQ6KRQ0oCgW3WcQ3DvJrn9ycoJumuLq1avY3d3FT3/6U+zt7aHb7eLS9iVsb19Cr9czbcC+01e18kWhAHQ6Fsw4aQsxNcp+R1iQheeEr0HRN0ZxBBk5KZCZr8ViYUCJQub8JBZuzypocB14YrhYUuf5Z9C21cHMOLEPRCSdP4pSCkWeU3GZUtbSkdo9GgBcuMd8hrYsKXyLAZvGKEaauhS6nU7HgnWaptja2sLrr7+OTqeD2WyG733ve/jkk09s9ACnKVVKO0ZE+JER5NRWFuRFzsmAOOqhjbZcBGRDZii8Z9Xzq+5ZRqNCAcv/NzS5nEfnwgiPtn5epL+1vb1M+xgcrzRoG6SwkhSpnMxHecC23HAvrbqBgb85IJ70yj/t65dIkh7jsIxjbzuY+C3nTmHVkACgVBMcRO3+5f3zF0C4IOsteipBC4CiBppAHXwvoqZ23+wccLgllt6NJxhcZ+F09PZbVxM0vsVrxZ6kpnRN5cTJOKCpSEdmQov80B22abO6sdPpWFsoE36/OhW9zq0DUqE3M6upqoQUsgbEAEnLEgJvvnUb7777LgBY4stFJXjNM1MJoCY1S0FAk2WZDRHyE4fU++LYQQCYZwsk0yk2YuP9Dm2doRgwuc/8zqoscXBwgNlshtPTU8znc1y9ehXD4RCdTseW9izLClWlamvfSs0gW6+/njj8iyRHsgfz4ad4td/htVmVClIQgIvIVEUzDniLxcJmn2Pp2V9T3KYUEhzOWFWVcUVzZh4/Fp4T6fh7Oo5jRJw8BaSZyBcZdMlVyCpAm7zdHtPp8LsplPiH1lTsJMsyZFlmtCOFXZ8MsFJKy2ySx/jHmEwmdq6qqrLmEJbghdB27LXW0FwgpaK64lqq2vez/bwt5KsNkP3ry/5e9t0v651+kfN+/8L3r+yPN1f+EdKoZd+9/BxHDqw+Xm3QBuzChjBSktZU29cOThuHImD95r1/fI7Ghz83dr6T1/kczzIucdnErVp4bRu1fVG7bzq3by199K/z+Ak7RsKq7Cx+2k3Y8tpl/aiNIWOzm0eLc5J/eBJHkBdQ8LtbOHqnHrdn3HVhz8AfdWG+SWlFxKuskHQ60MJ4SpvwLgYqwGXB4vljguWnwYyMHZylyKoqobT3XSaMTQpnaLCEDQqdJMHm+gbKLMez3Rc4Oz2tET67boP1xBw/E9LZbGG1Bn7OaB8sldYQSkGzhAogy+ZYLDro9bqG4XApQv3CHAABWG7s5xxvvm7AmiUxVxSjXnqR+0I2em3XR2VAkaViltCl18eQCPoOUQTmVOWrrCpAaCwWc+/7MpM0R9aY/NBcYNeN+U1x73WVNQOmdUgSxHj5TEdVVSjzEovZAossJ7W7KlCVpau/HOx5f558RiukJxQHP0eadk0CIGl9Gfj9RVFAgDLAZfMcZ+IMGrDFZ3iObG51OxYaSpUgHwT2iqd9Aa3tM9w3fw80jhUCCgA7rucJP8uk+PPobdvxMozCyx5tNKqtT8vf55xwVx2vNGifJ9EtAyNKOxlcYxAzfzcRRzOy1ySzVe9vvrdOjMPvCNsKiXIbaDe4QNFcFG3thd7fbf0SggBN+Wr5Wp/8NtBgjs4LTVjFhPjjv+w+GrblC9iOD6wWut4/bsdcE953lmVp7b30zQ6YmXACLucyxzj7ntr+e4QQ8CL2bKlI/gIh2AnNjRqtC0KntTWqwPThhx/aNJKRjFBJP6d0fR0x0WS7alEUqMYV4oiknzRNa9/DWcikEASSnsRP4zFHHBNRHwwGmM1mxn5aGUm2silctdaWOeD/GNw5DMnFGdclUgohy6HYlipczWg/XShQZzxqYx3MMe0NeHNWQWvHPPgJTSAcAx1W2vIPYiyEBRdmjrhNBtcoctIpryH2gi/LEkIBWmiosmIOtPE9jkEOzGFo0g92MlssFuj1eqiq2JpcuI+qqlBJCSko1a2AILV95Jg8X0vhm3586ZuWs7C+CDxOfJ2ZhHAPc9nXldKoGQt/HpcdbcLRRZ47777zALb1WHHLsn5y222MxkX7yscrDdr+0bZRARPe4Uli8NaCu08aPF5tZ3H24tXu/CvbwHKOq+25UPpuLP5A9cS5q8PnGgwA6hVq2pgCq8FgIqH9eHWfwYETj70+rt4Iy7+dxsf/W3t/e+hresHc5zImra28aGPeDLITMdeYTifgHNZaa0RedjFfxbhYLGx5Tc5eBsBKKlJKrK2tOTWhJim7vv4EKk1AJ4XnLAVY1eba2potEuFyjava9zgJVFsiy45N/C4uxsFSl79W2saFHL4oNpfVrYMB5RH/5JNPMJlMjYo7x3w+gzSA1+l0SCsRJ4jiukTPwEXE3AGvP2fdbhfKjBNrYnzHJgIPB5Y0Hk5i9+ebD1W6+1il7feLrrUTVre+FDQicO1oNqf4hU3sWCptmQs6F0EIo4nIchR5DmG0BZzVjZ3Vat9gPTc5i5vToPjr3u8rF04hIIXnA1CikyTWka8uuMCOn9barllfU+OXKiWGmCJMIpDJSEkJ5ZVG5XHxn/HXnPPb8Lzr/SNgYuqXltPri6qgL0KH29pf9v6XacOft1WC3MserzRoL5M+w7+ljD2da10CdPdrknIYnCyAe5POsrhwIhIRFdpUJMFro9YFgGapziZwMOjwu3jyzKIzGcIEYKuSwRQ7gfDOmYNtYZIonSNkRiKgduDAdsVRA2ejkq6Bja4ZEeymX7UJLFx72gpmNOD1Swpqn/vMUqeTQlGzU7e9UxkbEJM8EdwnvDa0oP+iSGI8HmMynVL940hCxjGkb882duxIRpQnTwPZYgElFGS3hySKMVvMbYrO4XBI/THJEQBt1dOOsFWmYAiFz5C9tjKSe4nxdIq4kyDpdNCREkWRo/Tyc5MkT+tOaRjvd9hqYCRB0rouyhxZPkeax0jiBJAaiEDgKgTtBGHKdgpBWc1EhLIqMZlMsL11CaOzMaaTGRaLDIsFlWiUkqS1JEnI5p6mSIwNl6V+gGpOEwADUeTSsHK6TmvWiju1kCHeM/zNvj2b1oSy+8i/rjWljVWV0RmZNeHHYbs1pCERQQoFpclpTKvKLH9HK4g+SLLWaAVdViiLguzzSkEoMjNQTtnKSO+0+ouiQGaqwAkpILQwecElbHY0o9mz+SFApVSFlNCo3H4QLGw4BhCgHPjKFH5RlUIlK+RZhiJNURjnMvLwjo3pRxh6AZAGQ0BK3jlO7c+lU+t0jfoaxRJaC1SKfYwoOZDvo6EFrakKFKFR5JwhjrK5JbJjzVUcl7yMVvlMgJu/+rW2Z1b9tt8WJpOyD8D5GKgl+TEteXRXfce02nte9pDn6S9fcdAG3MYLuWsHOIYrNwujbZIcaAJWDd56sL3RMQDuH2Gf1ZoBfDWAuX4KCMEEx9t8zBzAhWnZPtpvc+2EC7UBUqjf23Y07EFLztfuWaI5WCppW0W0+xzjduQBtOuztr4EXguC/lXt26ZuxwYzAoEEpVjl4r5Ra4X5fIHKqLx9la3vkMYgmSQJpCCwYkkm6XQgYwL2mzdv4tKlSzYmlokeSx6sTlfsZQxai1XFiUTIPprlC8RJbCt2+ZW9amveLBulla0ExerqqixRViWQA3lOqnwJAR1FEJFnd7SMoLZ7pqqUBdCDg0McHh5hMhkjy3PEMUnN2owZO8nFcUx5r4063JdsoV3VrWWetryvfYc5f+02XUC8dMUBMdfapZilWudVDbT5fkoBqlBVEpWqLJj5ffPXp9bKgCOF1WkS/2v9EJKYQQVlzQx5npl1J1BWpcmV3lzF1D8zFmbNKROKKqUKNAN1P55O0sHO5R1AUI5xACiLAoUxPwghIKMIsjJ5yb35oWx5/vxXNZW/DSNTnB/dqNYVeeZrmEQ1Cuh1nRc5zHBWlcJ4PMF0MoHWldVSaWikccd+NzGR7limTWs7wnsbe6XlcPc4utBozxHS9nrauv4MtxseoUblXBD33rvq+JlAWwixCeB/AfAe6FP+WwA/AfAHAN4E8CmA/1prfSLo634LwH8FYAbgX2mt/+N57/CdV7z3un91U3XaDtzLz9nFJp0j2nn2BrrtIoBNhxddAl4zvCGFEKi7xzSJW4NZ8fq+bHwa39hyzX/el3LC77i4islpCfgbLdfEG5SxozYgVqaGf5XzSbepM/2+kYTlMRYBk8EEfD5f2JAoAUHqXRlDChc6xDY6Gg8BYeo6sxReKkX5pqXEcDi08c2+bU8Igdl0imw+J4mQOXvFHrgKRZEb4F4gUhEleRHChEqtyOcsSMtQlAUWmQFtU5iR+51lGRYGUDuJUZMKp7oWkhhUrYyGJqI+K2VSqiqF0mYvi6yDWCSpQIUMVN6hpzrbsVmD4QOBz4S3HaHKM1x7ocrRJ4ykLjbJaoztOQwZY/VzanJsa13vf/gunyFx74fx2NeAGRetKmTZwpQtJSEiy3LPfMGg6Wvc+DuZ/mhEIgY0aWea40E7hOnibDZDJ02sTwEzlpwzP4oilNKFLPr7hyNV2NTiO15WVUWRC9olEQKEdQLmHAPdroAFfykAEdln8zyD0hUqLwFNHCdI4gTSjHkI2P6/4d8I7l1mMguf9dXz9lwbFreo3FeJvRehicsYifBdbdeWHT+rpP1bAP5PrfW/EEJ0APQB/I8A/i+t9f8khPg3AP4NgP8BwH8J4J757xcB/I75d+UhhbT5uT0NOEGcrqs3zgsLaHJFygMMDa2b4Ojb0fwFQjRQWxWv/wwDlFXa2naZi2thLviy9/5lANv2O/zG8xZU23tWva+tzaXvqIV48aQJC6Q6mDdzQ+O3z/Uu42h9Jkr796nmfUopzKYzZFmGtNOlNI2S7K6UtjGqSRokXUSIpbPVRnEMWbkkKtPp1BIktpGvD4eYT2c42j/AfDanqAeyrNB/JkEFEdcclarQT/vW2Y09npfGhZvlVVYlcvM8O4jxc3meY5Hl6HRKRFFiCn94jB55PlkGi6uY0fwQ6HHJySShLFt5kVsvaYA8vmGSsURRBGFst8p8KLVtHObM+EDrmq01JKg+OK46+H7ui+/dLoQn2WigKiuUqgA6ppa1JMDytXh8f6gW5m8AUNN+0L/+PoHx3p8aRqEyhT4oJSs5ZVUQlC3CVCLkxc3jQDSFvdKFiACUtT5pTbn9taowHo+xu7uLza0NXLq0jX6/DyG4ljszKRGEDB38uC3HrPs2anag43Sz89nMhsspk9wFcE58USxh6xXZfapMwpYUhWGmyIkvp3BEUxd8GV17meM8kG+lU77F4QLt1s+306NQcLwI8xG2cZHjPxm0hRAbAH4ZwL8yL84B5EKIfw7gPzO3/W8A/gIE2v8cwL/X1MP/WwixKYR4TWv9Yuk74GkMPJuYeT9dsADZ6F+NEycA4BARD0igrS1q2YT7kqhbXGajtcCPn/aTz1BFJvOsMh7bPnDCxWev6kN4vu33hRcumovrotfohvPPrVrIfNTVnOcvYCGEte1bQq+lZeYkYKrw+HOmschmOD0dQYqYOP6kY4lbkiSII5cNjSVuKan+m00NmeeIdGxLVnKGKq010jRFL+2i3+1h78UuTk3Yloyktb8z08LJMSpFmaWGwyE2NtYRx0TMQrWaTyRINV5iPp9hsZhDwyT18CRaKSXyLMM8XhBzEicmM1k9rEQIUgFqs9l4rKRk9TRRt6qqbPUvP4e57ZNRnfMSYAbKzrdpW0aypsnw10XIJIYEse1vfjc75LHEKKVELCNoochbHnAlJiOnkved5Ph97FzlLtTngcdIwHmUZ1mG0WhkHLkESZpZDmhBsd9akC1cKrNCHc1hrPP3r7S6t4BJ5w6BvnsymaDb7WBzcxO3bt3CdDrFs2fPkGWZrQfvF7jxpW36hxwxOd0pj+FgMEC/3ycTjDH7aK2hqwpKUYY3rTW63W5jbEJGSGk3TpSUpYJI0hr989dByLydJzy0HavuEUK00u2XbX/ZeuVzoVmoDeBD2t5kHJvHzyJp3wZwAOAbQogvAvgegP8ewFUPiHcBXDV/3wDwxHv+qTm3FLRDIG37mLbJXMW5hQMUAl3b/ec923Z/beI9IVvQRUiWNi/IkYULoq0fS98ftHHecd6ite9YwqqSdHKx9tvG0V/QbX3WnnbDPe8kbnquHruptbb1nYfDoX0nS7d++lL2vLbxzjKCBEmWMiH77Ww2s/1jVXBVVZjP53jx4gWePHli06NWVYUysPn6ks3a2hq63a4FbL/P4XfzUYuz9cJ9uH0hhLHtlgTyqvLeWUJrhV6vh36/T3nRDZgLCQgtvXbY/u7AUGtBBU6EC3PyVav+uDMBR1UB0oV2cdKTNsYz/O7Q5u2PAavBfcBWShslmtOQ8P3SAI//br9N35vazUHT/KaUA6KyVJhMplBaod/vYjqZYHR2ZvLYU+54Mt8osF2eZQ36Jh4zF7lCqXaVXc9MN0izpwDhpP6DgwMMBgPcuHED4/EYBwcHtbh0CKdB4jEk9XaBJIltCJ42WpDBYGD9FDinvM3iV1UoyhKz2Qzb29sYDAZW9Z4kCYRRrft5DbifnPVPa02lYyO33pfRgLZ5ugiohjQ5NPuxj03buy9ynHdvuI7tngj+3/bB78c57/5ZQDsGcB/Af6e1/nshxG+BVOF+R7Voi7NacQgh/jWAfw3ApsnzrrX+XeeA69ftedEcaJ/DD58J7/Pf1XZtFXBbYqNhdfzhBNVCrS4Ami/LeS67r62vL9vuRd61iuMMr/v3Lbvua1hIAvE9z8nhjC6THW48GuPw6MBKH7yRfQc0IUnCTtPUlim0akYDgj3A2gyZyPnhQPNsgSLLoLW2tukiKzA3DmNceYvVuRw+xXHjft/85Cnh92ulyKPdgEuoRpdSQoBtk7mtBc651ssyx9bWFrppCpl6jkHWOUnaxemrnnl8HbiVlkj7jjeRlIjMOmUJnIHVbwOAfX7ZugglRD/G2AdsO0ZwoVo8f2zrpbGsv79NahLCq9ClSN3Ptl5eX6QCL8y8SQyHmyiLDAezKaJIGKaGQrJYdobSEFKbMqwRo7ntg7esQTZwT2unyWM+iqKaKW1q1NccH86FY1zFsXoK1qqqTCGZKdbW+tjc3LTzmSSJXYtUCnRuNQlZlqHIckBIbGxs4tKlS3b8eB8pw8T5Y8oMgLBMlbKmgTYmbRmN9a+HNHDZ0UbfacTrNrplzOPL0MBVuEHvRF3CN8Kcvc7fdc57fhbQfgrgqdb6783v/x0E2nvCqL2FEK8B2DfXnwF43Xv+pjlXO7TW/xbAvwWAra0t+0kXlSb5vNsEvJGXq5fZ21mw6yOadrVV3Fhbf/w+2H/DewAowZz0ctBeBdCrxmIp4C1pa9m7GmN5AeZimZTs3RHc33YuWNVofotVwwZcrRAsESmUeYWjo/+PujfrtSXJ0oS+ZebDHs/eZ7pxb0TciMjIzKghq4Akixq6KYFU0C1onnlFLR6B/8EfQUItJIYHJATNI0il7EqK6qrKiIrMyMg7D2fao09mxsOyZW6+t+99bmSBuOXSveecvX0wNzdf3xq/9RbWGgzG3IBDuiGFLOhEQycKg8EAo9EoWNvj8RiTyQTb7TYk9yyXS+R5jizLOvMi5BPWWlxcXmKzXmOz3mC5WgJRqVQMUk3TBEXCOce1vSQJYxppmnSsBPEpiGDtxnIp9OS1xiIRN7C3RgF4l36FsihQjkbYbrdIUg2lcwYngld4uKUorHBxt+s4Bt74OQsoZmkK5bPNTWRVx89HwFSOlX2s52wX61gsQDlOlCP5XX5KvFxASVz5Epc11mK73aAqq849iDLQglpLzMK5DlxK51xLtMNzzpn6TVODYDEej5CkGmkKfP8Hn+Lly5d4/fotgMYLai5v4hBfww5yxyVZHM8hBnE4jlkrcGKXaedMrHIFCklwSikMBwN89dVXGA6H2G63WK2Yg4ABt7XKZb43mw2WyyWs5Rr9xWLRaeRirQ2hn7Lk7nZ3d3coyxKT0QTz03Ocns4BPyfD4ZDP7Z9vkmRIUwOti24s3StvTW3gspbxLVbI4nc7ft+PbccMjUPAG8q6vsN19s5xZJx7csrL/3ivXaPx0D3sbr8xaDvnXhLREyL6LefclwD+DMDf+H//GYD/2v/8H/0h/xOA/5KI/ltwAtqdOxLPjrd3AWxZAKLlHdu3c24P1EG/6QGP3bEcXAhHAI+A3vIBDr22oH1METl2T4cs2/j7foviuGvokELSd83O967ns+4nO9duy9viexAA3hsvn2LPc7F7T0ScYbtarTAcDgNxSkz5mCQJlCZkWeZBXAeLezweh/NJfLCqKoxGo3A9EeREFDjJlS8R2242aDyLlliGsk6bpsF2u23nwAFNVaGuahjf7lMBUL7sDIDnKQfqugr9kmUqeOl6gHUO8UNw1sE6A+cMFBGSNEXtiViSNIHWKnRdE+HNlii3Z+SEJgrJbgA8c9oYg0GOk5MTAAyyk8kEsBZvr65CW1BEip8iCnSech0lwEltkwoAwR0rCtF2u+UxewCqqqqtrU9T7nFdtY1HxpMJRmNuUWp9C98Qn93xUAhoy7yJ4ufQJS8xxqBuOAGQr5MjTRUGgxQfhbjPGQAAIABJREFUP/4EaaaxWF5xvoLiTl9wFtbA07paDrUoQk4ZFLjDFjlAEXNOSCFUrLBAwDryKoin5tmzZxCin1i5sNbCOn6mojCu12vPad+GjGTdiowQRjdJuJxOpzg/P8f85BRplqOuOdktjzxXcA46yYICkKa55yOwoWQQYD72voTD2ILuA73d7buCe3d/2/nsu1jVu8C7q7weAmJ2qhz2KhwC8d3t75s9/l8B+G+IM8d/CeCfg/XGf0FE/zmAbwH8p37f/xlc7vU1uOTrn7/TFXoEdvx3PNnHrVBe9J3zMZTuTNZ+isLugz1UVyqCgEG6ey3eYX+htdb9kSk4ANj3Wbq7P49Z7MdKXuTYd1lQfHKEe+3VOClAzM7W92LuHytKUJi3KD4o14q1+Kurq6grUZt4Fru/0yzBYJBDKULia7CFwzk+52azaclXvHAS607mMUmSENqx1qIoSpRFBWPrcD4BfyIKvNlN3aBBFYStWDti+Ys1aKzBZrP2sWkGcYV2roP1SLEF0/IYGB8rbXxsUikK2eMisBk4fcJeksMSJ102pi2hYis2w8XFBUbeap/P5/jk48e4vbnGtihCP2/uQc7WcJZlWK/XnbhnXJLFbU1bq15Ac7PZ4NmzZxgMBri8vMRoNEKe5yFcMcxyEIBiXAFQODs7w3g6wWq1wnq9BikFlWgkNgmg1Ho1VBDk7dqXvuc2AusadVWjbiroRCNJNZJEg8hBJ0BjKrx6+hpltcVwqFDXBs42qEsbVnyeZ/jgw3MMhzmePn2Ncrv1SqCAta9xjxQIHp9XziL+dCbV4eexWq06iXUhh8GiE8KQdQW4QPAj1rKEAMTFroiQ5zkePHjAz8oSioIBfzAYBOWXSJqlcAx/u9369ywLSqoxFk3VoHJVpGy1vPKHAfq4JXqffLrPMOk7Zzhvj5yST7qyLAb9Q9b9vjG3ew/vsv29QNs5938B+IOer/6sZ18H4L/4rtcgEkvYnwfAfpTcxy89c1CwPcLf3tINJ4D8By6xEOd460qHCEEPQGIhREe242IfLY/Pn9uHqsK+tt2lc29ild4HqvcB9zEXEUXjFLB7lwUSL6zvEkeS+To0Hv5MOtp4IeXk8+gkEPaoLhCHc7p2LVBIf+YPrOPK5du7WyzXK064UszDrBMCKU92QRY6IWRZ6oEjxXg8CcIEaEuvSh+rTpMMWTqATjRbrt59LVa07J+mKQNbkoLsEkXRwJHihhaeAlMAikG/9RRJoplkASulAEVIshRNYbBdb6EcgRyhMYD1/aiIojcgcBz4+fZgzUDJjSGMKVEUDg61V1o0jDUAUhBxL+3G1PyMLECUQFHbBa2qKtze3jIo+vVxfXsDnST48KOPYL2i0zQN6s0mkNpY52Asd6wyTY00Y/e43Kv1rnVjDHSSgAAsl0ts1lt88slnePz4MX7nd34b8/kMb968wTe/+hXSVGM+n6EqG7x9+xYE4ObmCrc3N9huCzhTQcPCKgtmHeOYtXCeSyhB3vXaWVhYGBgYMqhtDesMalOhbkoolSNPucGKdQ3KssDTZ99is1lgOCBcnA+wXG6wXlpMT1I8fJjjdD7H93/wOX7ykx+jLCr8D//9/4a/+OkvYAoOzZBzcGjAPcL84nYE5zkPHSQm3sBBgwmaWNlYrZZwzmI0GrJnxK816yis08bzx/N9175jXe4VtAzs8dIwpgIR9+POBzmIgBfPn+Pt2yvM5qfcxW2Q4+zsDPP5DMZw+IFIBe9RTLpjTIO6ZEU1SRIYWwM0gNa0a3zyLYf3HJGtdVg+xscc2jqyg/rguMfQOCDuWlnILHfyDIK8bFNle88fD5W8cHau/752t/eeES1I8WBVtdSX3f12fu5oO/zsuw89WGxymAChWIlAW0rZOVe/9SrHS3wtPk6hH8gOgfUhze/QPsf2l3sC0ClGO+TaOXbNQ+fvfo72efntkLurnZNd7XTfXb43Nn8xifXx2uDzaa1RlTWurq5gjMFoNILWvm5VQhGqm4xGRN6CToK1GmLNPtkpSZgaVAS8WBnigYnjy8Glapq9cWvFZWCd0hgv4OT3zWYDaaEolhB5t3tT8zmta7mdw1yTdBPjxyCEGO0rxAoRW0aarcaGcHJyASLCarWBDXlnDO78q4JzJoQYAIRELLHOq6pCURT47LPPQn6AZAwLO5yMIc+5Vr6qyjBGuLaEy1mLJE05WU4pPHz4ED/8ocJkOsVsNkOW5Xj9+jWePX+OxjRIUoXlaoW3r69wfX0dlKGyLLl+3JqwzrRWsFp5V61rM56JPMWnRhNl3AM8jy0JiUOWCb+7Z7erK5Dia5zMJpjNhhiNU9BDwmefPcbFRYbxaIIf//jfxqefPEZV1ri5/gP89V/9GtbWUCL8SQGBstW/C2Hl+DXuS0j5maqovroGEZCmGYzh+WM+/7ZcT+a3zQ3g/YdDjr1L05gHDx7giy++wPn5GV68eI5nT5+G8sSzszM8evQIH330Eay1vsys6iiv8v5IKCiey6qq+HmQC0K212tKLeHVIQR9F6DblXPvch4JWfXsGX7yOePPwtFy0t7rdJSSvev/f+se//9n28HJvlvcf5D9ABe7VURohO+O1E3v/n0oNrF7rftix4e2Y4DdN5a972PNsmeh9I3t4Lnu3d5t//h6/cQ4/bWQfX/71z7Sb10AEAa8lC1EraEUg7fETuXakpgWxzmFUUvqoDmBLUeiGax10m0RGZOziJBq6gaN7w1trCcacWz5Mnc0l201TR2EmgjhOHPaWAtyDmVV8X0q8tzPJsyVTH2QIxTX/7fzphS7dVmAlzg/P8WDBxcoisJfm3soe6OE3zPnON5KDBrWXzvu5UzEOQTffvstAIR5IyKMx+Mg1IfDIU5OZr50ygIKLRudY6VrOByGREAuSVOoqwZfff13uLm5wWKx8NnSpQ9drFCWJVaLVahJj4lvnPcAiUdCsvOFeaxpavbEaPZ+WNeSjjjHWeTyPBRxfHixWICIUNVb6MQiTS1IGWhNSBLCB+MTPHx4gdP5FHVzgzQvsNm+hKUTpHmCs/MMs3mC5V0JRyW0TmCsZjEk3qNuFNXLF8m29+0ztUaaOmRZDiLFruimYcrW2sJaviepxZYwDQAkCSdDGs+Ad3FxgdlshouLC5yfn2O1WuH5s+eYzWaYzeYYjSc4nc9BRPjml9/g7u4WVVVxi1vHnOgC2IFKVowGx56NYlugGnmiFaVBR/o4yO/idTskQw8ZHvLZfbLsnUJ/PWPjTTyCbXi0j3WtZcXryrDD593f3mvQ7nPHBksN8G4T2osVAwfcuQeeya6FB3KhVR5hHyh2jzm02A49gHhxHbK03/X3Y9ftu3el6B497vi13mUcoOPzw8eqsMDjcx17ceXv3TIoBqsong1mCzPGhNItrRImGZHyLjDhhcQA0zTFYDAIgjy2nEVoSy/iPBtAqDAVWWbcMgYeCcL+AvhN06CqGzQC2j7GaOoGTVXD1A1M3cA2JtRei2CdzWYhGc45hHpri5ZlzME3Kom1MiL/o52jAFre0m5MAyIDjscS8kGOJE1QFBWsLTmk2vEGeBBR4lonWJuG0jWx4IgoKBySGyDzGSdI1XXD86iJ48M+1yD1btWg/HiKWOcc1muOk0sSHv/jBLLG1Ci2ZXAzBpKUsKZ4/MFaJgfuHW7Bu6mQQFhWBcq6LROzJlLMiKB0Emrk+dkbMMlNjSwDmtohTQiz2QgnUw3QGqOxw3Bosd6+wpu3Gcgl2JZv8eOffIxvfnGFq7crOCfEki0Bizw/EplEbbLedDrlNZnnSNPEA7YJbuiqYk9IWXGDG4ntC6AnicbJyRzDIbOcff7557i8vMTNzQ2++eYbfPnll2jqBsV245PVFJyxuLm+wdXbqzCXSvHnRORZLBUstYrurjeqqqsQW08Sglbxfe7IY//zXUN0fd/3GzL7++x9fUjEHTQKudSPqG153LffMQXjvu29Bu1D2x44Re7qo4B45FzhofY8qWMgfAyYD1nZhxbeMdA9Bp592/7+7Tzt7Bntv7+QjrtxDlzbg0afBtmeTzRTQOLX8XYsoaR7Htp/ZNF33G/YeNDWnfpnpbSn+Gw/l9+FAU2AQyyHNE2RpMyfTERwpgnzaoyvIRYSCg+8HLftZvQ2jQ2czOKqFJARYozBYIBHjx5hMBiwBa4IyrW1uF3mrhiYusI9/r61LhsYU4Mo7pFtQ4zdGq4jltiosBEScViBfIIIH9sqOkSt50EUF6DlfhcPBIO7tBBlPnN5hkQETW3jltCX2QHGIiTDxecFFKxpE0HjUrjYNWq9y5PXTTsnotwoIhhTwxqDpuLmI4rdDIBzXlHjrmKmbjxtq2GmM++NMI1FYWv2cLgB6mYLpYE0VVDUoCju8OxZBWcV8nyIL37rI9S1xd3iFqZxIDcMeTbSDJ4IQTF1VkGrFCcnc5ydnUO8BuKpkL7v1jgY49dTXfg1apDlOe5u73CzuIVSCmXJFu9oMIS1Fl9++WWIS8uzAFqWM2sb1I3UyqvwXgSrmshTmPJca1Kd9y6uFw/lj1BBt9qTL1E89D6wo+j97/gnduXh7vcAnMhAhyDw7q+ajmVnHMf2SWw73SSZOnb/XoJ8tM43kj68vfegvQt2fQ8t/l2ssHgi5IXfnaw+pqV3AcNj8d/d7/rAui++cgiw7xvXntLRMye8Q/gG3a9I5FEA0t1xxyeJ7+HQJlZh37n65kiuz58d0Ip7riGbCGJ4AHfAzjgPK0kE6lgDAtxJkgRqR0kqGw6HyLIMeZYhTTMQAGs0jElAVMO5CnVt0DQOdW3R1BZ1ZQLlYxy3NqZB7S05yX5u+chrJEmChw8f4uTkpCMMK5/x3SUqaYWLNA1hshm5766VLZapNTW05uzjqiqwWNxiOpkFiznLOKTAwpppTZ1z7DbXDOTWGd8go6Uy3WVF67KL8cbWOdA0DLhEBIhiAMB6i9FaG0DbOm7vuBfDj+a2vUcXvGSyD7OMMQ2szKk0zGjXHLOWyTOPryGxbFmjPNsWpBw0dz2FVhrOWZjaoSot6rJBWZRIkxTWKDjNT6kpK2idwtoSSdrg9CzFg4cTXF9tURUWUEzMIrcpz02UysFgiNP5KbTSsD7JLEkSnJ6e4vHjx7i+vsZysW5lDUzImBems5ubG5BSODs9x+eff47pZIqbq2sUZQGQ0K86z29fcy4HEUyUZc+ylZ9bxwPmMYzQytkA3JpzI7pr2IZ10CdDv8sWZACOR4f7bWXqfHGveRLGti8r4zqk2CgK6zPGqM5+x7f3HrSBflDufOf299+zsqMnGMdPj03SIeuWiOMVhH3wOgQOMVDfB8DfFbi/0z6Ejtkca3674+vOXxf8DnkL+sYUn7PPxdU9D7uXeFr3LfD4mD7lKRbSLJQ190t2/QoHC43WSoythtVqhaIoMBgMwj92ow8DuYX2a0kEUOV7KUtJV8vCFdNe1twvu6kDaAtYc/0scHl5idlstgNICC1A2zgrQjyQvKDV/mfL1S/z3bJ5ORgoZUHaAU2DolxjvV4iSVI0TY2qZkBPNIOqPIckYQUHkTtTWlIKPalY6zLXcUZ89xnx2K3yFrPjODJbPRF5SrR2hD5Uzh0yzY2BadhdHZqWRGuiVYgaOBKaTY1MJZ2xWcsJcLGnIhayWmkAFonWgE5ABFiyIDJINbfoNAZo6gpN5VAWFk0NEBIocI/2TPN8OuugyGKQE07PhvjwozNsNs99HL6B6NDOCd8fjzPRFEI5TdNwww7izz799FOcnJzg7u4u7JOmKazjdZgkCWazGabTKWeG5zm0TqFI4cmTJ1gul4Dj+ngoB+kFn2cZsiQFKYKJlM/wLG3XSNmVIzF/BveV55yTqqpCOaNU+8Tv9HcBbMYCLxPQSo7DrvEdwKWuXX1Y+nQ3Pn/MJyEVS51RQIye3XsMA7rHiyDbew/afcKdNcfIdAbt91LePQZtv+VDwHrvZ7T/IA+BzyEwv89bcAjQvovl2autyu+0O/74LPGL1sbRxDqPgffwmIgXf1iDImC75+8bf/tsYq20O8ZDyk8Myo1tM7iTREO6rOmIeSl23zZ1A2sYEAQAVqsVVqsV0jTFfD7HeDwO9ddJkrGrNuL7ds4LoeASj+g1/Rglcct4xq24lWLcG3s+n2M+n3fmWuaiqipfeibtXrv2BIG8daw9gKtuqaK1HD+0DtbVgLGomxpXV29xfj7HZDoBW5vWW3qi1PBzCNSfLjwhJm2BZc+inz+xuHcbcnQEuiNYGDRk957nobVG1DKZAdwH3DmuPYZ1XBftuhn8Ms/bzRbWAtnQd1PTbbxd9qkqoUS1HoDbtaa1ZnHsABgLpQkgDXKccZ4m5N3kDoQRUm3R1A6mdiCXIEuHGA0yOFfCNAZpnuJkdoIsH2J+XmI2P4O1wF/95Ss4NHCuJbeBc3CRRRvIUFT77NM0RVEUWC6XKAq2loeDARKt0RjCZDrBJ59+isvLy+BFWCwWePLkKZ78+glu727gnMNoOPaKl3/mOsVUuAK0gnEWVVWH9c/hHhPCE3E4qY/+lp9LC9p5nvNz8FZuv9Hw3axtWe8EwEbyoqO0U7xnuFD7uxPg7Tm3l1OtEdltcAKgkxZ7bIwByt7xHt970JatA2YdLQmhRAs44uqmFq0OCYi+c3Q+95fliT5uAR5aZH1W5+4YDi3WXSux7/tDYxLQjqM9u+fj4+Pzy34HrtNzOb+UQ1ioFbq7ikyr5fbNmQD9LnX9sWfVWtfMMcX37f8W8g6v8YuwFrKJskzByokKTGWDwQAfffQRLi4uQmJPmqYdgK+94KmqCmWcRNY0nIiiCPDUmMY2/M80qCMLWwC7LEuMx2OcnZ11vEHBNasoXMsaB9N0+y3L2hGBItQQMoXKK7fGOjRVidEkxdn5FKQdNtstzs5PcHl5iu2mBGBhXeMtNE5C00qHRjfWeWtUectetUlcxXaL1LPLics8tsBa0DaAA5QFGqqZ/CRKVtt9Jzh50UTrtp2jum5gfHKTTlrhLHSvxhiAFMbjIfIhhzryfIDJZIKiKLBarXxuQZsn4Fzr0oW31hVpWEuAsSBLPt6tkSYp0hRwqKEISEhBa8MWd22gFGfDX16eYpBrjIZDzGenmJyMcbO4wXS5xYMHH8G5FF99dYWb2y2Ys0reBYm7+zwF/2BjD9F2u8XLly8DkORZDqUJJycnODub49GjR8gHAzx78RzPnj3DarXCzc0Nrq9vQQDGkxFGoxHG4xGyNGOANgZaKYwGQyaRUYTaSNewVvElVGhgO+947GXZXZ9yXFmWGA6H/L2iDkj2ybvvuhFxTzXrdlzS7wqSR3YJYpAIbSMYtrqPeQo7Msx15esx7JDtvQft1lKMBDtRhxKUtd/9OMGhc8V/x/sfO57Iu8SdCzFTSWjpLqyum0TOe2g8faB9dB4opKh0x7Z7jQioYyWHgE4pQt+cyJgPKRLt3R0ZK/UDajvOFrT7FJFWW+3eq7wLfdMUwF9xqU9RFKibBgRp24lA4SlMTgBC8pdYDmmqYZ3FyckJLi8vAWpZs1igt/W/tU8aW/s4swBxAB3HGePGNN3kMedgbNtScrvdYjgc4oMPPsBgMAiuR5l7IVdhpaDpuCf5ew0421KDgkJZW2DTInaN393dYTLN8Cd/8kd49OEZGlvhbrnAaDSBVoCxFZSOW3PK+6VhfRkxZK6dg/bMV3meeY8DKyXilgYQGORkvgFAk09y074sLQL/kLRkDCsJtmUnE0vN2pbrva5rmKb217StRwLAcDDAbDZDmnANfpJqzOYznJ2dwVqLJ0+eoCgK3ydaMpwJSgFaZ50Mdk54M3CNJ9Xx85ymCkliWZnRGtbUgONnvVlvsd0WODud4fd+73dxOp/C1Lx+NsUadVViOMyQZgOkmcZsNsTrVwuYxnLJtmEwc1E+ivGJg0mSB48GEYUQhdYao/EIjx8/xng4hjE1vv32Wzx9+hQvX73CarMOFu58PkOe5cjytrtdlmdBCSMnXhZOQkyIs9RFcRWLuq673dPkd/knjVu0VjC2DSuJR0rrJPJUd1/wthvWIUBzvfvGivzeEbHBIufdkY39WBBLU5FRHPIIsotcZ594nF0jqGvNH8Mv2d570AbaG1TOL15rAQLHFdE2st+NZ8bHtjGF+JyiCcm+QL8Ll+OsnA/ZpTntHrPrNm5ZbmJr6D7t8RCQMmB3wSzOnN/dXFSfG0o+/cFh3Ii/6L8m/yJd7i1g79N+pRbRX861yTvtMFv399644w9JdYQVH9a63IIF5xUTB2C9XuPVq1ewhmOMaZpBeKMSIqRaI/XJZiEz2ddM11UFaxSUTpCmORaLBRzA3bnIc4uDuLyo3KAsGBw2vudwcJl71xorGdazUBk0TeVviy2W2hgsVmso0rh88AGG4/FePFYsqaqqsF4sveJoo7VEwSp0RPxPA5RwTbrjl4Vdt5ZB5kc/+m380R//Fh59OEeeD/AXP/tLPHn6CnWjYV0NpQEoB1IM9Ep7Ri5nPdgSjAV3vAHP8XQ6w+PHj/Hw4UP87Gc/w9X1dWhPGluEwZL25CBKR5niEdkNwLFV69ncqtq3IPUJYc41MIaZvYrtNsyRUgqnp6cYTziJbzIZAwA26y2Mp4WdTpnF69mzZ3j58qVXBngssArKaWjDz9E4HqtWCqAEDWo0ukKCxCtgDQi+rJAyPgYW1hCcBdbLArYCHl08xNnJDKvFAm9fv2WmOWJGO4cajTVQqHE2G2E8mGC1rkHOeDbFxvcVIVRNgbrhcECqNBwksU9i3AlSrTEYDrFcr/Dtk19jtVxhvVqCHHwXu5xpbrWCFg5+D/ZAyz/vnENjDFJkSJRGmiTQ1sCQ9RY3NwrRSQKdGlhjAYtIweUtbhyiSSEhTii0plVcmdxGwUXSrSst+B1n0GxlYSfrjNrfrQ/ZtLKxBWZybdOV8Fl7hfbzPlEXDjEg2CBDgznSQsHe4QLYsVGyK373ibS723sP2rGlvQu4scYTg5YsmI7GBzmma1nLzz6LN3btdhLg5HN12BKN/+4D7mP32vd3Z+EJGCLS+HrO7WTwO3MAIu9Y5DPsabU9HgeHvrH8/bdD5woAT9HLSxB7o9ezIAJmsVigqmqMR22v32CFR5q/NKmI/3bWYltVyAcD3zPbIfOMXIPBAOPxGKZpsFwsYK1D3VTYbNahtEnKWBiAJFZaM8mFYWtRax1YxKq6giLg4vwc8/kcRuKxkZdGwGy75VpbR+11+HupguCpaEvXKPxz0fnG4xE+/fQxvv+Dz/Dhh3MoleDnX36Jxd0NkvQEznKLRoICfEkP85irQHIiFzSwsGWJNE1xcnKCL774AtfX10iSBNPpNMROV6tVCB3Ez263FzcRhfmT5+r5U0ONr/Mlc9Yaz+Q1wHQyYa5spfC9730Pv/f7v4/NpsDr16/hnMP11RXWPrFwvd3gbrFAURShExYRmPY18uY1ngkuzVIGrCyFsw7L5bITC68rfo4OBmmmkGgF7tjFRkbTGKRJhvlshru7W7x8/pxr1JUDKQVHGo4492E2m+Li8gKj0QY3d1dw4Gx08u8tAx17W5yfN5J58s8XjpWcq6srPH/+HM4xT/hkOoVG1+p0qvUiyfso1RQxG6DEnpVW7E1QBI2EM/qd86EQh6ZqYE3rBZJ/wbuiNVzUzlbCU0G5S3aSiHcM4GAIxMC2g8nhdy8g2fJt5X/fRtiX4weNKwK6YbvY8Gt/Gmexf7XD4b53DQW816DdRuV2t32w3Y3N9oGwOqDBHHJR707ovvXeZ8333AUdHmt8/LvEM1oga69IPoDcWbNBo2HQU6K0hNV8HHz3E4AAFygH25Kaw+O8T0npnwu5KyIJQ4SnjXh+9xQcMK94XW1hGocszTtWW2zpKf/Pq73cA1ipoOSExgplAecMBg3H8PI8x2a9xmKxwHZbBCvBCrlH5BZXioVbVVfeLS412g5VVQTQds7h4uICHzz4wCeqcQMQ7Kw1ax2WyxWKquIMZn9N6cwlLSQUsUWolfZNQBwILQtbXVWwjYFShOEgx2CQYjgcIUnYm1RXJYiAPMtgGqF85eYhrCxx6RUpglOExjNr3d3d4fnz5/jzP/9zrNdrTkbzgl9qcSXzXcg4BNDjBiExYMj6MJbbdQoAGB/OGI/H+NGPfhcffvgIdV3jxfPnWCwWePToEbbbLb766ktsNluUZYXtZouqLLFerwEPVNJaldcGe+6sJyYpigJ5koamJIPBAM5a3Fxfd0rbrG2TsZQFtCVYct7i5LlLdYayrPGrb38FRRXKkntf54MEWZ5DpzlUwuVi05MJ6rrG9dUttxclgvTdljC+cy7U8svc6tgq9fFi5xXJPM+ReMUrCeGS4Ifm+n+loKQDnjDT+bUnoCoKIikNcgqaHJxPOmQqWAdn2tKv3WoB2WJ3vmm6yZjy3Pvd0vcbC7uGTsfD2dmnX9b/xluwpdp7bas39j2Ku8rBd4ndv9egHW/fZUp3k1gOnnNHszp0TL/FC7gQHO5T9WT/9vc+F/l3XywHxrZ3vpCGFO3THc/eOQ783XPZo/vFL4VsfQqJeCC6WxTzdhKM2Leqe/3qaF+ALgsT+X7Z3DObvOvXkUUjLjzHrnQovp5OFFOElr7syAOeuCCTJAsWhbUWxjZBgAPwrvDal31xZq01LsS9RegKj7NSTFOqqKVWiJW5siyxWm84Xlw3cKYF6vCkicLxSrLGyfEz8dOY6AQ3dys8efIE33zzNS4f/AiDwRyjQQ6Cw2q5gKIxjG8y5UKIhy1tay2Ms9C+llnmO9EJbm5uUdcGeZZCJxqkFBJvNYvlPZ/P8ebNGxRF0SkFk9K4NE2D8iP3zpZdax1WRYU0zXB2doazs3M4x3SzQqP5a1+6dHV15XmvxTpvwjn5GXlKUoVgxW+3BYptgfF4hJPJFIPBAFmWoSgKXN/coCzL0BWIqucGAAAgAElEQVROnmWa5Vwq5tibAmdD8p+1gDMWb169xd999XeYTBIUxQaDwQCz+RTTkxOk4GQ+EME0NW5vblEUlbxMsMyrw9a241AXlwcWqKoSec6lXeIlCCEVpZhpTnv3t1LcMx2t7CMiQIiFFHsUkiRFotmNbZWGyQ2qqoS1DUCAShIO0fjrcJKX71LnAdm5/T7ZIXNcyvTqOnSi63qO3p39zEuKjtHSDV9G16coH8hbA7HM75PzSqN3iw01CYHtHe9loYReotGGfX6TRLv3HrT3rEf5lNrPdt3P8f67oLZ7rvsAS87Rl0h1yBLf3fq+O+imOWDth+v0HesXB7nuHO12yOpab/3zcWjbJQq4Txk6FhKQOGz7aNowhIw9zHf7qP09oNd17CyXAK1W6yBYxYIihdAcZFeQOGe9Ra67XMl+ToU+s9iypcbkKgMkOkFRFwFseNj8k/nAmw7TmbPgDkuNDTSTWmvMZzPuA+3dmqKdx2uZk7uqUMMdC7TO2vJz3ro/vWAWBciyp8WYBv/6r/4af/yPHmM8+gM8efIrPH/+FMV2AwJb1KZuYC3PgzUOzhJUogC0rk+pLWfCE4I1DtvNFs4aTmTy8yksXV988QUuLy/xl3/5l3j+/HmYXwlnxSAeJ9mlWQoQ82abxkBBYzAYoCgKfP3115xvAIuiKFCUZcjEbxUA4xVAA6UB69rYuXOcy1BWFba+5O7s9Azz0xkGWQ6AcySufXx+Mpkgzzj7/Pb2Buv1yruXHWfaW4PGOChfLpdojdWmgiKHzWqDPB8E5jLJtAcIjjR06hVFWeeBcrjrilVEPtmyQl1XyLIUgIIiDfKletbnGiTQwf0tNfAxn30IpegEyoO7VknIy3fWQpFXaP0Wv0OJTjgxklhxE44DUbrEuxXzH4TObU0TkmJ36777tl7rm6cqyAS7I6f6PJwh9B29Q7vXuE+my7MAvDJF+4lucs37PKl747sHyN970N7VuDhjMwYCuzcRHS2y/fCAAnA/gPZ/F09uDOD9k963MA5Z2+8C3PL7IRt/FyT7r7E/znu1v/iwA9MjoHx8240D7bu/vTew/dxrxxbw7FntWbIsxWazxatXrwE4DIdDKEXQidorn5J/AhrCgCYuvZgvO6ZcFCtb6CGFCUysCqUUt3FsGtRNFSw7pbgHcWOY4UpitmdnZxgNRwwofs52AVtAf7PZhIxsZ11nP/mpVNtnmadLeZc2mPzCW8xaa6yWKzRNhb/5m3+Nn//8K9xcv8V4NICmBNuNgTXeYo+8NSLkY6HM7sy2NreuayjNoKIjd/doNMJ8PsfV1RXqusbp6WmYt+FwiNlsFoBM3KvSMjPNUn8vLNxfvnyF1YpbgTJr3TY8O3Ftxy5da20Q0mLNDwYMyFXVoPSx7XwwwMXFOUbjIabTKZzlWPhyuYRzvKZGgyFG4yGUUt49zclYSmnAcHgDhr0RXA5GSJIUpe/d/fnnn+Ojjx7BWofnL57i+voaaZ5DWYVcc+kYgWAagPSOxRm/V851+ADSNOXvo3c9fsdbj4hGEtGKtnK1ze/QWkP5nCFWurT3uDBffa5b1zkp5dngmvA+NU0DkOOqAAvPGMdhFQcAlssJQTZcQxTcsI6PGTkOe3KvzzKP/96XtQzv/HGbnS/7OO+eOowNHXs+tjjaYb6joRiP/10s7/cctLsulvZny9DUsS6p1bliOKP2yR4FyP047vEEM0lsiB/g/qQfBuC+7dC1w+KTe4vAk3b2OTze+O/D7vnduejMSwQUhzhyyT+HQwuRP4vvrd/bTTu/hXFE3des5czmum7w6tVLWNvg5OSEG4UkFOKmRG2CU/yCxwk3AHeaGo1GUKDQmpFLgRBAu6kN0rQC+x9ai0KRBmB83Jq5vdPIihZwFottOp2Gx9i3DuWey7IMJWVxrFDmsaOkdtYZeYtLppCtTQIwnQ6RaMJXf/e3uLq6hmkMyBH3sG4S7xrnDmSkmV9buXbO4jE0TcP82w5w1nlecSDzYzHGYLlc4mc/+xmqqmrdqt4KZ7f0Njyj3WzzNE2gvdu2rmtMpxPvUq/BJDAtOcpmswnNRGyoMhHGMyZMUYpCR7XNeg3A4fR0jtFoCO29AlmW4c2r13j58iU3bRmNkWUpJuMxlCJcX1/D1A1SzclYCt5N3HBrTkly1IrvdTAc4ovf/gI/+clP8ODBOd68uca33/6SvSf+mTNNq/ZeKq+UETe2cQJU1Kq2jbGoa8MueCImESEdgIhV3lZ+aq1Db3Lnx6vQKnukiKsEFMsYpQgJpVxy5pW1pjHIc4JOEpiGWdusbcB0rhQqARLNXoymierKwZ6t2KKOFTTJWO/SykbyYEfehc9pR1IcMnbuM0bQKs5ifB0+pt/oia/VJ0ePWfL3W/a8veegvSOQIFqQDW4RXzTaC3DRWeSL7uc7E3Z0JDvH7k5wHyjHlvh3eWCHAFssa/nK7QFv1+0cz8v+/d2/4Po20fX7tOHuOQ7fJ9ACNfmXZRe4d4/ZHb9zDm1tpMLV1Rvc3t5gOp0gyzPkgwxJojtJMXGdcOx+lXpt6Qo2HAygQChqdkmLBcAA792BxnLymhfKijQM6nBuLqdJPAFLHVyUyzVbbScnJ8iS1CuSvIZjIJS5k3ivUKJy/NyGpDnypXicIMRxZ4eWTAJof4IMnKvgXIXz8weYTgco6xvUVYntpkBRlLBNEixsY71L3bW1pX3vgdRTK3AM0DQ1agIn+wFB2ZDs7tjbIQQsm82m7cAWgUySJAA5pGmCRKdwDiiKAi7iv47PF8fHARGtDNhEBE0cHigrZj/L0gSzkxMMh0O2RJMEgyyHNRaLxSJ4CaaTCeYnM5RlgaurK6yXq1AnznTijuPSSnPs17lQM7/Z1nj04WN8//vfB8jh6uoKv/jFL3B9cwPrLIx1SH1pI0ChJzZIgVnR5D6BttSJS/sq06CoK2TNADpJw37y/sUAGHMNWOupXL1CpDXXy/M88bNTSgHWIlUEazU2mw1XZYw9sGrNrWWdNEsxMKZmC1oTyLblZLHbXKz8OBwlz6/x9fC7ddVB3u/Iht6/WQvmd/2IXD92nvtc1aIUd+RofD6K99vf+jyv8vl9wP1+gzbtgyFbewjuLv5MdfYB+ic71nziMqDdffp+j/8+BNj913sXi73/uv2fAa2Fv6uc8Hf+jQ8guHc+YkpEUd2p5572xkWxQ/vdt905bv8WD0U/I1rf8e38MzuXtZwlvlqt8OTptxxTyxLkeYo0TQKnsVhwfYQlsXAQQWKsBZFCojSQ58HlCsD3mFYsrMDMYNwPuHW5yzmNsSgrZuPKkxRVVaIqSwyGA+RZ7j0m7XNqa1Th77O1SCUjO1BHRnNCytfQK84BsM6Ddpgzjq+SMiDVYDAk5AOCdTU261ts1ksUBTN3GaOC+52VFYJOtQdJtmoFMOV5ZEnKXNU8aB+/b6C8h0LupY/WNHaJyj6yibJinYHWHswdE6vseiMkVipEHXye1hMSrlfX2NZVIM+ZjieBEjQe32q5RFVV+OCDD/Dho0eYn8xQFAVevHiO9WoVFCitlC+9Iu9u5fg5OQtYjlFXZeU9LBVev3mDuipxe3vLJCgJE4o0jUEOwmZboCprWAuoRDRZ12tBSthG8h0k1COeo7hOWrwwEoSS7H0JN8psiqIkz0H+Zpc3BardNOXmIY1/ZvJ+yU+tFOC9XHVdI/Njres65BPEYwu95/287pGhUGR8RXPQfh3J/pBqv7//IVzo2/pkbGdA4WfPOUEta2DPc9u9diwD/0GDNqFbxwl4QbZjkVHHumw/57npxnniekT/S6+7pQ9U74tB97mU+/Y/uMX3Ff+UMYaf+4dSdB/sjWDg7lN6nAd+Od+xlyEeUYTfPNx30GIPeRRaK3tfQWl3ju4tWJ+isClkGZNpPHv2FNvtFg8ePECapsjzPHTkkvh0VVVYLpdBaMRWnYwpjcglGtMADoE5jRO4DCrUSHTC7nPDgsxZAbQ2ts1xugZ15ROhjMV6wz2J5/N5C0LecqLILSfzJIJV3MtAW599/Fl1Ac3JpFmDpimxLRoAFpv1Hcqq8F2vHIN2wwQZzqie8/i+3RBlS0F7typ8aZesCe6ZXHfyLzqlRuG8MWVp20mruy4sGp8wyKGG1hpnF7iDsTWqqoQxDcS7QJ5zlbuRUSjnMrbBaDzmOLrWkAQ+GaNwxD948AAfPnqEB5eXePP6DZ4/f4bNeo2yLDx1J3tpbMOVAs4T9FhroByzljW2RFU1ePjwEtPpBK/f/hrLxQJ1xf3Xg+XrCHXdoCwrKG/5JmkCW1lwNmb77jMAt0pPWZahLE2s2b4mLbEnR+Sg7Bu39YwBVfbP8hxTIMT3B4MBhsMh7m5vUZUlyLUeLABI0hTKx6qdf9nF2hdZtetVEfAOa6R1VIY/RQ7Gv+/tG4VM38W46vuu7/jDx7UJwvH6VqQ6obxj59j1tB7b3mvQRsetbOHgfIkAgBDLAw67etvfnSB95Lbylwi6uDpiFbeWS/T5zmWPWqrfYdNeyKpoIRKYXcl2usm043Udy0q+A8T1DIjgBQsyEvdh/+LeBdu2IUvLRHSfhyHepx/g457au16PfvcUEaCcgzEVdJLj9ZuXePbiGS4vzpCmCZSiIMBGI+FSHmO5XDLtaF1C68SX+fD5q6rCaDDEeDD0LkEmaWmMgfUCWos1AQNDQGPFY5NAANs552t8+DuO0zF4F66BsQanZ2cYj6ZBkMlmYdil6JtCkNSNO4fr21uUnvtcaFRZidpvgNJaKQrkFJzTgNNQRCirLYptg/FE44vfOcfp6RBpOkS13eLKrLBabpGqCxgPPIkiKMWsUqbxglZbf13fiEV7sCMLpYDGcA9qEMGaGoYcjAK0JvgIauiiBXJwULCuYRe809Fz9uta/g6yQINIXMDiiXDcBrWuYE3jz2uCjACApq6xWixBACYnE0xPTkJGtSKmiNWJDhnleZ4zk55z+OU33+Dm+grFdoPlagHT1L4Wnt8thRxwNQADBSY9USpBWW5Qm1v8+Ccf4k/+9GO8eP4lXr++QlXXGIyG7EqHg1HsDieVI88SgMYYjIiz0CmBI1brHPGz0C4BMW07GmNAnrJXFNV4LYj1S165dGBABRhkQ4cttCAq4MoOHGYBHI8n0Frh+fMXyPMBPnjwAMYY3N7cwFiLwpcwyvorvUVelSWz2hkD8gxuFsQ0uQC0J/4JgOcT+Ug7D3gKgsSOujK4BW75pRUSLhgkOxInCs/IOju0HbJ6+8B1N9mV34nY+uf/d2V039j2zcju9n6DNonV2AJMsAwpvnm3/3T2T8VUjq79O7YChF+Xca4nCULO4VfNIYs37B+O71s6BzaJo5CHs45l67Vt6ioOu9cLP4+M6dDxh7wDv7HnoOf87RjU3veyiXJwiL9XXrq7uzu8fvMG49EIw9EImS/FkX/j8Rjn5+ehPCi2UOV64vZOJlN/cqaydIZJJZq6gSby5BRcS11XVfvyNZLcJnH2OJZsUVYlVssljG3w8ccfY3oy3fMe8bpra2hFADgAy82GqVRd25eaX2507iUGbCIm0+H2mw5whMYUMGaJywcj/NGffI4//dPfAWgNpXOs1immJzmWdxXubu9g6hpEIySZAiVAXZe+UDiFhkKSpCBynLTklWjlNKB5fTo0rPRIuRsAlWho48lagoLmwCQxbd5BfD99a885tnBFYPNxPpZd+1i2V2DF6yFeFmMMTk9PkY0GrQvY8hpLlPZd4Hht8nc1NusaxbYAZ+Y5pDqBdr4CAAQFBQNupdlUNdhbUKMsl3Buix/84CH+7M/+EFmicX11i1ev3uBkPkaajmAcQJRBUQ5CgizL4dwS27JCY1wraxRJkNrPge30D5CGM5vNJrjIY/f2bgOWmBxGtm4mufJudiYsGo/H+PjjjwAAb99e4e7uDs+ePUNd11iv1+wyN00IP0lGu2Txi3eoY0UDHFYiX8+fJNhsNjDOtnFoimTnjqGyt/V85jpf91uxv4ks47HvJ8sdte6Du36XBjvaFx7j/mFb2ryFl5Qi0JbvqIXf+x8AtcAcHd8B77AnWsG8M7HRwb1XOeY2PnSoC8pAC9wUri9jj5SU3nO2i8a5/Yffjqujshxc0PFx+6B67N5Y0OzG1LrarVjS7Tlj93DfcbKxMNZ49fo1CMBsNuM+xVmOwWCIyWTCtI2TCcbjMZqmwatXr7BYLDCdjr1g49piEeRpnmG93WCQ50jhiSKaJjyDGEwqD0Sxxi5hG60UZ2BbzqguCrbOPvnkEzx8+JAFm91Zr06iltG5iN25tzc3QRh3asJB0ZxFCZtsk4H9RwrGNlDKoarv8L0fPMA/+ad/iA8/HsDYa2w2V3C2xPQkw+NPLpDoHH/9fz+HyoYYj8YoSsAZB6gG1mw51k0ZXIjVCWmEXJ/j/dohgDZ7gBwT23gWOk0+QTDIM9cBlXhuBIR5jlz7PjgXku1M06Cp2TUeXLFoS4lurq6x3W5xcXaGs7MzUMLnUESApgBQYa15hYKcgbMGyhkox34CYR5zzkERYE2Dxq5RlWs0dYm63mKzXmAyVfjH/+7v44/+5N9APlBYrxd48/YGV1fX+ODDM+SDBJWxcC6FViMM8yHybIS7uxd49fIWVeWQBunc3rfI/k7uAxCazoiLW4Bb2qTKWhHlL2Yl47K69hjyAJ6mKYZD9lhZa/HmzRu8fPkSiwXH+weDQegBL4mS8GOJe8mLxwmkAWc6coAUQadpkKtaa87L4EfT8oN/B2w95gHs+/438ZDuWeE95+4zdGJlc3cfwaf7tn8QoA0gMD0FUO1YjT1a1q77I7zs6FjKXWUAwZoXNCHn4g6AHbjrBFIiPBVQcuE8XavBub6Fs3MfxC4ef/fh2rHnoXt83/n6LeZDc9a3UGPAjl/8/jPE1+mzrvu00n3APgbcRJzgsVlvsVwuIfSLbB1pnPhMYBY4QxRFgZcvX+Lly5eYTCbIsgFboor5v4WmsixL7gjm3dIS0ya0ddXBEgGXg0l7TRmXcoDxZWHGg35d17i4uMCjR48Okkew69LbbYo6tcqr5RKIMmz5OXTnhS3ssLgZuMmPiRSUMjiZjfCP/vEf4OOPz3C3/BZVfQWiCnAGSUIYTzXOLwf4/X/zczz64HexWib46suneHu9gEoUOA/NcczGMs0sZ5Vz6Z9YqERAqh1cYkIiWVM3qKs6WHccluB7sOGefCw00dE98rsi1eeSYOSiUIo1DeqyQu2TvQCwN823MV0ulthsNri4uMD3Pv2MvS4NU6my+9xnMseKGZg2VgMwnk2NnIUzNcg1INQwzRbLzQKLxQLpoMajh49gTYpvf3UF62r84R/9Hv7Df/KHSFKu9X798gW++eXXSPMMaZJzT3Y0aBqLLBthPnuAsiB89fMnuLpaIM8HHNowPK8Wni0MCKGd2IqzzoXYdlmWgcyEwwdt1vZutrbQ8w4Gg27ttn9HtGYL+NWrV3jx4gXu7u6QpllIdpNySLGi4/JJuTaT+igOUfpy3ThuLeOTuHr8rsm6cth/dw6BbUfh63vXejyp95332BYDcnyNvn06XSL9xgrgrjl6ePsHAdqCt7s3RPFNRl/G1sfuiYL1unOcfN7Gkal1kzuE+ETs5LCiASNaBPGAxKUVCVmEs+xvDvuA6rB/3+3tHF60u4rB/mKV3/v3Bdp57Iv/vIs3YfeYQy/TIY9Ap4VoNAvGWFxdX2G9XmM4HLLrWjK/PRHJZDyFNcDt3TV+9atfYTQaYTKZhLpp6Y8t1oIwlGmtmQTFOmjF3Mgx2AbvgWULT1p6JlojUW0yjWk4tnl6eoqLi4tQ8sL3CxZi0fOQDk6ySX/k1WoFsbrjRhpxnbv/wK9VbyUSx9u1TqF1hdOzEYaDFMvVLbbFEknqPNsVC0SdWkxnKeazOT58eIEnv95gNs9xdd0ANgGshm0YqB25wIHNYRyfKwHjQZCQpRlEK24MxzbFHW19wh8zfklculUouW4Y3mfAlQ62I4zbHIK6rlHWFWrTpT6ttiXuFneoygrn5+f47JNPMRqPUFUlFHyWuOu6OUVZl3rzxgLWAM5YNE2Fpi5gUaKqF7i6eYEkcfjs8wf47d99jI8++hgvnr9Ami4xmaT49/79HyMfWCzubnB9/Qo312+gU4vxZAhjgKbhODygMZteAG6I//P/+Ff46U+/QupLpLYFx6BNCLdwXFvthAMdAGeZEU7WdJ7nHSU7Bm75uwPaeR60ZeNj0NJQZb1eYbVa4u3bt8iyDKenp5hOp5wV7i10+Scu8RDX9ZY7LEK5IpflsaJJxBwLxjScFIid+HAIjWIP7I5tffLpmMw6ZH2/y/WCd+eecxCxl8mia/zIej8AC3vbew3aBHY3MjVf93OJQYcP4uP6ABvYnxSi1tKT8+4AVt+Ydq/TB3LheG/Zx/vHbuOd4YT9Oh9IJFC0l73wQPd3iQnvgm13bO0d7d5mH6jGAuC7APYhbXfvepF+Q0TwzRcBxAkaQKoT3Nzd4u7uDuPxuNPYwFqL5XLJJTMG2Gy2uLm9glIK8/kcWZaxMNxuUZYlJpMJiMjX/bpA9BHaP/pYaVmWQcAFoec4Wc1ai+1mg6aqufY6ywBw1vkszzAYDrnZhGvLmXhObFAMo4mILE+H6+trrNdrkGa2rfjZBis0fuE77jj+aRrLCWENodhuUFWchEhiFVmZb4vhKIGCwaZ4idPTEwxGFd5ePcEgn+H07AFcw+vG1A3YsNfcvMRr1OG+wO9tnmVQilD52Hax3aKpa+R57gV6N+yQZRkab5GL1ebvpiPIRTGK69fruub58+C1Wq6QZik++fgxzs5OMRhkMIZZu8hF75MDFFRYf8qfmxyDqvXla9bVsNhivXmN1eoK3/vhJf7j/+g/wPe//ynWm2tsVivk2QSz2Q8wGWfIcos3b17g5uoKi7sFFFnMT0+QJCnSLMH0ZIbV2qAoMvzi717jp//q5/jf/+VPQZRgNj9DWdRQygRPTusil7LA9l3USsEAgaRG6G5lrnZlkvwTwA4NW/y7Vtc1CAiJZXXdoK5ZIZvNTnF5eYnBYBDc8cvlMrx76/U6lN3J9bRSMJE8NdbCOObih2XjxxjOvs+yrJMQxx3OOFGw00qzR57shqsO7dNnbe/Kyvus8fu2QwB++LN3c40D7zloA5z/wvFZ/4GLwfW7JITtfeHdbeJGjJLUdi1CoghRwwkidzqDKbWnhiNfxoNYkFJHePdtfUC741P4DguCOot43+3UKgV98Zfd8fRZ3Ie2Q26o3pdOPgrxuv1xyIu8LUu8fPUqzGM8T8xwtUWxrWB9e0k4wnw+x3A4RJ7nmM3mePPmNQaDgeesxl5HI7FoTWNgPL3i7vxZZ4N1sV6vYeoGFxcX3L7QW/1JkgC6a1EHoQFvpTpRWsj/zqBXVhXeXl+jrOugTLTzujN/iFOz+BOxxJXimHJZbLBY3OCDR6cARS07/QukiQFcKQOdcheq731/jqfPzvHN12+wXqU4mSg05KCcApGFshIDJd8b2yfkWc7IZvKOjPmpBTC90iOKkqwTsdqsNTDGhnnkDOe2DMk0XEJkfLxa4rOKCJo4NOGMxcMPPggeDq05yY98YxAV1nv0PjAFnL9+HaxNYyqAKhizxHL1HNYt8aPf/xj/7D/5M3z88SXevH2Km6vXqKsCOm0wnTlYs8HLV0+x3WwZ8IxBkqWwhud6Mh0hyTQWyzX+1//lp/jbv7nDalliPM0xmUxQ1RoOvquWIvikcbDvoZUFArydkBVRUE4BhJ+xwi0dzmQ/SVZTnizFBEWBj5NncXp6ivl8HuLb6/UayyWHH8Qqj7n7tac7JUVIfKWDGCytm54Tz4yxyHx55R5x026Zzjtuh4D37wvIwGGDRL7b3aeDJeiR4UCrSN6zvfegLa4+hCyMeFIAUhoOzcGbPfS5WHTy058RhIh03lu2zl8+PidFv4cTxtdF9+G8q2v5kFtGopXxxe5z4XRBugsaXUv78NiOaZ731SAe02TDOdED0hS5xaL9iQi3d7dYLBYYjUYAouYHUIBjV1xcDzyeTDAcMkBPp1NOWEtzzOenTFsZtYwUy8I6B+ctbhvceRFw+yQqIo4/O2txfn6OE19GJGOWkiKxYOJkq9YLIwLVG8t+Ta7X68ASFte/dubWiTzz7jn4bG7fPIK7fFnAWtzd3eLm5hbOnfE8OYmht1CgEq4LH+TAYJDhwYMLPHr0AP/dv/iX+PLnzzEYKAz0BM6lLGxtiqoin2DGVJVKceY66fZ9FeWGIgtKkwqAay031iAilDWziTkrvZZrNGXte5E7GNMgyzKs1ys45zCZTDAaDlhBIKbXHI9GODs7i2raPWBZh/hFtZYpXXVQ4A2auuaaa2dhbYWyWmG9vsK2uMLZeYof//iP8aMffY7JVOPF86+x2Sxh3RY6cSBloHWCqgLWqwJVVcM5IEkzNI1BUzXcPraxePPmLV69vsY337zFzVWNk/kUw9GA14sF4Ijzafz70BVCrWYbW9Ky5iSDHICnlI3qoylqEhKFlGKlMF5vg8EAZ/NTOGdxt1jg5fMX2BTbwO0u5xdgFw5xZlwjAFGbTtOuBwlTWd+wRTqRyTgPyQ/5vE+evMvve+/Qkc/u8yp2FYt+Q2r3GrsNTeLN7XjLDm3vPWjvuhBiwCLSAWwPH3PovPwf7+tAjlrLh9WeduLlAB+7EKBXe5P+bhpcn5Ym3gO3sx+DqvLCWSGOC8Sg3HOVI4uyf8EfG3+fxdyXNkFoxy377R7f+Sy6ZgzaMkqKspaKosDr1687jE9sgbXWZ5IkyPM8xLDzPMdwlHshRthuC2RZjslkivFkjKapWsGWJAGwRXDVpuEGIN6qM8526lzLbYFEJ8H9vuulCd2S+AbDvcRzQFARePM/cTNKnFDAX9irGHTRrkmZAMcJRMoztwFSM+wAlya87xEAACAASURBVGA6OsN6s/GJPb7Jgy/tmYzGmE5PkCRcivPw4TlOz2p89vkUt7dXqJsrNGaF0WgGpcfgaDhgLfNvO8dlYKlSoCQFEn6XSHmAUKp1fQ+HAbAl7KCUwmQywWw265QPpTqFVtzZ64MPPoAxBj//8m+xWq2Y3jRJvNLTutSbuo7AxwXubLHuWFXh+fO2n3/uNRpToioKVOU1arPFyUmCf+cPf4xPPjnH+fkQZbXEzdUVW+Ew0MRUnlmaIMuGMI3FavkcdVOzUWGVj9kDeT7BZmNRNwbWJBiNBshyy61eLS9+60laeNXYViCF9y7az7XygJUag/V6jfl8Hur6RZEUsAx8+EDoZS1Kqcyf1hrj4Qgn0ylM0+Drr7/Gq1evYKzFaDLGaDTqWPpN03SUA2tVyF5vhUObICnXMdZ4pbsNHWqi1htyD7Ae2/oMlmN/952/V4b2ydYjCsMhQ2jv+9iCObK936BNEZiEz1orBvJg4+zuQ5bqngbTWq3yEMSgj8HYBnCicMguWPW5QzrXd62T/Jh13LcUI4O4DQXsnKN/EXdjJLF3Jg43xAB7bOtzk7/LdtDTEZ8P7b21P9vnI9tiscDd3V3IdBUhxRq6Cm4/6Sg1Go2Y0SxlQg6pG5bwxHa7RV2XbeZqlKQW15bWhkG7bmo4opA1niQJGtNgPp9jMp12Mmc7+Q1+/NLPt3v/rIi1ORD85m632zBeY214RPH7LaZ67BjfmX0QEsAZpOkIziQgykE0gLUVrDVwiqC1wsnJCS7OL9girCukKbBcvsH1zRpf/NZH+N5n38PrVxv8xV/8DTabW+hEwzkFJZZUNALrgAbeM6E1N5ZRbXcwUTaJWt73mJUrxFitw2g0QqYzpEmKBw8u8eDyAd68eYOL03Ok3loUcKiMf76QOmoA1ve41i3JCMAduJSn0bWGU96s45aqVbHB3d0tHj+e4LPvfYHHjy8xm6XYFldYLt/C2grONgAMFAFJnkCpBNPxHLPZGZ4/f8FxXWegnIIxXEvOykOCsnCYnV5gPndIkl+wGkayDz9jEyU/UjSvFK8BUdpdm2xWFCVubm4wGo3w4MED/5xat3gARsUWdlmWgHdPE3FoI88z5EkKZy2ePn2KJ0+eYLPZYD6fY352isFwCCLC3d1dpzuXrH/2rOS8vqwDUcTEphWUuMh97TtTEjPFaZYkcFkOStgosp0AY7Syj8j5PhCOP9/9vq/mujO/+6/VnhFy6Jp7473HQ+DPuH/NaHu/Qdt1f+10d4IDwbLx2QMk/bHh7gT7d5YXKxwkkkMRaCh4QRppu/Ki7EvKfQCkSKew1L2+w47wBrvECJzFzpqmA4jv1pF3YeHwA2/vc2cCwa5L54QJLB7z/5tbG9s8uEf0MvB8dEGO4JswgBOkmMNXBYKU2DJrhX/qY9Yz5pSeTlsK0nBehzTj52uaGmXVBGCU/TY+pidMUsZwaVdtDVuVxnDv5e0WH3zwATOc+YS4QMBJBJB3jWsF8gJ4F7DhyNektjmy0smqrg2McWgaywk74VnxP99pEyoombxOuFaaIBVanAkNkErx8u0d/vbn3+LBwwF0OmSmKtdgqBIkSeqpUrkTljMOm9USzja4fDDE7OQSjz6sUJTX+MXXT/Hm9a8BDDEenUInA2idgSgBoNEYgrUptE2hDeDIIkktsiyFNdLNiYK7nAlQagCEYlNis9q2eQGkUDUN0izF67evMR7/EjdX18GKFDduY0xwPdrQScr6/uUOrvLKmuL6aoBZ6MSaZTpPwKFCWdzht3/rMf7pP/u3oLXBzc0r3Ny9gLMFSDdQmvtyc9csjfF4hvFoikTnWC2ZDMc6i9pzdPOzUHCUwrgGja0AGkCpCcrSW5lOgWwCB0IDB0sK1ifIiVdAwXoPifg4ZE0wlQ5Bo2lqrFcb3C0WmJxMMKIhFLXlX4nWzPzImgGPBazkJEpD6xRZkmK9XuPXv/417u7ucHJygh/+8If4/PPPkeU53l4zwQp7T1I0znJ0hGxgUsuzDFVRonbOyzL/PiuCkjadPs/AerZAIlbunCI4RQARyIk3leVAKzOOeRL7fz+Ut7P7/bu41o8pAccAXZIg/Y6d/fiz+z3k7zdo+213croTfPyY+851fH/yF+ja1gJKFGKJaPfbWRxOMueU4nIZ19ZHHhg5H+etTtYXDlv2fW7t2AXeftb+jLOY5V6OJW0c2np1YNFC30EXOLTw2989ZS1ccLMNvVu13Y+gFVtos9kMp6enGI1GGA6He129kiRBlg/QNA22dgtb2/Bd7I6NGx/ITxlTWZa4Wyzw6NEjfPrpp0h8TDDmdY7vQ6Kou8lCnHzGX7ITm/9M0xRFUYRErdalK/MtD5K5C6Q9qgN7hUSwcTmVV/bAVtzzZy8xHBg4+hgffXQCosyPW3OSlGNAc8qXGTnrFQGL9eYWpBN88ukDKAVMpjcotoRi26ColrhbVBiNpsgHY27naB2qpvZgrmAsd7/SWkeeK+XjvRar1Yq7oSmFJGHAzvMcMIYpKYlwc3ODRBMuLi4wnU47rF48v62LtWmkjakLYQZjGi6tc8xW52eGyd7QoLE1FqsrJFmF3/29T6GTBre3r1GWSyhlQAkhy1KQSqGJE76GwyFG4xFubhZ49eIpjLEYjSaYTk+wWm05qYsyj70JqtLBNBm0muD1y1/j9esFSKVwpOCIe5OHDmbhnd0BFPJAHbxkXV+LtdyhLHudYT6fYTLmMJFUREAjrPfYM6QzBessnj17hpcvX8IYg8vLS/w/1L3ZsyVHkt73i4jcznaX2jc0gAYw3TNszbDHRCNlMplJepD+XupRpBlNi4kSt+HMGLvZjW4ABVThbnX3s+USEXrwiFzOPedWocmHmoQV7r0n82RGxubun7t//uTJEw4ODqjrmuuba65vbskLcTFVpaQ99ilTnVSsoQoV8uSzsKLVMBMgomV9BGy4z8c+EMXkfcFfu45t33ufDLgPVdxUGtQgM2T7NXHfbw2W3uPa63ynju06/kEJ7d2fbfdN3HePTct79zPE3zgoUqK5E9AoSydA6RuLrC2oRYBi5MTAnyttobcGVedbb99w2LZtysxP6Yf3Xb9NkA8m5S5Q9j1C23vfRi3fEfxK4VtsokvNUUq11KSt/0wnRFKVLEspRjmjURH8nLLx102NdZ2/rm+lR6HYDzaLwjduJP0cbe+FwGJUFHz11VeMQtrLQEnbmE8KcJv92xPY7XvGvRjP7e0NVbUGOiVv0O+6N19bRMW3AhodK5gpJLVMyC2q0vGb33zDwcGYly8egRefrPcCdScmkdKKvm2M3FtbVuUN3hlGE8vzlzOePn9IXRuqUlHXmjdvTnjzwwmr1RpNSpaN0CrHe4tHoa2hqTRZlkvdca8wWU6SJ6zrEtfYdj1473FNQ+ks1jatUjYqcqqqZDGfo7ViMpm0MQ9aSyCiGJByLxfy7TW0cHYTfKauvbcCo/C+ZLm+ZF1e8ld/9RWzA8vl5RtssyZJLZPJiPE4E3a5spT5ZxKWyxVn5xfcXN4yGk35x3/1lxRFwf/7b/4/3rw9knLY3gXFO8G7nL3Zc968vuZf/ot/z/VVxf7BPs7JmpF52RH2SOh4z7+r+sJEt0M0iJEIuc83NzdSQCfLBUIPc7kvsPvKplKKm9tbzs7O0Frz6tUrJpMJeZ6zXC5ZLBYy/8cjHj18SFmWLBdLbue3LJeLIHRlLkoaXkXdNMSqbKKoChmPVgrba0PTNHcqwA3l5f379H0Ctu3Ljes3P991/bZDbwjp+5SCvmEVDbx2ngekMcoDkPKx9x0ftdDeNUjxHGxO1vez3fS/u/l7+ACvVMtBJvto9AF3vkUV9sPhPaK1PdScutPdRh6/10UF99619wwfBHhfn47v+r733PbeH9qf8bP7Asn+1KO1QNWmN1YFd0UvH1N16V6R6QykfrVSXaSsNrIRr9ZLsjzFJAIVyj9hGEOZgZDuWwcxGKdvdbfc2eH39VpSoX75y18yHo1agR03SmEKk/dxYZONcH8HbXaMeC2zV5SRSlGWa87OTlksFkgEc5/2EQYBHL3+bP9pqYscjbBAX4JWKVk24fLymovzOVeXKx48LKjqiqqyku6lDE4JTOmsYOsquGecr7DW0ThJTcqzAm1GTKeHPH3yCe/e3fJ//1//hm+/+YHzs2tubq4oigmQkCYjGq9IkoyaGrwhTTJUA01jaKoVSQJZKrEJcbfWWpFmGcrLQhgVGUUuZUBtU2NtjUHyll3jkTLWAneDaytvVVWJ1uE9XENTiT+/aWqsq/HUKFWzf5Dxv/yv/5T//n/4Nav1FT98f4Kn5mB/xv7+FGOgaWrK9Yr5fMnV1TVVVTHb2+MXv/glr159yqiYcHx83M45F4LenIOq9hQq59/929/xL//Ff+To6JK8yEAbbBjgTdIc2WaCv7l3qrNAt6eV1nXDel2yWq6oJpMwpq5bC+HoC/CyLFmv18xmM/b399uKX1FJjvzms9mMpqpRHg72ZiyXcy4vz9v0OhHaFhtT1eK+4z0q+O1Tk+Btx87WZ2zr9vD+WrlfkP6UPem+wLAPvd+de8Cgjdue0Vfkw4dSDiV+Z3By9/FRC21UF9ywzUfdDe5dLWqX8N7UsO5AtEohBAY9a3pHR+pwfZxUGw9qN+T29412DNu4AbfQrsp+d9x5p+HffdEOUTu9/xhqqZvCeVs/tYEb96R83We9A6EIwobShb67OL0CF/NrQ6qSVySJWM2JMW1+Z4Ta+sI4fhafHbX6GA3eF9ptrWrn2u/Ff+v1mpubG7766iueP38uQjXSMwbrod/2Ll1Hde+B5Df3x9452r5USjG/vObm+rqXZharesm9lI8zo0vdU4RUq14qT0tcgrhlBC0yGFNwdbXk5kaEdl03iIGjSdMsRHYIvKmMJkkyEit+7qau0cpSjDR7s5zDw4dk+ZiXLw9Yra/45NN9nj6dcXZywdGPZywXa65vbrF+TVVZmoUjSwuMzlHKoE3CuJ4IzG+krrSzofKW1mgMkcRUG0nns00TilNAWTrSNEF5CR5sqlrQBeVCmc6K1XKJUo5PP/0ZSZrw7t0lt/NLQWISSBPH48f7vPrkM/6bv/yKP/vFz1B6xWJxJlZ2oklTTV2tuS1XrNcrrq+vaRobcpcPODg4ZDTOWa9XHB0d8+7dO9brVbu+nJfib3XpODk64m/+wxuOjm5Is5w0L8IACiLS3yVECVNgXSSsoDMMNvasjXUjcwyqumG1WmGdlDelru4gZHG+J0nS8vYXRTHgL4hBoJJL71itVuR5zt7eHje3ty0pitY6KL9R8TLtnPQB/XBNV/jGNrIe+qU5Y5Bn2wdKIv53Ce5dgWCbe86gX99z/kOPztBSrSZ1nxXfw6/uHPfxd/SPj1poK9QgIhd2d3A/kKl/7baO2By0bQMuFvZwELTSPTiJFgqXc0K16EPaRlQ04oTb9ZyurRChpYEg33L9wLIa3LP/rlvyene8b/xsl2Kx6z6bKW/D7209NXz2QCFRrVbdv06h8TpCS0qiXpUFLxScRivyLG1JIuLCX61k0+zTN1pr29zS+K/zuXUQedNImlcU4KvViqurK549e8ann37a5mbH6FYFbRGQQX9FSLP/PsoQa0jHzTciLlLpaEFVliHq2d7pR4/wFKt2Xvt2M4/Pbit9qZhKE8W8Ic9G3N6uuLqa4/0DjEkA29K/pllQ/bxH+5AmlGSUqsIoYUArspzHjx9QNxV4xeXVW+r6khfPZ0zGe5w8KPj0Zw9YLEqcU6xWNcfHp5yenJMmBq0MZVmjdMPDR1Oc8xwdv2G9LlEqEad6eB9jDKmW6GyJyPYhkGmGu7VkaYLCsw7sXNp4lotbVqsFxijG4xH/7J/+U37xZ1+Aajg6mjGfL3n56jlPnz5gtp8z2yuYTgvW5Zyzs++omxVltcRoRVVWLOYLjIa6rpjfXmObhsl4LDWjjcG6mvPzUy4uLqgqy+3tNTe3V2ijcRiwEmC2WJWcn9+QZRmzvQlVLePpgwsDZVslbrBmWt6BuN6H60sFhW1QxS7M/bJcs1plrFYr0jRt/fsK8LazsiPRSmRI01q3qWFXV1f8+OOPAHzyySd4L7Eljx8/RmvNulxzcnpCVdfd84MykYYCJpEpcDGfU9ZdAGisSR/XalSoIz3qQH/v7an/pcjqNuPkQ/zem8cmMvm+3+Pf3rneuA7f733C+6MW2ijaKNH7OvbOxnaPoNlmUW7+raLw0MNJ4Tct156W5fr3UdL4CPFsM9W3TRo1+N7uoIa7wrpbzP373ffM4We7reLNhTFcNLsn1+Y77IKNQuvpgs62tLUHn2VZStNUSKUpyPNMKjTRpRBFKkvoin1EkpI+9eWmb89a2xa4kJKN8u43NzcorfmLv/iLQOyxINEBAWobfLcQzDaEKB4dAUyXQ2ut4+List3Q6LlWVKSvVN0mLd/vNnOlVJuHK1ZSKPepvaT7osmyMWW54PjonC+/fEYxGeHdisuLOZNJyv5BITSniJJqMCgHxksZyizJxffdWMr1GudqKd1JSZI0LBbvSJOKJ0/GPHjwM37+5S9Ikpw/fv1H3r75kdWqAowgJlpy41erNbfzp9RVg1IJVdnQNOILL8uK68trrHMslxIRPplMGI8LbFMDjtQYppOnPH7ygKdPn5AXKc41XF9dsl4t+eRnj3n+IqdpFM5nPNdjvvqzn/H48R5Vs2S+uOb03Vuur6+o6wpjhHQmSyXtqalrdCpwrtYJ47HAxlp5NFLb3TaWsrxlva5ZLpeMRgXTGhZLj2sS5jdLvvvuhNUSTJKjdSmoRiClkXHeYRH25lFM14xWLe3XfO8eSnylIQVsbuacnZ0BImwlUl7m73K1JMsycmNQRuMA6x0GSTu8vr4OyEITrGzPeDzh5ctX5HnGcrXiwcOHfPKzTzg+PmnXXV3XOGtJi4LHjx8znU7x3nN2dsZtcktlG5S3uNrhXadcr9drobMNkLwOBUZQgbWyt498iMDeXHvbhPaHCv9d97yD1t7zXMK14q67azx+SBs+bqEdjn6AQj9wYlsQwK7P++e2baTDztoOu0OXaiG30ET4O8jb9itdO+4K0k0BuL0N2z/bZmFvb+t2ZeGnHLsE9od8L1pKu5SjDuINqW73tNUHQYWWDQUdyimmCTpJBEEP1muE76IfummaHtd1Z21H9rM4H2LOal3Xov1bSTGJfuv/9p/8E6azGcvFQoqF+I6usR8weOcdN+ZgNye68YlC++bmhuVy1X4WI21j+lIMQoLAUR7ncQhYiznOaZqSZRl1bYcR516BN9hGc3G+4PzdgpejfamUVTmq1FOWDXmmSLSWQC6LEA8pcU9o7/GNY7VYgNZUZUU6STDao7HYuqRuVjx5csA/+osvePz8CeVqTfXJAZOJo1zXZGlBkqQt2Yc2CR5JH1LKUK5Lqlry0yVVyfDu7B3Ow2g84sGDQ/Ki4Ov//Bt+eP0tidE8ffyIx8+e8Gd//ufsHUypyzX/9l//a16//pbRqGQ8qklSw+XlmqvLK87OHOtyRFmtqKo11knUswIJTsOjNaSJCiUiJaaiGBUoJVa3tY34xRtPWVYslyVpkpIXGdpkzBfiz06TKT/88JY3P1xyePAYrROyIsciQlIH4p9IZRsmwB2kZrif9WNgQrwEknrlnUeC12ij52/n85aHIC+K1hUU0QyU5IYb72ispVosWNzOKUMcx2g0AmhJWJbrFTfzG+qmZjKd8PTpE25v5232RYS3R6MRBwcHbTDbeDzGe3FfrFY+FCYpA2QuELhrLBphzWvXU1xjf+LeeZ/g3mUt77rvzntvjNX7YPttbfgHL7S9E1/VZk4uDLWS/gvHTa7/+eY12wZpkAYlvw3Oh6tpQ8dj7vZAgArU1QpNFbfnD5s89x19TY07fbDNWo6RnN3xvuCK+ybxNqTjfe3ehnB05wBMUKK3LyLvPTqRAK+bmxvevXvHza3AiyZJ0MYIDSLdPFksFkynU4A2rzsK5CiwozAHBgK+Fdp1Dc6zrkrKsuTXv/41z549Y7lYtBBktAAiEWtb/zy+72Yf3FnAIvCbJmxU1vLm7VsW8znQEcHEXObwlW7zCn8rJQpPYpJWWLfkJL6LFrbW4hopk+is4eJ8wQ/fnzGe5IxGCaSOuvJU6waDIsmz0E4J6hLFQPKaq6pitViSj0dkeSbvRsj/dxatPA8O93Cu5vjN6xClbdnby7ETqWWeGoFMlda9oMKULMtRekKW5yRpikoSnHXUzQs5F+b82ekxR0e/Yf9gxKefPAsBPXO8u2K9WHB2esTl1fckyZrx2PHw0Qjva9brd5ycfkc+qlD6cWvJ4nwggfEIX7sL5CsW5z1pVrA/28cYw8XFOTerVetioY0JSKTAUeRhd5qqtLz54Yjf/+6ELN1DqQKTpDx6NAJluL6ds15XxExs77uMBcFRuprlm5NABIMb7G1KKal7EOZMrGFe1zU3NzdYa5nNZmRp2hkbYa1Ff3K8tq5risDyF11Pq9WKs3fv8FrKqKZpynQ6oSgKskyYAgWFULjg516v1zjnWC6XeO9J04TZ3pTGNjR1Q6IbnLK4UN++qSWAMCJNUcWN7dyUA92esl1w7xKU/f3sQ63cbfcPv/wkRWJTof8pz/6ohba1lsvLywGxfRTMHbF8HEjhXY5MaXJ0Vo1McNrPo+zrBk23G128cDMoJEZvyhqKJtbG0R80uolxZ1A2rhsMYs9y9757nu5NtqHF/WEBDNKWu599qEV+n4ti46b0x0CMy7sLJ9J3xuviM/rXNE3DxcU5x8fHlOuy3RDFXycUpFmaYJ2nKAqqqmJ/f588z6mqqp0vMWq2D40DdyzvKLS9c8xvb/n5l1/y2eefMZ/3BLaOlbVUUODotV3mog+Qntp4p74F5VxIx1LCf35ycsJqXYUIXNpruoXu2zmF0vhASKG1JkkTsjxrLe2uOtQQSvRomtpzfTXnD394Q5YbXrw44OHDidS9ri2jIvgTw/MS088G9zgr9y6yDK0NTSm1x7WCIs/I85R1uebo6EfG4zGT6Yi8MGid4LwmMSkKTZKEvsCKoHSWqqqZTidkGaAammoFSpFnCZ4lzsHN9RX/57/632maW379139NZhS//c1/Ih/N+PGtQSnPajVnPE6wjeJ2fsG339SsVnOqckGRG1Kp5YL3kXQoKu+KmF2fJIqmAe8d1jYslwuWqxVv37zh6vqSwweHEt2uZQ3G9eW8kL2sy5rvvz/lb//mLbZRjMdTtM4pRhOePX+FMRnfv33LmzdHVHWD9107+tZarwZht3ZkArZKWz+tUKDXXj5wUEpj7WvnpCCLMYbJeNw+J66PyMNvtCjVJgR9RuXv4vISbRR7e3t47zg5PpZiIdbKXp0kVFVFVZb44FcX5CK4gZzBE+4beOlbQ0RrrHOsyxKTJKSpGWxPuw0ddQdc3IZKbh7bzr/XuNmxXw4E9o5nxHWoI8PVFvnwvud/1EK7aRrOz8/boIQorLMsGwRMCMwmQrtbfLqdiHGT/xDLWwSM623A7ZmWyKIzd/o2efw85t7dr3G5VgHQRM9kkARAx5DVbv5KUtEUQ+Ed7ral97YLc6X631Ptew6vuWtx9z/fqYiE405qyjbdxnvwDU5t0gh6tJZgpdVqxfc/fMfp6alAv0keLCONbXxI22lYKgVKSmiWZclyuWzTVabTaYAfBSSJsCDQWhZlWbbC3Dc1eMd8uWAym/DFF5+zXi2xTYUxIdqbmNLVvayme0/vnRCmxJQ2cSl3cy0Ida8cymjyPOPq+oL5co5ONI2VfOI71sXGfyiZkUaJlZumCUWRt+tA4FEpM6m8wnlJ5dLaYHTC0dsr8myC0RmZ0aiDjNE4wXqDxaOVlH1MdAIrLUFr0bLzFu09Oswf7x1Ge9Lc0VSO+e0lifF4b8jSMc7VpKnGmBTnpHSnUbTlT5WX8rtGQ71e0VQl1oeCMEpcAzHt7ptvvsHWa/6n//l/5Odffcnvf/MbLq+u+eLBIa4Wd0aiFKM8o84MrqlY3F5JVLJOGBcjMpOinCdLU6E51TIvhJlMcv+VcSRaUqVsU3Fbrbm4uOD88pTJZEyWG0yqEQtZSYpTQN9q5zm/uuU3v33DutTMZk9I0wnaZEDCel2R55rpeMpsNuPqWvz2aI+30Q2oUSTSv/SZAyHuE1pLLXJR5FQrBDpkRxj1VJpCsKYjApWlKZPAIQ5S4S7Ww1ZKtcxxQ6jXo7yjXK1YJwmuaVh6UWYnoxGpMUFhdKzLFd7W1HWFKEEJ4EIw44g6a6gTS504lG6wjUNrg/OK5XpFkqXoxARUa7ew7M6F9u247IMMDoZCdusep7izv9+Btze+r7qL5eemjCB+7O95Szk+aqHtvW9zA2OEb57n5HlOlmUUhVT3GY/HbbEGpVSbuxuF+jB4aoP4xG8QV6iOISz+va1d2891wUi7IN/2OfH/waQeDt9dyKtlC2JjMmzR0HZB5tsh6u3t22z79gn/YQtg2/NV+9534SmjNbe3c77++muWqzmTyUQ0/SBwlFKthRyt8ZgDHaOgI6NW0zSMRiOSWCihR33pveSztilgTQNIes/NzS1/8Rd/TpIklGUZ5lGHznSohbxDfJ94rou96IqBDPvBD6yXs7MzqqoiMelAsdjsxyi8pSpVZyFF3vU0zQbz3TnwDrwL6V9Ko5ShGE3Al7x+/SO2WeHsC/760S8ltaup8T4TFAElNKCdC70N2FutV0wmEyC6GQCn8bZmvVqxzFKSRCBfYwyjQljqlPfoNKVxEnBmrSNJJHiuqWuur69DhSyPV4rJOCfPM6n0ZRuePnnMk8cS/PTu9JT/9Hd/R57nJEka0sckZz9PMybjMcvlosc7DkmSoZQRQhOkWIpXwn8d14OUFk1JU0XlS/CGxCSMR1OeP3+FUh5jEhEyTlwIK89KDAAAIABJREFUPipyOidNC8rSsVyV5PkjxuM9dCI+5bKsOD09ZTSakOY5s9mM5WrFulwL6Ui75u4Ggg5cJb25sc2q9F4qhnlF62rx4fN+WqOgVuWgcIgOFq+427v5HPchF/LfhfZW9trxeEySCMqjQlW3WA0sfkf26xFJIsx/UQBGH3hcG5vERsO1EN9vY22Ek/1teTMS+17Iesu+vssw2QW5D9qz5bNdz9gq+HccH7XQNsYwmUzwXiIZ40DGQu83NzcopRiPx60gj8I8BiS1UYg9vzgMhWELQ/WgctgtnLuJ1OpH9LyYW9/lzkD4bqNvBae6+8xNhUKu3q4Fvm+wt5/fjjhsCuxt39mlEnac7iFQS7D/oW8f2vKWmxN2XZb8/ve/5/LykkePH6CUoixLilwWexzXrliIAQzGiP9Tntm095RUpkzYnbJMhC9KrHXrqOtArlLXNFXNalXyy1/+kufPX7JeV1v70fu+oI7xA653TY/VLZKUEH0dsUykQusEaz3XVzfoUK5yU2jvGleH0I4ak7bIQn9DjhW/HICL5T9jbrjBmBG29nz33TtevHxBUTxiubiisZrpdIzWkj+eJAbmFc43eIQ7ug4IheTLh3KKTnz0zjlSrWiqksUcLi4uSBPDeDRmVIwYhfWp0TgbFCil2qAsoxXjUUE+KvAeUqMEmg7KmLcNdVXz+us/cHV5ia1qDg4PSJQiDXBrXUv0d52mA0U6TRKckwAtpTSTyVT8rSHgMLrRlNKMxzOKwnF6eorWkrOsjfC0R4XCOfAq0MdqJ4qA8+T5BGcNTaUYT8cYk+G8FC+x1uE8aJ2S5UXr6tNKY+nylgUt6cXnRIEU6pf3BVJfsZfxD+s3GBL91Me+/3q9XrcxEPE57fzWGmV0uy8ppUBLPYCqqfBrT+Ma0iyTwh5e8rKL8USi7YPwjXW2Y8S6BFyumc/nlGWJ977N7rDWSl/abh7Ld2NM0xbFfyC07xoKf4rgfd9xnxDe/Pt9Av2nPvujFtpaa/b392mahqIo2sCPqDXXtWjj8/ktNzdCYD+dzhiPR22eoQS3pKRpRpKYdoFISoxw/cqE7w+CiMY7FJthUbtWKHVpN5taXzx2DUaXstMJ7M1jU3MmwqJ8SBS33Lu77P6Ju2ty3z3fxQNsvR9yTtFve9eWAYIAWDqFKVqev/lPvxGB/egRidE0VqzlUTEWH2ovaEwpSXMqiqL1YzsnRT/KdSXkDVqeu5jPOdg/FCpNHQWko6kbvPWUKyFQefHiBb/61a/aeaZ1Eqwwwvt3lnaH1nB3EPsLWw03xEgtmqUZ79694/r6BqXEyt3s/75iE78bNyttNNoY0iQnMUGYBNrLwIWG1mC1FR7vtqyGkejsbMZoNOH0eM7/9s//FY+fjvn5F8/JkimPHu+TJhnX1xd89905xngO92dh47SUVUNeOBIiq5UXV4B3VHUj9aGtxSioylLqXWuNVpISZJQmDalpdV3incX4hDwx7B0+IJ9OcHXD8uaai7Mzrm9uAnWpvPdyXqK85cHhfkgF7NU8D5u3WMyiCHjnSJOUuhGLem9vj6IouLy+FndHb57v7c347PMvOT4+5u///u95/PgReVG0ArVxPcIeXKgQ5qkbsd6VT1jcQpKMSNNCoN9E44MboGkErVgsllSNHYx5LCNrbacE+v462rI++3Oli+tR9N1t/XkULef5YtFmHfSDffspZX0rW1xDlqr21E2N80XLGaCUJtWmFdbr9bq14KMArqoqrF3b7sO2qXoC20oQm+sYCTvlxA3WXDfOtOuh3yfvQw93nWv7/AOh9J96bLbzp1jZ8A9AaBdFMSC+GBBgWOEPtrZpA3asrbm+LjuCCa1bH3j0g8eay5HxxwTtPCbzd+Tvm4McJkvUxttSD2bQbr+xAcR77fId9y12pQC1DdIJ/9Rw2d4/4H7j96FmPoTdtrdxUxmJ+dH0fPrDI+ZWboeG7mwyvfPGGL799luuri55+PAhWZZR1ZL3ube3x95Mihacn59TVRXeCynEbDZr61kvl0tub26Yr9fgkZxrpajrirKswMJkIrBkDDyTXFzhan748CF/+Zd/SaINdVkRFSQVo8UH7+BD6cGuL7t1HuBrOqF9t19lYzo5OeH29jZYG1Ho9sdID57f34xBAnrSEKkbn99a2wrwISUosLGhJI9XI/7YNCm4vFxzfHzKYvmIPJ9S5PtcX19wdXXO17//LVfXF3z1xc/gZyP29yYo3QRfryYxGrAojVCoNsLL7ZVCBd+1UqZlVbuM7os0C7m3kY5Wt7/PF3OpgY3HVhVluWY6GaFNmEtWNndjDEWRB9i5DG4y6QOtNWkg3rFNAzrm8ftwb7i4umoDDKPgiFDtjz/+wG9/+1uub685fLBPRioKoBIEwkUlHo/zGusUTZOi/ITTkwXfv74kz/bQJkUlui0zKQVcnASGaQnG6txfofBLj9HPBZ82m3NrByq3TQGP+2HffVOWVbtvTgJaGYV3n5s/7pFyb0fTuBYFnQSKVIkQ98CSWLBltZJx3tvbk/RBuoIhWtchl9tTKWGyS9MEpZPAWdDFm3Q8+kNB1zdqNj/fdvSVlvdd9757fcjxIdb3Lsv7vuOjFtpKKYqNnMI4mTsWK9vyS7elFIMPJfoqV6tVK7z7kegxqC1qmuPxGB24c6OfZhtsJH8DbbTn0JLs+MTjYHTpV+2EkbO0fOYBuoybslId2DoU7ndh022TY7uWGCHdfjWdbUFsmxCUPDvChhFd2HVEJWOXX3bzM6WkYtLJyQlnZ2c8ePiQLBV/dJpmzGZTPvvsM549fcE333zDd999127Qs9mMx48f8/LlS0ajEWdnZ1hrub66ap9nncM5j7UN8/kc5xxFW/nJ4p2jritmsxl//etfM5tMuV0sUUrYxxo/HM8BdK1DdanYc72N1LeC1d+ZP/FYLpecnp5S1RWZygXCHihT27kFfMgTb6lLjW7nT/eM+Gyp1tX/LA6sQuG8Dr7gMd4VODvh+McVp6dHLBbXXF4u8N7w5oc5Rt/SPE3Z28vBO6wValTna7yvQFnSPCPmjiutBZkKPnyx1BwGgUOFFcrSNB5rpU3rNe130QrtBOomFkoJne2dR4c66ovFgrqxkv/sLChFEVxmSSJsakZrTJoEoUtQMro63zKeCussl1dXWO+obMXZuxMeP31APs5pfNMqYuKBUDhvcE5jbYprCi7PG/74h3O8H/PkyQyvkgCLS3xA9J2LFWnI0qyFjhVdfnU7xwao311WsP686Ch7pZyt2AAGYeKT/co5sNZTVXWIKRBXilKql5WjWhg9tk323oY0TQLBzRhjTGtRCyVuIqjYqGA0kpgj7xzVWlIuKyuV1+PaUxqSVOPRKE27R696KXWjUL/be9cqFMM9VvplF9nT+wTkfQjjruNDz28aRx3Cul2I3wfnx+OjFtrQaYjxGG5KDAo99GkpgVabjX9XVU1Z1i00qpQKqQ+aohi11neWJ2RpRlHksqhC9Hq0ItuO3RiQKMi07vxQznVQplLqTnUwAJRo1wpCcIwsVKN6ojEOOrqN6tw2uAP4eafw7so99hWBvoDu36v7LL5LsPa2TS7VRwa2T8JNCz8Ge/3www+tVu+cY39/n4ePDtnb2+Ozzz5DoTk/P28LdxhjePjwIV9++SUPHjyQ0oHX1/hA7tCyoYEUZNCCxCyXi1YhU0qqRY1GOa9evuRg/4DVatX2j1ISwxtroW8/XIuA3O3zOCf0nblrjOF2fsvF1SVJmraW2/sWbYS+25rTSQJ087JfKlQEtItfbAcpIhxKESKTE4rRjIP9JxTZAXXlUH7G/mzG3uwFq/Uc3Iq3b25Yr+Dly4dMZwmz2QitR+BLrPah5rsIRYfqaoxrA8GK9t63+cxeDTn8++sqVoKTgszyq4togxKI3FmLxVM5S54kIfJe6lg3zqKNIckyKEuUMaB8oB/VwRKXYCmJ5qddrzhLMZmgtOHk7B2frioOlUHKbNZySSAxwScYXbCuFH/8+pTLC8uoeMx/98++4Oz8itOzM6q6plw7lGpaoRwV4D5nfAzoiwqZc5KJgFf08glkXvYE2KZiJ4iNa5m3+vPO9+ZZdDdqrUgSzWw2a+dftLLbdgTkc29vhjGmjS3qxxKNRiPyfIRSUFWhNGfdtGtaay3FQnCtQtAqz75DIOq6DkVzfIhr6jjMaeduX3HZbh1/iDV93/GhFvAm2rH5jHvRxg9ob//4qIW2TEwYYosdTCiTOyFLJOI2S9LAjOXFempqihBBbBuLzXJs01DVNR6HQriFvfeUK8kBFrhN4HSJhkwoRiPSYI2bJJEAUS2EECYEkLQCLC6eIOOssvS3yj5ft2y+cmGsta2NHmxYKvxfWLeGgWjSR8P7fYgW2e/f2LL3+XiG95ZYANrFsvFdFU/v1mBbpQJJBXn9+jUnJyccHh6SpSn7+4c8evSIyXRMmiYsl0u+f/2mTf8CmE6nvHjxgtls1pKvXFxcCH1img4EV2IkeMdZQWdmsylFMQobpmY8HrO/txdoGH0vKtjfecUhHN7Tmu+883CjjO1xIW+sqire/vhjywctCFHHbd/v0M4tweCeUpAhkKkgArgZBLJJupf2uo0fkJxij/gIA9saSPxHOqbIp1hrOdhP0dpT12sUBusK6mpOuTYs5uC9ZbbnefBwTJ4WUBmq2mFb37aSVRZS3KyXFLEYQOdVTGUSK8vHFw9zXRa4D0JH5pVYuQFiljfAaUXjLMY7TJaQZhlFnlOFOs8YHQKokOAqrWisp25CwRgXXV/gnbTVmARjRhgzYjTaR6sc51K8FSHdWA9eY5IUbM7x0TX/4d//jtffnfPVl/+YVz//OdO9A9b111xcXuO9wSY1VdV0GzhxD2BQnGPnHAuIRVz/mwLiLkIznCvtPKVbz1Eg11VFvS4lFdN5vB7eP7oUY713QcFSDg8PGY1GbUCZ3NsGxST4qTesde89XndFfeK/iIxGA6xfK6AoskH/bGYFDdFD7vy+69yfIrSH8Tq7+7//+X3t6aMG0n+7UUz4yIU23C2YHj8HWdfGJOD6PpcuXSD3+SACsW+RR6s8QmPxX1WWrFaLFqLJ85x0sWhTiCK0niYpSdLB7ZuaX1wQ2uloJAw2/qjthmlO56+MmnKs7NO977AP7p+UMSWor4Fufn/nd3cI8Phxq9kqc+e62FpP/9q794pCJs9zbm5u+N3vfkeSJDx8+JBHDx+RZRL0c3V1yXK5pCxLri6l+lVRFER/9rt375jP5y2c1jQNtrUQ5NnW+s4qsY6HDx/y4sXzluMYaNONWirI/gLc5gqIQmWnm6APUTticFi8Z14ULBZLLi4uus3ZbSIe3b0GG064SKzszvqIc986YfHCOSlriQbv8E4HHcSHewahGBVGZDMcjSY466hMifeiAJVViXMN47HEDlSVwnnLzXWJszmHT/ZZrK64vLrBpCnWNzRVTZJlpKlEfMewDI+4LIiBkhEO9qBULBKhgkDvv7duiQjlfV2wnmG5XmGShPF0wqef/5zL83OOT06YziZizadJ6GPpj6qqQ1oZgBb3iZN0K6UMSTqiKPYYjQ74/PM/J0v3sE2Gc3KfxBiaxjO/rTg5uuIPf3jD7393wsPDVzx88Iw0+Ou10midoVQDNHcsQ+/FwIgWZ1mWO+ZTb+xbD4fco2/FxvkcyaLiM9pnDQRdd1SVcKavlismEy1KnpM0sWhJC6vZKgT5Bu7y5bIVvv1AttY3rjQuKsDeY6PwposliqhYFNyxjTGNV5TZuylt3e9D63uwcjYE5n8VC1vdb5Dset6uvv8phhZ89EJ7O5wQf3afx7zVaH2E3NgAERH8RyDEJ5EqDwibnKOuhHO6XK+xrmPPKqsKG9i0ooAWCCgnTXPSJFBHZimJkWAaYwwmWIP9ABPfeyctkqH1Q6q2vUEDDvm9rg1AUe09oqXWbnpbO464u7d9JP22u583+3j4+T3P2vLobfeRMdOBelRoEOu65re//S1lWfJXf/VXvHjxguViSVmuWa9X1HVF3dQs5gu8F59X7K/VasXbt29bBjRjNN5LYJSUpuyluhjJOy3LihcvXvD06VOur69bH54PcGWLlLQxCrHvY8JaD1Hp9W7nOpBrvO8S3Pqpbp11bHj79i0XFxdBmRBha3pZBbpltwhKWG8M+9B430/W/hwoDeFLAdmIMLyO80NFlsGUIi+YTCY0tVQx8ziM8SyWt1TVWmpuOx2iomG5cJyc3jBfLfj+hz/Q2DX7ByOgJkkMRR4q4FlCIRIvaWHekRgh8BB2KGmzVsKONdz0wpoIedGRnMZ5JIjQSq21rMh58uw5zjnevn3D+cU5hw8OODw44MejI1HS8SRpTtNYGutJkgxrpXqY0gapf6VZl56r1+948+YMa3PWa81DPUNliqurBTe3S25ulqyWJfNbQ1WmjIsHPHr4nDyf4r2kLkqZyZSmobf4BPURBEEQlCzLyLOMcl0GWDoUe1Wbe10fvenmY1ymnQKn7uyVUXDEOdL3Da9WKzSe6+trlJJYopiZ4L1nuVjg8bLf5Tl13bTfM8HVkCSGyWTMeDKRanwB8SpXK5q6wcVI8KCwx3RCa3U7nyNk3q1f31rdaUAjtgpupe5YwO8TkvcJx13W8bb7vO/8/dcNDStFN5a7jo9eaH8QpKGDVamG5SJVogGZdMb3cxgTfJG1G7q1FltkWGsZjYtBlLq1FhtYfsogxKsAZwIDdrYY9BI105hDHFMbYtvjhJRNXqpSqeArbok/go9Nbyw0heqgW6X6UmPj2Dbydz8bBE69ByLftPh3TUYVbbnBxBfLXCqXGjwWtOb7777j+PiYX/3qV3zxxRdiMTddrWtvPb7xGGUY5YaqaXCuwTrJHMiLCePpSAKVAF0pmjwLQt93rgatqcsKrQ3T6bSF85QEFIgV50H40H0IMOuUKU2ncISXCjBtYDdDrFbvoxUbutur4BPv+qsoCsp1xZsf3lCu1ozHY2xjW/SB3kYko+bbDTpeY9qUxgRjooDvWW9hPfjQJqccXlm8sjgaUCL0NOIPF0UzJcsKppMZq/WSxoqAnExGeAXrdcm6rEizHKVnOO9ZrS3ffnPF1c0Jx8ffk2Qw28t5/uwhP3v1EuVmaGdYLa6Z12uULkGLAp0YWQcmphcpjzFO3sULpajzHmOUIFtBoGqdBlTCI+whCUbnpEnBxbuL0M8GrRLGoz3SNMNZhWs03ik8KdZryipBJ2OMgTRJWCxWXF7NuTi/4Pzimot3K+q6QRvD/l7K/OaCpoGjozMW84rZ7JBR8ZgUg/GOvani8ePnTCZ7WJdQVx7ndFCynPjxVVAGlcwR6xqUhtykGG1QKBKdYr0NYzdMB4vj2/nEo1WtB+PPPQIsrvV+nXnrLLVtWNcVZVNjXMooF0u3qiqwVtoLVMq3lneaSoxCmqbs7e0znkxw3lHWVeufXq7XuEayDZQWtERryPIU5yym0SSJxjktbgQr6JgJWQkaj6sbVFagQ331zb1J0SGttMvnTxe4P+X7f4rw7ithMahU5rPqMW9uPz56of0hR1+b2ilIVD+HsQdP9/wsfR9LFNzx7/idCN/Ec+v1mvV63UJCMWc4wul9Qd7mh0NrJUVkQCsJUosRtt53GbUDYRpKSim9FbQdHEPrK/5+fz/uvtc27XaHzrAFPtK99iolZR4vzt7xh9/9ns8//YxPX33Car6Q4JNGqDd9jGwlRJs6iwp+0AitTadTptMpaYDY0iQh0ZqyLFu6RhMqgTW24cUz8YHHetuDeeO7zS1Cs1t912yMydb+6p8fohiJSfnu6DVnZ2dSPUmptmrYZh/3nx8/0yF1Kc4tFSw25xjwqvddLv37bkJ1SgWoMigCk8kU6xpWK0PTVGRZxrNnzzg5Pubm+obxaEJVWeGFTsTynowPefHcsFrfcnt9yZNHY9LkAXm2z3o15+2bW25uLhmNC0aTgrzIZJsNc1OboDhSY7QKfNe0aIMxjVjlpiFJIguXDq6pgsn0Ac6nvLuYc3j4AOcz5kvLyek1SWIoS4N1Yo2ZJEHVFXWdwlKxWKx5+/Z73r495vp6QdOAIsEwJS8OcM5zflpxcX6MVinWGmbT50wnBzSNo7YlWT7m5csDHjx4jFKGPC/wqCB8ErRuBkG1sf8ju1x0B22uo/4i7xT998/B7YjkcB+Me2E/oC1atdEHHX3MGvHWOedQYb/UPYIXmYexXrYE/8byrXVdk5qEcZjrOjHCTV7XLTLZb1efBKazPv2g/X2o/x7LZWe/fMi5bVb6f63ndHuobuOZYLezrX/8gxPa24WzaLPbB7CDCTsD5u6kHwRJRN9gj0ovCuyBdR6Eez/dLPJYx4UQre64wcZ/WbDMWytcC72jMrqtCa1aq5vBRG0tw3sEcRTUoom3vXfnml0W9t1+H35ftZbm3R5XAXK9ew9pvzEpy8WSP/7xjzx9+pSff/55m5PZpxgNrcS5ULYv/Ix92+eiT4ISpLKcUV600DeInrNcCeXmV199ufEOvaLzQXHaJij7beojH/177eK3x0uak6QoyfifnZ2xWq2YzWaUdTX43i7mvtjTMUUxojgxP7s/h/ttULI4BvM+IjV9qFTprgzoeDzm8vIS6yQv98GDPZ4+e87F5TXWQdMIr3mOuIRm06ccHj6hLJfc3t6gfM75O8fN9Q1XF+dcXZS8O5/juWF/f4/RWMpzpkkirgcNaWYwwfpOUgkYTJJYJMhjDEFZqzCJJklgPC4YjSVPP8lS5vMF7qLi9taB3mNZpuQ+Z7FaURRTZnv7NDVcXb7h+OiUk9MLjo5OUCrFNsJkNhnvk6YjDOPWms0zKQSiMGT5mMl4j7qyiO3pSDNheyOkVhX5mFVZYhvhEY2R4v25E382TQO+DPtFSlUFv+6Goux2xjzEedL9Hlfmtjk7FHhDgRgLi/SjuSGgZ1q09E0mtvhP9kER/HjPeDTiweEhSkl1sNiq2spat03TugT7jG3Rx+2cw1mH1/7OmhsqIsN+8FtE30+xmu9DEXfd7ydZ7oOfwQVCDLYcBhBuOz5uod2z2O6HbrufdztPBYEO79Nj+s8YkBv0BHd/gm1GPfbzySMzV0u9GCbCZDIRKzzA6ptwepZlZFGb3HjXdkKFNeM2+uSuEjI8t0s4f5j1uBmIhkywHfcTZaG7r9a6LbJhXcN3332H955Xr16htZTva1GHoGVHApUkMYGsYUXjLFkgRskyKR9Zrte4oASNigIbIlvjvdZliXOWP//zX/Hw4YM2pQv6G1DP9xv+3lRoNufW5rn4r93owu9N04TiF5401ZycnPDNN9+Q5znWd/MsCudt1lF8nlJdelBHCCRc2/3c3v53YxDQwM3Su79zXb/LOAjkmiQJ6/WK+e2CZ8+e8erVp5wcv2OxmOOcjPFyWVOWCrykf+VpQXp4QFXVXF5a6nJFuXZYO0Nrx9HxMd+//jHk+u7JGkgN1tYkqWY0ytBGBeEtfZIkBpMYUcyMwXtHU6/JioQvvviMg/1nPH78gNI2/Lt//3/w7bfftsQdjx9fM5vMyPOCX/zic8ajh/zx7Wv+9u/e8P3rtyQmZzJ5yHS6hzEZWmcYlaN0glKpRJsjpVO19+T5mMl0Bl6DrsV9g8KYlLwYhzXnaRrLfD4PyIrBmUi3y2B+KHU30CruVQo/mFPdfNviChmsvbuq9DZruz+HYzDbfD5nNBpRVbWgfzE3HoVSRhTP6JoxCXhPHYrtTCYTiiLlMDvk4aNH5MEoubq64ujoiMViIXD5cslyuWwNnsiaFtsW90utNdZ3gWndGlAb79B7d7ro+l0G+La1te2zDz1+2vWBs2MguzYhlfvv8HEL7XBsgymGnb0bEpef77//pnbVWTfdxI55i5tQet8y76cpAHes88VigdaaheoVNkmSloYzSSRlJfor4wKBzgJr/fZbrL1NxWOXdr+52LdZ3cM+2dHH9/RpPPqaeZqmgUTlhFcvX+G9bze3fnBVv4+bphGBHYQxHnEPeCko01Z+y3Im0wm3N7eIq9pR1TXOWX71q3/Ei+fPB6kp/QCuYdvvQy+Gv6s7i49gVTmsC+6TssQ5iX+w1vLb3/6W+WLOdDYbbFbil+wzn3XP6m9W/bzeeN45f0dZkPcYwm6Ddof7ai3WoVI6KJu2VSRjwZ5PPvmEZ8+e8fz5c77++mu8l8wN6yx1bbm5XVPVjtGoCEGBGfgGsgznMly5xhjPbOrRainCQOd4n2FtrCOtqaskCHHxaVrBqsnSNPg4hcymaVLMSvH69ZLl8h3HxxXfvv6W/+df/y3LxbINLn30qOHhYUWSpLz+Zs5iueTq6oY0yTk8/IwiH2OSgFoog1YpSiUYI7ncSim8EzeNSQyz/T1MklJXDQ5LWa+xDtIsYzQeA8JQV4dSnnE+1z16Wq01BtOuN+89tulIoUIwxGDMhnvgEP25zwrt5tYwq6WvJLZ7WKiaN58vmYxXjEajwGYnYjAJzHstguUceHHtyXzJA6nKGK0UR0dH3NzccHl52daOiFXEIjrZr22/TbGIMT19hbbfJ3Jt1ye9wnpbYcD/EuG87dgm9HehGLGxHRLStZuorH2Alf/RC+1tndI/15/I2wZ005+4G2L5MLijL7T7QrHNSXQdzerm79FyBNoJLHCxIUtTkiCoR6PRgL2tKIo2T1IphYkF7HtKxDZLr09FuA0ei7/f9zMe0XLedf5u323R7MO73t7esre3h1KwWi0ARRpYoWJcANCiFTENJhI/OOew3nU+uKbBoMiShIP9AxlxcYhS24af/ewTfvHlV216Sn/eDMd5KIC3QeB3+2VTWIf+UZIyU1YNVdW041qWJUdHR6QhCr5vZct349zd/mylOoUybmLbxnfYRn8HZPLet77CNuMhKAJlVXH44IDJYkKSJJycnHBzc8vDR4948OgRj66Wze+sAAAgAElEQVSvWpIgRagfXTuWtqKuPWnWkCamGyunUDrDk9E0GucTEpUAKV4loAxZOiJJk147ZL4oI8hSG8iJCvzUDXjFu7Oak+M3zG9vmS/n5OlT0j1HuV5TqRqaMYvbhJvray4vX3N7e8snn37CJ68ek6RZKFCStP7ZxKSAMIhFbd/hUSahGEu1uKZ2lKGMpXMOk+hA0FOwWpeY1GBdJXzqWKTUb4fCxfHr5+33z/fHcNs66xsR/b1nFxq5SVDVn0+bymDTNCyWS27nc7TW5CrHGKGlFaE8ogkFW6b7Y4pRAUBdVsznc5qm4fT0jK+//pqzszO01hwcHATrvWrXct/Q2USA+m1K05Q8zykC7/su4Ri/Gye6QtxifnDufkG9ee/7jvdZ6/17bEc53OA9ZY0OfJk7j49aaN8Bure8UBQm2wavU27e38F3nr3lO/3NtW+Jx3N9YX6f7zsKm5ji4JxsAvPFAhW01j5nutACSpqZ1poiz0lDDmMMRIoCum+B9dscf9/GnhQ/77/HXat7KLgFitrSb8P/tc9wzpGkKYvFgtPTEyajUZsSohTUddXmwI5Go7aPlssVVVW1tInR5VCXUnBCezAByt3f3+fg4AC04vb2lsViwf7+Hj//+edtYIwKqTARQmsDztr37Avu+33+2z5WIlVDnWna8UvTlOl0yt///d9zfXNNFkh/+taxxGZEKLL/nA4ZEAGrN6zsjoZz0A6GY7ztkLnTsf5Za5nPb0nTl6F6XkFdN7x+/Zr9wwO00UxnM9ahctPQ/y7lU9erFWsV2qt1yHYAlKIOKZYGRWMdStvWdeJciBiXFAOEelNiAaw1IZpc4ZxEGhNy3xurQE/b0qu1rcEnOLtCMaGpE9Jkn8koIc8OefjwOUk6DZackCTpkH4Uo7CVhN4Hi01R5CPGoxlNDXVtWa8rGudxaEZFyuHhgeQqGxhPJKbCeYm49tI57RgqrSFmC0Th7NwdIYQfWtj3jePmXNll5PR/H/4TdEjqnTsWiwXjYDw458hGYkAsF0s8nv3ZTAJutQSVrV3J5fU1x8fHXF5eMZvNePnyJY8fP2Y8HvPu3bu2KmO07mN7+/tSf14nWshrIsnV5t69DXkYvB/gPgBl3dZ3f4qc6H+2XaFQPTC8l9JJyBLi/coCfORCG7YL2U3raFNoy/F+K+nuve76Kbc9e3NQ+hBV9Mf0N9MhV/pQoEdCkL4Qh84SX6/XXF1dDfLDs2B9F0VBGjbbjmq1lxve07Jje7qgJWRD9EKy0de8N7X8vmAZ9s+2KIGhlR0PKQbhOTk54urqkiITIZbnOYvFIggwuVuEyxeLBWVZ0a9bXNe10BxWNVrpQWrddDpFa813333H5eUlSilevXrFZDwRpjPtUb5LGZHWxv/6gGR8hd1zJgrF/uk4H2KsQQw6VEryXq+ur/nd738nQl3rUKWu67PhPL5rbUeotW8Vd4ff2t72fj3+3P74Stty0jQhzzOcs1xfXwU4s2E8HvHo0SMuLy95/e13zGZT9iZTvHWslkvZFFWE4x1GGVQMDEXhEOGqw9wUEhzhqPZ4lFPgNDiFa6TqW2IM2uu2TxJCHrcXchwpbdnPRNconYB2NE1FbaFxoHSKdZCkhiTVZLklV5o0FY53rQyKKLQj97c8NwpaH+9v5F51WbFelzSVBJgl2nBwcIhWmuv5NbO9WesGa2KRDG2IpT2jMOmPA3TK4xAC3oSB7xcw/WPTaNsU0psWvzy3K3u7LtetkTFOR2it2lgQEeSwXAr5lPeecrWiqhuePHnGV1/9gpcvXpAkkpP9448/SlYItPXso8KqPXilBvumtRY8JNq0hZ6MMRhlBluLQOE9pDX+3VtC/T162D/vh6F3HVtTzu65V7/fY/aPFMoJc3hzzb5Hbn/kQvt+jSdqL8O/Qagg+59DBztufn/4+zYtKR6bUZPb2rNNkPe50PtWbUyn6E/ivjUe00Hid5fLJVVZopTARqNQmSf6dLu8XdP+HWHUyJ3ufZdGI+2LVJbdRh7bFPsiRi7HTaRdANpwJ4tU3R0X+b5jtZKI8SRJePL0GU+ePuXy6pKqqanrBqUa1lXJfLGgqmvWqxWJSdE6oarkmugPa5qmZUxqmoblcsn5+Tl//OYb/uY//g0An3/+Oc+ePRPhGDfFXkSu35wDDM99yFhHA7eDxbu7tEURwrWvv3/Nu/PzFknoNpK7kF+EyvvPi0K7P879+9yrpW/M9TiuolhI6do0TUF5rq4uOT09aV0yh4eHrNdrjo6OSJJPRGHMc5y1LFcroSXtReCLMAyPDCRBHoXSug3QStOUhBSlrLBmhehKbRU+oBWxyd57nLXgHI21QkUb6E2VUlKn2lustzTOSp12LbnxjW9IfCK50COpJaCCYDQhkl/raFkL9arWRjZXHSheQ1nP9XLZzkMRdIa92R5FPuL07JTEGNIk4+b6lshhrnWCw8r79zdvJfds55bfMs+C4rOpTO8SFkMFcrvR0Z9n8VxEmpRSQmMazkdDIk1Smsa27i2IpEWitDonJDXj6YzJVChwf/ef/zM/vn1D7awghIkIXO8lqK8sS7A9V1VAj1rI3HnSkDKbZRlGm1A9cBua0Nt3w17fduBGP7Xv2u/m9wjcn/p5H/bufz7ca3poQH8sWmf87uMjF9r3TzxaGHFT22x12dBZ4SM/zPHbvO9QSA1vp7j7/Ps0rf7f/cAq6HzOeV4Qy4rGzbfPv+t9F0Hdh9FwYJ1lGaIxu803wZik9QPledazzGRz7kcnyz9DZGWL1p32vmWTcy5uGGxsHl4KcGwZFWG46sYtbpCnp2csFxLU9PTp0xAUdM3t7S1JkjAej6nrhpv5Lbe3t3jvOdg7wHhDU0uUqVJB+UHq+V5eXTGbTvF4bm5uuL65wTnLV19+wbNnz0mThKauWqaxGMTXGrjBJGnXuvJt23cdnZsgoA393TL+HuCMiL5c39zw+9//vh2PLr6hP4djo9oWtn3YD9LrR41HSymW7oyb9UC5am/X2aZKRT7pjDxPKQph9dPeM18sOT0741EojzoaFYwnYy4vrnh3fs7Dhw+F39sLz3kVop8HW00Q1EEaiHIVXCRVXbFcrSi8A8QVpGMUvHKtoiOokEUhlaI8HuvaQpXtvWOamvOurW3t8TjX4LzBerHclFZkeWBc04E1r2UmC2PpAje6NjjX4L0jMQnONjRN8BsrT5IaxuMxo8mIo6MfUUrx9OVLbm5vAn99EP50gjeOnVhctDULRIh7+oZFiyP4npDquvaOIB90PBAJV5QivKsZ7KWb1raQ1Mi7KwXWNqxWS1GIbINC2NCiAh/3yKi8rMs1RyfHXFxeSiBuVYL3ZHkmtdSNIcszirwgTzNBGJ2k9RmTtPhcYgyN1jhcYJrMAuIRRj2+r4qR4vGVY3+5TgGhE9J3eui9xuCHHbu+vylfWkMmXr/lEYL0bEtYGx4ft9BWw07prNjtKTH9L8bNtN0Yow/zPX6L4b1827ldVw7vtQue2jy0jhAcmJayW9KZNn3NfQi9T/LivcfWFu0V1lscsWaypI1IkIcKxQ40aZoMLO40zcjzot30Y64vUfMnCCStMUZJ4YBW2RiiBN5LoYZth/TJkMTGOc9isSRLMp4+fsp6uebd6Ttur29xzrF/KP7oi4sLrpvrlpwmH0nhFu899WVNmiaU5RqlhB3NqxKWimW5BusoipzPPvmER48ekaUJtmlCzYm4WIbw/mDB4wNc5+9RduPcikJ2mPNKUAycEjYvFf4+Pjnl+PiE6XSysdl2P+8S2NwNFIrCO+ZUS3WvmI7Xv75rL0HJ8nicb0QQeoRpLE3Ii4w0TzCJQXnZNs4vLznYP2AyHTGewX5Vslgvuby5QqcJDx88YLa/T5rnXF5etnPPBaGmYz/h8VbgV5MkmCzFa82qKoWtw2g0CcpLhHYa+g7vA8dVoPPsCamWOsZH940waHnrwEk+v+T2C8pVl1XLRlZrzci5oJ5KAFjMxfYEpERZ8Ud737PAo2LgMZkgWU45js+OGKUZL168wGG5uL5sFTWlPFqDwpKYjnpWa4NGCrjowBHutFiy2iiU0Z3gCcaGR6qmtYJW3d2DuiI37VSkzUhQcs8+w2KMg/Heg5PocYkp8DRNTdVUNE1FVVekQeGIhoFwxMu9jk9OODk7ZT6ft6U0Dw4OUMFaFyZCiT/xJiXJcyYTcVkt5nOcFQIfFeZ19KOrxKBCsReZEq7dj1tRHNZJx0Y4NEqiWd3u3u/Zqzdlwq7LN92jm/cetKH9TNZof3w2nx1X6n3Hxy20e8ewM6OFsktoDL/z/vvtvKq7xkeikt2a2eYgbrsu0k3KNQ4f6FVNJ8nvCO4IRQG4WqrmNCHitLaSLiECPm5AYqFXVcl8PpfCBcYIBJpkZJnAoTGFI0Zsq2CBJGkii111bEnQkR+0bUwSNssbqPguQQDF7zSNlOd79OiRpLwtFqxWK9brNQ8ePODZs2e9Ygme/f19njx5wnQ65dmzZ9zc3ASYVupP13WXYnd7e8tivuBwf58vv/ySvb09rJVYAcWQ/31jaIfj1g3AwOodLsrtxCrxOqWGObVJmlHXDX/84x/Relgcof/dXfeKlnOfUEYFC9F73ZJTCMd+DwWJVkmMTA6fKWgJZGI6odYSQOaaziWyXqw4Pz9HJYbxeMTe3h6r9YqLi0sWizlpTLPLc6bTKR66lCXve0KnW6fGmDaoqKoqjNEkWdLl45u0hUAHvl3nI1AmcyogQXF8bC9zIwrqWDjGlSWNrsnSDMK6aLMQQv+gI2Qaxjekz+XBsuyPZ6wr4L0Uy8iLgudPZe5e396GuaPa2It++cl+jENsfee60jS2adeL1lpQtQ2ruG+IbEMM+1be5tG30GMfd8ZCFPAdZF+WJWVZhtKYfjBnQALy3r17x5sf31JWFePxmL29PQ4ODjg82Kdar9uA0Bi7s1qv8ApG47EU/rGW9Wrd+dW9KHzW+9ZVaIzQH/czFlB3jS6tdZzhO9fV+/booXuqfdrdvnyPsbZdaO++172urY3joxbaEd5g6894xebRh5n6O3P8sb0T79Oa8BFuojfBdw/c+xZQFN6bpwT+kd9jwFgHTwd4POkscO89WcgHJsDuXeCbwTnxiddNA3WNs45a1ZSrGOQDSivyImMymZAF/3iSpG2keie0uwj19tBbqnwpNRDa/T6aTqdtu62tQ/3eCY8fP0IpT12XZNn/T92bLkmSHGeCn5kfceVZR1eju0EQRA9BCrAUId9h5+FnRWZFuCQGOwTQIPqorqq8M053N7P9oapman5EZoH7o9pbsivCw93c3A799NYSJycrfPHVl/jyyy9xdnaB1WqF2WyGn/3sc3z33bdc1WuP7baLdXfX9w/4p9/+Fl988QU2mw2KouINmPdNToytnKiEM0k67a+FxGGHrH0pbymMHdFVi4vLS/yP/+t/4JtvvmHihwywj23ktFZkHooYT5yYIhUyE1hd6D0L2AHOd2nOelomYzj6AFSytGtbFJbSmXoXcH1zg2ANLi8v0XUtTk5OAGOw3W5xc0eOfqvVilOfrmId5L7mIfC46ZC+9XodE3fEutSVfE/MKqk5TbQ7G2Mof3jg/SLvGUOHSAvinCc7uMyZ7RDEyTN4KhOqmBsBNB9SfWsosARYA1UWpKIPAcvVKkqM+8MebdfCGEP+GBwOBiDmW2i5rnR0DuW5rusaZVWgaUiN7IOJGrbgxjPcicTsvc8Y/v4aEjUxL8h4TsYsv15ymRcIgezO9w8PNMfMbDiXQle32y2urt6ja7sYIXF6ekpMs/cwhUW9mKPpOrTeoXEdup1D13aoihInp6d4+eIlttstHh8fOZ0rheHZQIz+fr+nMStK3VEaC7WmIXvW9EybQDbWzwHHMSk6b3DYfv/f5+xt3f7zhEg6PmnQ1hzTGMAaiaQfsVpkLy8sWnh6YHKwH5OoZELod9Pb2Pra6edIWcL+PdRHIXBSzjH1xxAh4hhlUncmgpV7qlNBjYpTopLUaVGYAh1zvULUd7sCDw8PVMiewzx03nQhtjG5i0gCnNawf/RBOwQqMCDVuCheE1G6t9bgcDiAapnPcXZ2GuMyRVohokCmBGlDkq6s12u8efMGv/71r5MKNWoFTCTIA4m61/eg/md4zYxJ1WmjCc3Qqm6S4DwCZpxO9d///XdqThMY6XWiOXt5hwj+sDCmYBtpMmMAqhZvBG6yTVKX0nNCCLQNvEiMkvqXpHSpo2wLE6X5ECjxDQHUEicnJ5S32xjyH3h8QADFzy+Xy2ivdV03SRwXiwVOT09xd3eH7WbLQGxR2OQ9XJQlSc/Bk6kHFmVBDmNe7NpKWtTSkTgpdh1liPM+D62q6xqwNsbwxhKmJvmaEEgksxHZn+na/eGAsixxenqKtuuw2WxQWhuZVQFbrV149eoVr9NtyrNtLQokDVsIAadnZyjLCu/ff6D13XbonFZ3JwIfFEPZFw407dHzH3hdxPAivZfVmuPlBGMMdtstNpsNFvN5lMwBF81xogEURieEgMfHR1hrUNfEONuCpHPHRUOETiGEDOwfHx+jk6KxFVrOllbXNaqizN4H/b3MklSsXPeMo09/P0ba7eORnpvnSNfP/X3s+MRBe3gMpddxSRYgKTIzaoxM6PgAk5poOPk6x3l6dgLx1L9jnNP4RLH43tME0F/a2NZYrr9Ldhwps6g9070HvO/gXIfgPRyrCuEDvPOQglAkWVkE53Fo2wiAta4brhK+yGcBc8y6wfAbQ3ZSwg6p1EPS5cnJCvP5DPv9Hvf3yTNeGAhRYwsobzYbIFCISdc2uNpssH5co2tbzGcznJ2eYLlY4sXlJb764svo4KXHLs6c9jw1eX/lvDGmZ88WSTqpI8fmTRM60eMKMfzDH/6A9+/f4eT0FEBy3BHJPF8LQ+5eGKUU5kUhVVQDOknZhNekIjdAdNwyBtERyql1KUydEHIdxkLSPAEbxcpvYUuL+WKOU34PgMK31pt1dCKsqipmt/Ii+cqQKKlwtVoBQJSihNGsZzNUXYtqNkNZViiCR+GBkh22bCBNSMelcgVE9NqXbIQi8dOkkHNSYS1KXtdae6X9SaKfB1S0iEEsMHN6ehrV686TNN9xyUlRfbcqy1dVVWjbFvcqRjmWRlXOXPNqhi+//BLee6zXj9jva8pdoNT+2XoJQzoyRleyNcvcXgzhHNE6ivRNXaPCO7e3t5jVNVYLitsnhsjH93PBRSm5z0xJvgnvPBUA8h6BvcS996h47VxeXsI5hz//+c/Ybre8fw84HBo0TYNZXaO0RUZbn3uEILT1449jt/WxY4xZGrv2v3p84qA9nKCnJi0NGt+f+eONc0f6PnmuPqel3TEi22P+MrvvsF/6txFVfPwsC2BkYVhLTjQIlPRSER+AnHK8LxBCxaAtMeIO8A5+VmHGhCVwGE3TtRRO431Uc8bRCCES5bqusVwuOQHMpjeq/fHT/SZCWFUlqqpE0xzi+wgRlrkt2WbmvUfXtHBth6bZ4+bmBr7rcLqi+O7XL01MwFIUBW5vb5MTS29MRZUWVJ/0EdeDGXpeGzM+n2MYTkuFQvJub2/xu9/9DobjyWluJLlEnpkN0X82195EELUpA5ok6PBavcmOUkbezSQNQ5oRvaaTNGVYgi1MUiPCyvsENC1lstput5EIC3Ct12tst1sAiCVqDYAOGGS7EmlssVhgPp/HXNRN28IFj6prMZ8vMIdBCAbeUzpTb2xMYSsAlsYzhVPqjITyGWBpmxnDkrU7slckzMgYk3l3C7giBGx3OxTW4vLyMsYlN22b9iK/Z1EUHLpYoCwrkBDvcXNLYY0iwResLpd++OAxm1M88vv377kGd8mxvOOhQ2JaGBM69DqVvUD23nzBBvR8B9gvAkiZ2jqOOb+5uUFpC5yenqGuZxDTUFkWCHuPoixxcnKCszPKJ++9Q9sSHaH2k59O13FtbUMV1xaLBZbLJV69eoXlcok//vGPFFFiC4SyRHAOXdOinCfnt/47J43DONDq/TR1jAtw49ePzYl8npLYp56tNUXPYUo+cdAeHs/hYDQ3OiZdy6GTkMghYDo+KRq4RYrXz8xtqEOAz0EYSGr2BNK6/XQuaBsxf4/Liq+R9ykKKiABcaopRerxnEeZsoMJUe2cQ9WRylzU7SIpiBS82+1i3nRxqFl2Dq/6hCAEUnXbMjk59dTBol784osvcHd3x05JRWI+OGe4tRbG07tIjvFXr16haZo4J+v1Bvv9AQ8PDzg5OYmOTiIt6Q2lDQ3j867P20gAxtaEVmenuQxxzK0t8P0PP+C7H77HxcUFJJmKAMlwHeg0ptKPJPn2Q71MALGjUXJK4OxEejZDIqL7TV7AlnJsF6BS4jbAWzIPkFbAwHJO8oeHB7Rti9PTU5ycnMQ+7XfkBdy1LflGcPw8TWYK4ZK/qqIsVw+PD2hZSm3aFpQlivqki5hURYlSzacweJop6GeEk3clAO/imJKDZkPFWvh+ca6SGHgA0Z4q7/vyxYvINAijIGus5TaatsPh0ACB8rJ7H9A0BzScd9xYC1sWMdGMmHAoTLPGdrvFfr+Pe6woCxQFZX9LiZHyddenU2PmHA1APgT2pAetIU+MB2IFPco9EG3nzNTc3NzCsVnt5cvXPDfUblVVOL84x6tXL/HFF1+gqirc3d3ihx9+oLLFAegaLvFpDP9ZIARUDNpFUWC/3+Pk5ARv3rzB4XDA9fU1ttstLi4uMqe0/vsN33N49Bma/6rkOyZRT33+a9o6dnzaoG0M+xVE5R2A5xvv4+/p1tHfp85NcV59CTjvy6DFUakscYYC2H0Oqy9l57/bCUlP+haZgQIIhWWcIKlDO/oEDzhHzmziheuc5EunkA3XduhcC4+Uxa1tW2zLFq96faCMWveoyjoDGg2k1lqcn59HABenHSGiTdvCg1SVG79B0xxQ1xXevHkTnZhErRoCce6Pjw+4vV2g67ro0Ty1wZ9zSNzzGFefr79eIpRAtjznHL799lsCqbKKqlsBCcuEk2eT/5UMa2Hwp0HPAPDBsQOiqH/1RBjWLkhMc6Bc7dQ9crRDgCksRKHuWfVMDpJe9YkOp8rPSh6Ak5OTqFFo9ge0bYP9xqCsa8DkyYg0qBpjcH5+jvV2G9XGntehSGZaBd4xaFtrY0rffjikzjiokxOR7wcQjIV3HfZNA+8DnKOSo+S/MefQS6A5kJlou91isZjj1etXlBoXKQmGLYo4OloTcji0lM/ceI5vJgfRsijRuQ7BJqZbAJHao9S0m80GzjlcXl7i/v6eNEsh90uY1vql/iRpLa8aJ2RLpHQr7ZnhvfTZkxbGd2jaDl1zwKFpcHN3j/l8hpPTExgAq9USX7x5g3/+p3/Cb37zG4QQ8O+/+x3evXsHA2D9+Bj7b61FzdJzXVb41a9+hdOzs6ixads25irvug5v376NTJlEoOi+To1DLrE+9fvHH1o6HtN4TLV/7JnP7dOnDdrQYGhH7af6XzmiSnAE3J/itI5L8n2VVB/URdoatDoC5mOS+LjNlK4VrYC+frzPgGQ9M/KFWuJNKJs12UIlDjXZBYWznVVUmartGrRdGx3ASB3oB/vBOY/r62vU1SxKL2IHn8/nlB86JMc0AHHDilreB4+KneFMMGiaA5ZLUqlK2FDDBRtIK9Ay0HgcDvvovCKqzL6jzcc4nOgxTgxWknii+SWEaFOu6xn+9M2f8N3335Ea2Rp0jdgK7WCtkBZ2PJTMCoG1yU4OQzZjXSQiABS6FKRXab+YKFY5BnOee7nPpIxYeqGKJBUlbtaaCNMkEtLJaoUtDDpmSrq2hSkkPM1m8C/S0sXFBe7Xa6w327inRKrTmpSiLIGSxlbCjygJD2lidrstqEJYcn7TTCkhpOWc6hvUsxl7dx9iNkHqMzlvbjdUMvLli5d49dnLqIbXNmi9HoqiIEbIBRjTgaJMAue4Z09xUFUv79n2zfuCVOMS023RdS07Yp7h/fv32O12lC3OJ01FXCMhj7eW3/se4dJXWXO5+t9T33xBPgheg1D05EDwgcJAPTmZ3T8+wjmHs7MzfP75G5ydkZ3/888/j8z5YrmgUM3FAo/3D7QmjAEspaLtOnKSXS1SXnGZ+7IscXl5iS+//BIAZ450Dm3TcLW3BNxjx1+zv/vtPUUnnpK0x347JmR+DG365EFbA14ffKcmLXk5qlZ6A3Z0gBF52ajJTLK+0TdNtjH5NlHsz+2+3PP4nVSzWsrrT+YYIxDdfrLfEqdOsb3x6hAikdchNkRQHNu8xSu9o+o+bQJuM18P3i8Ej/VmjcLso1OPtCkpCYVYxgIo8zk5pVQVdrsdfAiY1TWqsoRrHWazOQCDzWaL09MT7PcH3N/fYb8ngA7w+Id/+Ee8eHGJH354i3fv3sdc7brQQH88ZAwGc4Rx9mkw1mwXlixMJF2WODQtfv+/fo/dbodXL1/S+PkuEssp+1oIhjgopE1OkpwuFMIbOzJdqViIlsLksBKD7C0zfo7NK4B3Pjo02YLU5FGvPnJ452ABHPYHrC17lS+WmNUzGBjKWrffo/MeBRBtwtl7W8oDYBtygPSdQ1lVqIqSY5OTUyVAIO+7ltYkPMy9wWK1wHw2h7EGTXsAwElUugMOLTGXnevgvItJaMhHI6CuK7RNA1fVADs4HvYOTdOiLCkf/sX5OZarJYoyqeFlHWnwjGlkjU4LWyAUpO5HB9iyhO24GAbIkdSalLLTgELCxMZ7eXkJgBzfXOcoL4om5kyctGZF1lO+DmiNapOLMSnvgjGUbjaAa2kXnAHOc9tC80TzExlAIHgyOxhjcHKywuvXr3F2fo7rmxtstlusVitcXV3h9OQU64cHbLh29qyuUc3nNN91jQDg6voKy9UKAVR+VZJBLZcUrbBYLAAADdvXnfcxgkHvk8HeVIesd65FKKoAACAASURBVPkWL9dL/Qig9g8JPYzfnwBrzexNtvkMgVKOTx60ZeE8SWifweU8pVY3xgAhoBiVYkVajT9MPFu3rVWc+gi9fwdN8ibL+5mpYTMbq24nV+eOObzl6jbqc6au48QdZZmqkIVQRpWjSOE4G1uMBoUtgICoRpc2NHiL05IANz2XHJWip6jzMXTn4YHyOVN89hb7/Q5tS/GiX331Ff7b13+PpmmwWNxju93i3bt3WCwW0TGmv7n1WuivJ6JTU7CdiGAQ1XSg2O7OkTfser3Bjz/+iMVsDmsMOpfXC+4T/2w9BH42z3/uhEbXiHMhVYYaI1gk/8OwH0OgfgoRt8aiLA0KY6iSkgGqsuBYaHn3pK2S0Dk1ODjs9/COMqtJIRvK1GbQNG1UJXs9jswcmKIgT/ZAnuGl4WpgxgIFAEv5xMk73qF1Dl3o0PoWm/0WD5tHVCU5WQZPSWF2ux0679hzu42aAQp7C6jrElW1wryeMWNExUW6juzXi8UK5xcXuLy8VF7Qibny3meOarJmJKe/C/S7hPvZ4GAKA+MNbFEiBANrAizscO15j6Y5xHH88P4KbdOhKmveo10MURPzScoLp2Y+6IyFSOuFHcxML4bZIIGK4bA1Up9bBCdAbaDNLyEgJggirccJFssFlicr7A57bHZb/OW7b/Hw8AAA+HB9jX1ziLHqsBZFVaKez7A4IbC+v7+H9x71bIbPPvsMdV3j/vERnXfwBhQD37SxPKveQ8NDCyyiDcv0krngpbClP6LTz0i/Hzuekq6zXk8w8mPHJw3aU90fB7PefQzAGBm4pwAeer2a7MPRfuRHDpRjqs/s6p7mYKzNgYpMnZ9q/9i7qrODNigZU55QRYiC/OtPhsBmDZfWdOlaY1K8tTGUnGO9Jil9xikNq6qK9nJR+3Ud1UyWZBVCPDsmzCEEvHjxAl9//Sus12tcXV3j8fExagOurq5i4g+tftKqaE1AtaTyXFUVD1/EXVtY/Pk/v8HN7S1evnhBDEvvWdpjt/+c+J1/145/MW81OEzJB1Ct5t7cDwXubH6EIQCIAFNMPDNxJsTwOL3edJ8BxHhocSAU00dVVajqFpvNNmWzkpAqn/ITdF2H3WEPWxao6qSRMRxDXRc2+l/ASNW7A3Y7KtUKTxKwdwGuJQ3QbEFV78rSRtW9jBvZUisqdOJ9dBhbLJY4f3mJ07OzaH4RZgkIUaWttXtDyckihA5FWaDkvmrGLP7ZnBbI3mq7DrYxOOFiGzc3tzAwMXPc1CFmlX7fdAibjHcE5wl6RGsjZWKTLNhJe6PrOJgYurdaURjYxcUF6rrG1dUV9vt9dFy9ubkhrYQK0ZPwMKlieDgcKCGSMAMnJ7h7uMeOzV/r7Rb73Q6X5xeTfdfHNPANGXcNlLpU5tG2RgSqsc/676nj2Lz0j08atIGnAVr/pk5QsognAGvyewR8/qw8hJ/Xv8SlP+d4iiObamfs2WOLaEztkq4VTlxrB8RGlqh/sp+lqmChqhB6ymRjLVarFbwLKvuZ43CYNgNeY0z00NUxnkJgiqKACRau7VCXFeqqUlJ5EQH/6voad7d3TCy2+Oyz1zg/v8D19TV2ux3qus7tvwq4+7Zk0Qj0x7IP8tl4hhC9nff7Pf73//5/UdUVx+g2lFSi5w8xyhiQ0MXjbzmHPFU5o8Qqqayq6livL3HKqP2R94V657IsmbFNDGv/ncfUe9FJjBPchBBUPH8N58j2LQAW5zUElLYgXUAIEeit5aIhlhK7kBezi8xb27QU8dB12G93cM7BWrJHB35G13VUmKIm9Wk0yVQVm1uopO1qdYrVcoXlcoGTk1PUszrGb+ssgMZQngHRFPUZF7UQYAoLEwrYkKv3Zfw91wXX6zuusZCysN3f3+PACVykP7JX0jyTX0V/b+q50iFtY2Ddfw9r2EGOBZYcbIRxD1EiX61WrBmYY7Va4csvv0TXdbi/v0cIgZnoq8ici/AUAqWS3W4pHXHTNDg7O4OxFtvtFn/65k9YnpzEPStV5h5t8rjv9/85Eu/U+awd+f8zyLYxtIbFjBAwTEs89nmqL89VjQM/AdAGhi/ff8GMkMqf3hTp5me1D8MqlBAQ4gZ5Tv+0aob7BpHamVsFkn38iYnsP+OYev9jQf8YNwpImtWhBEiFMtixqyzR9u82BovlAsEhqtHF41h7+1JITPLwldSIIrkZQ6FBwv3XdU0JP1SGKO89Hh4eos2SpHHg9etXACiGWIjL4XAYBW4tlYxxxvLeOvVoLrUDgIW1ATAW7999wG63w+npaebZXJQVF4ewvK6Up3jSe8ZnWGMgFdtEBas1BXQEtq/laxBRwrIsjjGIBJHC6dqqoixjrutgKjJpiDQ4tp76Up3MQdd1nOXuwP0lfwWRogZtAJixz4EBq8wNh0MppyoKd0pRBd45GBhUVc3MIxf0MJxkhbUFzqXEH7N6htVyiZqZg9PTU5yenGGxWKKsSorbtikBUC61pjHIpdc0T6QZIMc/0SoAQ7A0wPj9JjkYSkIh6UcMg2RgJ58UoXnSXr6Pc6EmMIPdU4trIYHPZbZu2Bg8IIy3ARUsKViWKa2lDHowWC2WWC2W8N5hXs+w326xWW9iVEgM0QseVVHFMd7v97h/eKCKcZxx7fFhg+1+H6NLlssljKE1unlcU75y3o/PZUjy9ZcLN/oeKvB3RE2VWkwq9rifkjaiL8E/h84/V8ADfgKgfQxwBr/JYEGG8LltaklaDX7P/jG2GIZtjaipjSwOzdU9DaTHVOZjjEt+v36XwaOye3QbT3F8Io0bExBGJDBjDGb1DMEjxsLmOdHlz3McaxOdhGTsNIEM8DH9p0gcnmNK2zZ5ygqorlYrGGNwd3eHX/7yF/jNb34TQUXbxOQ9daEJ6aNsvLFMVMNxRvTIh7H48ccfsdvtKLa0lTrhlsBJvPiR5j8IYAcmBZbt2GWS+nR8dmCpnvpB8ywVnwSstfqOiJT+nd5huVzi9PSEHdVkrBUBU399CVMzDzJOInEDQFXV6Fw+NzqxhjBzi8UCgRkFw+8qcyShZ4fDIflQqOdnoDOyB+Waqiiw5DAxKWhRVbPYd+cdpL6sZtCyRDbqfeU3OUpjWDOQp1ON4M30SJtItFRMa4z8Px4eHkhtL22ztE3x/Tn9GNurwlzoc1PXy7VJ6s+T/ei5D2of+BBg2Mv+sN+jORyw2+7w52/+E/f3d/jhh+/x4f0HyhQXo0wos2I9m3E6WhtD+BwnbwkhxIiRx8dHGENOeaJ23222uL2+wWazwXw+j17/zwW7Pv3VMf6yx8R3g7cVvetoNFAuxNCJlD2R5T6+Ts4dQ6SPOz5x0B6qE+MvI59DuiuWBvT8e5i4R+6QCaXTNgo+WsKdksbSMbKITE5E1aUZbD/FnBzjHscOE7k/aWMYUqTfaeo+/SxRkfHZcdAGUJQFAhNCHW6lwTEEcKxsFyVw3yupGEKIBCOAPLCDJ3DR8at99eV+v8fp6Rn++Z//BVVVoWmaGGrWn0shHPp+DeACNmNJYiirGY1IVVXYHQ64uvoQ35mqrhkYqWXMEpPcr8GSJCpEcE9pS+0ANOkd/MhaG1sDfHgg8LvUdY3PP3+D+XyWJS3pr4u+ZHhszcg7U2QBhZYZY6LTEoBYK16k8oCAsq4iWEt4lUQrtGyr1hoSkcABw6CgWG61V72nFKPGkMZGEu9oG7usnbG9RZoJg+A9qewVoEdwBhC6jtT9Jq8x3Y9LN+lLbz8BIXg4h5gjAcbH9L95n4aMewQag2yuxgQb+azXcepDLgjofSsqfukDWEu0Za/wzWaD/+ff/g0AsNtt0TmPA0eYAIgZ8KqqQl2wf4ZNIYGSx7xkx1RJMhMC1RmoihLtiwOqssQt1+t+Kipkij47l9LeUt1zxL0mIarGEpNdMJKMHYnxkgfmAE2fdY2J/1pcuD4+cdBOG+gYqNHQsFzc28QGUxMo1yjP2JG2n9MHOi+1jftELmSbLbXBG2RCFXO8z8dSsOpz+vzTiyb9Pi5B97/7sfYMe4/3pDHdBhG/kBE3IYjOtdFDXeIzk5TTRQICIMshLWNC0rjFanWC29tb7Ha7rLKSZoDk2TFm1qf0jYkg5u+spRmx/wMkTfzww/f48ce3WCzm6LoWzpMtP4ASmQj3LjwRC9i02y0zPDYv46idz7T2QfojqkvuIZJWJ1f5A6nfr169oiIW2w39piRDqdz2XIIYY8eRwCouTQVkUcsQQswMR8wJovlDVOpa5d51HdXjhommEi0ZjuVwF2bPs1nm9PQ0preV5+p51uOr14DnhEaFyU0T3nvYokDnHeAcoEqupqx3ui863/dwDDVDG/cKlcCO11pD6Yn1OlCzg/Gt+LQzVPIKp7VsRvZttn9FDA0Bj9sN1bEvbGTEttstdgdKwtK2VBlOUt4WRYG6rGLWOTBDICmTjTFAYdMYGwMbgOVqhfOzM9zd3XGFvx2Wy2Xs21O0Uv51LiWHkpzq8/kcJycncV/3tY+jA4uM/4Ymtf19cmzs/9rjkwftsSMbhBwDYVhakQVm+GR/2I5JlP3r9MLoBQww0UibZiCxAELXe7+Z0Q385PtO9evJhZG4vbjhzTTT0GdkhIvUv009U8a2z83r75IgIXoIQ4C7ijHiSQJPoWaasApIa9WX90BZklPLjz/+GOM+JUZcUlUK4PezpkUvZmOiKlSr9oX4yBFAKtiiKPD73/8em80Gl5eXbKOn5BWUcIP6p8FLnqOl/sLmHs96TEUrIA5NY0efoIcQosRpjEVZWsxmNXbbbaZd0MSlz3hqxkivN+mj/p3mJgdC6bswIkIcyVltg65p4FsC5+A9gnNwTQfXtICnAjfEF1MFs5Tylp8rpgbul2FTA4W2lfF6kTCNNaR5UFJ5qsBGxXZCMAi+4Nh1mbsCXcd5xivKOb7b7dA1PjpS+tbDBAM4IHSBQr6MRWlKNGgG40hjNwbEvLqYcZDEPfpIe/nj1a79Z6X1JcWShhqDJF0mjdY333xD9bO54MfDwwN2ux3atsVyuYy5EuQ+LsNF+4r3lJg/uq5DVdcwAKqigO8cttttrAD4l7/8Bd9++y3Oz8/Rtm2UkPOxOEYL83eez+dRA9BPExzHZWRoDchPRJTphkXGUY1qb4zHNFcfe/ykQHuMi6GDnDVkEMXGl/lo9IBbgEWk4CmAic+Kj0ngPaE5yZ/BBEeYiXSEESB/7uJD9vt434eStgZbIh78i1pH4/fK/c88NOM06Jc8k52Peg5vIZRwrotEPoClJp+rrAXQY1Upn4iMhI0dDgcARCAkJlykWPle13W2UbUqup8IRXPjBAIkNS8WC1xdX+HDhw+YzWbqnUNkDPoS3djmFcLZt6fKZy2R6XE9Rgjic/ne+XzGxSxGvOTVPGntRQS7kbUq/05JFEYWP5LfwYLLv3adx3a7Q7trY19FfZ0kU8OpNF1kkMuS5is6SUWbPcgsBkQNm5R4lThrx5IxAXfS9ojTGaVS5THn2PUQC/5Ry857WM4vb20RNQLCVLmuZ3+Hson7lMQoY55NSnCk59WxyYjakj4MBQC9P8cY+f5n/WwEBtG4PhHpYmTKVBtyb9u2+O677wAAX331Feq6xsPDA8dwL3F2dhq93+M6U+skJb1BpqEIgfxlHh4eEAJFGBwOB7x9+zZKyTLeU+/bPy+as7JkXwc2mfQjBgb+Gxg/Js+PYNTzBavje1mOTxq0jekBqpxHPgAxXIH/leumXj8f2LHfctttvISpgdo7k9xTAvdESKZ+n+pMH+xSv/v9lz6nTTdcH/nGjucMRhegUS+d+tGvdjUhaQ+kdOm/3mTCMGnOh97B2mQL7UIX7UpUppAJWafBW3JJd3HzC8ADyW4pCUpISiw5wQupZSXZC1UvI121VFnSKl7nHQLb40tTAJZSsn7/ww+4v3/A+flZlMrleQECeiApmVXaAuyGx9vyM0yPcdDhVQIIbAnPN0Vml2TVpyH7v3cdytLi4uIcq9UiOgrFdzOpAER/IYRAbVhmi2FAmcZ4Lg33OcjcK6DGCIMie6YoqeKVYydDHwLqWc2SSwDpiDlnACzKsoIFVeqKqmjnKJyKGXew5CqOjlVVR6clgNKElIakXxeEEZAkNQm4u86htEmdTgwmAY9zHUJDktpiscDe71id7yEZ6pzrIJOTQNjBdQ18cIDxgPFRDW4saQjgeE0ogq8jDYwR5nSc0qW8CiGu9aMH32qNQWEsCmMhpUxl/tTyip9F01IUFre3N1ivH6NWajar8fmbz3F6siKnSU+Z97xzlISIbFxRwhbNl3cOXdvGxEHwFEbYdh26tsVyscBqtULTNNgd9iirMrO301il3kbTk4yBsZTgplAU2YDnVmWjNFLKN0wLZib/M+o/achw21PM0zhu5ELU2PFJgzbQA2x5355k2Ac+bfecGjC+ND4n/T5UUeX3CyIOVdN9laAcdgrcBDBDj00wx6TtRFz63Hb/0lx93peopZmpTZ0kcZ1rW37jK8ZvNTlwC0jn/2qGQ47kuCGcsUVSRXtPqtUqkJ1QiliQqjVEsNThY/K7cPSicW7bLRMeCkGR3OiiTq/qMuY51rHEHuwx6onYnizmmM1mePfjO1hbwJgCziXJkYoz0GhFNTL/JuCdCHQav/6hPe+J+OV7It5qhGBJuI/ncXUoywKLxZzso7EMo4640ATHsKYq8J5ir5HIyBRkp49MBv/1+i0SmraTCrMVANiyQFlVaLsOretgOg6dAhCMgQfgXQDFqgMwATXXZI9E2oCyj3H/pXoZSc3k41AUBpbzhHvnwCW683mJjF1ydIvSF/skFEURmaOu61BYSi+737dxjWmJ2XGqVpLqOwJsOBjL+ytIdj0desiZ3GzKUibpbSVHgjFST91lDIemYcbQetd0Kaq7hVOUeWd8MkFA1rNKnvoY+F8DdR/rjruuRdPslXo54P7+DovZjCMEeJ2HAp0PcIaiQFo1vlVVoQXNTWkMynqGGTuPth3ld7i4uMBmu8XV1RVpN7xHqYQVeS9W4iM72aPRopX1co9R5hVjohrfjDKyqnkeesthdRaW9ol92pY90HRBaPbR2z510AbEIJxA5gjzcxSgx7+nRZ6cMJ53z9PPfo46JDIAyNmFo+rGSaBN14zZu0fxP5hBc30nF91GnxEYfT6GfReAPn6vSN+AVNkygeoAS1e9IbtmsAGl8gT2PhElDXASUhbLKgYhoERcD4c9us5FCaVtW65gtYwq9Pl8HtOtGkNpKS3HUC8WC3z48AHX11cpptTpRAsTaVLVPMnnPleu50OKuIiqUgNN1qb8TwFkAOC8j3XQO+UBLVSHQJmJFNfXhk82TAsLFzoENi+I2tdam0LOgD4Jjf2Xf3PwTt7domIWDYXYvrX3eFmWKNmcASR1OyDakNxHgOb/gK4jhyhSAYPszSHAGAKYvH8K3GzBOc1blKaCSJdVVaHzLtPgaLOMnu9YIpcBPIipgZlszdDQWBMiFEUxWk87rat8bPVvlEtBxgLx+X11LbSazYCYr6IAXBfHlLQsY+YtmemkhROGp+scNlzBDUBMYRoAoOti5rOmaeC9x+npaTR7IQSUqkKgsBWzGSXHWbC0bVUp33ytAckQPY0HUYNgp8ZWi1HjxxTeyLyOPhf5nGm/lT6ATx0/AdAG0Ic0k+S4p+y//QGauk6yf0393ncKOvbsMclb/yacZ0SuyPFOH8cYEjnGbJxTkrZiSY8+q78vntOP4XTlnHl+QZIwidgAmi2zcMICw1hDxRmQA4CMXAhQEo5jVd0sqlKdc+h8h7brUNQeXdPC2A7O7eP1+/0e2+0Gj4/30atZpHCxhVf1DPVsjvPzc2y3a3zzzR+x222wWMwo3Ampkld8LyBDNCkyISplYyxML+uTfNZMiEg/UTE62OhDYhNCiHGxTdOg5KpSVD9Z2SwtVaSS50ZGIiQgFGcyY7gusigFNcM7sj9lTvI9k/aJZpq0RzoxSRR8s1wuUNYVv92Gx1rasKydMUp6KyG2+6qqUFYVDm0Dg+RkKD4VKfTLQOhAzJuPgLkx0ZGxKApS2Qbyq4DzcVya5qBCqnidx8lPsfCyYDUDR3b2NJ55/HCKLdZmpjFak/a/9lvJGadIz3hNBpYujTWxT1nYl2iGJuknva+sV3Eeq+oKpytimKQGgFzfdR3KssR6vcZ+v8d8NsNiPkdnLIrOovQVKkvanLbtsNty5j1m8oQhhWZEYvcSM5H3kdd2r+9RArfiiDekpf33HQPmYKf9O/S1YxL2c4+fCGgDRAj5xUYAQX8f42SmBjm/N4wQwWmuqQ9gT4H4oL385AC0x/s57eXbvz7/3cKYYZGB/rV9wB7vQ8AYOKgeDtrKJWylWDd67Ex2P0C2pWBS34IQkihF0B2Z1BmSg1GUsNn22ToitE1D6syudahKcnQhSYk8YDebdeakIrZuytW9QFFSXW9jDP785z+jYWlecqIPRiOo+RhZD0MpKAc6eZ8kByTrHbJzIUrZ0Y7rHRzHqmvg1IAtdbZ9CDAOCvwKFFHDUAz2kxnMM/XE+zxSYQjYZEfVCWSorykDmoBmWVY4Oz3F6mQFU1gcDgdcXwe0bbLJR1BS7YcQYhjSy5cvUViLuqrgO60OT4Rc5ksYOMdaBI8Q48gFTMuCHNA8184m5oB6QAyymgMSnmktexXWBQpZ8wpEo/zK58Qrves6zuqXe5GH3lzL+CYJG/F6o8Y7XRei1B/Y1GELy+FliakbTzQk4y7rjJgVYZLrusbq5ASLxRJVWeKM87uHQM5lr16/xvXVFX7/+98jhEDXzucw7CC43+9JB1oRTDVNk6V2jdoDtQcycSDOx9CuPOoVbgQD0thOmTbl98gISLu936aAWf/Wx5ynpO2fEGgDJIENgecpMD02CH2Q1wD9FLf0MedHOak+UI/cP2xznFEYu374mZ0rRtpLl+ZqL30kAqA2b697iYg/bxEa9a9mZagXZCECkGy4fFhYBDs+FkLwEmglG2MNAsLZjGPBmw6zeobmcMDhsIdzZNd+5JrBOq5TpLHZbI6irHD/8ADnHW7v77IUlpkJASSRCsh6ReSkn5GQmvQu8j7aW10YGwGCAWBmWosE9DqpDT+gd69SnbJDlNiopT/W2ggmuo9awjH8ryZ6Mv76ntgnT/HXhbUoizL2UTLfyf3L5RInp2eo5zXOzk6jJ3EaYwvjDYIJWX7voijQNG0sUHNycgJTFrBFQBFEvWphbVKNi8pdpHbSKgAhUCUua1OJVGsF4Ckpis4qpkEOQJxfee/Y92AATw5prFCKC92wrVeDlM6M1p+L/ncZd2FM9DoaCiK0A5NNn5nFI0ATtQcavHxAVc1wcXGJ3/72tzGa4nR1gtevXsWc4tZaOAQEA7x48QKnp6eYsaR92O3R7A/wbUDnNijrCoXOgBaoEqMNgOXh0Ix/Tm6kj8iPESFJ1oB+3+GNMlZPY8vHCnFjv40dnzxox0WSzmAEK0bv0Z/HBqO/2AfPfCYH9BRT8NQ1fMFHPOfpie23k4BUS8h5e1rapXEmZ6Z0PE+F0wftfl/kkfrpfbkxzrrRcnmeLCSpm/O2+9KXlhasyZOp+FlAN2OpuyO76nK5xHK5RNM05KnKlaXEO50kgAOatoVHiHG+4smeh6IIodWELqk/9b8GQ+/xIbPHEiJnY0m4G+IwaMlLS0LxN+9jbn6S3tlzGEkC0eFmooKUbB+6fXlH/sJqVDWDmlnoHTFrWUie8xKvK8+v6xqz+ZwqaHGo1/39fXQ2BICit7aEGSo4+1YIAdvtlqID7ByFKYAihRmRA6GNyX3S+gGKgswIVAbWx8Qg1houJtLBxVwBfRtlYgC0DdeCJGHRChBDxOMYh5KYmaqqYtjabDbD7e0tttt9HL8piW5cczYUTtSoRYmU9gsNQFAMV39djZEpYRY2mw02m02sjf3VV1/h//jtb8mZbLPBu/fv8cdv/oT9bh9V52VZkq0a4kRJFQFNUeD07AyLxSLuP/Eh0MlyohAx8m5DeoTsnGZ2NS4co8V9DdMYGI8JkH2t4FPP6h+fPGjrY/iyQ25TjtHPJiVi0McUsD4X/Meu/2uuGfttOJlPgOHEb08B/viiSQRZLy7V6MhDEQF5XLlg0mUZQyYccg5WOta+P3dx/g0gzjf66Dt5CHcPMMFzAcECpSVA8L6KISiz2Sxm5ZJsT/Gv4fzZ3lOIikupVzNioN4/Sjm9YcskVtm8IcQiFv0jhCkO3/OAa4krB44xIp9UtXl/xv0/hmpYYazyIwfs/jOl7eh8xMesqinsh6VdIfiL5Ry2IBvo9fU1rq6uouajKkrFrOTjQz4INQAbmS9blVygJBXkCIESp4h0mRzMcnW9jlfP4/UTsAmDKM5pMmbOOziVeteApEQXctpiLDFk0Y7tPVdOq6Jq+XD4ED3Vc9W44fl32Zj31edyX+qLPJ+dDjlXvs+2el+4GdJdUePvdnvMZpTfvSzLuJd++OGHmGfcGoOT1QpX7GdRFAW++OILXF5e4urdezw+PGC33eLQFGidQ1mWuLi4wHK5xHa7xYf370lTo9ZpZDCz9Sl7n2hEthYD0Re6bFwgeS5oj0nf2d5mLi2M3vu8Z8rxyYN24kLUsLL6bkxVLvcMP09Lif3rR1XZ0soER/TUJPR/H2M2hnap8Yxnx54/pTWY4rifc/+kmmfQSnwCYMwIyGZopdlbwJCzcuIt+IM1kwxA6oPJQK7fXyGisW8hoLAFS8kSdhXgnMkkPFGPC3gLl992Dk1LOZfd48MgLnzqiJKA6pMxZEdGCEpizJObZO/FEhCNyxgzx4wpq2G1SlT6KXbBqApmr10T5yIBt/Q7yHllAw6e494ytQl5LyOQqpSYKckyR83TWFFNa/EYN8agrirsDweEQOpx8donHwQa//v7e2y3WwKtIPZYfrgXJy0CL+k3bxhI0gAAIABJREFUzWNA25GpozRlTLKj500Dtrax63j2LIlKTLFr4gLV4x2CUWF6Hs4LcEjf2EfBSKy8gS3LCEYBQFlVuLi4iLW25/M5ui6VPbU95o7WDam4NXiPrke1gkKg0FQf2MHQGDg194lOCQMgzE56Ps3TAa9fv8Z//+//J87OTknaLkvsdzv8+c9/xsnJCf7u7/4Or1+/RtM0eDd/G9fYr371K3z++ee4/+IL/Ok//oC//OdfKP0sO/eVZYmTkxOK+tjvUw5zTUsGY6GlW6EJIllQxrl8/6jxmQJXA8Q0fUEv/aFfijHi2im5B4Y0MadPTx+fPGgDiYMaEHS2cU/h5ZAT0lJB4gKOSdhj36d+O8aVxfeYAsBnMAJpwY3/NqZ2OXZN/xj+FqLkop85ppIb9DNbn+Nj1B8P7ekZQQs96TSMjJUCu6n+xM3BOuUAwNqkOjamyK51DG4CcpLspZ7P0LTk0b5YLPC4Wcf+9t+LMLrPfCX2Ub+7OH3ZHrAPxlXYddH4BQCaIQ2UIcyHEJ2evPdcsYj6IgUXRLUYfKAUotYjGAOLAO/FbsvghQAED+s9eRgHKVcaone3lnT66mKRTuVoGvITSHZXkkyrokDbmSihSc7w3W4XC1QkyZGAL6WLlXkmhkGqoYkaNfiApulQ2U4NV4o00PMhoKuzs4lKVt5FmA+RSvVekcIUOo++MD5ZJAporoqiYEY3OTVJtIIwL0VRYD6fY7vdZ2OXxjtnzL0nZnSKtphsjaU9Lo6BztvMtJOAL10v4yK//8M//AP+5V/+Bf/4j/+I6+trMgscmujQ5ST1a9fhw4cPpK3qOrx48QLnFxeoyhKr5ZJrtPuYr1z7fszqGj/72c9SDvPsvZI0q99Va5/ohfgNRuj3U5KwviY5hOYOftmfnpoeDe0zFs85PnnQji+iXt5AL0SiXOOD3Bt88UKO30cWMwxsUGoWozdjrgock2Llex8Ap67tP3uqX5PvNHXVxMKbYhymwdzGzarvmV7YUs5PGp4eo/55CbvTxKFfZcfIPQGRczUwUecytVmHfQjcV/AzUyYpGMsgxfm1jUUoQUkerEVVIjrGdMqeKT2MHL1Sh8klgSil2vRpSUUGZYLJiSYDBOX9KvsDcX8Q/bb8XizxgmRwH4DOe0oBwZJ+QGAPaHZaMuIEFyDaLOlbx/2RRDNR6GBbPDwlc4nEXd6bz5Hk2qLtWo7TTuNjCkN/BijFhm2B3XaH9XodmY2oEjXk2GdDgERG+OARTICHZ494Yjgce2lT3HWXgZCWtonwClCJZJyYAFGhy3x47xLfxJk6DH8PIfCzA48VMT7GUD8Nl0UlPTQ5vmlHxYK91LuuI8m667DZbHF/d4/9bs+TLYy8qIn73uT5vtNrNeU9o7EMrOoyRUGRAq7gdcuaGH4xTQuEkTkcDvjZz36Gn//851xec43V6gTWFni4v8d6TbWwd7sd/vSnP6FtW7Rtg0NzQFXXePP55yiKAu/ev8ef/vhHXN1cUwmmssC8qlCVJbpDg23n0BwOMcTOxjXMqm4e/wjIsqVZSBM9TNBYMEKne7srO2L7Yj9QjHYfsAEkE59Ja+s5eDB1fNqgbUZeilWpiUPhC8duTsN7HAcHdyayKWmHhbg9JU2PfX+ONC5PDeq6KcB5Th/GpPvn9FUfGbOCYcjH1BGQYknH5ua4xJ4TBRN69ysg0KpRa4Zqcf28vhQl7yXaC+/TRrMg9XlgBiIQleXdYgCWirfbXQbaqU0i9lGvbyQVZRhSgb4aXG/2Ecavz6ELo2FAGcykGR8AH9XEFragfnsALpAGRco/+hDgEFBZwwUyEiABBGQFx8vawpKKnLeWePVr+3UIniUrE/cqQkqoQvZdFx2OUuhZgLGUW/zkZIXT0xM8rB/x8PCA5kAha8aYKL3KxEeVffCRmZPUppYlWB8Cj09A2zQUzmVpvqTfpBJPgE3rgpKiFEWqfa3nByCGxQbE+Y0MWmA5zIDXkGSo4zXCa1nAkO+CtRxXXnIiGe7zZrPB+nGD/W6Hru1QllUCpN4a0cA9zGio1pYKhwqGnPJsoHEripIqlAViuoIXHKTrRNvQdQ6fffYGf/M3f4PFYhFV4HU9w3q9xo8//ojN4yMCJ6Shuutk599ut6jqCm3T4Ltvv8XNzQ1ubm440YuFCTaWytztdtFjX1Kfyp6Bej8ZTqPeU0bI8l+HBKZ9CpUB6hSpC7L8WEhBciAVvBgy3EP80AzgcwH8kwbtzF6VHc95wb59YVz1cLQdQoIegf847uiYxJsdJJJB8yAD8Dmi/j12/q/h5uS+BA7CID3juTJv/E7H2p/+noj+9M7R94k6PR3HfALGbMbGGJZ2mKA7m+JiC2KpyrKCKUhVvmUJMMUgy1yL/VYTEkuETzkjCaAbk0KqxpL46HcZY8IGarW45HMvYm3X1ueity7E7hpiiJIhzjnGaFshlAzE8KRSl6Q38v5xDUMANanqO67sJu+tnb1CCLi4uMAvfvELLBZLXP37DR4fHjCfL6I6VK4VZiKOkgJLY0zKxMXtSlIYL+/rDYIfiR+3Nlu20m9KxJL2NI1jAgw9N0Sie1nIMgnMRI1hfD6oNGtdzWJeALGJHw4H7HeH6AeQ9Q8JoGR8kkqfGAQZZ+m3dpjrry8Ja3O9kEoCJw9KoUrraD6f49e//jV++ctfRlPSbrfD1dUVzs7OsVqt8NVXX5GjZ9fi9//r97i6uoIxBrN5jbZtMZ/NcTgc8P3336OL6YZTfoQAwPmA7W6PorQRsPu0VcK/9FyqF4j8fiRLE0LO6P0jBz0/r5J3TLg6tn8/5rmfNGiPS7Zp6Me4lkg0MC15jR1x0IAMbGizhaO4MQXKHwWWEeSOgKEsyo95n5FFkh8yRiO/hP7559ldjLGiq4KZuGcKsOnfZzhlhPRPCCGquQS2E4Dkz0hq0WFcK11fwARHIGuJEIiEZW0JGMrIFELAer1G13k4F9B1ookYMjfMxpDWIDAgsBRmpO882EJQ+9JcfO0xgGbpUgAy6D8F3MkOnZgDckqj+6L0CkwSRniPfrIKPaYAVGpIAzERCPA5xTTog2KqO1RVhS+++AI///nf4Pvvf8DtzS2PPRFxAV6a82SXDayB0/2VewScRFKXPnfOwfuOYsWZGclVyxIOxuMnoXLMqNAbsuHABFABEA6pM4FBmZ2dgoskRNOaqN5VfaTMYSkkjxKrNKxSlnS2auy9j0n18/7T/tVhUVoKPwYwiuvKxjQAHJNOz7i4uMDf/u3fUuGUPYVvtW2L9+/fY7PZ4vLyEr/4xS9QlgW+++5b3N3d4ebmBq9evcLf/7dfAwDevXtHiXRUSKWEgMmeMCDfC4MChS2z3Adj/Z+iU8I8jdHZcbo7Rou0c6XgDdMQ1VZ/jI/RQb1Hnzo+adCeOtJAjal99UDmv02pifsSXuBJZeqaNfVcjui5gJ0mDZOALVJrWh8f1/Z0f8TRbOSXkNTUU6qbY5K2HrQ+QE61I5zrMQ4pqZHHn5pP1vC+/iYRL9v8OpOYAtnkSOYRYyjF5f5wyKQhkdSpHemChM8oacx7nuv0TBnjsVCr/vhlG9wi9yQXaTqkpCoCCCJlhUCq5MqSo5PpqYmNScUyUu1qGmFrksMNqU5JCe9BccViYpU1G5CS24hD3FjCFzofcHFxia+//nsAwDfffANrLU5OThBCiJL2dr2BaziemhkWvQKkvwLa4qHuOHQoWx+KZvQlIclTYFCkcr/CcChaMmCM1DhaYwfthhBgCksrw5jYp7IsUZUV5XnnKnau7dAeGrimhe8cFcnpOnjXwbOTYF+7JOsk7e9cZa6d/0hdP3SgEq2KLQouciLtIN57OBxQ1zPWRiHmd6+qip3NSIsxn8+x3+/w/fffxTrbX3/9NTmrXV3hw/v3bK/f4O3bt5jP5/jqq68oJz0zKtZQLe7Cimc8TZ0VxlCWP4Y0Jr6X+s0YM3lt/76xow/GUmly7L7nYsVzVeSfNGiPqYP7AEtflV4knh9yjs8Cj2FTA65JwLNPJI4R27H+Dz+PMwSaM3+aDxseQ0ZDkhcct9F/jKZi6pnA8cWoudX83+Ocaf/Q6QZHaqBM9EPGXKXITQ9SnJTkaQ4xzObx8RGb9RZN06ic0JowE2CPc9BDDvwpCahP+GOb8pUXhwZI592oVBuCh3cediYpRFO2LlGhilQu4O29R6GSbyQGgLzU4xB5n9nFp8Y+qpu9gQsBnfNYrU7w9ddf4+XLl/jXf/1XtG2LFy9e4O7uDs45bDYb3N7c4OH+PiOMxrDNGnlom06qI2lAjTEx5M0Ygz6LmPczJ8T60OMaxwGkrRAmAQAMz5FV/Q1MU+ScaDQEvB234TkPQKdqTVtjYlpZyZE91v+0ltL6ysFazpETX3+dReC2Fs5QzntNGp3zeP36M7x58znm8wUuL1/gs89e4/T0FA8PD3j79kccDgc8Pj7iP/7jP+C9x5ZjtCUH+Xq9xsPjY+z74XDAfD7H6ekpMYt8nqI4uGAMj5XMDo9o8k43w/kapcvPuIb+xeihx7jPaPfbyjUf07TtuWFfnzRo6+P4AOdEYlwafiYAGZFqTeTEMzskjnv4jvX1mCoqTeL4farr6fxHQrcmcNRmGJzvH0PVDqGCvvwoFxqOXTfOfgj3rO1rHwPckelJH59kPNJ7EnBLQg0L8kin77QGhIETVa6WFvN+5sxfkHrPSKplPR/a1qiJ5lhftVQn0lSU4gPy/oThexMYi0NUeh8J4+q/i54L5z0MaxSkcIZoGEQFDik4oZgXPU4ZUxGAYAv4rkNZVXj16hVOT0/xhz/8Ab/73e9iMo2Hhwd0XYf7uzvc3d4hhJCps40xsZSijIUAoYwpAK4h3hKbJvXDFYD1AY/WfMGsnWjcQmRo9Bp1nBRG1NdAIsIWQHAejevQuC6Ouc5tn+bGIXQeXUyh27HkTj4HRVGgns3QcOhZf3/opC76+BjJT18XgTtwdkRD0vZqdYJf/vLvcH5+nmkzlsslLi4u0DQtrq6usd9T9rbCFihsAec86rrGzc0t/u3f/h1tm2L1S85PXpYlDodDREwx4ZCfhd4bnlMZpygM2vtD+j98Z6kKN01Lnyshy+fpvSuaoNBjsfJ2njsvnzxoHwNE+d4HxvHJOk68tTTbB/v4/QjXNXZuDLCn3+NIu7mG/tmTO95XAEcYDuCYZKy9UMf16tK8Zmr60gudozboPP0dYyKexWwd+y2EtLEzRkn6SKr52NeQWAs1DTDGcOWwFhuO0Zb+yZ84KKmRQipEEKJKl5y8BAuYKEKpo00+hvrfuL6YDGQx2d4jqMISmeqWgcX7WXqGSZKVpP0clwTS++l4aSPhX8ZSuKT0EclhSZ4NvqdpmgheolL13uO7777D999/j6ZpcH5+jubQ4nBo8PDwgO1mQ8k0ijJj+wKPqQ/iLJXKo6Zc1+x01nXwIGcFiu3OGeRcKqLPVKbUR0bMewZ/7r9OriNJQGwpXt9txgyJc5XUbZfxlFhyctTryMPeO3gKXkPrHWxZoDIGfv0YQ928cqST/vfnb0ryE22H7GstgWt6qfP4h+BR1zOcnJxgtVrh7OyMTUQeNzc3CCHg/Pw8gvVuu4X3Hi8uLjFbLMhz3zk457FZb+BcF/eIpAKWdK+z2Qwl514X+gAAwQSq+638OOj880A2ZN9lJY3jw8g2yNob+8uflxjq3s20d1Q7z3oofgKgrY9joPwUJ3mM6E8tahitHkMmwsl8PIepeF5fxq/rb77+dE4DrMkWzVQfcgl8+Hs6L8Cq2p9wGLNpsFT/xF7NNiArbR5XCfXziPf7d+yQMB96vEl7M0qPY2oq6VOI34La0EVVpnKCh130ps4JHniXJqDmEdBIQ6AQCOyMgO9Akj5uJkj+AyFJu6KgCUNNg4BnPw2ntUplbPU8WWUHTjZNzzG9wofAEzF1XmdXcwm0kfdlNpuhqnKv5u12i7dv3+Lm5gaXFy/hHfD4uMbDwwN2ux3NGWfISz4etK68ypGv1ZYlZxgzIZDa2VAkBIGtifnMyT6eAx5J2gT+EvopJoiuZVt8QaYBXVu7rKkMaNc08X0lRnw+n2OxWGQ1wfsmDO1bIAyCvEvTbLA/7OB9B2OqTDPy1J4Y0yjQ2CP7PrZmtHreGBNr1L969Qr39/dsfgi4vr7Gzc0NvCPG0QCYM8jXdY39fo/Dfo+uaSl9aVmyOcWiKCrs96QJKeoKVTmL0rVo+WjPIPqXqA2RveuYFPwxR6KPI78hZ3RljKYkZl1omPa47Fi+Xsd7h6f1qJ88aE+B4MeDtMhZT6uWM4LYaybJi3lM9VQ/9Pkx4puu0a3372VPWWnfDMF6+OzjUquWLPSiHlt8IUjctbTns997j43PHpOw9X2J050+jm2GMUkUYFw2w5k2xpCNsde3AWMkhA26jeTlfX9/j5vra84ipouDYNBukLHK/BWGwCwd7/fl6TXlB882QOb4psdIQFuXygye7NJUgtLCsmesZIITZztrTAqbUuvGWsvx0qypYOCW4imROYhMQomz01P4QJnRRLq6u7vD3d0d2bmdw/v37/HAldRCIGcfMFNC80P7M0orPMZSCWu73TJzQMk5imgPFdAilbkAg4yHEGIC2gSoxpho10/rhMeP14YtCtI8sMOfOPLN6hrn5+dxXIFUUUwOkdblmvTZwpgiFath7Uaa1zy/e3/Pje3n5FFusuena3p7SknaIVAa1ffv3+Ply5dYLBYx6xvlRA+wpkBwAdYkx7TdbofgPMqixKE7kLd5WWC2XHClM4vZfIaqKGPIW9QyWiUwMI0RzVeaoLTP9JyN7qPsew7Qz6VPuk1t5kjnQ1yv8Ttrd7SUHcc5aqiOH588aGeiCQB56fyYsAGqu4wxXObRDH6PalOkn4/PFyFCIZPN4lzImjep0ZgVLHBfx8B7+A4a+MYWo/73Y46MeRDxIbabdUlvaaRv017nsU1hJ5E+q7vlouGtevyQgOYIU83nRF2cT0FUH4tIGFXgcpFWB2oCLTbN1L7MxePjIzabzUALQJLASJ88JWgxBjFrE+Lb0yKJa7UnCUk78pxnaRggyUV0Mo8ytuG9x6Fp0bYd6ton+zDfZxE4MxpiRjFTGBS2RKlCwaRvkoKTSlR6BJBHPqVDTY5tor8IgTKUIQCubbE57PDw8IjdboeqrIDK4HDYY7/foe1aWMOJPkIArIdkeEuyigCKgzUFm7cDxTUvGtTVDFVN5VQBoLCUs1pGX3KlwxiyvQqo8joxXDXVWMQkK3VRxxKbBGSWGBmrkmzUVVx78/kSZXCqDjQBJnlYU08IKFMsOGC4zwWatsXhQHNG1hdLf9ZyCtW0bmhqUq79FKJHf/kakrFDfJd0X7qWmC+5hu66vrnBu3fv8auvf4WyqrDbUj55mgeHwhSoyhIIwGG/h0WSIgM8bGlRFAbWBKAADCyqcqaSpnA2FwMO8UrHGBjLfhoD3/ydh22lz3n74xiQkEOErT5zLOMdtYsyphgyFlnLRwQ7OX5CoK2/J24ZeAK4Jgh8v22jL34i3SkxANpjuZd8RIgswBLysDPCbUl7shmyNxXulr7QtdYMRmT8/Y8T9z6Hmj84/Ut2Xt/74ThTY3pLM6pQ+Z48y1k/yUk+N/mrjV+jz/W7ZJBsR/RwylcvwC3MR38IA6upCGSE7yD743q9xm6/hy0KAp+sfyOMl2F7Oecoi4wiP5i3P/HhGQHJwXp8nlPhnGw/GMOMfi4pAuThvN3tUFcVjAFWJysYW6KASI9UFtEHD7gOiBI1q9aDR1VWKCvKOW6tTKwlu2JB95sC0clIV63ynrzXu7bBdrvFdrvlGuezaHN3LkluzjuOj3acnYuZQB67KPXHOSAJuW07luQdOhdgbEhqcKWSlDmRdStSJtFbyo5XVkXUGhhLeQhC4GphMaMbKESK58w5j2ADrA2wBRBaAmjx2CaHwJQilf6IOS7LCkVRkiOaa1kgMGg7RyYIUJIY2yMGOU0Mae1GEOmvnzH62lthrGkxvI4RSIJ+eFjjP/7wR8zmC/z85z/Hyek5vL/DbtehmpUobQHvHFx3ABBgi6ShaLsWRWFRsu3fsmAiSzfrL/8JvZV5H7wzgFTt7xj4GdkevXMjWq4J0mqtif3MQb/P6COTIkwYXifHcwAb+AmA9jGVqP6eE/40sXL5mDpyKL/G9ZFdo7FC7qH2R/qiswiN9DcdfabjuN0l8QPHwTj1hZ8yWAfDjTsYBYPBWI73aZpZOHqPGc7H1ML//+PQKj/6LBKy710n6i3HxAlIzAO1sd/vYz3fsizRNQf+nd7J2qQ2Te2C1eR9UJe2h7G81L+8+k9SyebMHpAqOmUbXxHr/li0bYvr6xt0bYO6rlBVZfRozryahbEIgTx9eZ029hDbKosSRZGyj8lgG5MKa0hMt2T3cl2H7XaH3WEP7wPquoYxlgtFJNsqqfFFW8ArrrdmBmsoAIEzu4lkK4xDURSx+InsZXIiJw96zyrNgBBrfFsGae+CYlBSAprCkKbBFlTD+9A2UY0th3eOAIz/gJTZTfoHsNc7xyLDBDif7MmHw4GzoeXvq6XsJP0BQs2SpJ3WpdYcpfWW1mR/vejfKU8/JVn58OEK//N//t/49tvvMJ/NsFou8Pr1a1xevEBhDQ6HA9pDQz4g6x3Kkrzfo5+EyWPZ6VRfzZzWsDCkA7rd2zvHDtqPYwxMAmIZ1zGMEFqdQr3ytuRdRsMts1aQmM/Qpw3TxycP2vqY3KS939OJ6d/yiUFcCEQCGfDVOBqAiWACK682h9WL6a8AHcMzOAqW3I/YB/t0+1MLeDBE2cZI1yQbVv+6sXtHzof8+1CdPs6kDM/1GLERlfFzj/7GmmIwjCGVb+fJPivpK6VSkzFEjMTLVfo5/T4pLAsAJFNWOijBhRAC/XeMgUlqdACQqlxiumDGA3lWMz1uu/0ewXdYrVaYzWeR+Eu7feAmCVXA1KdwIC6aYZyaU1k/3gOOynh2zqFzHQLbbjtHmb3KsooAqx3k+uf6/R8ba4bhCIQi6WfheYYLYXAFLGNtJJ7GkHNaslGmsSiKIpYKDSGwvZqmTxLHOEdlIzvO8CXP1A5nKSwrB1zxRCetjOQ9Jybn4eEBj4+PKf5bMXCiHUkapAQYubZmHBi0eUe3LeMh70+Vy/J1Z4zF+/cf8MMPb7HbbrFaLnFxcY7lcoHVcoHZbIY3n32Gtmlxc3ONl69e4M2bN5xbvSRNVY9exH7JvMp6OkLv8/WRnEyPScLD9TNOf8ZGLW8TEHrWf97gndQzNE1gYGHt2HGa9kmDdn8Qp8CacoSna0IIEeRCdj3bFoHseg3WclN8QtSfAryzASPWidTPOLFPAHYCC1GSxl/G300e+3xsigvnOcCty2Hqc7mKyQzu09zv8H6pDiRHGAyLLPT+0WcSppmM/vdxwBw6meX/6jWVpJHc0YrOBZRViXo+A96+RdMc0HVt9E4PQSdH0KFsI30Rz3mvCSONkQD1GMiOEam8bSqlSX0pWQXsMyYgsMqcgKTDfu/x+LjGcrmEtQVms5QPXPoikjeMibZgeb7Yt0lqRNw7IYjEauAFDAsL75PNt6qozGkIKSGJJrQCdnFRjGjL+nMbQgIzAUqJnRbHOlkvw7UvJhPPbSVHLS0Vy/tHAAup6pmEwwmzASQHL2MtebFLjW0+X5Ql0HVUNMqY6AnfNGQ+uLu7ywA7rQfx70nlicckaDo/bmLpX9tfd1E74dmXgCc5hHSvhK9VZQnvHG5ubvDD2x0zQCX+7m8pjzwljXFxOiPDaw3tI5lmYNjX3tof7ls5nzMf+RhMCwm0dyfMTBOHBunELCTaq7VkY5reKfr8VJKVTxq0gemBjxMFUT0i2qTib4K16WaBnzQXMphJAZ1FIQV9r0kOQxIlaBWX9dx3iM+JYDiNyPF9e/059ryx5+YLRAPieN8zVWd8srAmRxiM0WcPf3uOhJzv2bQxx5/9HGZp2C8t9Qj4AmC7ZSLSZV1zLeMtHtePAAInJCH7ogaasSO9r1Zvj/fzORz7OEPS8+guC85WZilfsy1g2B3IGHKQA6vzu66DZ0/pvGZ1al8ycQkhr+uKba9FlAgRDJVR7Dryrmf1uJRvJJC3cC4ghGYghca+997RGhO9z/tzqRk3PWayhgVE67rOpFP9vHQe6rOP60GS7miva+ek6EkRARhAjJnXzxZbfnJEM7FGuwgGxOzQejocDthsNthutzSuvTmWsqnCXOj3GYL2mCo4Hfr6/r6U8dGCjzEpxE081wGgLC0cAsqyRlWT13xVVWidg99tMatnqDj2epSGGDPYxWbkfP+afp8FvKcPsZVPrSPFDJgRH6LePRq0+4fek5rhk3vHxvup4ycH2v3DGqPqwrKuSlSNYOUGt1H026YHJCmbDz/yTA3eAl4Cek/1/Wnuyg4mcJT7zTo+vG7Q54n21N1Huc+xfiqdwuQhC3gaYKeBOx+zNM5PjeExojN+fd/uLNcxwUWuulwsyEnq22//gh/fvUVVV5Spyk+9Y66l6F9DHhHpXbU6fAq08/Ecl+YFVKitEigKHr9Ug9oEcoqTfSF5rgUMhChLGI+oMiX8KwE2Sc6SHKUoCsznC3JA4rSn1lDo1ePjI7wPaLo92pZidHe7HQ7KxKABQtTKNIw9Agly+OpLvkkgpw866UkOxOl3YwycS97R9P4iqadKZHKfZP+SghEAKHtZ25IE7V203wcgJk2R9SAhYE7Zt0VsAF+/3+/J7t/LupavX9EUDPMY5NdrrY2+t69lyu8bBTCkvhCD67M5MAAVTBFGi+eybSnO3FgT87JTFAdLVcKIIKDQ2g/FzIwd/b4eo2UDYW/0nqFtegy0tSml/6w+syv9PEafpt5r6vjkQRuYBhE5TzboEfsFoKTvcagRrkmrZuR8JptyA0GkU+TejPLvGNhgqQZzAAAgAElEQVQ+9S5j0sHU9WbiRcYI/LEF8fH9lEV37Bp9fhxwpo5ppmIaoKfa72+Q/F2BxAz0NnJIIVLeU9aurutQ1RW22y0+fPiA7777FpvNhtXn+XOTrW+gWuAVk7Q6cd0ZcRQqKMGJsVQcQdrrrUT6FuK55EyXog+MSclDdBibMCNyvUi0naMiFNI3utdFcJF/27YlSRkGTVNiv9+jKChuuypLFGWJzXobibAxBsYH7Pd7bLc77HcH7JsG+8Me2/0Ou90ezjsm6CnJCqnWAe+YQQw0YiFI8knqp+8tA03etQQtzEdRWpB/oTD2Mm7JUY1AnBiGomCmxnUAQtTKCAgXRSKfQn9m9SytJ1Dce3Q+azo4a9k3wkVgF49x5xzarsN6s4ZBzsCkdZqAJa1bil6ZYqYTLZhWkafr8vPaDFIUHqQYGMtn32egEmPUdVS9LZkNAkoe22x7Gx7H/nv4MBk1MwXKiakdp2U09T1m0AzpxVMCSrpm+rpjtHZM6v6Jg/a0inAMzDQnTrKMvlYRQJms+BRkHJ1Vm6IP3un2IVA/BZwaTKb6P/WOU0viqfE5xtlN3Tt1HOtfPBfnbAicOXEYShBj3wUYn6NOP/ZOejPrfiWgTs/vuhaPm10sNditHdbrNT58+IDHx8cUn418LkcBG8IYqmpiAUD0kCWwNmpNZsUlAjMY0vuIzNPEVgALbJ8fjAmDouF7m0MD7wLqqor1qQX4M6kUtIt8CLHusS52YdnrWZ7nncf68RH73Q5d6+A8ZajbHw5o2gYhhEHMt9i7rS3pvY0F4JhJhvIlMbzWQnQVIsEsrSvnHGXdKgocmj12uy2K4oQyDsT+mvgeMXEMMw+kXSggRVUk37qo+AW0RcVdsgf94XBA2zU4HPZwvstSufpA5UBFiyAahRCAzjsUZYFKqfHF1k/vpFdUziwmTUOPyVO0aoyRTmsjZwaG+1B8HUKcCf3MEAIoPT8zWWrvitZGUuSK9qPgKmXGIFv/+tBVkU3qYH7NKMhO04sogA3uHfs+2kKONwbZ2B177lO/Twlb+vjEQfs5RDg/J1w4+F+lJAJMzsXFNtT8ShB/jwHMnyOSkrXZEnnOgMvRJ/b98/12YmlAxXQM3qPX/tRvT907zaE+A/QNawt8umZKGj3GqKTfjjtgaWljrK9j45xALqg/Iqzk/MNSoHMoigK3d7e4vr7GdrvN1J2Oiz/ov7yPYkowDJIUxpP6lYdz9e+fXPsYaoFkrNIVxChQPCnJp8KgUC6R5GXcsYMQWLrzao40sEmqU525Szzoy5LKfFZVHW3cu90Ot7e32Kw3sKbAbD4HLCVhiYyPGXvPpB6PznDGcNGKvtnBsB9qQBeG1daMMXC+w3r9iM2GHO5eXFzg8uIylvrUQC+fBcTruoyqfzE7CKMhTn/UC4ogERNL06Togsxngu334rgXnbuMxWKxQNu22TrrVHpUamZcEND2dmsLEKgmf4v0njn5SAx2YrT7YxJNFdB7yKi/ICpIZpwKpBDHnLkUBz2hofJIg+E6SL3qC2A0mFMgmDMqU3Q5Z1LGxvQ5AKzvHWPax2j71DFFE/vHJw/a/WNsQIugckUbKNCVcC7Fo/cHhIldxsQCnLQgAWXgaxNI84Nk8kPWypEFlUuY/cWSOM70pNSVoeT/XMD+WPX0c5mP4cPlfyY6OYXYaxOlOwFN2WAJRGV+9Xdta1JsmAKqyKerblNhMjOucovtkmNW5wN2hz12+x2arolOQjc3N7i5u6bCB8rrV6S6uEbCiO0xAMYQGAakKkX5+3FvFNeeVm8SMwItMEQJO6j4hR5R1v0Rb8yMUTG5xgMGOLR7NM0BVVWwVztiwgshkNpzXCTRw+EAFzx818IUFkXwlIecY7IdPEzBBUXqgsJcCktpKwMDXewzvaAPeTiMMTYWoQxG8jcbBEhVNNrfVUHJW0wIMEESdhBzFYLl2PRr3N3e4uc/7/DixQvU7EhXVTVYd44QqAq68x5tS/OnGQgZazk8pSQjUHIObXNA07bwyhseNpUgFQ/qqBlg6XRezRA6nwSPgJh1TVi1FLOeZ+yTIxbXgIl0T1Ldyl7ra7qMGn8NeEO1vIX3HSS8jGeEeVIaa5G8s71pJM6/Rdsc4F0HmBoBPqbMzTO48fONgdfgqtesOvQwjFGtPs1N24rXdtQOCHJoejN+DOn7EPRj/3r0WBi72BmeWxP35fFn/6RAu79hogQgEy5FGhTtDtAp/MZzZkse3wwXrJ4Gmy3soC4a01j1ObBj7zL1PfWHiS4SB/kUnD4lIX/svR91bQRhE5kNY5hAEZXiDeQGbeTtaUerY2M13LHybIPIk6X7PEm4PviYhcp1Drv9HhvOzBWAKCXe3t5gu9tEySjXGuR9S+pJeijF7idmMo8wGlsfanMbGbtk49VSSaRUci36WghaKaLClDmg+3IpqG1bPK4fcXd/B2OAWV2jtEV8mAGl9xQb8Xw+x3w+J1tx1yKwxsGqeGcqU9nQPHLmq6Iq4duOO0cgIKs5QCQ6dgLzTs0ne/hzYRVN9DRBjLnP02ZV6y1JjLd391gsVoAH5vMZ5vM5lsuAKngUVUXe4KCY9C4Q6BVFchTMc3QnT/FUQS3VJad+GcBLfnO9TuIXFJYjUQJVBtPx2DQmGrACnDvmsxISM6CY4HR9vvYErPU7aRorTGpqB5F5CHHNWmRZIf8/6t7k164kvRP7fRFnuOObySQzycxUlUpSqwwJKrkFQ94Y3V5IC8FaeIIBwzDa6KUB/wXthTcGDPTGgIEGemF704AbBmzAGy1swAu5qlRSVUnVrcqsnIpK5kAyyTfc8QwRXnzxxXDOufddMrMBVhCP994zxBzfPOzol4VkJjOwPp+BHAxK+hFz1UkZGjfS8SVnyb9GgcN3c2MhRJ+cu5igHWzK9/FQ7nyXC1fYuymivg0Ev/ZIexdySzhS/4hQ7V1uLCC8oTrlmlByAu1t+kAAAjv6OURhHSLu2HufDqP6hqm5w8rLEBeH18fORcYhDkUKFMVcHNT9Dra1f/3jxxKkNVgf+bzR5PZGXddYLBZYrlaoXeCPxXKFm8trXC8WLqQmA+M8K8IeQdgScbIAvu4kP4IkCd64DNF+HRqLIJ/uJkvGQhRJNKLd3qmH3b1cYBcPxwicHxyRqLvB9dU1no6eIc9dooacLb9dWGjfTpbn7LqT52jaFnlRRGFERe/KPWraBo2kyMyLCAE4q3yISR33MfaprrbbEGp0R4ldw5ggC4ZsIbMYj1l806Wf1bbCZrP18zAajbhOgONhK2JRvuN2DVkoSc5C7JlCxNyz+F53fduJnP86LLRNk6ekCBIAWVgY1E2FuqphTOtc3OCM/SQ4DBOdziMxKXHdgbtkEfkuxLFrDw5d6yL1IPbmNY+JIwI4I1v0XDdgkEeig4ixC+d39yfFASms79YVSOoUXkp8eTiiKKivDoPd3TZ3PRfWnjn72J5Gyq82p90Bbv5yBxEaG7Eh1olqPFVF0a1UHNltqitGSSaSL8RbAfEiHYqEhqjZoefdsvZE4UPtdAHBrrZ3lV3PDtXX1Snvfo8Ri8S9UcJyu8IGLbvn7BCiozsfg/MthJoTRVqw37J1om5v0dq2qDdbXN9w4or1aoOmqrBZLVE3NUaTCUblGOv1Bpv1xjNJCfDoUfpOZNPpixAP8k7c7SCdENWCdWL+ULNw4ja6Fs9H4FBc/TboJP1sWUKQIClsNitcXV3h+PgYZVk6vSi7VrXGcm4KC7StcYZkHB2uLEbIs8JHi5N5sbBoGk4gopV2KUwDkPLdcHu3rit2nXLGY3XdeB1x/zymYlepJ55164huMZCS75w6lPy6x8ZRjFDAovWYoDAGFhwkRmvtcno7IyqHdLtIUdZBKcVW7k2DodzXcSFHBWql0DaNQ2iq078g0iZKz0sidfBzs5/o34e00+fS9Yqf657BXWfXWsvhXONYBjTch6E+Skd6xCkC4t4lh0y49nAI+I+YsBF6U+ZV6t5VX//s74e5/XnhMxh2bUwA7C6vNdLuUlfAAJAMcmP/FlscppCQ53QYiXavHsYZB7HK4Vzj7vtDXCEQ9lh3Yw8d+Ns2/8uUl0Hk/WcA3/9wwRc2cIqtYXe0Y23v0AzNW5dzkesECnpZsNuIcQdbqRykmNMmIqzXa6xWKywXC44vvt5gW3H6wLIscXp8guOTU3z++Re4urryXDSpkGpx33z15kpk1unTaYjaACkH4cGu+beOq3NigWSekvZdmwBQliNonaOuWzSNQWssmPtrfTtiTR4jEEFWsauisRZVXbN+GRJRjXyAkXh8EhZVQnaKtXTm2mKjtoCY99mCWGuBqG9x+FOHHRgJgn3TxSiqaST7VgsBosw5i9i7SQA5EUcBCxbziKzK03NorYWtyKes5MhkQaQe93G9XqNyVvmcPzvnsKig3vjldx9pC0IPYnKWlUSMzU5UFOaz+5u5e6cvHySWPWfk9p6FSAe6fR4KS3sQzNoFb/xfl2juw0U2NA7MXGxPEdY3NhIdanMIBt7e/90ETVzf7QzLa42047JzUSOOwz/nkEYf6e+23vPI2wZuJ7yVLgl17vv3aZhL3zeGXdekL74PO4DvN4moX7aePkr1tfi6dgHZ7sYUTqlbjzNvSXDcPkIuviYaU8ZffGCNVt7KeblaYfWEw0QuHLLebrfYbrdYr1bYbLeYzqZ48803cXFxgW3Nvsw+E5PWIL0rPjiByPg13C9BCO/HnKNYVvc5m85+7BAufj5crOl9QEDuCeEh4ulgcc7zLoA2RtZD8y7cFCO9KE42yPs7+/cigK6IYByXbdqgMw4AXgx1JGZ3ZwYHzkH/nCgvLjcGLs1lEMmLHzrDFIPWio9143Jak0/YIXHIy7IEmeDPLn0GXIAa0yZrExKhhFS3ck/iAsj7dc3SgHiePCEwyChI8BiCZCCL7nbmIpJQkKyzir7DIy6tFawVX3VC0xDCviKHaEIs9V1wNt6nu+BWoFO7KoT97lCplCGMd7AfoCSxU7+fqWHz8DNp5D6p+bYytH4pl97FNv3yK4O0uyWeqBQhpFyPRbCO7IfmFAQccYXucygYZcyVE4hFcHs24aHc9m6gPyBIiMbxTSHqoT7sO3RRDw+qr8t5cFGQWHayBkndFrCSfxyUEggD+zpGKH5NwFSzcuumtYbK2IL5iy+/wKeffopnz55jvV6jbVssl0vc3NxgtVpBgXD/3j28+dabODs/R5ZlWG22LkGGYY5YBc6rD1QskHg19OfO+nHExlXOUlmnltrxPmOOcphTifsDl1a12zcWY4f32UWPXbTKsvShNgPVGN5rW/aZNkP6yQggmTYYL0GRFzNzcb7x1qXrdBz2ZrNFU9UJRub+OZG7DXr47lnuJuHoFrlExLG9W8upO5u6QZtnPoVnEj1NhXMtMcvX6zW01j5tqLUWZEI2sdgdjojQ2JCtLMQcFyvrIQ7UeCTNCTqGk6XIXMdifd/v6D4j4H1ujzIv4XssPZFns0yjbUMMe2M4PaXvs38ZDngOMy9tGyLUdVUKMTFxGzzdTbiH63H/02fdnHfqC/0JKoVBVoLwSgi729+hcQwK4DrlayFtIvpvAPxX4Jn+GwD/JYD7AP4FgHMAfwngP7fWVkRUAvhfAPw+gK8A/CfW2k8OaGPwe/p7Bxfnb4fNMPQ++T/y7yjA+bNG9ykYMgCEdqBPh/f5sBIQd1rnN4mw+23uoVIPaJek0wN1eR0zAeioFwgxGeAQmNyJ1jVx8RjoTzhQ7hkH9fOiQGVaPHr0CO+//z6ur6+dyJf9jS8vL7FcLjGZTPDgzbdw//59jMYjZDnH2J5lHH9cKT14slJuOkaMw894blO0p1YicWlW6ajOs9HU7D70NvpMEb4/FwkSMIAxrGtsGmy3GwhH1aWOYl4AYugV70utXN5r69yarDPmCiLRWIwb/7aWrbVjYy3pY5foGCICh85EjNgAwCXjhrXM8W7rGlVdI29yn3tbUoTKaJVSKFzceWst1mtOhCGEhjEGyiIidAJxw+JX7pdYYDMXnK5bV1Tu46xHXLpWwVOFEQxLC2Lx/5D0Qbjh/h4hvz/kff+U23syp0opwHJu7IrqZP/164UDWhYSCyBdt3RtQyx3uZ8SuvHnru/9te/r8QMhSw6AUJCYDsJTR7gMJFSS18L/gjdeHib3CYr9krHQs1coRPQWgP8awL9trf23wIqT/xTAfw/gn1prfx3ACwD/yL3yjwC8cNf/qXvutlZSziG0PdAfWZjOIlIwJtgnVk5MzIhFqfIX90HBm7cl1+MNPtTnbpvdZ/p1yfP9ZwZnaqCtr/t3W127SnQken0jCvflunLzqpN5V5E+Oh07RfXunWuhiIlQjkcgRXj06BE++eQTbDYbHwHLW5Avl5hOp3j33Xfx9ttvYzabASAfU5qIMJlMUI44VGUczSttO/5lOFzlIPdnOblElFgj5cYH9rq1vb3n6/LED5KkFd0/kGWVATkMZg20AqxpkWca0+kEWdbRz8JCwa1TxHnLXFuCR86NYbGwAaCzkGc7RtzdfaG1xnw+x3w+d4Zw/QxJ8bvd70Nz25tPh0zEg8BaKwILl/CEDeAADpxSZBlGRYn5dIY75xc4PT7BdDxBmefItfNnt4hyH3C7PuEKumuTImopSUIOS9F8tWACKrZi7nLIcRuC0CMJCCuG/PuxxKYHs0DOa5bHpUkhUxpFlqPIc2Q6Q6b3nEuPGFMWKSa40qQr6Os50N/b3Xa6z/avDdcXLgR8Ad+W6OtVOi9DiJiPEFziW3jP+JeCr/2+yffbkPbXFY9nAMZEVAOYAPgcwD8A8J+5+/8zgP8WwP8E4D9w3wHgXwL4H4mI7C09vA1J8WeHI4jeseJ3B+vj3PY2BELEMVihQfmOIBn3C9Jc3OnbJrq7+Q4rh1NtXQLk5dviMsTN7G934BrgVAcpYo7vyzcL692KQK59d0ysrCmFY+M3ddR2PPcpwGJgl7nIVuv1Gp999hn+9d/+rY90JhHQlssFVqsVLi4u8NZbb+Hs7AyT6RTWGORaYgBwg3Goy6F54v64e4pnQ1yXushK+m4tAGOdS1KUytGZjfuDLvt3nz7OCjHQt9LmNm20v6XPCqZtoYkwm81QFgUACacKHg+p6BqBLOvcw54JSIF9qslbZhNRktM6/HEfObhJDiLObqWU8pzskAh8CFnHyCie450I3fWhbmpvRc465NCno/mRS1lKqMQosShgTOb3gVKc2Urr0Fae5zwHitj6vm2xWq36Eg/fIcAagpOMdyQiQU0hIm1BOAQOMBOPS94P80Se0AOle4/i334vdLN6SXrODKMRG+1VVYOmbUDOGVAitSXjEnDaIdK8FMLdEy8F/9oBIGsfAg97cVg8z10j3xCl0J05awpzOggHKb0uMOn2ksYYcDQk0IGT/8ZSc1prHxPR/wDgEYA1gD8Di8MvLVstAMCnAN5y398C8Hfu3YaIrsAi9Gc7G+lMzj5RGF9ni0XAHYwI4Xb67uvhOQvJB8ghG7f7Y+wAC6eucZfELQSw3rDBWNPr2yC1lvR7+L4dmINDEfEuBD4kbZDr+6nZGHjsb1t7ga8jlhyxY2VQBBZRSehDIYRIUDVFcxz6Bwo+oGFK+4BagBFb4Ga4vrnBB7/4BR793d95AC25iiU29dtvP8D9+/cxnUyR5xm0BuCMszjcMiEvCmS5BmzLa08IO8CGyFUSCpeJOwWfUSwiZMIeFKIgBbb8x3UxIUmd/exIG3/o4TmzQCxxtiljDSTwkJcPOwJJKw1kHPc6KwsU5Yj3eRRAhJTi/U1B3KuJw50aa0AK0FBOZGthSHlrahEh+3zbfvw8sTpCGkSEyWiEMs9Rbbc+UMkgx0UESOpMRT5AEihIGWAt758usrRwomc2MtvUW+hcIzMZmqaCMWPkeY7pfAoicjYPDVSWYT4qEfJYOyRkGk8FyfWmafzZraqKw8ka1n8rSKwAtymUrL9DcgpobIvGJRUxnKkbopuOJOK+XQOXdAQGGhLTW+BgG2HDPscv3DHDMfA5I5ZCcDIXIMuYEMnyCnlZwGy7Epywz8UAkzwJz9nIFGlnkMjGcpwIRvalQvApH1jvqBBRsPqWOXfgREHmVRgIeSaSSsU40cNX8ZePEDb2GZlS99KtxZ91C09sEfWJ+dvKKyNtIjoFc8+/BuASwP8G4I9etb6o3n8M4B8DwOnpaffe4Gf3fleE5O72JjbheOLn5J4gml3cZxd70UCfXCW3ccEvyxXvejfmQvbVOQQID908/vbOxyzICrcd0T3RO93oSaz/CodE+qKi3zayxo5649+JDZEKFwDkiy++wIcffojHjx8DYE65aRosl0tsNhtMp1PcvXsXd+/exXQ69QDeiyitBQzQWuO4rTWs5TzBbdtyCM9Y3IeYeobDkUxAauXyWxN5kadxv104LBDIcyJKZV7kuRt4wI894cbJ+aQjpujjulhPqpRCoQrMj45QFAWKIsTj5k8G2t3EIG3bggwjCOb6JPWn8ZbWYrQk45H6mMNiJJ87blzm9OjoCDc3N3j61VduDobT1hohl4TYsSFwSrx/ogXpFQksYwyrP+qmxnq9wmQyRtM2ePbVs8Sdj4i8mkT+2GWsdghXjO/EOpy/13Xj03wSkddZe0LVSVnEqIuzf1kHf9w5UJJDW9ZQYBzBeumJ9XsNbi5izk72TEx8J/vKI0IbEc5C+DGyV44gy7Isdd9DkATExJHnfK0IDhxh62LcKw+nUm48lQhQVH9E5AnHTNFz0T4fKhZCYIv6h68SWSCyZdh95gKBGS4cDrt9PnsXeqrb19tE48DXE4//+wA+ttY+dQ3/7wD+XQAnRJQ5bvsBgMfu+ccAHgL4lIgyAMdgg7SkWGv/GYB/BgDvvP3Qj2DnBB6ImHZd7xEANuYp++/E9CofjOh3t02bLvAgxXgLcr2t/0P3dnHT8bVX5d67OtcdD/qPeF6SdxX1JlkOkecF2IQ8HEpQYvjkjy6xO1Fdb9G2BuMxR7f65JNP8MEHH+DZs2ce+FcVA+bNZoPT0zPcv38f5+fnKIoCAIvrSPoHAMb5lNc1NtstsizDbDbD4mYJH3ijI/7z3x3HF/R38MiMAT7QTQeoiLNjGQs02EJnrEvcCYSkPQDBQi9mxULdsfjUOvXBeDxmYkUxMOsGG1HacdZOhC0ctCQa8QkxBKgrBbKpH3csEpX+aKWhlcaoLCF6YOFKL6+vsd1ue4D7NoCm0NHzR/Mz9C6rRzhlZ1mynULTtqiqGnVVc2AgE0VBGwigEtdrBuwIRC0QI3q/JnIErEhM4KUcQf3CWc66Z5oJXKdicBJB5QftRO0R8xKL5l8GlspeaJ37nnLhXKU/sV1H7PY2VJ/ENPBz4SUOKdIahFmd+kSlJsi7yxzFeyBZNxXslEI/5XmG/CH3vN0N5DzCR0qc3FqEqkAy7njs/yZ12o8A/DtENAGLx/8hgB8B+H8A/IdgC/L/AsD/4Z7/P93v/8/d/79v02cDwwj2ZUuXe+te71Kb8lRXrLKrboOU2PJUYCSKGqpnFxLf9cxtfdk7rh317bsP7J4z92tHB4Cg1975SEevGij7sP8ZWPJzLmNR9DzHpGbAuFjcYLvdYjwew1qLTz/9FJ988glubhbI88K5FG2wWCyhlMKdO2/gwYMHOD4+9vpUsdq2xoAUA10tHIFSKIsSR0dH0CpLkobE853oWd08xBbRDIwV8jyDBNkQVyCtlePKOAuWbjVGpNjR3FDQkdvUmCoWn4tWx/WgN++eGwMD4NFohHJUom4qKJX7ACqJOoIC4i6KInG7EgSz3VZsQKgU6iiTlSCfWLLAk2VRFAXKssRmu0XriJ/FiiOzidtUvOeSc9zZlyyJ6e+x7kykwJmlEVVVoaoqjMdjdgVrGzSmRWEzFmeL+51hjpNUauEu7cuYfX9s8N9mF7iUgOClC5y0RFuTebI2PSUy/th1znMG/pkwXhFPIwqQk8xPh5DYV4Q4JRUyncVzEALvtGHmbbpm7FVQe2IvTv16ax+sjI2i7/Aj9G8TYGOYiwgZUjzm/jzI/FH03JDrLyACg9AJJkDSOvvoTZiMqK8DRM5tc/F1dNo/IKJ/CeCvADQAfgzmkP8vAP+CiP47d+2fu1f+OYD/lYg+APAcbGl+cNnHaXzTnKr/jpTKj+aa20Z6gYihphfSUW9LHYS4b+vvLsR62zy8yv1wrY8AdlZHLupQF4jGlH4vuYB1tk7dSruzHveJ0DQhleHR0RHKssTnn3+Ojz76CJvNBsa5H61WHPEsyzI8fPgQb775JmazmRfhep9O4yCC088Za1kM7DjMcTHywTiyLEsAhHDVsleU0oCVSF8Go9EI0+kIwlEKIpS0luPxCONR6Q2Zrq6vsdlsXL0p4SlAUHkxZr/ITuwhF4e4hRMVLlfyRRMRJ7zqcI1wRIzOQh5pQVJFUeLs9AybzQaff/kF6rpGVVXI8zzithu/dkop5EUOnedoVivUDZvByHhZEpHqs5O+JGLeWGwcTUYKRQcRlIxfYszneY7WcErMNnZBc2oMdr2PwsJGxFhXouDn23Gq8TutNT5CnJwHJoB433HazxCcJkYC3e8xahd6hk0QVASH4J/v7ZMODPV7Ixq/IGOllFcNeSv5qC9KEXgK+uff2EDIbTYbjEcjECnvjXBbEe7af0cf7rEENCXSCAHJ7iNSUoRuk+2TPjg0j8PwDugiZn7Wht6+dPla1uPW2n8C4J90Ln8E4A8Gnt0A+I++Rlt7ucSX4UB3XYspHTkYMafhUQVDO298lhoJpUIPTx0eUA7hvIE+kj6UCHmVtqIndiPpbv+QInQSbjleQ9UVDjnQ46hPATaxgZfUJX1tW+MRzvn5OebzOT744AP8/Oc/97mM67r1BmdnZ2d48OAB7t27h9Fo1OM0PHcJTrHonTyNfKQAACAASURBVHYsI3PJDKYjTiueM291K2oRANuqQtu0ePDwbXzve9/jIC0um5gYypVl6UTPCpmCD/Lx7Nkz3CwWWG82nlCQqG2mNQ7h50xcmNiwhY3SjAnSoriv7APMzzemRWZaFEXeAWipFbGI1pu6BSw89yk63/nsCGdnZ/jss89gTBAVC1fG4yWfnaooCsxmMzRN6/sn8cBDAI/UMjrZLRRwsvRbkQKRhlKAT+juxpuebdlv/D9LCrZsPOa48Lqu0WQamRufl5IYgkHqk+250AEgDQTipm44gUpjU9UCj92gqZuoH4IEQyAl2xmHtC2wiQBB09F+jsjezn4fkmD48wVGso1pgQbIMhHJp26tQwibg/Wk0QCF8GlbE+Wkl7ZdzyMuN+6XGw1sLFSgIBIXRqkXklQFk7Sux0UX7ku73fkxe+BnCoc78z7Ulo3vW4/8DxA4J+W1j4g2NKghaqmLZHfVddv17sEboswtwMEH+IGYB8SQOGtfv/eVQzjoXYt+CMf+MmXo1cH6HEXbNQhhardHiiY/Y2kGBuYqRSIEa5vIv3eGjz/+CD/72c9wc3ODoiiw2WxYP1nXuHfvHh48eICzszOMRiMXDzv1BZbDZC278LQtIyjtgrNkxJzobDr1HKmKRL7iX26V9Qi2rmv8wR/8Af7hv/cPcHp+hheXLzzAEo7aGANFhO1mg+127QC6xfn5GaazGbZV5YG5xEjfbrdRuMvaBcAIhkhsV0NwHkwJQFJKwepwToTbH+K4BCmI6LehxhFKvEZKc/CRuq7x+PFjvHjxwodBjXWf3XNVliVIKazXCy8KFy4sDjKinP48XSNG2NKv0N+A6ESuKecVUT9iX1x5RkKIFs7drWkabLYVAEKe535PehdSKwaFYR/FdQriDXOoOPZ9BB/kHnP6DeqqQVVVCfIUoqhv9BX3QVILM/whRHDBieB3MTm7YSLXaIxBSwRqjYtMF4ixZD/FBAS5nOhmWCwfdPappfgu5iYQ8eljIu7mdYmYg95g0jH7OikmTHfo0gfnZ5ioGGIspC3/WqeDL4uwgV8BpA0MI9VuSahE20ecuxZkX909hM0Xw6Ho3BRA1q/j5RDoUP/l+5AocB+hcSii3kXshL7s3thp8SckHTUR+/bu6VfIaxtZlGpGRgqxAZfxSPfk5ASj0RgfffQLfP/738disUBRFKiqikVw4zEePODoZvP5HEUxSsXAEeAX6934QLN/v/RHYTad4uLiAuNHj3xIS60Cx+mRdVXh7t27+N73voc//MM/RFkUuFncBMM14ljTPqUjgLquIiDI3K9SGkVZYj6fexEuEfsNr9ZrbDdbrFYrrNdrGJdswzoxdlVXifV2vF/YOcyJqbNcFjusuVcTwHMzbdsGdypnyKa0QtO0WK9YAsBclFi/6wHgaJBlJYqiwHq9xs3NjR9X0zTcXNtypq1I1dAFuPHmCsS68+WWEKqWA+t0w9sq248qJaJepbTz125hXGzyCRF0locMXypYwLMdRMhP7mFQUURhS5mLrrIMyiUE6cOl0L/YZ12Qf3q+wlmU45mqDfyRg3cnuKUk8+s+E44aNllLCeUaYE7gkiXeQHeMgqyFUGnaJtGNB1iZEjZy3QK9NPKCtLttefhoOTudH53qw3whUJL34ODRTqKmGxo4vT8kHenhbmujFw9nqF5zpD3MmcYLE1MzuzjZ2zjcXchv17NSk3dHGqhr1xh29W9okYfeOWQc+9qRciiFF96xiJPVw1lZDr8EiBV+TBzbDiLfPZawyb3Oz4XIlBSbACORFy9e4LPP/hbvv/9zXF3dYDTitJJFoTCdTnF+fo47d+5gPB77RCGJDjtCDiyStX6NtdawiA2ICMfHxyyKn8080pZxVNstlsslsizDH/z9v4/f+73fw4MHD6C1xuXlZYhJrTl+Oc8BkGly4m6FtrUekBERVKaQGW5bAnoQAcaOMdmOmfterXH1gkOwbrch6YQ3rLO2w5G6urVDOiCQM44bRdHIrLHCvsIahbZpYchEdRhoo2AblkjEuceT4B5gzlqkA2IfsN2sfdx3ay1alyI1NkIzxgyer2G1UbTXBIl1gWk8B1YobUDE88vlEsLhmraFyjRGAHI3V7G0R75rUkl7BOfe57wAhEjoMQE2VrEEDnZ2NIfWGtfX17i5uemci/iMayjF70rV/Ml+0LELpcDAg2FE9HyMNIUviblsiaceX4/hWephEdQFXfVSWFcCUSo1De6jKXFhw4t+LeNxqs5v/3ayj4bmxqloDoS3Q6UnIe59PzQoS1pec6SdHtKhDdfdJHKt+3tXvb3FkvfDg8lkW7c5JAlFrDOUCrwY2KKj4Y47kN57Ga45HduOyjvv9J44YDOmm667sVMA0qmAPxIROYFgD96kXqfpxLxBX8yHeb1e4/Hjz/D06VN8+eVTaE24c+eOT+04n09x586dKD+0BPwICNsDI+uMzoyF0gQ4IAxrYd1ax6JXjk8dUj8SmGu+urrCG3fv4o/+6I/wu7/7uwCAxWLho2FJSNUg1gu+1daE+lk8r6HzjLlOZzXug9E4E7PxeAwiwqQcIXci7sVi4VUCtua5Et90IYBiji7LMmSZRqYz5EWOsig7AYJi3WknVjxxoAxQiHQVu/3wRzAok7GNxyNMp1NcX914sbucJ285HwVm8T2hIBlRCD7T0Rb1BJe0lxCWxHspiekepVZlbr9GluVomoa9BGwYR8wYEeARFWzq1gUg0VnHHHfMVcoej7lXpZnYnE6naJoG19fXHrHsSmc7hJBTRL4fuaTcJXnCMn5X+sjibA1j0n3FboCBgeoaohoTwvnGNgC7mIcIB8cd3S2pu2WMfmwxzOq8E3PYQeo3gDuAgb7f3j6AHhH5KuW1R9r7OGggTOpwxhj3nS/sfLf7PdEe8ctw+AJi+9DC+tSP3fdVROATpYiKAyGQ/+5q9/926bHTvgL91U8P7I4h++thvx222awgm+TajvqtC1LgkCKi/jKhY0Oks6hP/BmIASJCoRgZiW4zL3JcXy/w5MlTvPfee9hsNphMJhiNWBeZZQqTyQSnp6c4OjryCT6IFLRW0CJWpLR9WMs+0oyzoZyvq3LiebLk3csypTEZjzEZlQA06qrCarnE2w8f4k/+5E/w27/92z6WuWkdEFCtH7ExFlpUBQ4hxHrJpmWRqCKFTNlg0S4zQwqtjYDsqMSxPkFWFBiNJ1gsl1gul6gXDcgF9ZBgGII0tNZsBa4VlON8y6J0ka/aBMAKN+6RsRuJESxGrI+2zgOAyEKT5ShdBrAtwTqiK89z3Lv/Jo6Pj/Hpp4/RtLW3VG9ti9a20IUGWQVLhNZaINIPy5itQ9zWwofCVcSRDVkqTjBkOCCP52gsFFm0yumIrQaMQ5iZhiKNTOdOFAw0rViVN4l+Vjvk4WPmZxmsbdBai0xz3nCRCDVNw5bi0XkNhnlu7gGAWmhjkGkNTayyYDVO5gKzWBgjonLhRAOnKOqK5BxSfD++PmxF7Yl1CEHjDM/cONlmQ4OURgPJdd5AeZGzgg+a5Aw6AQcnFLlzmKExgdBjL402gUei6hBCORzRFBf0w30q71otxPAw0k2RfyDwUuKFQ9T2S4BkMUwOfQ7r0mmfp6iD7G13ddBdr2557ZH2Lk4z/n0INzmEuLvUknDO3TmT4JoBgfPqDHHKUhLR+UB9Q5w17VAHpG30SbX97xxy/QBunOi2vZS+6zaf9DnU5fpv4wMC/4y1wedTEUHrcKjKokCWZfj4k0f4+c9/jqurK0ynU2d9zaLj6XSK2WyG6XTqfYpZhK184A+P/sgBemNgKJLYyNoSomuK3aWNwWQywcnJMZ4+/RKr1RaLxQLvvvsO/vRP/xTf/va3cX19HYlZ2QIe8Tr7euGBVwAY1huzKWNASrsQlUEcywg1NQQSBFCOxphMp1gsFhiNSyyXC6zXa29lDwTDM3E1y7IMmc5gLEcGU4pgmz7QsY7QkDnxZ8d9sqhUUksa+NSNaDjEpFKYzWY4PzvDer1GVW2RZeLfy5xYXuTI85wlD85nfRdyEa5a+hadYL9XLQzg0/WKmsC5aVkmnggh2MtkOkXTNk7HbVDXFeq69q5rIlkgEEhxPnVWowBVtUGzZRWBsvAxx6u2wbZmo7bxeAyJeV/XtYs0hrBPXcfXa468V5YlVqu148plfNYjNNkzNqqHor28q+xiDqKjwfW5/aUd98kZ7uBc4xrHlQZ3sLAvNHsvRH2IJYSNpDWN4IKcjWQBd5QUfhJCwo8Aqvbih3gPdQgY/p08tqMPsUQpCpCzj5uO6rO2P8qUoRourz3SBvqTfzti65cuvdkTB/EPT+c4/JyIw8J70TsHtD9M60UdG3zm9nq71/c9s+sAx5ztvmIjQOHf3YPsI3DavesRYjhkQT8uh06RTvJgl2UJrTU++ugj/Kt/9TM8ffoEo9HYhdUklCUHPpnNZiiKwiMmQdiymCRiO0J6cCPXGnIZxoJYWEbDnOLxyRHG4xGapsFqtcTFxTn++I//GN/+9rdwdXWJ7XabWP3G+vNd68IcjYJx+b8tBbcneT+oCFLiTdZEdPZ5nqMsS0wmYyyXE9zcLHB5+QJ1VbGBWttCFwXyLEOeZSjLAlqCtbA+IgBfIljJf6xTj9p4PAywI7EngNYY5hKtZe6TCFpz8pYnT554q3eRAAgRQSThXZXLvrUN6xStWUw4WEcoMBEThYdFhzAn5viCQV3YpWLEJtbiG5eGs2nYFcu3ZyynqawqvHj+HFdXlzAA6rZGlmUYj8eAc0csigKzoyPkZYlyPELpCMmbxYJzt683npDQOoMi3mMW1hNU3VCwcNs3Vuoq3de17yvduUx+R4g/5URZWgXLc5q1GnWt0LayH/ls8X61iXTCGOvdAOu69UaY3b50+7jrt1c3QY7xEIMwAOfld3jR15e2t0e6y29EV1IxuRCrtxUSGNRD3vux9uuNtGkIUae6kvRe//qu4ffE7lEdUSr0Qa74tnY7QxhGbkEumxACe+s6gFg5FHEf0vdODcm870P1JBtxsA0vmAIoNV7xnKALcSpA3FqL7abCl19+ib/+65/h6ZMn0FqhKDJMJiPMZtMkraMYDInBE+Met6o+YhP1euS/R/RGvD/Icp8llONms4HWGr//+9/Db/zGd7BaLVFVW6d7DIZFQ/M+hMBB8M8LoIzf8QAUNlHhxAAM4OhaRZFjPCpR5pxekqzFdr3BoqoBY1FkOcq8wMjFaJc++zaVQts0TOhwPE/AuIAxA8W7aSkN0tYhbZdNq2l8NDVjDB49eoRnz56hriqAQqCZsiyRucAtwZo75XZ22baE+Y7PUcBqyR4zLfsRU0oM1U2Dsiwxm0/x9NkzLFcrzGcz5+9fB5e0pkHbtFgul/i7R49wefkcWVHAEjAajXBzc4O2Yu787OzcifA1tMrA/sgshtcutnzTcL2jUYaTszO8+/Y72Gw2+PLpE1xf30RjDZvTOkvPABXD/OxTKQ7BsB4CR4qwyVHS3oDTAjrTyJrMwRXugfM6jOAZE8tiMxLbPbSt2dvPob7G1wSe9cdzO2zbhxcOLbdJMg5jLNPwtcMQqV9ea6TNhAh1r+BltPmEkJlLAg90N0tCfbnaD0GC+34f3L+knd166ts2QReQDW2oXRv94H5GXeSIyLc8P/A7tM8r0+XetePmylEJ01o8ffoUi8UCX331FT59/Ckef/YZlGJAOxqNcHJygpOTE4zHYy8O90Y9HaQnoj4gmmlKSSrPwSGdV77G+tGmYX/aoihw584x/t7f+y0oxdmgiOA4vtjNiNMXDs1/aiEbc90EqNSXPF1jJHWIVEDmUClWromaQN5dLpdomgaj0ShRH2itvFGRcHeQsUA5/TWxxTX3wANipSKCQinUzs+8rtkg7uTkBG+99RYbD376KRY3KyYGtEbdsKW5EFtCOIjelw3FlCcqjMytAmA4AIhyvx1u8S5HxrYAgmtfkAKknJG8qJTCnbt3cHZ2iqvrazR1nbgGCtJu2xZNXWOz2aAoS1zcucPPZSHFqPJzo2EspwA1zjNA6hTbgu1263Xcb775Jn7rt34LLy5f4MXVpbcpYAO/eN/wp0g4nCLaMwjxmOPf3X3U/S3nhyLOnZyUyhgD7fynskyhjizquR0LFpUHiVVcZL9I2FuxR9G6v8dD/10PfGa1/li6RmNDDEoP5nXaib/Hf6oTlOWQssvILtmDPrlMEJwd2tJrjbTT0uVGDw+iIoH0GVcM6C+id3aJ0YfqPeT6voVL3+8bjCCxAHVXOrj4ZRDwMGW6j2fudeegItS6tBndAVGcNjB9R4D1qCzRtga//OUn+ODDD3F9fY2mZc6GrYoZEVxcXOD8/NwjIAEgw0aJjugQcSml9xPg5rgJY23Pn7dtW2w2Gzx8+AAnJye4c+cO7t69i8XiBiHsJEA+5uJuRN093KwnjThtEnfpCIi4eTMkhARzXGwDwADcCIDVCtpFWxMddpZluLq6QlGwGL0oCkwmE1TV1qsCxAJcDHZ8P42B9W5EvGe7iKCpOQBM7ZDaxcUFvvvd7+Ls7Awff/wxFCkUDrFVTQ0icjmrVW9+/L7QCjpzltY2iEQNnF89AVpniYSlNU1PLeE5PhGdO0KUVZKMQEcjTqCilYICMHLzJ3MiccqbLUfcG4/HyLSCyjSygqVCTdNgXJSOACpQFgWqusa6YlG4zH3btok6rm1aH0BHaw52s9lshvX6Mgn+XMFFhEsJzXht4u/xngKQELi8z4TolMxjBKUsWtN6okP2j7j5AQStGXkbwzYUceQzbiMQQE3j9hlJNLTQl9A3IUSk3+iNJcYLRCnM6cH6A2B1uqdvh43p2d7NNMX70F2JKnEpgG3XMK1fXnukHSYkTYK6C1cNLUqPwvQUZLhPROx6Y22UW7tPmXYPxKFt7+3PjufiEqQDcc8Pr2+XWPHQ8vL0prQj0y0JEOCBa9NY1C4AiCCW6XQKYww+eO8X+MmPf4LL6ysvIrfWYjQa4fT0DVxcXOD4+JiBpkNG3UM5RBgZ6nRu6FnIfCE9Vw7wlGWJ+/fv4803gel0jrZtnBVtKgrvAo8YKAx9704cEUEj5WKlXpEXxNwLg0uXZYsUWrKA5vdHoxHyPMdkMvFBUK6urlj1sN2ibRuPcBLCx7o0kjAOeLrcyKoLrFj0uV6vsdlsoLTGnTt38N3vfhfn5+d48uQJrq6uQFpB5RkIQKEUSkVeJC5AvhcMBiwlM+5aHJBDDMpIKWR55olzzs2sEv0uE5NssGdcG60xUDakEPWcdNNgPBqjzAsvHpcgNmVZ4uTkxNsb5JlCMSqROQRWFAXOjk9c3vYaq+0Wdd1gs2ajxa3z52dXN8XEFlk0dY1nT57iq4s7UFp7A8Ik0lgvMpqoAAgRbov2VZ+jHCrxHoslAeSJ3CDNIRJjRu1tN2KVToA1KZJq2xbIea2NaVFVW4+0syxW74SY6fxPsm4JoRiPpwv70t87GZUdyLw/R0NnM6onftIGC/K47u75tnKeuveIx7xH6g7gVwBpc+kiK9mMfUoyKZ5jiZF0fwEJ7KYFgPV3AxM9tPD7dBr7qL3e6A5AoLKxbuvXvve/iTJEke5+Nv3trZyVQl1VePHiBRaLG1zcufBW3y9evMBPf/rXeO+997FarThtJFisOxqN8MYbb+DuXX4+5qyGDt6u/kVa9Z0dF7EYWdtD3EWRoyhCukxrQ8arFHGLcQ457s6paoQad+oBzq8sHWIdciQwdEBKeTGiGC4BBGvTAEO979YC5CK7aTAikmhk19eoHEcsumDPZUdzaFxuaAs4vWUUx9yYILp2fslaaRwfn+CNu2+gyAs8evR3+Oqrr3BzwyFLs0yzbtyKGxDPoUTdinWfAHOQ2gW+YSt0jTwDeJaYqMhz5mibpuktrN8Hbt4VMQFgLcdgjxFhXVc+aYno2OtthW3FqULv3r2Lhw8fQpOCaVk3bq1BXhSAJm+EGMLCApPxGKPzMcqsxGKxxBdffI6PP/6YJTlEyDTH6lYELJcLfPnllyhHI7cuClojQdzJGvuczPBwq4/Q+ohpF1HfdX1K1DeWjf3Y9bGGtZF/uTeWM37cwabAEZVunwghIgaGYpkviMz3EQBEsqJjpi32ie8GkAnj7Y7VM2cy9h0wgygWix8GN18GLgsu24k/bmnyNUfa8eZLWCTECHtIsEzunnLyr5hqlxcsyPv1Wedq498/EJEecu9lOfB99b0M0hx6pvuu3eVs/YqF4DhCSwCCaAwIYq+qqvDsyVM8ffIEs/kcs9kcR0dH+Oyzz/AXf/EjfPDhh8h0hslk4sXR5+fnuHfvHs7OTjEej/xBj6NUee5gx9zHemyAu2htKsNRbj8JUA9Ic5hgBMKcdnXoMiMeSUtbFES1sit9enEhGpECYOYwlReDh7bhbMTIi8VBFsaCEYs1TszO7WVao3GEiFaauTzD+mXAJpxpzDUxUraDSJ1VHiGQS1mOcHJ0giIvcH15jcsXV1guV6iqGmU5RlEw2LGGU5EKwm9NyBwl88r1u0Qg7HgLrTL2qc7gk/YUReESRDBBE/ukx/OolIJ3+os4LmtZB//Vs68cYjIoR6WLEaAwGo9xcnqC+/fvoyxLPHv61Ovl26bBtqpRt7Xj8IFmW4VoeVqhaHNk5RinJ0e4fPEVWqfLZyt+jbapAWtg2obzv2uNqqpcuNBuKFO3BVXYhqLGkLkUr4nAiYeyS2weExtybZhLDMZl8bsA227AuyiSe1asx40nOOuGiUVxRfQEfYxELcMnjqOv/FoHtWGX0yaIv3R3fGGvimEdelxFitSd1KDnCx7PBRzBOawCfdVyG1x/zZE2F28q1AWGMH7ykxC7bsJ0jIRjzE6A17qSrx28SyihAHZN4O1c5uHv7buWUs5fr52h64OP2V030jpuJzICVOHgHsDNzQ2+/PIpFpeXODk5wbe/8+u4uLjA+x+8jx/+8Af44ssnmEynIKXYYrducH5+jocPH+Ls7Ax5nnk3L0HaQ33q982G/936xwZJ/j2lPAck0bjE/SsQBXHaPkYqfS473O8SlTFXI789cHWIRACHjiJTJbr6CEAbY4EGTiog8dK4LuGAulxazFW56iC+7CL6ttZ6xGOc+5YxNul3vE+VUhiPxyhLDhlb1zVubm5wc30NC1Zt5IWzVIdFW3Pa1Kqq0LQcs1zGBAQizxtHubmR9rMsg84zf9+aVKweR2fzANm5zEuedA90FWFbVXj+4gWM5ffKnO0kyBC0MzJr2xaXl5dQmqPItU0DyjK0VeVX2RgD5YKjsP+59f7Ysl+zLPOxu2N1hHGheeumQe10/mKIJkgvJiBlnRJ1gdsTHOOgi1Qci2LDmYjXMuTFDmsgIuwYQXK7xr8TkC/BmH52MiksQSGWUjhCSVKiaq286yH3VEE582GrQkAkcpxXl+EgsU5El6jsI+c4t3Y8NwFxBwKlXyhqmxw8SPw5dnxPr70sAybltUfa7KsrxgiOagZchC65CiF5+CU3AY1YMSJcdrxToLYQuCsgcOivUvYhyiHdSvedQ9v9JgkJkTSkJdpIlqUQBoErCfUNNeJ8Rm3susSI7enTL/DJJ5+grmu89dZb+Na3voWj42P87Xv/Gj/84Q/x7Nlz5FkOskBb1RiVJS7u38Mbb7yB+fyIw20632vpX3f+ulxaPKaILocn2xKmmQ27CBbaAkqcq3xdjLClCgNAux0VxyDvF7/rekAs+Q62hi4ylSAsovTgU/SuAHNC68NISonDRcqf6CSVBrJcAZWB0hpwlvFcLyWIRCyey1LxEXNASsTXbWM8dzcajVGWnEVttVphuVoCipAp7bOaiTFdbRhZN23VS0eZ+LeDQFrDuoQiSilvx6CyYGFvLNityipo5VKNQgedKACLFnD+2K1toMmCKAfBwNoGNzeXKEfMXeedpB9tVWO7XoNIodBMLBiHsMQP3RgNXYgVOdggC4BpDGDYfmC9qbCtG95/llGT1jnqpkLV1DBNi/VmA+MUADCtc1UM6x4ja8B5xlhiQz0jHK7sB3G9kjMSOFO5L5ywEGqyBrIOMdEn54/7YgBwBrCQjhVOchRJf8B7Di5CZNU0yNsGq/UGTWOQ6RyZVtG4jM+kqDMNawOMZolTrBMOBISx2hO94i3UhRFE4Bzebh7YVkLG2MledjDz07VY78dVdzOWfA7Vc1t57ZE24LV3EccdfURIeSd3KNeTZyNuFq+I8A68Fl9/mXe6916FMrt9XOgnAqJgNQxEhEyvrh11u8MgiGy5XOLTTz/FRx99hKIo8J3vfAe/9mu/hizL8KMf/Qg/+9nf4OrqEnle+NSEp6enuHv3DVxcnGE2m0auSWnShts2/ZCoirrfqMM1sjmXN+wC0AvZSqB0T3ba7xENkQQnjhzVo/ZVFiHroKPrjs12OCGlGrRNaqQUz5EATjbYg0PU8JV3bTBiaUBslU9EIeyoZCgrmTuTHNmA8lHhrJWgL3nSp6apUVVb1HXIdBZznTGhEa+PvJ9lGbI8Z8Aua+yAbj8qmAu/SWCIZ41L2MIW4mQtMs31VVWFuqowmU6QOa5TLMYl7/loNIKhkMBF1AIiWpb2xX2OiJBpjtN9dXPN3hBNCwWWBmaaJUeZM9LydYCSWAXa9mO/ew6bb3hO3JpU7yPP9QP9CDHK+6gnrlZpXnNPIJlYdx3aiO0tlFLQ1sV1N4b7JNblLqf4YsE6/O1mi8l4hLJkb4aiKL0bH79vvUW7IG1pk+faSSSclJCJmD7S7CFw1fkdIWyldicMic85YAMM9dfjc9Q9X9K1YQnqbTD79UfabnBGYJ5QiB4GRlzyXuS3+5lX5awPreeQ67ueOdTAYRA5xUB+B7K3YSKjF+HErL6i4b7vpJF4MzZNg6urK3z66adYLpd48OABHj58iAcPHjiDs5/i/fffQ11XADi5esjtOAAAIABJREFUBpHCnTt38PDhQxwdHWE6HXvuugvQd41p6H76bMxldPvuJiDS18lMxXPBEp/UYKc3P346KdLHhfvd/nEyC5Ug7LjtgISZmLAQSZSUBhYaEvfZAlBRv4wxLlBKIFYVOX9sk7aRiKQROGAiRi5ifMYIiV1/yrJE0zS4vLzCdsuGW3meQ+eZF6GOx2NUVeUSm1Q9EXY8l0L4FXmBPMu9HUOSsSye7716REboeZYBpkIrhKmxgAYypTEuRyhGznWQAtKSiGjr9Rqj0ciPS+aJiAPDxPMckAl/r7Zb1JstFssFWsPi4LauXTpSYhczZzAIY5EZg9ZYHw0QAJp1k4zdc4PGSR8jBCFGffG8AgHJ9fcrvJW8tdaJq3XSnryfiuFTl66mcUiMKf1AoEKM2EKSHRiD9WoFWODm6hp5rjGZTDCbzTCbzTCfzzGbT5wPu46kWUxkxFbugcFwhFvUX+lfV8IlSDve4/Hf7XrpoCojAgdfcq8Em5jhMrTXu2u1q7z2SFuEmtTTs3osLh98dS/iHp7EIdH1Lo7pEES7797X4bSHDuGh/dlXd0xzRze95Nh27voNthPxcQjDJ0++xMcff4T5fI7f/u3fwunpGYoixyeffIS//Msf48WLFzAm+KZOJhM8ePA2Hjx4gPmc0xPmeTisEuOZOv1IxhKJx+V6uoYSpKEfgAHxbHQRf6QBF8nM4fNtEZHioU3frjNSU+yOFBOYiV4topPYlzyMKySecJxpZ9Us2PKaDIA2WPHyM0qCg/n6RCwq0g2ZU60159+mMFfSz9VqheVyieVyBWuZGwYxIQLAx90Wl7O4DCEWEYMr0sjzAsfHx15XvtlsXPzyCqY1SRjPob0Q74ciz2GcW5fk/s7zHJPxGEVZJASLJ0yyzPsji+90VVWM3NgIYNCfWiylWxdFbVttoTVxzndrYdsW6/UKeZGjGJXOfpP7qo1lYztilz0AuHapOok4Br0kxQhcrxuzI0bi+Yznt3udkSnfl3F0M5fFayVIO5Ys8JppSAIQohQRwoYIaTCcCGe73QJW7EYMbm5ucH11jVFZQOc5Tk9PMBqXmEymKEclJpOJ9yiRccR6fhuJvf35cUdoCIlaINFvJ8akdncAKZkS4aip04ZI6vhh7pe1diDJUj/WwW3lVwBpR9wPAofHDPgwoh0q8a1dk9QH8EOZZHaXV+HYD+HUdl1/mfYOfTZRFQz06bD2LS4vL/Hhhx/g4uICv/M7v4OTkxM8fvwYP/3pT/Dzn/8cL15cYTJhrqVtW5yenjpO/G0fU5y5a+Y4lVIu8Aj7I8cZfLrIdxenHfo7vP5DSJz3Gxu9OPMuz9V052ZnoZ3kTa9PiMiStE6bUlU27WOXi+DxGrTUssGVDdxHLL49pMQIVNKctm3r+2Msc2hVVTk/b9GbMjLTeYaiKGCtxc3NTaK/jvdUzLXFbZPz5ZY/JubY0Et8p2N7n3j9Y7Gw19M7AlApQtMwcTIajVCWJYxp0dYN6qzG2qyx3W6977r4cAs3ai0bUmkKscGZeFCe0xXk1rYtTNOy4RqIE6W0GWrDYuJNtUFRV+za1Bo33xxLvhyP/ZhlngG2JbBIrfwBJpjbtoXOJIxvuldjMXnYPwwj43SiQih3gxYJsu7v0YgIJZtIqzxSJLZqN56QshznwFo/t9vNhl3xAHZ/K0tM51PM5zPPhc9mM5fdLwRW4rbY7iKRAlg4T5E+p20tx26IkbYgYQJgdsB/YWi610CUSinhHrSWieyOgd4uQnNfee2R9i43mi6MPIxbvV1csWsSd3Hi+9p+FU78kLp3XRtCJLs2wc7xeIBPCbKRwxjPz64xNC6y07e+9S38xm/8BmazGX7xi1/ghz/8IR4/fgylFKbTMbbbLZRS3jr8zp07EcKWZB9Bl8nJLCg5VN2xdDnt/nj3ES9hrXnuJE55X3z7KgRazBl3dbRD3HsyhqS5/hrEADUJPqIVEFm2CyAWjmfX/u6KxuOoar5vbm1g4dJHUiKyBAh5USArCi8SFzcfBUKL/l7vrlvXghyAR9yxwZTkLO/OWzzPKUfIyLWpmQMWzrltG9R1heVqBQXlCYxZFIM89hJo29alCE0JPgsmZpL+GE6corRCURaABftnK8L1iyssVitMZ1PMJlOMRiNo7YIGWYtMa5ycnGC5WGCxWABEPpZ7jKCYSGhh0cIdYQCpFKALU1NdNzzSA4CmMchzl8xEoRdytAsPHM5y/6X35VMRZzNjbwQDZOx+KGqIPMtQu3j1q9UK2+0Wq80KV1eXfo+NRiMf2+Ho6AgXFxduznIXGpWReJGxxX9rWthoD/i9AkRW6dxfTcoft3Yg1j5B1FLkiTMPPkU6gZDiOV4f0zQ+zbDfKx14chsx/Xoj7Wgy48/kkQMRpmze7v3b6nzZtm8D5q/CQR9aZ5e7POT5Q/sRxxH2m9sB/27RWuP8/Bynp6cYjUb48Y9/jD//8z/HYrFIEkIAwPn5Od555x1cXFz4uM3s0iUGZ0Ku83++NRlD1KdDqNTuPpASDl5w6/Iy48io5RVQddJ40t/QodQ/NXklJjYSdnLnPvVrYwFCwyK+CPYopXzccfndbTveRwlxESF+IkZMkntbKeXXMEaW2+0Wi+WSI3zVnLCEAV9AyMKRxm16RNIGi2ZB1mLkBTCQq6rKh081LuCJZPoKkgch+GRsTiVBElazAcBuaHXboKlar7Y5OjqCtcH4zs+XtWysZPuEotgQeARhYiKJE+NwcpcC4/EEUAqli0EQu9qJeN22LYo8x2w6RV4U3li0aRpPdKzXax6/YeTNkiqN7pkfggGx90E8b3XdOBcyDWtDHPj42W5QFjkpXWmX59KJPIFARBhPxjg9PfWqk6ZpvFEcEev8ZY2UUlitVuzP7twMLy4uMJvNMB5PcXJygrIoMR6NQLMZ20JoDWMDQSvqH2OttzcRhK0oeFp4g82oSH9kfNYGF9EkQlw0fpFetG2LzNlDWNgko5qve6DNuLzWSDs29Dn4nT2IaKiqfYYAr8RNHdgnuX4Ikn3Zur/uGIYQR4zswiENGu/42clkguOjE7Rtix/84Af4/ve/j8Vigel0iqriiFOj0QjvvvsuHjx4gKOjIw/sJXlFcL3gesWwqte/jlj0gNHtGTPFF7x/ttz/umsFdETwOGzfxZyrvEgdoChIkwGS43KUgpaEGWBrZALrQrOMjbpi3XLqt50GKInjkgtCaVvjfZqlT109ctu22Gw5d7RtDXOljC2hYdGSgkHrgZyMSwzsCMTpSmGRacVuQSpYiedFjtl8iqraojU1FssKram5XxEnJEBTLLz5j92JlHMl9POuFDRlsC1z2KJL70ozPHEiaypuPn6jynebHhN53In9TZ7j6PgI43bi6pN1D8TMdrv1uvSiKDCbz6HFet2J2Bcuhztb7dtkTSVyXuoqJbtQgqIMl3QvaKgoQYwQQ0JQhZgAKacdE04yx7GIfn50hHtv3IORHOTOYl/UH5YMSIm7V0i8Yq3Fer3G559/jizLMHFIe1SOvAh9Pp9jNpthNB55KY3se7LGBRZyCBOBWNRaoxlCoAS/j7xhnYUT/ZMLaMR8OMceYIJou61QVTW0rtx8saomL/KE8LlNJftaI23gMI5x3/dw7fD6X4ZbPpTT33V91+8hBHEIsnhVhL2vX10uLqWo06KUwtHRER4/foy/+qu/ws9+9jPUdY3ZbOazPp2dneGdd97BG2+8gbHT18XGZrGvJDMxDgAMdzy53p2/XWPti8+BwGUTX+ggx6+FrIk5ZZIwbFFfGTspdz8dwz6pSHydgSKBDe2YmCLwOJRSyUk3hhNCsAoijUDWbUsAEyNt5QiC1tXDYsfwLLyuPUbaXjyYcO8cTVzcniRTld9bTv3BgVgAaw1zpjqsi1KEQmXIcw3gFFnOet/lconnz5873a+BBUsDuv0A0tC6/EeAJuQAVMmSg/l87jO7lWXZQ0QmCb/J6+nF1WIYBgtu2sUCcM9nmYaiEWbzOSazKb568Ryrm0VHosHSiu126yUMmdaYTqfInYFclmXIi8LbDqx9CFTxY0+tvWO9qqzJPkGV50wdEooRS4y42U4gjvbn9pAbd4yOWmv9uhARirLw8fHFZmK1WmG92aCqN6hrRuTb7RZN3fpxA/BBWqptjdVy5e0UmPses83CeOSlJpPJxEs0cofIyVq3r5jAhbWDXC+BfMwBfzYcUWyMAYxzJXOEtpIwiCAUeYFGXCUVqxyEnI7nc1957ZG2L+T0mO4Q+x3mgGGwlo0AYVoBYku9ISDcpR7j6/3uHI4cDyU8hq53Aei+/hwmHn75vsg9Igb2SgdKtDvRbduy/voHf4GPP/7YZ5HabDYgIrzzzjt49913MZ/Pk9SQsc6SP73TBnNwLGuKuBj+uosm7Y5lt467+x5/GpEsUIpIX6VYqYoUyAS9vEeWSnZtiJMfA9Uu5W2trzXueTI2pRQM2ACNgWIahY2zWDFgSQ2Z+vr2EGQjIHdGxq1LlRl4ZFGjyDOti89N0fzHdcdcWhyFK/YnVkp5H2mltT/tMbIQ4Hx0dITVaoXZbIZnz55hs9nAtA2MUmgdESiJgQQpSntaa+hcs4RCczSusigxn8899ycGYWJ4Blh2qyMAqn8GZa382YUQLHAEKZ+j+/fv4+69N7D52d9gvVg6VQMb8ImoWMTFgkgUkUfSWZbhFEBZlri5ucF6u+H2jYWN1t7DNzjiR/Z1LMmJ1knWIEhckLj7ddfR+zc7Vz5jDc+LEX/y1N6gMYaRt+NYsywDgVCOSlgAeVFgUtdoTY26roL4vOasf5LWVDj8LBJ/rzdrn8SmLEuQVp4oKMsS08kU09kU49kU0+kU43KEsbPS11qzZGiA6yUiz2n7sL7Oh14kUeypYdJ9rZX4gqFpGzf/bu608jrw22DNa420LeD8s0kIFQZEAsQhgw4vsGtLH3k5HmRnWy/LMR9SvgmO/VX6w5yKTUa7C51byUUb/T/UNwIbizAABkhzFCfq1L1arfBnf/ZnWC5W3ninqiovDr9/7x5OTk4ACrGOuWUGkrv8mV166ETy6NmavSNMarsVWUt9gb7mvbebYOoGqxiQWkSOcxhY830ruktqZH2KSokGJTp5lfTVWGL+hiygXPhKRSAN5GWO1UaMoYYMPkOxjo02pvX7y7QcohPkAl8oBUuAaS1Ma9E0BnXNFtMSDEbW05gGEk2LiENuKseBZxlHtWIRJvvkCleUBAcRgOc8C4gIo7zAyfwI88kU88mUs4tdX6GpKmgitNaASHsRKyNUgmQvy3XJ7lVKwTSVF6eKREiQl5S2NRyZkazX1Qv6k4hgLMEBLAxIWWQK2BoDa1oYCxwfH+H84hyXL17g6sUl6rpmTrAsoPIQvc1EYVpZENTCuBSktamhC40SBRtkXQK2bmAVz6WK+uIlHoI14PSroqJwe8pTmxFhZoxloKw6SNvlP2bpiIJSBqZ1xIExbNzl4hB4PbAjHBXAQW3qCkVxBDUqPDLMMrcfUCZSH9F7iwRCROlt26KuaoCYuGhMDWqBds250dsqw3a5ALlgOiPHhY/HY5ycnODk5ATHx8eYTEY8xgGuwBMHYFfL1nKmOGuMT2xirUUrUhVrQUZDezhmUbiUp/F+yiIJ1b7yWiNtXwSOUGTII2iGIi5zD/Tr8SV7EOarcqMv89yrIuxD+hbErlEbQ8/76wOIJHpXOQ6bAK9HgxzsTmnbFovFAnlWeApzPp/j4cOHeOONNzCdTHjTOx02ERt18Br2+9372UOefdLkNtXC/vm+XQzevz+EWHfUsW+PRqLTl9s/XLFwdZ7TdpnFYumRuGsJZxm3DQwbpZG7b1z+Z6nDGJcOtDUw5MSnBNjWwprWWQcLsmHkzKEuJWpWGh0OxP7Ik8kEN4sF6rr2yEIig8V9lX7KuIRTE254Op1iPp/j6dOnuL6+9txc0wS3prpuMB4HTlvqIyLmAh3nNJvNsFwufT1xhDdjrY9pHpDgkHSHZ1OQ4mazgdY57ty5g6OjI3zyySd4/vw5JpMJxpMJ8iL3RK9ECowNQq2oItzv8XjMRFLbet94GYs3nnN9E9c3dM5WQhS5kfjvIhkaGhsCx6jaoNrqrlF3nuV+XdfYbre+3jgscJ4Hfbhx+vvY9VBE45vNxtcjqgRJgWrAxq8t1cwl1y2nTV2uYMDBZMbjMWazGU5OTjCZjHF8fIRcL9AtRATt4sorOF22cX7tiTscPy+Eho2QtpyB2H0unffd5VcDaaMLBIMoh3G14yptdCd6fEgbGovCh9u4rQ+HvXNoPa/yXlecmSy444b6CLCHpgefEe5ajAH9oXNGYq1pMR6Pe31UiqNDbdZbZFmG+/fv4969ezg9PWVuyQHfmDvyiEIQj+OibY/U6iKrkMRAVv5QMfhQoe7GGXzmVRB2Vx5xWN3x+u5rM9EUIXCfvC8ApQLQk+t5XiRIMBaFe3cq2QPE3JA1xhl3caO2ZdGnMQbbirlSQ8KzElguxpw4x5G2jmtjzppjXodxFHmOu3fvom4afPHll54bJrLe5awL5LpnQETAgrjPzs4wHo85FenNDZ4/f47t9gZVtfUuh6NR6UNjCjBVBG+ot1qtMJ/PMZ1OcXNzg+Vy6TlvblNSOXbXK1yLr/uAK22LoyPOHNa2La6vrwEAk9kUkxkHENlsNp44IpcKzourozpz8YO/vsHl5SWatkWmtSe4hvaVRAMjIre2u6KlRc8J4rbRntI8TmvZijpYkgf/eNmLMbKOxe4cYImRrkhVun2QtY/VE7EbIhMtzIELIj85OUHjfNu36w22mw2WiyVaC2R5zs82DUbjEV68eIEsy1AUObJM4+6dO5hXG+Ton/LYaBPWAJrTxyobvCC0bAEren3DBK7hELrWmuTMH8JlA6850o4IVwSgF386oOKB1mEc8qHI91Bu/Otw37vFtYdz+0PcsUi2+Dr/EBASNhuSCD2MqJn6VqLzgogfWbQFYiOL+XSGKtv2+maNxeLmBmU5xttvv4233noLs9kMRVEEly4JARkhEe5On8iIkd2u+dsJlAbncN89ac+RK9RHiPF3u2ff7SIyX6bsEsmntFmKGJQKXFXMxcYclyDD0YjdiwIXF+YmJu6UI6QI8Dmk2a3IADa48vi41wCg0vObACQHvDPSsFZ7g6KL83NMJhN88OGH3iVQOGzpazD+YR/6mDPscm+id9Raeyvi4+NjbxBpLcdLJyJcX197PT1gcXQ0R9OMsFwusV7z39HRMU5OjvDVV1+haSoo5YzSSPtVhphNUoQsbfguyHqz2aAsR7h37x6UUvj8889xc8O55e/efQM6096nXQip1gIwoQ5PwFgOWvPVs+d4/vyFtx+xRKhNC41wTkQsTeTsJ9yc6SyDaQNB1LUpiOc41o0rRQ75p+tMApgposoIzihQjA/5XDRNg81mg+VyidVqg+l0Bq0zLz6WtmKL/aH+5RnbAMRz0zQNGofI24oDt2zWG6y3FbaOK1cUdO4cIIgj3X3xxRdYzNd4u3Mu67rG06fPkOccT2IyGSMrclbnRtw224MGNY61Fi1J2N40dWwSmvdXXzzuWa8EQPmNgZSTfllueRjgRolqD6hD+nNI+/vq+EbfIdEwgQ9mgB8BecPpiSOuGkTeT1HaVIpYD+oA4Ww2hTEt3n//fdjvdRCmIlxcXOCtNx/g/ptvYjweg6M7ZT3xIyKEEq+nADmi3auQEk084Bjx7J+zQwmiAIyGy3DvXlWScmg9XUTdvRcTMvF8C8BlozLtrWoH3b6s8yGVeTXW7Sl4v+y8yNl/WRGePHmCrTPUYkMlv6OSsQRrfPi+ZBnnTj89PcWjR49wc3OTIIayLF3gjMDZMoxTnTkSOBEIG7F6BjhUKUc9C4Fg8jzH4uYG6+UK1WaLIucY6pz4xEBrhcvLS1xfX3sJUVEUTnTv2rAGVozL4CREXqIcabgjLhUAptMJTk5OUFUVrq+vsd1ucf/+fdy5ewcLpx4QIyuttdMPc71VVWO5XHrf7MVqjbZlsf3p6SkWC7ZAt4at2xPiWAgcd9697zs1aJrWnz0virepzCt27wKF+RUds/iNeyLOnXPZG0oRRDRqbRQJzYm167rxLngxIRbvo/i3jiQK1nIAGxlj6zKwWWNgG9Z3N3XNbohNi5UzVhNDv6rawtjWS3byvOidsfVmg/fee9+fn9lshvFs4vztxyhLVg2WeYGmbvw88Gfmxp1a8iPq/20E/q8A0nbyhfhKvIg7ru96/rb71rGoATCm4rjue4eIMw7pw23P3HavSzQQEQwiwA0wIO7WEyHpBODzeQZRoBSzTKMsc6zXK/zkJz/BX7z3/+LX/uPUWCPLMvz6d34dd87voihLf/i6FuLdMcUiM74g//XXf2AGcIguOtQ3cIcOaWfonfR7bxyu3W8Ij/vS57bD9S6iHgJ0bJHNISClvzHwQBw8AswhWdKA5ehceZ7j/OIC99+8j+cvXuDq6opFslnGSUgAtG3DohxLYKmzR+HeAlkIutlshi+++ALPnj1LAL2IQwVhZplG2zYgEj9ZhD4j1ScqFaQNQcJAbEApnE/bQny+m6ZxYUaBpm5QjhgIS5zz5XLpE1kIUuR6woLEko1oxplwRhjXZDLB+fk5ZrMZVqsVnj9/jpOTE7z11ls4OjmGUipEjxOLf1IcutRa1HWF9XrpkfrJyQnGkymU0lgsFl6nG89jvFf82MV/27RQ1oKsgXJpWgWCNC6vtzEGddOgGI15HjPCdHqE+Xzuk8VcXV3h2bNnWN4sHJHCxotVVbu9wRbvft+ZFq0jKhaLhUf4so/jfPJhjwdXrCA1DCKxLBZRO4TOrlgWmFi0TYOm5kxvjUOegrS32zU2242b1wamXfXOXlPX+Pzzzz2xOxqNMJlNMJvPMJ1OcXR0hNlshouzM+QZi9pDUBeeD8lKFq+NuFXehlJeb6Ttqb2+iLTHEUX3h3Re+64nTfaAHPu99nEd7f3cOaRBzv6bf2fomS6SIbkWcWGMxAEJFCF6Z/FP/fDDD/HLX/4S7733HlbZutem1hnOz857YS8FYSd92jUGf1lkBbvGKnM+/Myw9ONQ7Pn1JCZ9DvCbLUMcpo20C0PIuiv6jANEJAZh8Tvk9HEA66PdNRBhtV7hs88+w3a7RemyfBljUG9rmNaidTmq4/6GfpFDqoTj42M0TYMnT54EA6moz+JlIPptpXJvr+F9n42FtU1KfCDMvAQDspYAR3ywa5KBdoQDwFbMm/UGm9EaRZl5KYCItKfTqc9o5t19HOMYkkYANrK4jtUjROTjnB8dHWGz2eDzzz/H9fU1fvM3fxOnp6fIsgzT8QTbzQZGfJEN60QpU5EYt/HIX96r6xrjUYHtdo3L62sIMUvk9NYyblnz1kkATAhEI3vKWpZOKAqx33WWYX585HX8YjiYZ7lXnVxeXeLmZoGNS+gi476+vsbl5aUPEMPi69pJRsK+K4oipJBVbv5EMoA+YSRcdkyQiOukpNbUWsMZuKPNMpQlW8K3CG5bTdugbSdOwsFI3BwNRJ0h3rujkYSRbXGzuMHTZ085iMtohNFoxF4M87l3MZvNZtBa+/0j4vv4XEoUv33l9UbargSLSZMsDt8TLvIQ5Bfb7zu3iWihA6cJf03aOES3evs4Dn/vmxCxyrzI93iTg5wuCgrW662Vyy8b5lh0n41p8aO//Cv89V//FMvFArBANu5vH6U4IppWmctYFQiCIUQyNO5dOmogPdwBWR8qph4Wocf3X0b/fOjacZe/OcSdBmLwF8HxHMTBLDW/jEXjiTVr5FvbLcZyMIwWcLHeg/WyBUeiWq/Xvn6dabREMLoFbIsMCkDmA7CkhC15I7CmafD8+XO/NlqF9JtFUWA+myNTDHRFauP3gXJjthZty8jSWg7m0f7/5L1pmxw3dib6AojIrRYWySIpiVpb3bbH47b7z8/cse8X23Ptbllyu9mSKFGkRLV2iftWlUsEcD8cHOAAgYiMLFLzUPfiEVWZkRHYAjjv2XCO93ZXiuy7AcyVDpm06Dx06vjE0ccWG8r6xelEl8slHj9+HECFHeNYCg31a5bgMzrl5246nWI6ncKYCvfv38f333+Po6MjHB8fBwn46ZMnePr4CeC8T4FSUMbQ+7YOqGpMp2SeODg4gFHa+x2oEEDkZHmKpmnC6QwlJDsN8k/QPtxta1toE2Otcw7vCxcu4NVXX40pSacT1D5BB4+3qiqgpaA1dV3jyuUrOH90PtTFjA6rzlerFR48eIBPP/0UP/30GPP5LNGGxPXKqnRezen+dc516RozTn6N5utaATB1BVgCbQdSp1trMVNTOFi0bQTS1flVJ9OX0RS4hcejlEKztliv1niwekAe9Erj+7rCpJ7g8Nwhzp07h9l0hr3FnM6Ee2aHj5uRpG9RVyYc7esrLz1opxtdB64sqkXKz5Skav8tu0Z/U7VtqQ9dqW0IhIeA53kBua+ujmTtnckSrlRFz3DiWvyGFqCqFIJ0M5vN8OTJE/zpz9fwh/few3q9Ji65aYlQdIZCXLnRlXfISYE674u/mA9wLGxmf8f4IezCJO32nqRaV17r0wScuTgJ3F4KUZnKHOJd9zJLyoNHVDXyGIK9TfGxPAULn8XKh1/MiWzwcoZfWp50aqXQsrYq1EdZrJxzePz4cUjEwUDL62Rvbw8Lf0qB1aXMgATtgPUMpgbg+96IPN3w9TmWvqBoDP73GnUSRrdtW6xWKzw7eUYE2BNpju/tnEsc4zabTQBwbkuCGikFWGMXHeROTp7hzp27sNbi9ddfD6ak1WqFn376Cev1GpWRmboUbGuJQdMaptaoDEnhbduG3Olt08JoHRywdBVjwnNpmoYkaEPnuJ2N+bTn8zkuXbqEixcvkrr+8DAAlANpXZgpIWmdNDCcM53XQq5Z40hkAGVua1aCAAAgAElEQVTv+uqrr3x7szDnlHOATWkRtAs5LQMdC3+RbgJvMOnQZKUUlFVovZ9Gxb95UyBpJLx6fW8PT7J2jTE4f/58mh52uYZRPoyr9/85Xa5wulzh6ckJ7t67T0cFFehI33yOCxcu4Pz58zh37hzm8znmswUqU6Eq2NFleelBG5BA418gorQI4fSRPyNLqjqU13MQEaJLUlcGiDlAijqGpLkhlXVJndsHeH31purnSNzl76w6ok2lM8BWMIaIeVVVuHP3Lv507U+4du0arLUhs9BiPseV1y8W+kHxnI33qEVot3+8o4p/NfFxxf/13NxTzRYAjRt8LMhKydx1wJP7k6w5ZgD5uaFpSPialCDF/uZ7ggmZPPqlsndsvCNWJBDyfRAAqQA0zjnUXLfWgRm0lg4oK16bfqsoraCtYr4Qykfm0p6gaQ9EdLa2SaRi9pje29vzmd9mfrBROmbJVWvA+aNQRpGkHaKVKaBpo9Si4Pvl1eM8/6bW4QgXzzcH66iqGvP5LKx76RzGcyv7o1RcQ6k2gwK5SAZqtVpBKYXXX38dFy5cCPduNhucnp4GaTcyUz7JCntr6+gUyMktlHMB7KxtKQvW/rmgkpfaFqUoTnbTkNe88clLzp07RzEV9vZCpi2+n6K5OQq05CVZ49e3tQ51VZGGRhuhine+jSWapvWSZYuqqv0a4/FZb++ehoQ0Yd/4dywd6sI79TSNI90l26cgVADe7OdoLwbhBmwGjYGp3KQLoMYY7J07wmKxDs5zTdNivWmwPD0NIW8Nou09erRbrB89xP0HD3D//v2gwTg4OMDlS1ewv38QGJu+8lKDtgKgnfUclN8MLiO5rgxmXfCMDirye2ypC8xR+HapFDMA2M9Ttj0/BPh5YcwJCd4zAh4IjaazztLmTGEbn4bY4T/++COp2YzBcrPBhYsX8eYbb+DS6zPcTxgdgDchVKm/cf7H4nW4X9i1JHRJv1bV+RDvi7cNzbFkltLvKTFw2Thccn867BCcMGnHCcIQVp4j1W3XGQ+eGXBhxKnST/vxiee08k3b8I8AmP5Z23qnrBhClAkznSGlqkg1TukklbUwVni9cjsqZiyT2h2rFOg4lAXZw0liMobSUm6aBm1jAYuQxYmBbrFY4NWrr2G+v+cPfjtAdQOgKPYgV3ReuLUtgXhlgLaF8jbDtm2D5GUCw0fq/qrSmEwrLPZmWG82cNph7VqY1QbPnp2E5CpVNYHWlbcnR5W/1lVgILRmrQVL2elRJdIM0DxXxuDypYuYzeZkTqgqrFen+NGfUWdJnvYsgWDrWj9WA6cpF/QGFtCUyMM5YqoODg7xd3/7d1gsFphMZv7IpQnMmDYUHY73Rtu2qE0dVP81n2H2zlZyDEaxBO2SPW2MgnIE6ta5EO4Y3luagbxpKDrZ4SEl8mhbC2OAixcv4ejoALNZ5W3ZcndEh9deoUYBVpG5j+OIM6g74nhI98NqdRez6+V1cTFVyQRoMJ/vYTqdYT73Gcn8HHJ0ts1mQ57rmyaEwK2qCk5TzH5sGjw7PcVytcJmvcaPP/2EO/fuYu4D6wyVlxq0gWEJliWL/CXmarGSinBIreyr7f2tdL0E3P0q+mHALfdnHKCHv+J/ClI6YVCVklcEivl8jmfPnuLf/u3/wZ///Gecnp4mG/by5ct444038Morr6BanOJ+oS9aG5JmBscwjNqd+UL23vuf7PxOUnOqQdmVwerru7xcrlIRJQ1ALIlR99Zi3+Tal9oGF+8nQIj38zu3tutJLtcK23PZ/gikJxG053ectV4tGiOpsY5BZkMrxd+WfWTVKXvsSgkOaMMxrIvHxzg6Ou8lIERpTNTHzCh9Ji9haCLYDJatUiGSG/Ew1gONDgFUqqoKEfqiaYCOIVHUMpPYsUmF3gStgRLvNDpJRa1AmEuWzOsalQ+Nyr+z9/rdu3fDkbeoXo57lLUIWms4HY9M8Xl77cjGzHbkquLIgykNMEaj9mes+WUakcJTHovjd5avHcm8xgWhoJwKWg0uMcIZrYHpdILz589jb2+BZ8+eYrFY4PXXX8fR0VGyVpRg/vN9kWsmWeJ2ftGExLq8PlUMf81OaXm9UdMW11BnLfsAUs61sLYm7Y5/pmlav65bNCs6xjafz7BakePgpt3QsbJ1A9s0xIApjabZ4P7dezhdfRfSfvaVlx60gQIgFQCwaCst1MGf5cvZ1t4Q+Pb1a1dQHtPvbdcl1yiZmZxYh+AKmmJXMeHa29vDgwcP8Ic//B6///2/o2kaHBwcYLlcoqoqvP3227h69SrOnTtHiQz0utsvrr9PcS3eVcnuX3I0HHpHYvSd3+KmLnYlqy9+3q4FiEzALu9Msg3JHZKnGHoQ2Xyo7m90O89hGazlvXVN0tXp6TJUmC4jL69Ynze7AqAodGdwamICC0CL6yzV5H3nVJJt26D154JtS/c1TYP5fE5HghzpI9hbXY6dbNQeGJQiyVlpVEpHJsNaije+oWNTFkDro1ERiEXmRmvKrUwZmxw9523YUrpnswLZ1gEG1FCHHxt8vTIpDql9KeJWnnHs9OQUDx48wKPHT8JvbL7iKZRSu/JnnTkwyWq1wma9wd58HvYnecQzEyHDmpIZQcP4IEp+/oCEEaH26RnjY5jTO4AfX7ZMneNkEWCdUKxLhTm3tsV8PsPx8UVcunRMIGYtDg8PA4MQz+THnPYlutCh+2Gcaa4JFlT4NITKTFZ9NN/ovixfFQDjj29ZVJ65rGsLa+n9YmbRNHNsNnshoE/bUvja02cnaDYbbFZrrDdrrKGxajaoTYX1etNpU5ZfBGhzGZJWcwk3J1Z99tM81nK+EErtjulb6ffUPtVP9M/Srsq+87WEYIvNKO1wk8kUi8UC9+/fx3vv/QHXrv0JSqkgCRweHuLqa6/hnXfewcRnW6qqCnpS9/Wq8znfINLHoDieZI6iWp/+5m3sBp5cuqAuv3egVT5Z/K23vewddd69Y5tPyuo450JTBKd9TIhQ1/t2us5wXeDmeMvTyQwaT0ldyu1lDJRzRGwJyDbJ3EUCr1FV/lnEvSSjPXEkNWctJRzx6t/WSyetbaG1gTFVUH3LcKql8URgEMRZaxjnAG3QQKFpNSV20BraRDADKOnDZDKhM9PLU9LEqygZy2Ah/JfVt2ReqMKekupkCrQxpTaCel0jHmMl5ufZs2d48uQJVpsNlI5MNKdC5XfRNE04mgYQYD958gRt22JvsYBtLU5BOcDjO4n7j/9Jpr0UB1yCNoAk2BKgBFo75NwmxzyHEpkXlRJt00qu6wpXrlzGm2++iXv37vloaCdwcDCVZ4ISRqN/b6WgLWghLdz4G6JJh7QB/cKWjCrYbZKdCVtwBEKnI36ENd7aoJ3hI262dWgWDdb7a2xWazhrA9N1cnKCdbNJ/DBK5aUH7b4XNhbAS1JwXx199fYBful5KQmUxjDUn6H25IKMmtaUmMl7tf/H3r/hn9iwSivMpnPs7x/g9u0v8N577+HLL2+Hc5R1XePcuXN47bXXcPnyZezv7QEqBkpxRTWOH6sTaQCL80y2NTlv5fnsgk0fmCrVlZJL05zMX5IRTonfS22MXwd8fZSWQIK3t73x5cikdMHeebDPWQheE9ZSAg1WqQaQEmeyGSAA0FEif9g4lXJo7NYC63WD9bpJpCEpFbUtqZ/btkXTxnPTjsfmyJ7uWv5sCbCbFkoBlTKoTI1JTU5TvjcdUNEMBP73GCCIJi6ufwsNBWNatI5U/C7kHPfzqzX2DvYx21ugfjyJQObbZelZjtNaBOBWiAFcGNApIMzED5kTlEQAlg5t8iwzzyfZyaNaum1l3nLKqsbni2fTKQ4PDsPRLtlPeocu9jUD5eQopvZZoeVcIz9Zw0dEPRvpAptIvzu/trwHgWyTC5tjjDG4fPky/uZv/gbL5RJHR+coJar3HI+mjxJ3D7DGpHNZ9J1dSoI/D9+lImjz/Xyf/N7obtvMfHCmPa01Woj1pLyKXsUkNszwNY0Nec/tghjXvbbxecLXOF2eYtP8f0jS3rXsItWWnj1rm7uA/Lbf02uRoG6tC2QrIRWiX4hig1ZVhfn+HjQUPv74I/zTP/0j7ty5E5KAWGtx4cIFvP7667h0fJwciTGGcg4XQTuTgnMGaszcDAF0iRGgj1xvXn8+T6V2cjV991rabymFb9WlF/udz0MEp2jD7fzew1AySDuqGExE8/nOJVMJ3PK4EnvhSs0Q1wcgJGWQoM3EyTkHZTQcvITtpY4AQCBAd61F06Znxjn8J6mSvY3ZWhhVhRSOnCLGOeczLLFtOzIrgSmFB1SloVuNSgEtHJxP1kCGT5q3qfeuluk/5btiKZfHCFBazrAavO8Ap79sW4fT02XoT8iypaLdvGSTpb6zSlYlDJZcN0opVNrg6ICibx0eHgbv9mCn57S3yiVjyoE7tA/VuY9LcnwrXDeIl5izpJjwDjHwTd6mbJcDw2w2Gx8Tgo8g9hnY/Bx2+N6C1AwkdvX0nuGUunJ/lEtKg9g0yeYfJfJo8x4zxqCqfb1TSyFm2xbWOsx83PvN5hcvaZftcH3ft10bkojy0i8hbgfzMf0cvl9nm0E6MUUONNo2WboVRFYpOB03CHHnJGlPvYr78aPHuPan/8K//su/hkxGy+USs9kMr732Gt5+6y0cHBwE55uqquLm9XX1j6dfQ1KyZQ/PS1ciz5mZEG41qQDogKpLufOoqoz3bZeOGSLGjWO4rtimUwQy1G0VxyPGIV65MDFEX3TFYbkARI/xrnqc/5LjV+XvJonMOgtl5WkDPnFAbVFYxsiE0Gdq29oW7boh8PJSNbfHDIZzPuORsz4HtfeK9sA/rWuyJTp/HlmR9VV7RQCBtU7GQupU30+WlB0oJzJIq+QUPStB2ykKIjObzbC3R5m1bGt9DucYu1ymipTvrGma0G+losQvHbckcyTBN489zYWlYgZQSiXags8O07E2mkvekwx6DNghk55fH7lDnFwDOZjma5TpBoGgPHtd2Ofe6TP3W+G6uY9y/XFs+dAX8L7sF7yISeXkLHJD0//4is7eWVpSbEnq3iLodXEpnmNhmpKf3YdzaBGdKZ21aK1B5RCi1U289mWovOSgHUsfEJ4VWPvulSrEbWC/S+mTsPr6n4A1ALYzlgQ7CdS86BNw9ZtOa43FYgHnHL755ht88MEHuHbtGk5OTnDu3Dk453B0dIQ3vXf4YrGIHCKnapQbHcOgXboemaEYnrbE7dK95bq7fgfM5cv7xPXkh+FkMLIPeennurfXNU77osAiRHhOeWSWfBvSz1Ldn867htYuAZCcOJGN15Cdz6bXfe0ekFU4GkZHi1KtDa83juwUE0bY5NlwrEwroCWGgAFUKR8foCYHH81mGD8tTmmP2DoksKEh0zrXOq7zMD8WUMbb2FWcF06NaEGSEXuIK6XQbDaoTQ0+hyz/5dKXlJoZmLXWYIeohMl0kbTL9y5NCLzf+DoRcIrSJSN1EVhy4gkGdAYLYsSov/6Il47mKm5f8V/xmTN/Aam3eb4u4h5O17GC2J/SNIIuTeXv0lNd1tdHf/k3m12j1SquDdCgnNnI24o0tUzjXGev2XDMjE1Wsr7IPAjQVkLwsXEdSh+QUvlFgHZpcvPPpe/y2ijbIsovb5fnS/fkfS5xcZHgluoUy0+lDhQlQsxg7eCP4wDYWyxgjMHDhw/x5Zdf4rPPPsPNmzfRtm1wlnnttdfwxhtv4NzhIakKvfer0cZvZoSoUr4ro8Y/BFh96ik59jFtlL9HApeWXLrmeR/eLJJJyIe0bS2UCFAqIUSilz05WO9Q28y4SLDpmyuprk1v8B7cIIBQ4hkJSExwyYzSevt2CyCCUNM05IAm7L8QBB3wkpf3uI7cCDj7B9FQXt+KtEnasCTokmM+CgjqUe0jusE5z2w6tNYlNtvJZIK6qtCs1pHYJkxAKjnz+rHWYrVaBQdNKAXlLCCeZbMDs+IcFCVnQlk6izbQJmEKOBJZBHYb/jXNxnus19CajnVR7Jv4ziUQy0RB6YkSRGafr3nmSGkt7N5ZiFBF3FVIqYnUzCI1FtIRlm3Ysp6UbvKspXRTQ8GqrP1gaPIlYWjjZ5dd76Uhffs671vQjEUmF+KOlKnxXdMqaKRgfJx0Bzj9SwZttZ3YjQHObc8PSb+7qEn6G8egcCcXSE605dog3IzA3gfaSXEO09kMzlp89e23uPHpp/jq66/x4OFDbHz2nv39fbz9Nh3nOjw4CCo2rTWMNnRu0BNBeMkHDlA9XGjstxKfkU2C62ycfD76pzbf4HwtzkF0kMn7FT13aXoyW7XMYTpQlALISS7td86EdNePSuYmUhX/P8fXpN1OSHb+t8i5p2rzQk89YUwlQSkBMRGNCTD4XKsLM6V8I/KdSxCz1sZ864LYk9o6hjx1YPU4IZiUKpSKGaC0EStdKZ/P3dv8FUjS1lHt7Si8lWBaPQjx3HtaopyDchokgvsx+b7MvE2bPbYZ1Cjve+rYRWP2fyG9jQ2UsiCZy4bn/YKJzITyqTaF6rppm+D01jSbWL+XpJWK74rU9zoB9LquKYnHfEaR3xJVdkpLlVLJvlYekBN6wp/9nuf7tE9Dyr/zWtacy8DFeN5Syk4YhjCXtD55bGXzl6Qn8jdi0hzTRUXz6hdZeI4+KvG5/3hwTvt7qH7nr/KhVuM29vQt0Hb+E9ePUuJYmgK09xFw6B4zk+XlBm1fxgLzmHvz33P1zdj2hkA8AQIFsJ90eMWKQhr6HviLmtQlBVVnXKO8kfoDxjBRYGK5PDnF93fv4f79+/jyyy/x4907ePrsGU5WS6yaBpePj/HrX72LK1eukHTt7dchqILvhvYOO7y5mIkol6iq65Z+NBz3nvNzxAB6tla57j4uVoBH+r+CBCoJQr9zGbdLzLTyoMnvNdUCKE9MnOJjVzkjSQRHoTTv6ZzEEKwpkebPsm/sWJWrfFlqSryJAbGGUxs1S56ePlJ0LG7bOqC1wW7nHEXyckrBKgXrmYOqMtCTGtVs6hcazQM1L8NoUr+MZ3LZQY29pzU0lK68pEt7zbmWgqkA3kGKgMKA7OtwwLSeYG++wMP7DwBYVKgpWpvXNWjF6nwn5gA+oYRCa4GmtcQwaOf7AyhYGChYKXUDnpmR3vW0xdt2g8Z7EDNDZC1513NKS1Z9cwz0xWIRsknpqiIGynip2KUgJT/nKuuSEGDEPYGR0Tqxb8u/zjko2xKk8oJACtzMQOZ7rCxQOTKNJABIDC5pV3h9qmiC8PQz3y85vRiiOVFyz39I66CiPa3n6OzRFCIMGtCu5RH7NlysiiM/9/aIyksN2rzpw/etE7ylvgJg8/VtEn3p2hjpmyWVKBnFYAGS4wM6dLrIBWq/Cpl7L/ZRa8zmc3z37bf4+OOPcfL0GWzb4tGjR95b0WKzXuPNN97AX/3mNzi+cDFI1kHCzsJFlsc7YKftweZtmo2ha0AqUUqOu6iqG1FSqfxsNuvtjCLAEsLwvb4PPbekxKd7U1zPVFdpnqWkw3VwgBVOhlHcC6TY67Ql640E0xMoL9G3cCG3O5z4DAU6/+0ZEmUwmcx8vuvomU7noIXknklt3Aep4tXGQBkD0gxwHPUoEbMdNY7XYTqd4ujoCD/88AONNzAOyqf+7HrbKw24ls7ktmjjsS8PyNZL9Bw1zjryGmZpix2UWOJuN03RjCGPXfHepDzkByH9I1+DUlBGUy5qB8rjp6JWRNY3BNq5VBzmWD6nVPIuuI2Qbc2yJsgl7UWJOpwHIAanZ9xWSAlKkXCTA7Bcq8n3kbRA3rvNf2V4/23Z44X3u0t5qUFbliE1xhjwHPq9JLGOrWNM/bFk+aRZrSJKXMyAlOiY6DABCJtEeKQyIZnNZlgul/jzhx/i008+wblz5wDncLpcYrlaQmmNv/nrv8bbv/oVDvb2Qyah6HE6rFobMy/9oLtdMt213pQj7gdferRPpa/QJ4WP6VMqfaWbV9q4hjd22WTQBd8UwCXhKvsIpE4+7CTGwMXH+brHfVJzRolJlHtH+LBDKZKkOTIZR1Dzv9I8ZUwAM41BqvOSMhN3pbpALYEFis84U/QuE8J0smZLqCW1DNhDkuxkMsHh4WGIu11Palotft+1nJRDzJVrKNpag5YY4qaF1TrYrZU/Hmk1JVaBs+Bc9TFqGKnojQY2Yk6MMT4ITRu4VRmxbDaj6Gez2SxhsqMU7DNl5cJBNof5XMr9XwRu8T0HbVlYSyA/d9vmkwcxC1rJxBSEFLG+xpY+mpFrl4rPjGwoN7NFZlGue98uPYB4dTdh4RcB2kNAcVbAlvedpY5UCoHfkNEGGLhCcZesLkonRES6XqVdiUcpwCjtCUnKebKDyt7eHuq6xocffoivvvoK9WSC9WaD05MTLJdLHB4e4s233sIbb7yB2WIOeFsYq8RzsE7bH8fB0rh6p673+SFmaciZLS3budgSYfCfRnHY2/pyFgaT2x+3xuMaKd+rE+aAIspFgpm/Yz7S13gAkk5WKjCPKRFTnoAar5kBvJrc38Zg3bQEZmQjZ7spEsmVi9YxhWQOHFozaHMAEd1hMIM0bsh722jvFa/gJb+cwUPoN//lHMdPnjzBrJ5CmQpaG593uusIVlUVSX3e+9c5B9taf57cxwf3zJiLDdK/1oZY2cHBU0jzRms0/ux1sP1bB8ohHvdtLjWzL0q4hn71uLzWN+8lKTu0mz2bz6uc2zzHuF9QiOs+rrvwa6i366k+VIaY43z8Jc1G2r/CVfFsf/3MGPp3J9eAp/3hM98wovwiQBsY5paGQH1MfSXnh7zu0nPJL8wJ5ws33KnCE9FmyDdkEnfWj2RDKW9n1BoxUCCpOKfTKebzOW7cuIE//td/4dnyFJU2OD09xbOTE1y+fBm/+tWvcHx8TEdrtEmkLA6SUVrM3P42UMvnaYwqfFs9iXNUTz1jGKzSWkm57e1c71jATvu8izps7Dn2fmLRJ9mXrrGzUDzOxY5qRGC5FRdsh0xkpSTMnt9cv0XDtmtrSUL1PhZkz40EKwCDMZhMp96vwkCrCAxdqS9qDVKVuZeClYb2jIjyXbaOGAmnY/QyqgteRU8ahwsXLuDSpUu4e/cuNrMGpq6jU5d4lvtkjAFaB1QVXMuq9xakzfXzqwD4VJYMZK5NnbQUNKyyQdvQ+tCpbdNAWe8sx6rl1qKa1B2tRA6yxFhx3O8yQOcgnjN1kpFXiuzb4VhaTx1cpCNaV/vE14Ho3Ej7j/0GYl3jTF9D9GHb9ectpXpjf7x/j0Ji30uf8YzxiO699KBd4uDy3/uu7wIY2+wRQxwbb+JQF//e83z6GcFWmDzXxwUrCjbBzhAWDlVdY+YjmX1y/Tp+//vf4/vvv8dsMcem2UBD4e2338Y777yDw8PDQBh4Q5bs13nb8tpY4B5b5DyWuHX5VxKHPueVbe30/w7It9bHgff1sdSPeG38nA1x8bsWdljisUgVOEs+HLKWo36FOedeewAila+fJy8sWuugNTMoYQRwzoXUjtxuwhyL41bOOUArVJMaupYOZNF+m9uyOWd0Duba0D+KCS6IoCVHMHJEo7PPWgOcBY3t1FVV4cqVK7h37x7axmsnRNsMum1LGclo0N6juvIaB5Uyuc6/SxU8A1RgHsJ9iEyO9AiHJYbKNSSmWWH7Zc2EXDclMO77PZ9TXi/yM/9N/vE6EgBfAuWotUEIe8tFgnZKKV3ynepI7xmzP7bv9XF7bDSrrbzTnYpmmJR+sGq/zLyMBWzgFwDapbKNkJa4vm3Pc+HFNqYeyy9FydeRtRX+J2LSxtYAcKjpGACCNwS3LTeZAUnafN/eYg5TVfj+++/x6aef4tq1a3j08CFqY+CaFnt7e3jllVdw9epVHBwcQCkVQhyypCAZjjHzRn+j5uBFlXy+x77nMffG4hIiIImrtCnn/cgJ0zaufpjz/nlLzthQ/9Nc6lIVHhLACInKOkVesCnnmYSPzM92B5ByNmQ1AtJTGUqpsHKcv0ZOYzpkpiKp1kvMHRW5jK0dVeJVVUEHVbZGZXx8bKUDIKrw/hBAWoIbE9qLFy/ir/7qr3D78y9xujxFNTGh//I+sMpfKco3Ll9COHKVelxbG93wgs3Xn9ftBNUQ6mWiCYCDgvIaBeM96fsEm0g7XDJ/cg7lfcFOzUPIpPcw/wzsGRMQ1hqon459GxydmuCIbnF4DGq8GoASTYm4J87uY9w+3PZb3/UETHuey0GZ/++85jQjq/73LiNVaL3YJpdfFGjvSsSHJO0xvw/1I1e15tPcfZ6DVMT4yQBDNam9LXPjghEA0s2jvBRTVRWm0ymWyxX+8vVNXP/4Y3z7zTd4/PARYB1WmxVef/MNXL16FcfHxyFjVw7YpJrKz94mI0k+S8IVPT8LY3fx85DdpzSfpfnb5d0MfWdHpK7trBsUITebjO3DWUq5n1u0GglznvdHMhlRZS6BW4J3iBsugNWFY3sq1ENqPj9XYNUyxDwRaOehGOVYJBBpTY5ayugQ+5vXfwmwc6mP1rH3MtcUatdoTU5ovFYBOE2e6jLRA/eFmRfu82w2w8WLF/Hs2Sm+++47rFYrzGazyNAIjRAzRDJwiiKkjntJgJpzjmJO+yQiDvDfo32zwxzI9aEiwBljOqxzzoTky1SCbA7aSTv+c65u1xlg53WL5RdoFf3Gfg+280xkotMz+/F35yUbleJ7cW/k/erbp0GP1NnzSfsDgkl4zsk//IQCHwfqw5n+vT1MW35RoD22jAX3bcA9tg1Zz/DzLnLLQVEWz8KGIAxKxUAVmjhqwBM5KCzmc7Rti2+//Raff/45Pv/8c9y9exdKKYrotNngrTffxG/++q9w4KObSecRqerLufS+jfhzqcT7vp+lvjF9j8Ai7yxv3j4J5nn6mPcnb1de63WQSXm6wCSVXhGPl4t8/wyQzkWho64AACAASURBVFGqzc1mg9ls5qUtF3XjvlGWIBiwoVKVXwT3/tMH/DkwjIok+rqeYDabUrAUZ8Gez4BL+tsH3iydx7a5LSKj1tt2KWKXQp4wggGSI5HNZjO8+uqrsNbiwYN7AAgk2aSQ7HkvUUrgloVU5M7HTfexD/xN1lmytzs6Cme9VqCVCUX4PXhX9sZaTCRTk2mN8s+l7wmD1gPifQzTOOa1xJTLwCLydyBXiyc1KRWWYqIJK/ZhrP17OOpY1rnRJWGYKAoAdjGNjSkvOWhvI5pK3Oc/JYshxk+O13aXlp6fcHs1EYO18pGaoPx5Q+ZkQV6kzKULNSEA1FWFSV1jvdngxo0b+PDDD3H/3j2sVisAwOnJKWbzGf7u7/4OV159FYv9veAVHs+68vEXuTGpj5H77CMCcdPsMicv+t4hwN/GsLHGg6TE3W1iJYlxe5u+5ShM5Xd3rvUCth9BQuOKw8hVdw58rIaJL0uW7JNBoNVGhk6MkV8+R8YKcCWiWUmbrzYGpqoAqTHw/xQo4QeUNwcphelsimpSg2NoKO+QxKDLqTalHTs9u20ydTp10vMztM+0gnIa5MwbE5nINc7OmE3TYD6f49Lly1guT7BebzyTwkxftMmydzZJoPKViJfEvzlKq8kBZZwCOciBwqw6FxkI55w/shZaDalMIdYgRSJDmCNJC/ndRK2YgkrmKWrLctDudW7LmBb5bPju/E5TwYqQaLIS1bhcYqWl7NdaWJP+3YZIaD19SEtHFyrceIfv7PakO35qP7nJv6OUbr6I8pKDNkDRw/p+y2dJ/u0S69LrGEtwt90zzHFSqrngWe6piPJh75QnYNYTKc6qA9ARL6XiWdqf7t3DrS8+x/WPPsKj+w+hnUOzIYefo6Mj/OrdX+GVq6+hnkzC2Wtj6s6mi312kHMjJbPIAcexyGEqVZ7T4HSzZR5f1O9j34XjTQQmKCr7bVw5GxMnI8T19besssv71z+3QW8YiEp8TCMCd1wHbdtCa4XptEbtE3U4p6P9l9tuLWWNCz7kPIuCMHmm0zkAWsHUBNoQx7ts08K1LbR1aOBgtUJVTzCbzjGbzqGchlYmaJ+MVqi1QuWBnCRvBEDXijRRla6EJO7NSOwQFCNxBCYilyRlsBWe/6qqYKoKq6bFyXIJG/YhPPhSG0aYHiACd/mKYAE0sDF9o1ForUMDi8bGo2jOkTbDWhvlMw9UhsHNkQMdxVt3/l8IzQ4Iz+scfOM/DQrBG8OIslYjn5v8/Ldcm4P7IIAWAzar6mU0NJBnvBdoojRd0EQJUiMofGcfo/C9tLdtHskqNpZ9L9C3vM6ETrKunNQunNZEyflASTNLu2oMHXrpQbuvlBbOdqn8xaopthXqT87J0uoLXKZXmSvmknX0zORntNZYLpf44osv8NnNm/j+h++xPDlFpTWapsV6vcalS5fw3/773+Li8TF5lFcVqnCOM3U2y+ess06z33dWjY+Y6ufRXvS9810l+q2eo8/JVAzdv+uc5oAytp30OQI76XDEameZqKLkxR/6bZ0/U0zRrqxtQ3pPZ6N6N0itTYvGh+F01nrvZw2nLUm/DpgYg9lkitpnkqNjRT5UKbymiYFEp0kntFjfYe+A8mbrhNZLUIrOcdLLN/zzbVemxrQmc9PTp0+DJkFrBWfoFIdWdBY7BE0R2jRulZkcZiQ4uA2fVQ/9sI5irIZ3Ree3PbzB+d+YGWenvSF/kFydLe+RDLxzCJqLkpRdqmfbeua1l7aTepUr5WVlF8/4d6Xx9FqpDzvvRfy8aBD7m7bEDEgf0z2GLr3coN3zHra9qF0l5b6JGlP/KOIPhGQH4YpSXhWoAmgbEh0CYGufLvDRo0e4efMmPvnkE9y5c4ckg7bF6WqN/cUCr77yCt799a9x/vx5tHCY1CRla9M951qyJ5WGuRszlF/pl7LHbq4x0vNZN2z+fJ/TV0JYtrRRIiZDHqhn6fPQOymr0yWDGJ+TUpQEWP5O0ndXqnKOpQwEiTASYQJ0KK/+Bt3P+YOdI+nSeuAWHUdlKkr9CpaaCbRZyxT2SQYg9JnOh4ezyIJGWn4HTqrz43qXcxE8t1V8W3QEjM56K/+9adbeIbSC0kDTbuDaho58GQPlUi9slpYdAOdNEpvNJqwNDcrf7WDhWgrMAsCrlxFpgVLMwsBphYnXvOVHqeJ77q4dCcb5+Om3spTdZ8fu2z/bGMwEgBWCilu+vo6jr8NgnUPXuaR7tCusjC196nHZj9wJ1D8I5aJaPq0j1ZINlZcbtNEFxRKhHkO86ad+IChxhX33ltrts0EqhZBnlV+Xpz/0u6agDazm42u6MqjqGo8ePcL777+P27dvhzSay9NTtG2Lw/19vPPOO7h69Sr29vfpqIvWMFVFbQT1V1e1FftX5lzPWhTXka3n55FahwB8l/4OcevP62g33A9SIf/cpSRxpR7ESkiLEQAJsBSqqg6fo8o21g3lbboKyV7hdizlygCCtAkArOoVYO9t21prVEqhqgwMO52R2IWYspEc1pSmSGc8vhS8FbRRgQONb5LV4gpwrd+BPk1nyMqls7EgMNF8fTaZYFJXcK6FtQixxY1W3olMwbkWqm0S+iGjDLIDG2XwakJY19wBrjdFKnwUOABWI0nsIz3u5TvJ10QO0nKdSEam6C2OfkaxBNLb9lq4j1XeOlqnFcoBhWWu711KGUPG7fdia2Kuhuz6fLPi/eL3Tkk9ns7TL1nS9mUMZ1VaUHw9vW/3dgp3gnnCbRJhCph8ciG1KxPnHp+dTGpMZjPcvXcPH3zwAW7cuAHnKMjCyckJNIA3rr6Oq6+9hkuXLqGeTMihx0cpAhMyVQbq7li6HGzfpssGN/DT80m/Y377OdrYvgnPVl5kXWdtX+4JSYyNqTCbzVFVNVarVQLYSb+9pC1JWXq21wXVnwPF6m5tG2KPs6MVgBCwpPIZqbQhm7s2InuUoaNgnIpTMhpyHDwWl5B90WkA7LnMrLO0Y0fGhdkNDa3Is5tBsW0a1D7DFpCeUVfeK51bdc7BKO2jngGtatF6DcZqtaI82T60K+/rkGgkl2rBW1oF73ilVQLYvOflO9kGvjkTr712Q94f5zaNWJbTiz6hZUgSTd+PCsJMGAMQj8H594IgePW5kHF9cvbK7Q7Btux38R5pzh7Apg4tcUHl0wv4v3ibdkkNMZZwd6Wn8erv/vsIrIc4tS5nG6XZhNMVG0quVsq4NMXjx4/xX3/8I65fvw6tNTberlZpg3d/9Su89dZbWCwWPqiEgamrkMyAyY9ss3/MYoEWNl6Jiw6/bZ257VJsH/c+dE/ftbFFPpu3xxKPUj5j0sh2h8wrrNr7OYB76P2Mtf9Za0Nax/V6nQQdkTbXfC3BpTbhQIA9QLeFYzVUhz+S5ffBZDLp2E61T7QBbZBn+OI80FprUqszAIU24PsRvzuXbLPExyMdG49bAY5iizPYTmczKGPAmoYI2jpoybhRAwLWyWSCTdtgs1yG6HBKayhhWlBKBb8CnnN+B9baANxaEQOjfawFrTWsc2m6zPCOdQeY4/x3JW/5vestnkY9y99nH2CXgIiYK2+y4DUQFORDTLMK2dGIZqZtxb8xYhzgwGlqh2jXkOatuGdHbOOu2ls82wPcve1l5aUGbS5nJdpyUdLcPI8UxdJ1/B7rKNkN6XYlrnEkIQcEwsN2RK019mZzQCl8+913+PTGp7h16xYAYL1a4dHjx9jb28N/++u/xuuvXQ3naU1dQxvvnMPORUpuzlSFmc9P37yNuQ8Dzyuk83HWMsxwPH99OdHJidaLaDeCyAs2RWyZm753nhNn5xDCYeZOaCkox2s0IgAWlANcxzE6gByohFqY1gTtQO2Jbg4a3bY4U5UOWiMgSvdV5rNB3tdAlATTufGtwMEDmrNwikKaKsQIbDw+Vjvz3Cik6E+OeA7KhPhfoS1rHYxSqKZToDGU58NUcCKoSuuTuJBEbgMTJAPTaBUsvsk7ZGfVElMe6I/4XjqyJdeAjC7Hzol54KVdinynco95WI3DicJn0DZ2fEyUF+C0CnZw2Qa3g8A4yn4wI9npoWfmhhmOMeMbW0pGstK+2sYUvPSgPSjpDUxs9970911ejP+WXCvVLxccg7b2x0+05qhJZAvjTeesRVXXWMznePb0KW59/jlu3bqFH3/8EU+fPgUAPH36FJeOj/G3f/u3uHL5ckimUE8nKcD4PtG5TRX6NWa+8t9HMUU9F3PQLpWS81ff+y3163ls0KV2JKFmCVtKU7tKyt3+tYW7xtW32zpN+9AP3DFrFgP1bDbDgwcPkvGX6uq2J47AKALFnElRgdby2WtBt32dWnX3Oq0lDcqvTVJ2rWPsAaVj+FC2ozvR9wjYbNFG8MaGIqjV0HDKEFF1Gtqf6LCuhbUOk8kUgIa1DhWiQ55tLWXxcoBVdLATAJzPDw5lYHQFM63QtBZNS+exlY+LzsTXWsrH7diu7UE7rj2AQ1sz4U+UwKokHZeBunSN6vDOf1Jz0blnjA03Ld1nJEiraC+RYyI0FSDP94OAm+eA50chZElTrkx5SvvgRZTSHKRaBnkv9Y87mGuCVRqAsLe89KAN9EsR8u+LtEV2n+86p6VEgbZR8hKUsC2B/woHGtBxjslkgsl0inv37+PP167hyy+/xHK5xGq1QtM0AIC33noLv373XZw/Ok8csNEh97V0QhG97Wy20lwNLeSfS50b+jgAyEPfcyDpq2uXPmy75+ech5+z9IEsEWgDpVpw3t+qqnB4eIi7d+92nKFS9SMVYkaZWQXgRM45L8HIWNosaSuqKDpJAqi0gVGKIoY5AlXKe+X/sQpZaVQ6JrmRmisHrpzAma+Hy440UHwWmvc0a7pkf1l979oWgEJlKGSw3OvMlFhnAZaMnSLvYMce+BSQpZ7UcCcnyM6gJevWKsSc42KfOmuhnZdOtT9ul+33nPZJEAc4B3f+NzL49DcF6XDefYSgNMQ05ve4nOXwuN2pwa+XIFk7f1TQfw5tdB8M9Uf6EPsgr7nsmuzriwN46g/VmXQvbUch/TtQfgGgLV9ynABgvGRIhIufT6XP8X0Y+FWl6iggJgmIAQy8+kkQi3o6QdO2+Omnn3Dt2jV88fnnWK/XAIDWtpjNZ3jzjTdx9epV7C/2qA4T0w6ySlzlg1JiDajumPN5O6s0eZZyFqmR+9gH2Lv0u19Tkn6XwTY6NrmBDf1zcPNjyxjHH2njk9IZp3adTCZ49uxZQcJK55xwQ9QrrltHYTjlkTBr2ygBO5KMbNsGr2GyV3KaSngw92pbpVAZjbqqUFUm+G4QAgnJSpjAgsuZiz/GX7TvLzEsiWrYaNjWBpV00zaYTCbYP9iPzLazSDRKjqRrqT5QRsE6i3WzRuNatK718caFxkKrEIfcOc677cL5dcYn5zkOKaUKyp+ArfzHdI9pD9PO9GiXH4dmB0D5zzM3+TrLHNES+76KkrBMUsP2Zu56eFa+vNLyVVyX6vwcril4L3RGf1ajM6MQR6GSa+mnTH9R6Ey55PQnGoJEPc6F95m0oCITGPqwhZa99KDNLz5+579yYCn3lkpg0kZXDjQQ6+Z6XOf+EjebllztxHtYwVQkMzC3OKlqzBZz3H/wAF9/+w0+v30bP/zwA5RSWC6XaK3FhYsXcPWNN3B8/gKm0ymcAqran2f1Hre0Tl30tg0d5GWqxJgQ/sYoc/6oyg7c8/bi2+zBrrLkd7b2o7TQtbttf8/l6/ye5VGg3Na6KydeWkNcBh1edijjGInUhi/t9tbakI9dOqPR86mEwh8YqK2nlZoBzEWHvlzVylm3rAddpTXWbYNVs8FcKzhoWK+61hrQcDCKALyqNIz3KFfea5rVoiSuCVAI0jRfouAdDoB2LWkGPJBBUdQ0pX1mJucoJWalUE2mmMwmmMwmRGVai7ZxCZQppwBrYRWgNEnNDg5WU+Ie3WpsNmu0tvV9I12302TXtoxXYpsq56CsC6p8ygam6Yy7o/atAqrsPcp3rpRFCDyjorCQS+NhXWspYYtgTLJe9DO8cY9wfPqucMBBFIXrWWLnVvwufdEMwAUQVUpFk4QHPgvlHdyyTmf7Q44u+qKLdV4Ye9+Y07Hzcyl0B18PUalAlGSP9tFOLi89aHeJWt+I4hTJe3eVwGIZcsDgdrq2H6WUzzAkrjNga43JZIrZdIoffvgBH378EX66cwf3HzyAbVssT0+xXC7x+htv4O2338bFixepJ1pjNp36SFGkHh+SMLfZkyNn153LncDjOYGmr70haTu/Z5f+jmUESuYDyaidVZrOx/B/RiqPRC/XHPBnDvbB3s5a62CakY5Zcr1FVXJknCjbF8pR1VT6DAUuIdA4PT316vlzFDHN7z3rHGqtRdzx6HCZM845mORTS1KZ779znA83SJky0Axf05Y0BlpTBrL1chXsziSVm9BPpVQ8zunbbNsWp6enYb6cI2dUksoVXBuZ66gFcGidRdtSFDkJrs7Xwx7jldIxNLIYp/gS9qikT0Xbd0iFGhFP8Vgy6bCXAsv9IuooMabhs5OjH6rfJfQ299eQmgWHvC/D+2x4X48XHrbeh614PKq89KANDEvVVITNIHku+Tayfrp3SBrkvZAAs+JY4TFofyAuUCFfcD2Z4NbtL/Dhhx/iyy+/hDEGTdPg5OkzaK3xm9/8Bldffx37+/tQitSWlQigkC/8stQ/ZhExIfdCytDm761ityV4Fgn7LBLoWevIAbXEFG0D2j7mou/3n79IIKN2WW1NEb4obr10QOIAIHF9pdIa18HjYWCXElHOVOZDJoc/isn/6NETOKdw/vwadT3xtt3Yb10Z6CoGKkHhLHMyTupAYSY80+LVw9LmzgyBY5U+3wtLanlt0CiFjThPzSYwGJZYUyBx1mKT5MjWMIpU4kprRpdAR6wQspzSdE5cR2LDanS4GByHIVa+GwZheKetonOfAGx5lI5pWZgfD9xBgpbz2QN2+TvP7yuD99loSS7lByMI1zei2qLtPdcsdR7y9yNfh/HHjlltoDO70IWXHrTly8lt06V7AJ4sV7g2hph3HbjSEu1EDNxsIyKHM1AAf3gnGn+MZLaYY7Ve4/onn+K9997D/fv3MPGA/PTRY+zN53j317/GlVdfgamqkPCjqiqKvsRpFJE7mQ2NpTyXqQ1F9S9MDIPU0G99HHZfX3cF8G027RcBlvnaG7Jt58RjTL0/f1HiHwBEO3PbtgGwAQJqjsi1Xq/jmWKlYIwDwHGupZQ21G4sqZMX/cbnjJfrNR4/fQJTVTg9PcVisYj3sQSoKQgLg7aTTLUjSUoBMclGX8c8SGLA3BHqVTSKyhgsFgs0mw0FnvHR0LSKAUycoAeyDqXYJOYDuAiGRmsNVZngfMZzylIiS/vwzlcc0x2IR9E6b1rUEblxjsaIoK3IJe6u01lGK724HRTZO+zfIQYWQFSZS2Es36sFOa24nx18VrTIdOugychOUkgGs9Mr8Q4LJEMh6mHzn1Wp/+LXLuvTbXNbeelBW5axtE4uvrghuinohp7tuyeCdaoSZ4cZ5Te7cghqNWMM7t65iw+vX8cnN27gydOn2JvPUGmNzWqNC+cv4J133sbxpUuU5KP2jmYesIO3r7f15apA5TfVWcu2+TgT2BWk91JbYwmAvN6xH215Z/K+vrGUpIXSvduI07bnhojY9r5JAC6Ri/Rah6Z52zRL0k3TUFjc5RJfffUVfvrpJzx8+BDL5TKoiwGgaejoE0fuYsBlAi4BQKmY+IYJZ9u26dljf++6abBar6G0xmqzxmq1IrW6pk2ktQraquANrWW2NHl8K/4pjd1POKuV0hljidVL0Kz9qgwdA5vPZjBa4+TkBHVVUY6AKEaGd5JrarQQMEhqNf4RL8U21BfrRBjTtg3SfhijV1vzuq/rmtTimekmMPM9jLxSKqwgpolk866CZ3nfHhMW2aSw5C/nFOLOPmk8jM0/YxVDGpL6+CtD7CCtgmQ3vLkik/Z5f+rEV2p3JjoICzs/iKDxOWv5xYB2n7qiTETTlxHv6QeInPPuBw6hmuIF4Dc6XATuqqqwmM9gW4uvv/oGf/7oI3z2+S0oo3F4cAijAGdbXLp0Ca9fvYr9/QNyNKtrVBOZSlP74zUy81e3/xEsEgVWz2yWxnV2SXSX+8cwTNt+202rsL30qcKlhD3EXPSpB3ftT58k4n9F+j6L8kGx3miTjlm8AGBvbw9Pnz7FH//4R3z22WdwzmE6nYY0sDR+BODlPrZtC+c4dndsMzgEKrZx2wSw5Vq11qLZNLA+nr5tWjx9+hRN0ySqZ5kjmzliqZK0ygO365dy8j0u/wYhT6Vx2Q17vLuYMa9tGtSeYeGQonDOS3ddlai1gqjzvaJ/lGCFQNtZG0A4vDf5zwOXEers6PGdvneO0Z0AufzdP0eAzQFqWFOQrzPuCQrXxRzLd8BPFehU9zkB9oVbCGCjhpHrCu/QhgN8tDYcdSTUqnr2pxAqOrPusntL/R7cq/GezjWgI3TtWn4RoJ2qbUrXtz/LBKj0bCRQaajGLhFPuVqpXtKKHVlIutZa4enJKT6/dQsff3gd337/Ham9TYW22WA6X+D80UW8cukyzh0cknf4ZAIjbHdEtMjut30DsH1aAruct6IipzhXo8H7ORbeLuV5Fvj/iTa2zVuJ4diNQerv2zb1I7x3NByl0WQQnc/nePToEf7xH/8RH330EQ4PD3F4eBiOEqZH3uJ6ZxV708jjRDGKljEG0BrOq9qbpgmhOCVY8rVKGygHbOwGJycnWC6XJG1W/my2r5f2QyR4CThmU6R6pN98npRSUB64SZLVlD5UMAwWFnVVY+KjolUBtDuJs5Grjp1yQQtLfXcUGS2sAf9+2PRiI2AwA07PONjWBUkz9KEkSSvvQyNpFFL6Rr1NfRRCaNkwlmwVcV/7igBswcL03x/myDMLW/YD961Ek+Hi2hLCdaL96jDg4cauij3ljUfSBZf9DY+rMHeq+/OZyi8CtEulX5rpn5YUyMbVydeVijbsCNRxcwN0JMuYCs9OT3Dv7l18/sUX+PTTT/Hk0WPs7e+hqiu0TYPz58/jlVdewdHRIWb1xAdLqaDFZiQCScTHyd0wPCs9a8zXEzatZErGqXJL89PXHW6jz6Y9VOe260N9fB7gHZKm87ZKkhtfHyN1910vA0w3utjQ/enDzqfBJMLROgdlNObTBe7cuYt/+r//Cbdu3sSFixext1gk6TllVLS2dWL9M+i2CZPLHud1XcFUdZJXm4hpPDPdtvHZqqrgnENdU4axzWaDtm0A1OTUqUXazRSZ5UQksmA0W0p1dc8UASF2gmUtmtJwSsMph9Y6mMpgMp2GzFohj3WhcmmvDFJ86IuX/BCE+6TfCgTo1s+ns7lUSWBrtA5pS8NcZIwhx4lTACqlPTjGeZTAHtdiuialdpNpZ77mSApGR8ouybClK2VypRLVf95m6Jef4HAqAN1+5pqGZN/5e4Nok6nle/uX1SX7U1pmEndcGN7/D9TjsvRJwrlEmdxXwCc56fJcbn5P+s8Fr83ocQpUdY16MsH9+/dx69YtfP/99/jLV1/h6dOn2NtboJ5MMKlrHB4c4pVXXsHh4SHq2mBSVZRyzxjKxxsAG0Hlw/1whTEMzFIBlEuLd9gR7UWW0twO3bOLJuVF9mvMfUOft23Ivnv6NCj9xHRMv2lPWGcB5aC1wdfffIN/+Zd/wY0bN3B8fIzZdJqAtDT9KBVB05gojeXOZc75jFYtvNdy3Ftk+6N7NptNyAEt9xy31zQbNM0GWu8FdTIQmebSYnWCyCPcUp6bfO6Uf1bOciAXivb4xrZxr2dMInuBc9fYGa4ENE5ZGMRYlfH9ea0Fx9Zmb3xkzIj/pGw0F3C2tNSpTJgWIP0MOI579zSAHFNfcYUEMHIOWZWtoDraD1FJ+rUwV1wnX2f1eFKhK9/LMzU0tpzZLtfTaUbeWf7G84CUdse6hgWMsUD+0oM2jW2sNOWXdpiveLZvmGeKdTPAJ5yoBzZa8FSVJGyTyRSzxRw//PAD/uM//oNyX1sLbRSOjs6hNjUmkwmOL17EpcuXMJ3OMJvNUFea4icr5c9eI2xGsGQhxhIA1vHClOMu0rPsWhlcyrCez2rKRw8RRn5IdT7z+3BIz8F3dFL99T5H6Xf0StsdzwlHopvWJUis8kc9ehjGcj+6beQSffzNz10i7TFIcL0ObdvAWof79x/g3//933H79m1cvHgxhMOV0nXaJ3pnSnNkP4R7mfjR2WFSm2+aFq2Pr8zMp7WW0nQ2jWcKDExFjpWshmeV/LOnT/H0yVPsLRZo6xqcMMRDdzbbop+KVN3iSvJXeVX1EKOYSJ6Kgsa0lmKGTyZTVFWNprWoa+/Y6uciAfzwN64NWhKFdv38wroQEQ5K+c8KFLkt2meVoiOlDMLW2QDKJYmS/hFIQ1F9TMs6403etwIFi8pze/v11sM0cgxwFp2KXtLZlunuIKHqluMJyWAyISz0RYf28vHkwph832eVeDuMQsCp7l4UT3WunKW89KC9DbCZSEpwz7BMVNNVdQIRgH0jKWj77cdca1BaO2DTNpjOZjC1wXfffYsPPvgAX3zxBTabDSaTCSU3qCfY3zvApUuXcP78eejKB7CoDFRV+dSDFYhhT5NKOJ99iMcelm3nHEJpUZa1DjlwW6HXYsKYcLhBZZRxulCQUZPyonguk4v5olWFjRPHG8fW20xSUnWo62zebg/LIM2qzG3t0nPpvMS6ImgU56JTdPGWPrU925nBUixbEQkJ+KZwttdah/V6gzt37mC5XOLSpUsUac/RkRt+11LTI0ZKYBLGmPp0WGvROoumbbFeb2CbFTj5BI+BndHqug5Zs5p1E/YZE9eT0yWenTzDcrXCYj6nmVEqql8FncxVy+kEpuuf+z20LiRgEwBpOND5DycfpgAAIABJREFU68lkCq0NZS3TJqxlog2x6aAi9f9jdtQBaOGdzpSC9mANAM6DNtOykABDa4CD1DgX3rXSxAhVLjIHEoBzT35AwSg+JuajnenCe054Z6lFofVDknQPHfbSjOVnSuCUbPPAUcbxdd6YvF8yQlxdRpucC/2mqrdrpBLhpSTx9z4pno1DKT7gQh8BiqzzfMD9CwDtclGdDSrtXky0mANS4feSxNL5m20EzZK2IdBmyWG9WcNUFe7du4f3338ff/nLX0L9m80GajLBuXPncOn4Mo6OjkiqMYoc0rz9O6j9OmPq9qs0B89jG+nUN9CGgqBM2TNjVEh0JQf98vji9VHd7jyXq1x3LxIOzl4iI9iVtLM7t9eBfJ78+AACNEXqZ8XtIZ7rbZoWm00TgPPw8DDUZ/25Y+YDu+9CQxl/RjowjnQzS8nB/0IpNJsW62YdjigBxBTXdU1e2N4eTOfD6XdjTEjhuVot8eTJE6z9UTDJTKey89lKSQqj2UTS3xz8ptMpZrMZTk5OEimQKY7x79C6KIlyfWzfd9oDp0PyO1fE+4Pnjs0P1jkEOdJvw1wtzv3No50pb6NXngkoja3Az5fnrm8eaTDJ9cjS8FzIOkRNPB+BR98tiqUTSEnfY5tl7dRYLRo3MrYP4+jxmfshyi8GtIdfpJR2SkSuO1EloCipl4xSPsCDTx3YEqHiYAvffvcdPvrooxA7nI/U7O/v49VXX8UrV65gMd9HVRtUtaZz2D5XbeR0PdPhdNy8TKtKq0ZI2n2At+1a556++9n+swOAsYai77dtz6b3nZ1Ey4hXWSvId2Pa3vOCNbchPo8iRJHpKPdNMiRZeAfm+AUXRardFq1fs23b4t69e7h//wEAF1Tj2j+UqyVZ6lSawLYK6zUGaAHIsUwBsA21Rb9Rm1VVoa7JPMSSd/Ao9xKWdHhyLnqcm3CETHlByoV5fB7gHvInSFSnsNCVQWV9gp+avMgpaFJc4cSTuaiuZSk7qGYBCA0WvyIp4TlxPIy7x8fmAn3wT/OcdgBa9D2COAscAAz9Jec+nsqC5iu54vuiWPChAScMMjWaz6hn8Lz3dEDtEj1TSB12SkDbfaxU5N7r01LtVHZYaCXw7go1kvacTep+uUFbDUkafM3fKB8Kqs2uM0JeT77QuU4FQCsXABtAsOUZY3D33l3c/uorfPbZZ3j06BHFJl6vsV6vcXR0hHfffReXL1/GxIM0SxkxbjJAyUxM6DWkuktwj2nnXXnh94wvLd1wr1rMXfEppbbdUXiEDQnFX0P34z5+zo0lSp+qK2Xgyu2lau1xJXa9DLilbdtTk6izfz6kNkkFIOu2xEDgHEKwkJs3b+GD9/8IALhw4YK3dRJQyhSYSom8yloBIK/yykvbrHrm42MM4M4nuKg9OBttUGnhbe2lR2amtNYBtOn3NnzO1ykPkKXNF1VySYmBUkFBGwPr7fDGGMznc5yenPq5BeBsYGxiZxWUcuH0FjmU+T5bAndOr5mAdlClRwYqMdl4W7KuNExVERDngWeQAnb8rEKoVQZyrVRKRhg3eY7jsorSMfOe4jkG+fyVsAQ8rKJmvU0E+HivfPllRjo3bQw5lu2idUv6OmKt9bXNPe/VRRaY8THlpQbtXuAq3duRzLpEtMSNxs8Axw7W4jeWDpjT1lrj8cNH+OL2bVz/9FOcnp6irmu0bYv1eo0rV67grbfewoULFzCbzUg1yCEYjem0LV9WV8ocZ5cpz0NfKSwgV7KJ5/cMMz/ZL8hX+9CYtvW5T8WV97lfsh5X2Flpt9KVVGT/iuAT2utKJ53aS9x7RjSpF9R3GaaUvbSbpsH773+Af/+330MphStXrgRtT2CMnQvnhyVwwxgYU3kAjuDgXAtjTMgI5hxQVYRdumVvcgoaoryk1fpgK4AHHH+dx9W2Nhwda9s29M0pH0Rli5S9C1HueAmH9aS8d7WDRkzYwRnQQrQyF5+JjISKoGf9W9Fkxw72a+fghC05f78hTadjm3KoHFY5CsA0qaHE8dDSP/kenY4JV3IVepwU+OOB4oL4HG/N5jhhWMaUXAvnaYWygg7l7wZF3ncsLiRmkLAn4/vg74mWRTBho0fWwxhInxNJH3hQQ5q1UnmpQRsoS8Xl4vnUDAjyl5F/jt9TO2jOrbLzzLfffovrH1/H7S9vY71eQ2uN9XqN2WyGd999F6++9hrO+SAVWuuQ7CPkAM76wf12EBs0+SvGwJJVD1e221yNK3E+fJ962ht6fsw12VZfP0vcaLoJhurqL30c+1hGSUroOQEYX0//nAzVkxMgLmQjBpbLJf70pz/hj//5R9R1jQsXLmAymcS6PO3gc9QJ8ffrvzIVJbvxHt6s/mbJOZdUndOwNobmbHwWsZAvmplkRHpP1wnMlstlkNyJ4Iq5HjGTZynEuBCcpHG4Y5nP5zGzl7XQvB91lBN5jJQGNDoqOQW4VqrMSwCB8Ls8XsU+A1Ki5kkpSdi5Y22+hsI/iPl0RAPjjaCUo/B0KWCY6luqnfksSo9enE9gOwShyWjiji+e2iygO7rzvO06EGntmJKPN1GPKw/c4d3zgHajM1xeetCWpaxCiC9a/lSyz+XcZfweHWqsDyfIzjNaa8xmMyyXK3z22U189tkN/PTTXbBNerVaYTab4e133sHx5UuYTafQWgcbnjEmZM9xiISN+pgRiPyv6Geukip9HrpWmst0DvrrYAmks1sLzbA3MDtH9ZXxgDj8/BAwjwXunLvfdROl9z8frMi6evvuGSiF9D0CCAFKdGWwaRpcu3YN//zP/4zKVDg+vkwmmkzaUIAPqZm17yX1qqqwWCxQVxUFP/EqY+c2CXC7ACTGr20CH2stVNvSsSwfPpynvETctTKwLdC2DnA6kDdb3P/jJex8ntO5S48gSnrBGov5fA4Hh6ZtwKFMHRzlvlapNMXzYf3VQI8S4h0dzorjgguTZbSGczaGTwUSyTmXusN18Z3pUd++0IX9rVh1EIDmbHOczK1swPsCRAbOdcmM6tdWddvkenfTUu5ER/N9UtSGxZM3vDLoGjNjZ7e3v9SgnUQXEosckJNWivKF8FmCdwnAyV4tncIQFvdkMoFzDj/duYsP//whbnz2GVarFeq6RrNpsFwucfHiRbz+xhu4fOVycDKbVJS9S0rrify4A/dWvvYiNs/ZS5jHAZZ7SJoeuiftq/Lcfxmgzzamvj7vPq+dGsR628VGJZ8f+s6FEkY6aCcls5i5q6oqLNcrfPCf/4l//dd/hTEGly5fQl3VQKbCt7aFLghPgdB7885kMqGY5FqjMQZN24KlIWtTaViBjkg6bcBJSqwlpy4OR5q3EwFfozIxoxcfnfw5ypD0pZRKzkCH/AIgBz9jNHl1c3AVKTAgsrgaCq1Xp7NKHYie95KBSuzYikDMWUv8hFMA5ynXOmjuJI3JQTzEJxf3yDEWS8JsBzVM/PrcewQJJy4pI/H6LjaVPNcVGrbZtLtt99OkXk3dFjqWS9fFz8K8UKINrKkbSy9eatBWSIF26/2ZBCGvUeEAJsg40xTYZ9MpptMp2tbi62++wccfX8fnn38Oay3m83ngvt966y289tprOHfuHOrZFErFDDzc9xLBcbzZC+MrjbdP+trGHfbZcUp1bwfZgqTdU8ZI2lufj98A9GlZdq2rey21d52BwQk0bew8xna33dffD5pfPl4U1NBeAn746BE+ufEpfv/73wMALl68SMFQYGF0Bee87RsUJc25uCZlzPFAdKxF43Nuc1sOJFFTn70UGNaZ91/T2ptyo0Rfmp5comWGeT6bw5gaSqcMPM/NLrRheE69nVV194wWe5RBe7lcoq73g/q0AuTxYG4pjNmo6HAl6+bCTEuQzq2Fsy5Jx8n0is+5M1PDzET+OWc28utSyxJnAYUXFJnm+NvZgFt1PlCMAObLuUccayAVdqItfGjvbDvylTBGnWe7wK0La0tl95TaiIAd/58/o8J62422vdSgXSqlScq5sBIAxs/dc5gAZ+5SqOsJppMa9+7dw9dff4Obt27h4cNHaJoNZrM5qrrCbD7HKwf7uHR8jMViEVJoGlNBgV608QSNF3r+ommjAukLpb50ON2MGy2B5zZwyq+nYNxXlFdz5ps1zmXvkwM/Ssmi/76zAX5fCQKM6tu0fN+L0UjIDTyupHPLdRSfdz5Gtcyi5Yneyekprn9yHe9/8AE2m00EbKEBCHZXf+QknC22ESAABE9v6wOnKJ9ne71e+zYp5kBrXcgLjZBCkqJvae+QFdacEF5yINY6Mnt1PcHB/gEmkxobt/EAilT4CyJtmdEpM7hd4FG+MucAPuMOf3KE+wwA0+kUFy9exJMnT7BarTCdTD2QpOpbdujiaXXOz7HKPLpFUVCwnO/c2/LhnA/qRE57VVVhNpsH05vm1JohxWb8KyXvvmxg1LA4OqiknXuYLmwrTFeZfg1tAxmuVYI0/b8YpqVbh1A7d/tR6J9YB0U2bgcQHWK0VfK7C0xFOj9Zz7Y0/YsD7RI3BGgxCV3Hs9L3khflbDaHtS2+/vprXL9+HV/cvo3lcumPaxlMp1Mc7O/j6Og8Dg4PMFvMQu7ruqqD7Zo58rzdHKQipxW/8zjibbkKaPxc5QuvvBDLfes+U+rT7gC3TeLcdbNs45p5zuT66N4/usnR/Rua0/56ymMBcvMQeWVz0o7pfI679+7ho48+xP379/Hll1/i8ePHOD4+TmKKK6XQ2sZ/J8DmeWLvc+UAa3UAbOccNs0GZrNB27YBtFlS0FUFZS3gLKzH/XjQgJlTL71bDtLTNVmxpM9agOl0AlPTkbSqwJA79L3N7ryl15mBi2fOw/gD2Frai/7Im/IAW1UVjo6OsLe358+mK8CpEMfQhXmMdv54okHBKUsRFb1EyKIGn/Fuvf0fXp2urENVGRhtYFuLelpjOp1FqVobGMXpNU0icUfJW0cGgQhMtuAlM5NEx+6b2d655kJzHkc3BER80M35qp3zUd9UrKe4U5L9ndPI8m+yr+xzF7raM44+lmGIKe8DcRbSwp7LtDpjyy8OtIGSBJ3G4e6CNH9Oz6ECMYDB3t4ejDG4ceMWPvrwz/jq66+xXC5xeHgYbGtHR4e4cuUK9vb26expTcfAjPcS52xf+UvIJf/oiFZW8e3yAs9Sxkjlz9uHkpQzBGAlh5Wh/pRUUn33R2Yn1Vr8XOXsczf8nFTtMahOJlN8++33+B//83/ik08+wXwxw3w+w8HBQTKv8W88UlRacy5fw37umobAfr1ex+AnRqG1LZxtAxZorWDJdZqOe6nt8yGZaEDh4sVjXLp8GbX3KQF7SAcboyf0WzjY0pqOgMLrp/t72KdAkPy5LBYLHBwc4PT0NDwsmSn5njg1KeAZAPgQpmJurWWoF+9IkSpeGYOqoqN5xijsLRZYzGchVkRIW8pn6n1f2NnMGAbtzKMc6Z6LDG34dSsoDc39i6Qd+bVttCT/LR/Hrpq0Pr+doT4mn1U/1TnrPL30oD3ELW0vTgB2JA5S8nXOYW9vgdVqhZs3P8O1a9dw795dOOewv78PYwxmMyKCly9fxsHBATnL1BW0MahNFRLTD3J2PxNQdurYuYaxbYxf7Mwtj617eNzdts9KSHKCvWuR73LIt+D5iBbX218HA8JisYdvv/0O/9f/+l+4efMmzp8/730uQHZgD+wxRnibgIusiwk7CaEkXTqtPGAqD0AUDpUycTXeEzz6bljV+tjTXupUFpxatFR4P3L7ZE/XeMM7dobY92wwdr7nTsF14u/HOvPvYwh1nyasqiq0tg2hVieTCfb29kK2snRoLECkgkEIRxr+T0fitOakI/R0h5m3nHfcYj6d4XB/H3uLBWpT+axdnLq0e+5aCgjDTmgq+du3lvvMDttKn9SZtJ9FeNzmtzPURl56+xp5v05dZzGR9c2PSzRP3f4MmwjL5aUHbWAMp56+ZOb6c5BWShw3gcVkQuEVHz58iK+++go3btzAs2dPMZlMwtEYADg+Psb58+exWCxQ1aSuquoKWpngJT4kMfdd61scu6tV/W/inoRvHuCat3HVQ/16ERqBYYYsAthZOeVYT9TKyJ26M+c9gtM/y0YUT+cthvakBGdMhcePn+Bf/vf/xs2bN7G/v4/9/X0Pzj77E2KQFfbaVhkBiX1VUMpHLzPGx6mmta6U8o5u/K+h2PraeZUs99FBOYsYGCRdVxEYxciE5qBpGly+fBmvvvoKJpMJVquVf87TWEUIF3yNBvZIH+HnNZBLbn2FpFUfc6GqKDtfXcd3gahop/mlb+wAxnNnrcVys4ZyMdUp0yf5Pvhv27aAdZSjXJNj3mI+w6SqoBFzgIfoZgKco2o8O9tdmI8UtVJTWd8cjpGyd9pXSnAuW+rN+zC2X7KelHmPqnupyQp1j9jHW9vNVPBno2Gx/CJAu1RSzlIQAgHYktuUnK88vvHTTz/h9u3b+Oabb/D48WN/zrXFdDrHuXMHODw8xPnz58lrc1KjqoxXT1VQPmOOJOT0sfSic4my5NF9NikwqXUI1IvSfpdLlJt8Z+ZBgRx4ChHU8ufHLt6x970IJuJF1D2GMWNwHVuvVIsDCtPpDH947z/w/vvvo67rANiB4Frrg35Eu6o8bsXt03VWwcaQozH0LgUVIsmyTUKXWh9gparyxBXRj0AjHafWKWhxf/lkxltvvYWj80dYr1ewtqX9hSithNkUhP6s7307MwsoR1qEqjJgP4DVahmlZ2tDBqzcKa5t28Spr/LpIyWg58DOgM22bQcHbRQWezPM5jOaN5AjojaG7O1CQJGAbTK1ed/4mSkeK1AMlT5Jsre+oD7p61u57l3AOr9XKeU91j0TOPTsljq3MThA9BSg+7rPjhmDLL840O6qbwAGQClZO+fChsgjmyml8OzZM/z444+4ffs27t27hydPnmC5XAZ1+KVLl3Dp0kXM5/NgQ6pCOFLtJRBT6FNp4cfN0ad+ip8ZuPsJUr5ICloe+j4CwJ1DQjj7Jen0rOFQkarxvL5hCYhHc7ZyFi72RQJ9LoWXJG7Zv1wCykuUvFIprJ5M8Jevv8Yf3nsPADxgR+JMKtW0jggygDQb5dIZ98sYg0k9DZ7nBNp8Hjx66lrr0LasxYrpH9u27YBqZ+2D3vZyucRsNsNvf/tb/MM//AOqqsJ6vQbgkE/R0Nz23Tf0e+/zAJkJnPSLATabNU5PT7DZbFBVFR2za/kYXPSil8x4LlFLoUH7ijnLGancFaz/boxGPa2xt7eHqqpIa2JkDgNiguSRLlaZDwH22PnogmMULMYCZ6rR2V6KNI9+6NS7S11yDylJp5+T5gyX2FYO0n3zt21cLz1olwgxL1bJveegLf8Rd6NDsBQG6/v37+POnTtomganp6fQWuPw8BCXL7/iY4dPyXvTn3OsRLxfrficNfXJiX7JfpY+jxh18i0HuqITRPZUCcj76gQQJCgj1P2p1J3WmI+1M4IRRKDQK2wD7THA3CUQLw6Yx9jbxtnW+9c22JNbxXOnLIFpbXB6usQf/vAHfPfdd7h48SJms5knjMJGDWKeZE5r0Ypn0IgOWuvAJialFCofIEhrHaRqPzJIr3P2qmZiXlW1PzbGEdPoHG4qxZFzFJdms0Fd1/j7v/97/O53v8PR0REePXqEypheSciRd1gnrfyuDFvv/V6s10qR45iO+2G9XuPZs2d49uwpqorU5Gx7bv3xuJw+tW0bhAXnHCpjYBvvc+5BI2ooHJw/LlppjdlsiqPzR5jv70EZ473zNaDE2WydntNmj3HZh/59x4LC9nmJmeWsuNYXLKR/vrcx8p095sJUdVTYpWfyNkuCEitGSs8n/RxJOvrHH5mcvvu7zwyXlx60ge5L7i5Gl3CV/M8YCiTBx7WsbXD9+nV8+eWXePjwIU5PT7FardC2LebzOY6Pj3F8fIxz587BmMoHMaiCPYtzCgfJHiDVlDiyUOrzGUeN0svO1ViFyQpPb+sDLxROdkJzFol8aUP+XCUwP1tUZWP7E9Rg4d7nd0TjerlPfcRmqH+D9yggz73NEeH4/rqe4C9/+Qq3bt3CYrHAbDZL1gOntGQ7J581ZiIejyKxjRxgELbWAj5FpLMO7WYDpXVI9EGObKm9mp91rQVaF4ahKYEXlGVpmbN3AWwFXi5PAAC//e1v8bvf/Q4HBwc4OTkJAYmUUiFBR5Dt+R0qpItlBNGTklZ/kWuNx0n7YjqdJF70mw19ZvuydQTczNx3HMQsHdVrk/frGR8Vj4YZfyrlYH8f+/t7ODjY906C5H1O/+hurTVp/oyC1uRtPh6wB2YhY3p5Higta3pPryAhtA78e599vZ+BGt6xkkZtk/blZyX9ZLJ+JGMvVjneD8jfLaT57SD+y5a0VY+qRCwWSZCilySro1RwNnv8+BFu3PgUN2/exJMnT9C2LZ48eQqtVfAMPz4+xsHBAeq6jscqjE+pCb85Wa2CtG/U7O6S5/Bv9ILPuum2SYJRC6EwmUw6RGabNL1rf4a+j1W57fK7BOz4PdUY7CqdjWuvn5MenAcFBCoFCLUaPW+MwWazwSeffopHjx/i6Nx5ilIGBwMd7nHOwSgikK1j6bYC51ZmqR1ACNDCzKvivM5Oo6r+X/beJVS3I0sT+2Lv///PPee+31fSlVKpUiqzsqqynLiqVekqFwZDYxtDzxo8cdkY2gPPPHEPDAbbgx54Ymhs6EHh7kljz9wDg2kMjcHQkLhcJC5XtiorlQ+llFJKNyVd3XPO/9g7PIhYEStir3jsx7k6t9C6nPv//97xWPFa31orXobn/eGArg8vCGnsis6+t27wxnLMhVlC4JEQX683eOutb+Dtt9/G3bt3cX5+breJ+TFGAG02TNm6VHA31BoB7N+R8M55M4pECjl8+uY0uA6np8+cK5uUIDrOVCl/1zUBN2zc7tCBFJcYyJTfW2baWh2wXq+wOTrClSv2BEZNd5SbKuHzpCT7/D7tNJgO+6EsX/nUngds/z4Xh3/n59LnjIC0nBl6+FJ5S7Ihla4xuFSwnnGqnK3tXyn5k3ObS3S5QRsAPx6RSCltrAjAbHsIABuu067XK2w2a3zyycf4wQ9+gJ/85Ke2Uhrsduc4HA64c+cOXn/967h9+3ZwyQfdf900fhU5lII51cjyBmpwEobEYFiGWot3KNDdt2w6EljksozTadvG1kuc7zRAU40KjnWU+ZYBN+V+rp2/Snf6+jmjUh5z4mVd51DQsB2JSxPL+2q1wmeffY6f/ewnUMr0b9UA6HrTLxu4swKaxri52960a9sqe3KWOa8AG2Xd1Br7/QH7w8HMozYtdvsDuv7MXZhDlrbueyhoNAruhiurVtotXsZl3ugGTdeYw0RUE7TJ4bDH+XaLV155Bd/65rfw1ltv4dat2zg/39o9ywTIyrngvXfeupFtnZCFpJkLPQVSeStbDb5rmx8ANG0D3fc4357j2ekzdN0Bm83GXCVq82/sNafa5kHeOaKu9beW9fZgnM7OhaP3AN51HZpOY71qcb7d4trVqwDglAMNWp1vp7Gaxu3XpgWBQcmSSqIBYpJfaZc41UadFcvz4e0+eX5dx+elhau9vbIfO1uGcbycZR6bBN9xKiHl3fMBANMzoY7NZTP2Pfe+FHzylx60JQvM7E+Es7Kh/b5IAnjSdj/44H38+Z//Od5//300zQrb7Rbb7Rm6rsOjRw/NntAHD1x8ElR+YQdrFAVAaTsHBQDG2lC2x9j+D7IOciQ1NHc5huXOD8RB/Siy0BM1GuQbpwOQdR+CZj7/IA3jIhF5zOWdSjvWRHNhS96FXPhS2jEvUyhnjQPmhisdCUkK1jQNnjz5BM+ePTOH/rSmndvWL75s2KrhtmnNgSTuFjvjQm3bNVarNdpWYbVq0WuNvbW2+866fg8GyAPeLTwr+x0wd3DrxgA2/Wsbc1mIXVPleO+6DtvdOe7fv4e33/59vPnGW1hvNvZObrtghxwNZI2ymqBxhqJQTVtAsUVIJQusHxp7ViXRvbmrq+s6d6jKatUaQdxraG3WGjRN4w5GifdGm7vJbfrM0j4cDu7+cPOsQ3fYY3t+ht25X6tgLNboj3UQaT92nsIyS/UkU73CSzK1ZElmlXMH/hyEZV5kYPbhgmyt96DorcuWsKCEE+/JyJSHCp698JY2gQfX2Bq7zcF1VITbrmiP57vvvosf/ehH+PGPf4zN5ghdt8fnn38OpYCHDx/g9ddfdydHcZd4PB9F7ifuMsqIC7EMqbINaehiMudl+/LNAY1UvjGYZN24BaI5Iym+/xw3+F26CVCvSaMUrgSoPP+5bZDgQMyTVn4/e/YMH3zwAU5OjtHYlct8twS5Zx1oQNljMwFvcRhLmyxBpYD1ytyXqTWw3x1wdLTBfmcOUNHWyiYFlhQEVwdWKCkNaLdozedDl/EA5lS1R48e4Y//+I/x1ltvoT8Au+3WnMtN1DQAuVSjWuGW9aDmMu1RcpX7qMw61BoNAFqHT1MIh8MBSlm3uL3pTDUKTav87WStOeubjAjalRFfYcr5M0pBD9U2QO8VhNPTU7cXntqM+gMv1zhldblpL8o/1yayolSfbmjMlOOkaO5U2NI0sOor+bvUoK3gO2ToXlH2X+PnmG2Y4+NjnJ6e4p133sFf/dVf4dNPP4VSCvv9DufnO5ycnODll1/CSy89wtWrV91AoNWdfC7KC54YcCLNnASXUiP00JF14c34C0h7WrrPaxDwwTvXtV2aW0tRjRVe+z4dL4xPedIxuh999BE++OADXL161Z48FvZLvi3RAA8tkuKeG2Npm0WWxj3etmszK75poXCOw65H3wBoFXql3OpyZ81H+/gp/77rAY3A4wW28v369ev4W7//Nr797d/Cfr9zp4pxMObGb6wa06hrVcMu5UivXC4pYdJz3se0hj2i1UgbWjluLvWwK8UzJ/8LAAAgAElEQVTRWLc9sFrTtaIrswDQAjcHazp+lnht2xaHvgN0Yy16uJPsTk9P8cknn6DvO9y9eyc4D14C7BgYnydIxfVYq1jF4XLtMYWnXNzp9RP2q+p0nAy3/QtOlc5O8cR0qUEbiK/QHG7tMlpjY1d7r/Dkyaf467/+K/z0pz/Fp59+ivPzc+x2O1y5cgW3b9/GK6+8glu3buLYHlTALezYqueAHVONYJ4aNxbehrwFcxH0PNMlYT42nRhw40UcQFpw1QB2rg5qhUltPZY8JvSeHzH68ccf4+zsDFeuXMHOWny0oEwpFVzBSJY2ncBFl2CsVhus1xtsNhubh0bTtDgczA6CrmkAa80ppcyJXPYEMGA4N+nqV8Nu99KAMkpso8yd0/v9DgDw5ptv4utf/zoO+wN2W7Pvm9am2FKDFkMo+BXSSsO6453D2hzaotgCNa0j/2faws55uFggKNiFX9by3Z5v8ezZKdqmZcBp5u2d7LAnLrZNa/Z5K39UK+XtvHZ2HLR65bwNfd/joM20BMkuczfCNazXmyAdyVIrg0hocOTqZAkFmf/OjdNy3uOUgLKiH85zpwuSeMz6f42SRNOr4cQXAKXcs9ravuSg7Ts9PwSCd9imMadDHQ4HvPvuT/DjH/8Y77//PrbbM+x2O3zxhTmW1GznemAXnPltXHx7BoCBFVH67n7HJkGGctolBzT//CJdsuV0k/ym4tkijAXGGh7GCpIxICo9q5mzKuVTEkxS3+IKiVIKT58+xXvvvYf9fo/1ZoO21cE44GOD+vOqWWHVrmCs3d7eU32E9Xrjtortdltr8SEYB4YJY9WuVtZatLO9DnQ03N3xfq+xT+NwOOB8u8V6vcarrz7G7/7u7+LatWsOiIBQgTILc9xEnxtSjQIQnbDn/G1MEMYtJQlWXu9Ci7h4xstvFpgpe13mbrdH3/VY2cNNmma4X9kIZ58+v+2LW9uAv8KTW+Nt2wKrlVPGttstnj59it1uh9VqDeXOh1BBnuXxERsAQogECMb9c46yGqddn8Y4RT9WGCRFXUcySixXRpjzOk95GgaKVaHua+TbpQZtpcID77mVDcBZyZ9//hQ//OEP8f777+PXv/41DocDttstdrst7ty5gwcPHuDBgwc4Pr5qLZEWm014kbyQu1Pep1jMU8DCA3YI3KYdl3HJThlcsfBzgyAVvsIjMIaPWqCuDVcC6DHtLSpwlTQMOxz4WmusViucnp7iyZMn5lnfu5O0VNtagPE2lNZmgdhms8HR+ggaZrWyOVVr7Szt7fbcWht0HKc/ohSaFpn5bUu97v0iOQrTmIVsTUsWswGl9XqNs7MzrNoWv/3bv43vfve7eOmll3B+fo6u0zDX6UqVAgSbuBSgtXKr1Xm9NVqjtwXIKUaSQMwLa1NG4qJdmRVk5+fnTv4cDgc3VRCAJ2BWefcHKB2+IyWF8m80nCJE6wugNbQ9353yOj8/xyeffIKrV6/i1q1bxv1uV+Vzl3naoxB/li3dVF3mKK7TFJDx8DVjNpSL893+JFOryj5hPKfaonTyWm1bXGrQ5hplbA1TxX/88Sf4V//qHbz77rt4+vSp23d6dnaGO3du47XXXrP3Cq/tn9kGxo/6kwVv6Cqv53is4zdurNCq1rrsRh1D0mCqtShH18VCnoEcoOY8IKW4UthcWjVpjKFcWtwqOxwOOD09DRY0AWa+GkwYOIWKLra2bt121eDatWt4+PAhVqs1nj07xfn5uQOew2Fvb+/q/LnX1oo19Wdus2q1cvu1AXsimtJo7Xniq5XZnaFg5nLv37+Pb3zjG/jt3/kdXL9hDk6hPc6uv3lZTLViLVVlneV2nlvbJ8rXD70wAhEOvCXgiqdG4n4h9n+rEGhtjnE9Oz0NxoFSVP9wbePb1Nv+3iKDrVevsKwac4uYuYfbuNfpgCOqq67r8Mknn+D4+BjXr18HABwOnT0P3QN3+s6Auj6bkgFxmaX6HSNTylMVecuz5l0qP/97aKjVeWPC8Dl5GtcZrcTi4D1Frl5y0A7P6SXwXq3W2O32eO+9n+Pdd9/FBx98iPPzM7etZLVa4Y033sCjRw9x69ZNl8ZqtXGLdUggpTod7+ijKlWlh8i4xqkDmNpGn6JZx/kNOnJmwKlIK54LdlzQpgar9LxmzkkC66VcgHPLHYMMt6p4HlIZzPWZDfShx8nJCW7duoVf//pTPH361AK2ncfuOndHtkvfnrut0QcLZRoY4FbKnpsNuKmm3W6Hpmnw+OXHuHfvPl597TW89tprUK2xFglYHP8aMHPYfgwq0CltrjTF+nVen4QQjQFbIn7oiatDxggtmOOySDX+QJt2tcIqWh/TNI3xThzM3jdl7xm3WM/yNNd+Kq2hVxr6oJ3LnNLZ7XZ48uQJHjx4gJOTk0B5i/tFCD5pY7Gmb4a7ZjBQDko0ZTpr6lRYLu+hfBhoi5NIkjspz46sPIwv5+UGbeX3PLr5HgC/+tWv8NOf/gw/+9nP8OGHH6LrtL3oY+OE0/3793F8fASl/P5rOpqUn7NMLi76zTOXLO2cZpiysusEN1n3SKRCYcL3KQ14SZKEQdH6j9xPw/Dzec21TTCPJPAvxeODSAJGKc+Y5ikpQyAOLpew32P++JyyAtxlEn1vDk5pW+CTTz7BdrvFfr/H+fnOxjdWdtf1OBy80Hdnjsf7YL3HGgoKrWrMFiVrDT548ADf+c538Mbrb+D6tRtoVy3Ozs+xO99CtZ53zzc5ocM6oKpzYlXDlJAFNdY1MeTT45Rqi5TiJ7cEHECaK1FbF5evIdhszJTD0dGRvd60gTnwhpSKBt3enyZHR8IaXnp03QF0zWYD71Ekb0jf99hut/jss8/sNaxX0fcrB9bE53CcSjVTR5QvWfz8umJeN9l6zIBanNdFU8iLLCsG5RuRduqZS38ovqvT4nSpQVvBF4C2Zf3kJz/BX/zFX+C9935hB4BCdzigbVtcv34NN2/exN27d90iM7P4ZmMPm1gB2hwPQYezUP2E9ZQ+vSenrU/pdqE7TSaaD4N1Fdbx5Reo8Hk3gQP2l1MWBMszzbHlhbbwpPKV46ayzQFiyb1fQyWQFtMZnBVuf6pwrzrNoUnKQOimpb5nzuwmwQkAJ8fH+OLpF2ibxpweFitGAFTbmjpXCkDvro7sdIfdwaziRg/Xj7RmW5D6zkxX22shlda2PI0Jp80cNrSZw26sMnG+3eLuvXt4+w/+AN/+9rehe2C33eH02dnAHR54SyLe+948aywgq54sfu8u5xWqQP3elFeL9Tm0ZkrKG1Gv7MEmWlvvgj3AqWmwtuHJqNhsNk5GrddrEl4uvNZA15p6XtuLRjrr3Th0HZquA9QKUC16vcUGGlANWnvIzUoDbbvC2dmZvQHtmuGt1+4kOUnZDAdRaRwO68VcVbwfHBiTU4Lj+k7V8aBNNHy7Im4Pew6eTpVDzG0QNvZC0LMx/UQkwXDX8UPtlVCpr9bSpQZtwG9jUUrhl7/8Jb7//e/jnXfewWazwfXr17Hf79C2DV569BB37tzB1WvXcHR0NFwdrujkcOubGtSy18Bq3KVjgaBomRZpqCEOQgTCyvzebreuLshiC/PlFn6OD6n8gnYJqt54YMWuolR+VIZ5tvhYi6A27OCdosEZPBp8oa8k7Hh/Ik+P5BZWymy7Wq1WuHHzJr54+gUUzGEetKI7PjNek+UNoHHzqj0Oh71b7W0ZD8BPawPWTri4VOyBLK2ZL29XK3f07W63w507d/C9730Pv/M7v4Ozs7PwSNLCbgyu0ylbCRqsf/S0Qj3yhNhIjTJbv1LEFaWUuzIlqM3FHBp0uxVZ2m3bQluZREoxHXRDNwk2ysicvuvRHQ5WaTPpbPdboFdG+WnM8bO66+GWIsBc8anaFivVoF2t0cAsvO373p2I1/cbN845hfOp/plMmo3HsN7o028PVIN6q/U8pcjFt2DMgTTAO+ZUkXiVp7OAWMaEbe2fJeV8lnvGq/YqQuDJURF/2vuWYuCupcsN2goOeN9//3382Z/9GX7+85/j6tWr5oCJvsdms8HLL72ER48e4eTkBI3VCPkd2IAZMA1IuAEQ3UgsaxW6qv37tOU1xcVTq/VLlNLS6MjD3W6LDz/8EMfHx7hz546zDOopp6GnSRICI2KDFKryesswzzJPy7ngyJMg2IBewyaN2gojxSROQ5YhMBjEhmgxmPl9cnLiDgPqtX8X/zmvCgBo7zptofxOJLGqbF0r2PP8G1iD29srGmjaFqu2Rdfv3dn9f/iHf4hvf/vb2O125ihUYTvXsO5g60IBytdPLPAMiBNjyi7YYj2TtQNPv2TpxbyFQBduo9NauwV6BNrkLu+6jt01DhwdHUFr7YyFruvQKwJsdkNar9C6o113Lv3DgT4P6A69OXa2acw58m2Lvtd49uwZdrudy4u8aksSnwKI667GEInjyKDK6p/UQ+q7FZTygtV43SQFLjXnPExESEswMgKFxI2jvPVfQ5catGmhy89+9jN8//vfx1/+5V86rU9rjZOTEzx8+BD3791zl30QYJsr61pXIU1DB000sKc1CG4kvyjGk47C1AFEicY2VMBRlfaqsN/vcXpqrj/s7ZWBdfn79J37cSR/tCUlZMxbcHz1ZpIXJS1MumSkhUHIphsUYK65tG7ilvVJJ6RI+YJZPcy9EObyG4Wjow0ePniA0y+emVOytA7us/b9vHGHeXiL1YdxFj/8817TJRTGFawUt/41eq2cO3u9XkH3Gqenp7h39y6+9/bb+Pa3v+3mXE05ay+gIfe7VdEii5icOVoDmjQODejG1DuddT6FYvDmQO2408qCrYZSLdbrDVYrI3+6bo/9vnNXdWrdY78/4PT03MxLW2AH7JRC4933TdOY7WC2RugubrrT/nA4uKs/jzZXAK3tdaUafd/Z+7yf4fj42IGN7BoPy1sCzlw8yUMUh8m5emuUZsHDnOQJSMvBmrykMGMU+1hhSHpimTeLW+Mi8FfSpQbtvu/xwx/+EO+88w5+9KMfOY13s9ngzu3buHfvHq5du4ZVu0bbrK02urILdhooZfeO0oIRBSgL2CRJwg5GQMJtH07WbipZEIN008+mUEpbdFza5+v1Go8fP3bz+rUaMglcPxgTcVLJKJqzzARR8hDlLi1nx7JgcyyKMfVfNx3ivQKJHF1a/f6A1XqFllAI1vrStBXEWI29eweQ6xIArly5gpdfecVZ9Z988gl0b9yrHcKFdvzUrLZtA5ccd6W7PdkKZqGYovJ417aZ3/bKQNf1OD87w7179/FH3/sefuu3fgv7/QHb3TawTDlQp4S5Yn8Evs7a54ojWTEsHU22GVnigfVeFsqS2zwev+YYdO3qyeyPZm0aLAIzdbXf7rBaGcVGK1iZZY9RYVdmEmjbRoH/6hfOdl2H/W6L3q4jAFbQ2ngX+Wp/WK+LVqaumkR/zPV/Pu5cvSfc7jWgLHkhs/kn3wzTq5EBJQBO9Y0pMjqZFr0H7LoMX3/mxrahtV9Dlxq0T09P8YMf/MCecLZ11vUrL7+MR4/M2eFtu8KqHV720TTcoiHRANe56XtINQ2W1wfnuLvHUg6EaX6N5vdTnTIeiBywSQjH4V24LHfk4kxrksLQH+TzZVFKmHPKWR1RQAD2aEvAgaCNMcgjBmxqi+vXr6J78MBtrfrlL3+Jw+GAzdHGxQ2PyzSgpuyYoOkissSVMtu3Gm0XNKneLOzsDsG+48ZaiRoan332GV569Ah/9G/+EX7zm28BALrDwSkT5OXJgTUvp9KsL6m8Z8e5xJnXgEDeCMZ6YM4BjH8fLtSj1dN+LzuYkmKYICAlwcz56DtqmwZ2i3vwnubHtdZQ2pgQh+4A6B5NA3SdFfjWKuf1SIrNwMyYCEQpAyQP/Pl3+TFNnWE8j1K6Y+RH3vhJl4nLwjhuyCetMrFtZcNORYRLDdqff/4U77zzjru67vErr+CNN97A7du3cXR0ZFdsrtE2LZrWzP0495Oywk8pZ/E5wYLI6R0AVsrKDsOOeVfjgipR3EFzg0BZiynYUypoyFKnVMq4BSXe6gWAsFUO1A5UjoAT8FZ5Xtb03LSS7W1eGsBUCmrVolVeeeKu50E9MYUyFgpts8KtW7ewXm9wfHyMdrXCz3/+M5ydnztXKRCf1+/zPNpscHx84kB+u9vZqyHNvKzZ/qXR9/7UL6MAr3B6fobddoffePM38Pbv/y17S9ceu/3OWOMgQWQu84itCKLivCGvDl43Oe8W1RkLJwG3RKW+xteAbLdbF4fq1LvHNXTj8+v63tWBs6yUH5tcvHAFSWuNTbtC3x6wV17Z5opC3/dufz0pSQQEWmvoGYBA/PLPUlgJtKoVWk6kxCAlfUP+KJ+UVyVIutI652G1ltQgCuxlWYpMTHMHvaSTTO2Tlxq0zSUHpkEeP36M3/zWt3Dr1i03b232XrfBdgTzB8CBtk8vAAyhvsJKtDCv+AIF5T75IJtDY4GBg680uFKuvrSFMfQ2uDo0Map59Uz4dFiyoHlRuc5ooLAnC1vbU9urNp4rLbeQ6SlToIC8AqSU3E691nYV+Q2opsXR8TFOrp7gvffec0dsmn3EdOhGw1xzQN910F3nrG/Ph8+zp/eAuyjkcDhgs1rjG7/xJn7vX/89PHr4EIfDAfvzrb0gQ6HRGlrb2zJqzaUgGKnVFvCVD1LqdcbCDpMcY12nAT5Mg24lI1nDDzehMaOhzZnifUd6m+n7ClBs25K5IYzx4caoufyIn4pmLnxpnIXdtq2b/wYQH8vullk484OVIS4jWfhTld2x4yk7llS4S2BMejmrm8Lx9yllI6YUJ7T6KWhD+PqkUG7aRykL3ioUchPoUoP2arXG/fv3cefOHTx+/Bg3b9yAtoLr6OgIrbIHT7C5Itf5naltyA1DK1R4teU7rQoGsURc26vt/HOt75xVL2mIqfmo+JjU4Xu4tJYwYknQSXnNoTH1PlUZyHpZou8EQQDs/uamUM/a9t1Q8PA5U7OY0lyBeePmDVw5voLNZoNr167hpz/9KZ48eYLDYY+1PVe/19oJCKUUus4sFtt3HaCAru9x6Dv0XYdufzCgzqx1Wg1+7fpNfPOb38R3v/td3L93D7vtDmdnZ3ZxFLWnEUZWRI2qUyquZjUZp+SsSA5APCchy7itY4WJj4nU2I2VZOKBXwRC6zO0Vui1ORPd5ONd1mahHUtPe6XJ+r6N8qNUsFXVK7M+v8PhgP3+MKgPgB34wspQskIvgmYbNBNZjPON66cE7jwNSV5yik25sA8OFQIH9Crs4zzfOI5Elxy0V3j11Vdx7949XLlyxbiONhus12u29xoOqN1cgXDMHm0pAGoAL3gqhhukn3PfFeLWvKuJO9Qca1xCw7SH+ZB4jF2Z40dWyFuNHVVKJ/8u5aZbKj+ppvhoTnk54jSp/+poNTpZ2TTvq7VC07TWAmtw9+49nJwc49q1a/j4k4/xyw9/iU8/+xS77Tk26w0ay5O5F7tD1zU42Lugu77HQfdAbw5S6fse2/NznJ+dA43C9evX8Zu/+Zt4881v4tFLj3B8fBVffPHMXViie2ulNaSgKNeqo6wlwI1OVnJvcbOkmsQYS7loJQtLqv/4GXeR8hX5/LCYXN9yyqk1Hgwv4U4IEuA9e9hpjb47uHwIuPk47XuNs7Mzr+jZ9QqB0HdDNlwbIZWR+tjzAPMkKQRz/PQsphwg07MahUHyeKU8MTme/UKLYdrmsfeJx8pfrm/m6FKD9nq9xr1793HlyhV3X/ZqtTYnMWkAqkGv7JEpFsDJxQQQprC5QduZB4K2QvuKw5ae8ecDjV8jUsqMcNJRPMM9fSr3e7B/OUAKl2gVjxLFc/s+alpYpdKZGmasACm1wRxKpiHwrgHXliQ77baFKAotTPGKi7ctQ6RyAh92B0RjVh+b27SOcOXKBlevXsX9+/fx8ssv48MPP8QvfvELnJ6e4nx7hu7QYbNaw+CzV3A7bUCo7w5QgLOsN0cbvPa1r+GNN96wa0ju2CNQz2m3pCuDrxoD1zT6eurzyiz8VLyqtD8trqf60n4e3K0WVzyKdiNAWUFIdUxx4oVdKUtb8nKkgAwwhrCxA8wWLtrKpRTQ9x1U6w9ualRjHPzkQdDEl/ZufK2hlLmEpde2fkjh0RrozCl2BNpakyXvD3rZbrfo7EUujTIemFYpNAit7FixLiktS1IKPMV8mf7Oga6GckA9xhCSFLaUTeFW6Nv2pO/xKYiAstsV/ZiO+/bYdrjUoN22LU5OrrqV4XQkoDKqvdvKZf5C61runCQcx7uzUzQmfuBqC1Tu/IECimnBLiTrUN7t5uNoJsCmkB8AGWt41tzMuC0ZgCwEar0PqfipeFVUoShYCBC8H2YQ0zA2LtPh/CItUjJpUJamTZpG2TOszaLDmzdv4uTkBDeu38BLj17C6dkpzs5O8cnHH+Pp06c4Pz3Hbrd3LtTz7Rb7wx593+Hk+Aru37+PBw8e4LXXXsPjx49x48YNdF2H8/Mzd6FFwwUbLz5Tht2cqtVa+AltVPKg5tTQVZjqcgpDpTfns5GAWrLWUtSwvfB03S+tG+i6g3Vbm9XgGmBWswr20Zu92aHCQ8e2mngASIaxu7dphoPkGwH4oeuwPxwAZRb/KcB5Hh1wqLL16MfEfABPeTOqlHyefSU7ubRL3rZc/BAbhDoT2CWvms9P+TFtEoWReb0zJlWGtxwVQVsp9acA/n0AH2mtf9s+uwPgfwbwOoCfAPi7WutfK8P1fw/g3wNwCuA/0lr/mY3zJwD+S5vsf6u1/selvJumcWf58oVmNWfgxnMSZK0kG6JCUEsaem384H1oSGXdQSlg8FppHa/VvAm0hHKzJNXyEg+IsQtcauPUeF+0f8GUHRW2o1Jolbe44publEVtZcMa3PQA3jQtmkZhvV7j4cMH6LXGF08/x2ePHmF7fo6nT58a6/t8i74zCNK0La6enODOnVt4+OAhbt68iaOjI3Mn/fkWh+7grdwKYWzKHfcXf9Z4yLsfCtGQGHTsoSIUBlEIlVbJZS79Lr0zW76Mq3qz2bhT0Shs0zSe/75HD9izIlpA+W1e0N5LFeTh6qMHenu4Td8H2+48gJvDVZrGn8jGt7gOSbn2iOtxqMwK0SH37Th+iVJjSepDtW5tCruk0SV6EQv8VCmAwbgZz2NMNZb2/wTgHwL4J+zZ3wfwf2it/4FS6u/b3/8FgH8XwDfs39sA/kcAb1uQ/68A/B5MD/q/lVL/TGv961zGqlHupDMuuGiwuHARcNdpd+M0nMXdrAMplScpaG30pQA37tRLDZgxbq1a5WjOIhguDJZIb0ARoBFyG8NUQUfXb8Z93/DSu2TIGuz7A5RSaFvlgObq1au4enJi4miNbn/A/rBH15tbQ9q2xZXNFVy7eoK2bQ1Yn53ZdBtzaQjgzhLPSZ1k22j2TtECMk3XZjuFRWl/xYKov7L6c3P8Yk0W+GHvOVhzN6sHMsWAcXhNsLaufmU0LQAwl6lAoe80+oNd/Y3O1LmLS3uuYactTJse9h3Qdzgc9u6GL6kP7nc7nJ9tcdgTuNvDpJRCeNpgtgqCcGO6uGTJTjEU5owvSeHKpVNt9VvSeuD/GUXcG+WVr7BNppS/CNpa6/9TKfV69PjvAPi37Pd/DOBfwID23wHwT7Th4F8qpW4ppV6yYf+51vqJZfSfA/h3APzTXN5KhReGxJ0i9ZvPSUjuMe9QA6r8MAWqsbSGYcyRlWCyUKfCR52NG+ZSU1+EVTzOq4BRCkktv6O8GZnwU+bR85ZlHcl1GMBMIIAk0AZ81caLsjiomz8z90qyo2latJvGea7QmEVQSsMdXiQJ05Q3K1f2nCD3Xgf6zw8CCl1yabpPlF3jvBwxj7GyH/NvrFnz2+xpP2Cz2bh3Jpzn1ZwdvrWATCvrpQNjtN3KZdqg1+bmtK7TQH8Y3JvO26PvO3cxy25nVpLTVjDuhUy1gVwXdXIsNwZqrOQp1jHv02MUsZi/KZSKmStLYH2zWW7R8LoI93iCHmqtP7Dffwngof3+CoCfs3Dv2Wep51lSGN7hOkWbC8kPMq/8D4VfCqRqLcAin05m860rI0GBCbnpVANsoQuI5uhSxBTMSVr4gMMRwjb3LJe21N45oV8CrNyATvIr1JUkgJWCW+iUK7uymqBGj7ZpoPvI1U4u6qi8OSE8xVoZpMnrGhCFWgp4yCrnJsvUnpUDJPPO1NN6vXI3bBGY0tGmNO1GbWFY0+4sCV5f5lhUA+TmGFJ/spuJ22DVmt29JnzDLhI5uH3zSpkV46enp+aClq4ftEmowLGLShC2YRivXJM1inAuTM245PyV5G2uj9b2UylcTdycIu8US4ALQ5ASzcswlmYvRNNaa6VU/SgukFLq7wH4ewBw//49ERxqBLbUQaU68qzLgquUT6EsAEK3smS1hCKM47lUTp31EUxVcAJ+ggHtrYTYVZdy2ft4y1v8QL3iBKQHdfy7BEbzlcUwLzEcV8KyrjkPYCWulLKXlGi4y0h4vo1ZQWPySwjelOWSct0G8ek5f+/e8fKE7u7YohYKNvDnluqd8xkDQ2zVGovWHzdLR8CSBc3PGyD9QSlab+MPfCJ3Ok1pUJ58ixaNpV4r9OixUiv0fQut/VGlpCQYy3+FK0dX8PTpUzx79gx3bt0K5rhr+jOvFxNuuuIbh8+BGZU3B7pZxTaTb5xeLo8UDXifKMIMYEd9unG3AU3y9hFNBe0PlVIvaa0/UMb9/ZF9/gsAr7Jwj+2zX8C70+n5v5AS1lr/IwD/CAC+8eabg5JJAq8eqGoGuRqEq6G5AKUBt22lRhjzPKe4WGrIH+7gLcfQYqrncUmq0fZT4dJTJssoPFL8vJuS6phOT+tH8yGGsFafVwLcY7b4SSc72hxLI+bDJii8g7P2QVZJhZJVep5np15uKKvPkOuZr+KFH28AACAASURBVK/xUxBm+5ZSHpzNFrHGAb6kqIdjCQCMMnDQGlAtnbeCpvFgrDXsdana3Smw2+3Mnnt2ME5IoZeM5z/sl9OAO1auatzk0rOcJS4BflyOVB6SopYrC48v+zKH+Utpc6+Q10/N7xqjMEVpH2ee/hmAP7Hf/wTA/8qe/4fK0B8A+My60f93AH9bKXVbKXUbwN+2z4pEnVuyUOLGi8MBsdUYhmW5DNKLeZDykd5zSrlJRdeN1dTdnl4hTpz/knM3cTo5a9R30n4YN4o/xk1V4kPiqxQ/9SxVPukvxVcqTE3a7C3gjkBhcUtljaq0sRt//D8Txjo9wuCsDmg7FufTZTGx7fgWRSphbmwpRXuc5fY27xN5ZcBwFM9C2xjQVW4Xy5UrV9xpZTHIaHu9qVK0yCxOH1CqtSv8m8AS9zcTtsH1udQ3lGqxWq1BC82U8mt99oc9ELm/DT/Udr6tU3LU5zWNUmOqNm5OrqfyKqUXgzxPO18P4/hOpW0fROnPnyoE6rZ8/VMYK/meUuo9mFXg/wDA/6KU+k8A/BTA37XB/zeY7V4/gtny9R8DgNb6iVLqvwHwfRvuv9Z2UdoYqils3u1Q1uRSz0rvS1TTEVPicYrmOodqNN4l8pUUj1KeU/PmefFBVus+L7mCc/VVyiMe1LWk4MS6+81T4fNqCn7etTr9SEmbQ67uQb6bfL7Bb5g5fG6F13qjSpTv57RLpXeXgxCw0uUhjh9t5rZ9/OCtK4lpg8a+1zYPZa3pFroHmka71f8+Pb9qlbZ4HQ4HHPZ7HLpDYNWHZQiBe8gzt7LrxtnAoqyYz47zk8ZQzguWy79Wjkg0J+6YNCz6oM7bm6ea1eP/QeLVvy2E1QD+s0Q6fwrgT0dxlyBJGy+F88SWbGOoEUvxUulLbs8qcGbWv2/w6JhVYQrQL2IQXNUj+IhKAVmElud3s9YT5h1eM0YLzs3FBmBNYSZxVE+8XUrzd0Bv50VcZPORmdPm4lUD5j5t9yYKR9ZWIrFUXcQWSopigaUUXR4Cu1jOAg3lRH3fyi9eSs4i9UqTvXIuxZQCFI+pOUoGATZAALnC4dBjtz8ATQs0Ldr1Go29a7uBBs1j890uZiue8mVAE3mnQqte2211jT08ypS/QdMMPR5t22DTNtB9Z1es+8tLSuuA8uWurZ/8tE99+rGiQ+1I34cKLelvXo/T7DsAlBeilZSGEg3qADDtp/xYVlGHDsftEMBrdYdLfSIapyWsLWrolOa5RB5zKACVbLZ5oTTfAq4NN9/TIAFaDrCnurLsF1+tI5SCONxcRYRIa+3aepCiSruEJfIAFyQyKO8wRL2wcBmlc3G/FewqaKpnsIwiq9k9In6AQFSrIJzf6hWD8xIeAUonBtSmadBrjf3hgPVmg3a1RnMwC8XoeBVzwI2/CjVeFKbtdAVXMAhklRX2qgGUNpfDdPa41JAvfme3xvnZGfa7XXCPdzimZMOE16X5ng7D85bexfzlldQ47rB8hq9+8D6MH6bvv8vjdLE1GoU4HIozI26gZDtZUEGXHrRTwlIS7CnNL5fm3HCzQGTwOz0wcqD2PBQL0zmJx7QgSMUdppV2E6Xqp1aDzwmTdE0vR7Xg4drvAnmRaOqURA3RQsrAT6CcWe3RwX3YtrWPzGJM7YKqQAwOeSu5Zmvcu0IpgnDcW0DXcwJ+BXijaU81oHUHrRXadsNu6oK9matjQG2FtxqWoW0be2HIsO9zS77ve+z3e2itxYVoBsDTZecKRY0hkBqzqYVeY0EwNc4VU/IuctzmeIhpOEUg/yh5hmryiunSg/YYKllDkttMDFcQo8F7HbwQ1awaYTJG0ciVc+78TDpvUhD8ncByYBpkaaWiVrmS+ah7Fy/cq01nKX7i94OwUQU2FrWGS/tG5AdcqFSrqTUC7OGkiweQYIhE/BrgDkdgTZfOucVj93mePJARMPIDS8iqdavDtTbu7CA/oG0VNhu/eMzcgX1ueeixWvlV6IfDwcYzC9/6zoD6atWi6xoHyNyCp3LxLWnxKZHES1xHvAo8SBWqJUES+Ehz01MsWJ4uP7ddA4POOFVB4CTGr5EVLJqmaa2EsuR0VgG4QyUqTS8kaE+xpEe5cu1nXHf0PBY+7r2O2zjhIBFBJBQqJXdyipbovImQQv+t08ynzLnXlmNqPU2lJTwr9qEDLQUwy9NQoAtmFDMlpTWTUnUvCSORpGajQlo3IN0tHLyGHXOCQDbvZKt6iXlsNrpd+pTubrfD4WAWex12e3OVaaPcHmyytMnVvV6vcXx8jOvXr2O1WgMwJ6XdvElW9MEdgbparXB6eoqzszPsdnsACp3q0fUa6FoG0n4h4Xq9tkrAHvu9+VNKOct+WBchgCvbWchdH1obmRrKWIj1StEg1YG3QcqXjtN1+UVhqBg6MQZK3r0gLa50SDgOexqhjvjOyCzJm5oaZ6V+/EKAdsnKlOZSprrIJUEixSu55Wg6Tyf443HdQjSmhU2hi7CyPZG1bfj0RzjGTMCVJ5lSRfmqABusjSqsea21WYaoyaLL51nT15K8jdDQ45ABbhUsFQ04d3Kwilzw+OTSqWoTNawziRryRamoF8Rzfzox3gTeNfxYidtgrDLo2YndZHJ4soSPjo6wWq3QHQ5oVytzq9ZKQR/2APzc92azwd27d/HgwQNsNhucnZ3jiy+eBReAEMhuNhvcvHkTn332GT7//HNzJGnbY7/3N7yZLWRkUXtQprPJnfuenZFeIj0wMIZ1NFb5z8nduO1y+YhgprzCp8Vw2imCS07/JER7UrwppazykJIT093iRC8EaBPVdoiUO7RqQGuvtTER6MhVMxcoyv+U3o+y8it5nUN8cOUGWlif3DZayNpE2aLOubY9N0q00AZpsU/RGKyw2se46Iu8KKbJOyHKZnFVSkANAc6lV81BgT+hLD3y7nsXF3BXVQagzMtgvQOB9WSFctw+sddhjrdDVsw8yMWgwt3jm83GWd4nq5UBEaWg6eIQawVvNhtorfHs2SlOT80Z4efn5+DubADY7/fY7XYAzAEuq9XKzS+TPNvvdwBadJ3hp23NFrSuMxeK0LXF/LjnYf34sUtz75ISOsTJlHUatlDs+jVWfHksUdhUuLC/83y161xOWYDZtZBOsZ4CHlOyMXjPTxi3b8V4vm2L+Wbo0oN2vUY0TjtMhg+lTC6FOMFiEJ7vl021i6WiWACUtQAwCyHGWEewWQ0A3P4vgbCc5lANk9zQY/vQVFLWeuDM8CTJGuLATS+k6lfJHwuRlOmg4v0zBeUsc2XNExKyjRDVJaFCEdiJGYXhp/RnJXRi7sbU2o8TcyKacXsDAB2kohSgmyZYud11PT7//At88cUp+p5OKwNWqzWaxisDFJ5+A8aipuNLm4ZAunWud1Iguq6zi9VM2VOXKnkaAmv4iUFd8PqQvRLDNgm9bOm912OtYefGd2Nm6M2TFI/c2pYaSnIZCBGrLWvNXi7fX4kuPWinKGcV5RooZ7mV0ubvS52uBErys2ySRRo7KEpE824mvT44/3hlLY1afuLnOTfz4Fms7UMA7Jq6Y5YtWbVSvJo50uluWBfAf2rt+fGsOjccB27zTpmFazbgxaxhEOICaAeep7htlDnUT+vAla7AWkuZA18ap4PUTTkE+VR403LzhbrYaRSU6u1xoh1Wqwabzdpee9pjv98565YsaDp3XGtjRRMRQO/3sFYuBmBmLGvlpp3IIqYT0ni5aNX4drvFjRs3ACBYnDasx4S1GHjc0vXvF7DJGlrspubxypQHuCCcHQfajhWd81NX5z+BLkAhHiO7Lzdoq/EWmZjMl2jd1ued7rxz3IGcxgpH3nm6rsPTp09xenqKzWaD27dvlzC7mq/cOzM+Q22/Ue6gTjFcksilhmFNz9F8S1QF8BKuo0KcZYTt86aQj6FXg56raDEOkBBUXMESQHq6UE4rZJI7mNze165dw8nJCc7sfeO8z5jjSf0lIPyqTApr/gi0/RnzZCGSQkxl7ro+uHSE0qFbv7quc4vS4ms5Pf+mvFLZppFin2E7hmMovxI65jO3aNU+gO9TifU0Ufql/JcGdZemQiCfag08r6zlx/OlBm1p6xW3gnwHl7XsWOssWd9z5xpq6SKs7BG5J377QeirwVzrp7XG6ekpfvSjH+HXv/41Hj9+jKtXr0Idy8krAVRdisLag1xHNW5Ue2MOCUTLW1iCisNISFOn2ImxlLKyU4pQyXPAjTpn6SP8TLDrvG4xHDqcX9iYyAmzRsyPceaMLbvP2rVJrH4Yt7KZI6ctMrYvuEUlPulGw3kWnJeU3NeKPUet2zUsiI+iAmFPQEru56tXr+L4+BjPnj2z88+mVribPZZF3nIGlOLf+X3bng/znMK07ohTx5MCDrrHoe+w2aywXrdoW3MYidEPekHBaQb9VCYOwnDz0iEg+6s+nRbsLG6A9wduvScXUjovE+WbGBGqd5Z1mFaUrvIWOf3WmhZqeikxC7DZtIlS9ux+3Ucev1AJ4dlREWO5V4szlxq0Y+IVPbXAMeUE8dh4c/gYm8/E1KJPQzQYvMDhz42r7/T0FKenp2jbFsfHx8aCKLDGBZfkzpQAPAgXAJwdjDlXcwVpyiNCQqkvlYA71U/kNgvr1iDC4LWcRyr9TBkobi3F5Z/leRi0YaSpIHqtogexkQWzIt1ZMRx8Mt6TJHtxdgog8I3nbvkCsxs3bmC1WgXGAnWlphmCAQdlSrvve7RtG/R9TuaObX+qWt9rN02ltUave2htAbs193wDflW5L1W+/w6VTammfGOE8WqVo+FhK0HqDLBr3cNGkSCezJQCTza1UFIB4vatqTT0BARMBuHCef4QwP2zeuZeKNCOSQKC1G+pU3DhlJv/GsvHmPjxQLt4Gg4cWuTC+eHuKlpB++jRI6zXa9y/fx/r9Rr7GfXTdZ1b/ZrdokK4pIadPVe/kpvzIikL9MlIQ0EydvogFS5WcHPxl6obr0y4jAsR0oK9NB6d4sWycx3FPk1mr8yNYtry6C3lgXoU5Hl0dITbt2/jyZMndkyQUurXeZCrmvNJa0G01q7f8/FFIE4ryL31boS9B/Aeyo5V2ie82+3c6nEKQ/akcu6YYT1PpZLM5HUXx0uFk24L5GTy8RY9jzvEzuGZ/bEnLOY79y6jf4+iFP5MoRcOtAfAHLjntLOk4uqQOtg4SynPy5x05uQ7jspCWwI7cg2enJygbVscHR2hbVscanNNgDY/LznFrnMnO1eocMiL0N61fNS8q4mbE2DJvsGsRIC57cOA7mtshKbSXUo4j013MJ7UcGzOIWkXUWhlRQqpFF5MWQJskzYvz8nJCe7du4ePPvoIn376qQNkAlnad82v7uSubcCfXEbvCLSVMvuuTZq9s+D5/d2AWc9Bi0CVhjv0Zb1ee8UxMWdfAi+p/HHNccBOKzteX8t5f5QaThGUqORNaqCMtR15A4Yio045rOWDKxQlxWAuvVCgLYOk3yMXz/3ZSRUTHuEgzllG03kJqcbCSbmnlhK+LMUkD6lPEizr9doJBf6XVENjhVggsgykxTO5EgwEsVJuxwXdLMbLNsvNy9KZFZf1Q8C2hDZWAZ/CpbLAvveBObCbyuUWesm1WOJ/iToK8g8sXvtcClvJh0YKsMmyt4AW7JmzndD5v43K4+w1N+78XeZh2h40CVyPjo7w6NEj/OpXv8Lp6SnzEDXOyj46OsK1a9dw5cqVAJTMVZuNA+Hz83OXFymwFJ6AuO97nJ+fY7vdWgX3YEHJeAl22y1u376Na9euubh84ZukysbATWHTRKriPFlUWi9UVnrNX5Vb3kd0afONoZJ3Zw6oMqePy4+nm/IAc2+L9D5FLwRo59zewhTYYNFOKb34eQzIUxt0nGUXdqo47+kUCbFcSDXU0DmoDtYRiKnoIBsel8cnyyQOw38bfpgLlFmlNCBjPT0eKCnlbG67pgCGBGeQtuAJIODmpDm4CwqmD5i/CCIZrxB+KUqBbCnH0rgskVv4Rl4MxoeDa6dQpPuDi2Hzpbu0u67DjRs38OjRIzx58gSfffaZ2+ZFYEnu7+12i7Zt0LakmJpwANwJawCwXq9xdHTkvE6Av8XLXDKyD7aTKaWxQoPtbouu63Dv3j3cuXMHTdO4fdvFekqMt3SfiDTIClK2nnOANLTa05Q7rGWQh2VZs6Hk+oV9R/mn+PLfs2yxMLInN0e87GNk0aUH7ZpC0FpVKDXoV07RRtRwUdoSYOUE/lS+S3Gn5JVICZJgIqoR8jTwxvFm61GnB0Vc1ylXHgDogQsi/OmOJa1QtCSBkS+LTPF8cazU0CcvZ6ODBMxHlG4M5FT/ZCVcIM6KVNPe4rQT5AVBUnkV5H4Z5FVZ7hYwkppcs1BBVGNwG0sVyryLFwmFefsjYMiSPTo6wiuvvIJPP/0Un336OdADq6OVe7+zF4oYN7jv60Zp9d9pK9d2uwXgF62Rhb3f79EdOnOrWBe+U1DYbfe4efMmXn31VVy9ejUAbEmWpdy1cbnz7nN/b3WtQVEyXOJxmAOv2v7v0vUuLHikTvMmyoxCXqV6jPMqeRxq6NKDNlFOsAsv8r9r0ymEyXcw+SSgVLqTsXkB4oM8HEAAULPoJE4QoqCdooBo/plq7iiPJd29Yn6JQUmnX/EzoPu+N2dUs7C5mgzKYn8pCFM/C9KcuipbaRRQ4H8hJcT1XYSgowQPB73jTl9Z8LpvIK9Q3/foO42b12/ia6++jicf/xq/+MUvoJU54pQWoGmtsd9vgwWWJg/mulb+QBaahiIidzm0hu7NinEKr7XGbrtFA4VvfOMbeOmll9w8uffwKPYXKiWxwhnXYQ2FY4wOOYkHfcmTMaQUbzy9UcoCT48no2URJaYtVItKha2gqfE4vTCgXaI51i9/N8VluhRIXCTQTMkrtrQH8VNpJPrklDqOvWIp7Th2M+UE0pR6jpWB+Pdut8MHH3yA3W6H+/fv4/r1607QDreSlhWLHM+12n2pPGPejfHSKPDTvPlT+ZHUVkEeyiswOTLYYYS1n06R8vUznCrOSySFplmhgdkfjbbBwwcP8NY33sLufIv3P/olAOD4+HjgafFph+52KiNfWU7PtAVrUpjRWysbxmW+2+3w+PErePPNN3Hz5k037071R9uiUh4gafzVeN7yViLVJoWVw80BrNK4Kc+Le8Y0yreL5SiMl667XL2m5tVL9EKAdmwFjrVia97Xap214cYOiKR5KsRfBtyHwoTyqvVqpLggDTxFY9ol5HQ4u5br7KmyiC7dSkUiTpOs6d1uh/fffx+r1QoPHz4M1gIoBecv5kqIbEsUeNAWiHg62cFOAYdWR00dxnnEYCRPQ2STGvIRK3OUiDZTXzWAHaTBPEfpTupst2ANQkh+77ap8wZNY9r/6tWreP1rX8O6bXH13b/GRx99hP1+j/V6jdXKW9y8tKXpIg7exkvgw+x3O3S6x3a7xd27d/Gd7/wuHj9+jPV67bZ9eVCL1lRAXufB8+P81skXPxpN2tHb0NCtohqvTdz34nosAyE1/HAaYLpCkZbdtWAcT7Pl6NKDdjWAjAQCCahoronez3VjSJ2I8uPa+JdJPPtYI7ch6O1z4EUA2IrqyfWHi6xf3r6bzQbf+ta3sNlscHJyErhGe62Lc/P0kGKN5VueW1bQ7oBv2/fghSyBv9Jws7+1SkvK6nH1XsFzp5zYh9L2jmIb12zx89ZbDNxSeXvA17MDZX86G3/m39j8g+Tt/LNm6SiN3vpVzRWlCsc3r+NrJ7+BK9ev4sc//jHeffddPHv2zJ5LvsZms8Zmc2SnTJQ96rQZyIS+N6dp7buDKzsAdPuDTW/vQPnO7Tv4zu9+B1//+uto29YtVAstaHKJ+9u2UvJMtrz5p68j/4zm+gfLQAfpp6l3oE7XjtJ+bdngKcv3VH8UXd4zPQHDsOmzJkKLPjxwJ5V2ji49aM+hUqVILk+inCuoxvKV0kwKOJXoRQtSmHet5T4ljn+/xJyP0uMATPLG0POxg7LmGRGdmMXvM84rZYm+WRJ8ideipaYUdABdUTncZ2jN1tbTwEIeAdjGIjahFfxqeG8Eadflqts/Dibwo8GKLcyTBvKA1wnxyJQxBWCzXuPVV1/FrVu38PLLL+PDDz/Ep59+irOzM5yenuL8/ByHwwF93+P4+HjQRrSSXGuNXXfAqm2hO3NQy/HRFTx69AhXrlzBzZs3cffuXdy5exd3793F0dERum6f7O+8ClJNKQG2DzsEbhPeWO50GhmrZjFvV++ap8EVAeXyqrU0x4BdPCUgz5akF+DlxmNtvxzwIKQxRla+0KA914riFi9/lusUEhiM5XVK/GVpipIQDt65lHIVzvVuSGnGz5eYE47jKhXelQwsV5aYdGD1AFBq8CzwUDA2AhjTVrCOYHNq20vtzQzpWVQ7nnLetsHY1p41V7Ma8KY3oLQ2x4wqhRvXb+DG9Rv4+utfBwA8e/YFzs7OcH5+jtPTUxzs6m66nev09BTb7dZt+VJKQbUNNpsjXD0+xmq1wpWjI9y8cRM3btxw93RDKewPe2d9xyRPV9SeYlYmrwTMNzQMj2XlH6ByjVOk6f3YMgdplnToivTD+h/FikgvDGjXaFdTtJaxQmiK0MoJi4vKsz7eeCt2SviSvZls38yzsf1fmpIQwWRCOVOaepx2nsG6V9r95nnCSNTAuulBK7IidaIqT6Iawcg/axYEJa1yXe4TNTzlKCUzAv6VAWXHI7kAtHZz7Y0CmlZB914oH2025oAVuw3LnJhmqIdZeLbfGdDt+w6boyO3Ml3bGfy1XQ3e9z1aZU47a5oGu/3ONZdREMu3XfFy1lh6smXOR5xfwBX2+zgsgnTDPH04/7rihist/NCWF8+dGNWpGDr6neBxafJ1JSs7ktcjRS8MaKfc2ETxs2IHYPFyrnCJj9S73PMaksowPW5phbJwHOiAOKBVs2KwI55GKrVZYspBQYUWGReyjMuUtTXV1VZLFJ+vCI6pti9KFM8o0ndJSQhsbaXsHnYD8fHitbEazxSFOI4/AIiYZ/Zds3icclNTSpWLlXOhBt/Jfc9+K8Df5czCN5HFS2eL932P1p4T3useDRqs2xWO1hsopZylfOjtFi8F125mr7bxn7gjfxEpFontmJKVnaoLpfwtYpSu1mlPWKgoSr3T1E+c/9BilseJ5PkEAKXjfuBg302hxS3LPSQ+PL2b5ykIQNamVZNaqLCk2y1HLwxox1QShGMs8/j3bJfKjDDLUcn36K8ITMfndTDCIkf5aktpgAa523fOQrSskOBSSokCn+JKefJ0q8pRCCeVYUwZS8RFYuzuzvVOY1GYEHyHeCDWlOcxRzUK0NS+L3khuZU9xWNRW9fpOWC7NgB2aVEsI2iCwXW+Br32cbkHwYCyedmqxp2NTnl4K5yBGqyHBNqsQneuaKmcshHjysDqLzcdFQI2WdPhs1S1mnByv5AUy7hdqRx5WYQA54fegUS8idNgYZi0fAqLHRpBU5TbWtx5YUF7russBdhAyqVTb+WnaKhx8rjzND+J0ryGgD4MFwO2D1fTqapKYa0X44q03xkvZC0CVlOmaNY1KUmRKcrWHMophnPAmtMAsDH0LCT5E8LVCrw5/X3M+9jC5srE0opwTmGP68O9L7j6ud3IPQgWigDlwzWsIQmLjQWo0MPHdf1eUfZs25njbaiU5xTIuE+mLHSuDIThUvIgXkFuvT4sOFcg0nLW16QM8srVl1GqbN2SlcswVtn8ta0mqi8ThmSHqc+c8mY+B68om6jEcvxQQfExh9MLf8P2aV8kOdfiSCE72Xp6TqAiDd7avONBOjZ+iR/67QQd67iDcMSK4vHI35VTPOr4APLCrpaWSGOQZuqZqrvVLE5kbrnGAHhNX5laQ2lgkl2OOV7GWV3Ce8C4yrlVCw/YPBxXhpWyoEIAQoBiQ3uQ9cA9hlKgHFu5OuJbq3hs8qyVDxh+idIaKhQloqj5PuYNG3f6HdUPt3J5UAW7VoC+h3yXKaHUwi/+XNLcqsGhSw/ac4RfrWsvOygzFrmsTdUvKHgeJAs43s0kK3tYNskSUUqJfVopfzBESuhL7jq5vpTTnv2gG2QoPZ1U/2PjXHhbR8Io57STFJ6kpVAxNuLwz9OLIeVfDGMCAki7g6vzcIAV7kmv9pCJ40J6QR4m807me2i9pvifqqBowO5DJ8C2TDmlwZZbc9c5oBJbAMzz+JAXegdod+lNE8WrU6RqKFUfo8asyEu0mDUD2aEcJYs/3TdreLrcoK3SmtewMfhvNXgmD5hM1pFQex5W+HiqXUyWAENnDYQbhniakvULkIuqgsMCgzFg8/+dBU6uMcej8jf4KBVcZzl2ECzlxq6lEpjkenVgQYiJD2PFQZ0ylZkYL3kj4rE3VXFxbR1g5ZCpvFKXSHuiVyFmkMuaQY9XgJniCcugVDiegnQjtpznhE0PpeaiQ15N7OTY1PLhTenf1v2unePYSw7Ftiop1oeyCoIrnUB0ex8H/zrFcHQfYwoX8Xxx4z0H3lYPTAQZoxBfbtCuopQTMdUwshJQ82x6nJCftJCTfg/FrmxvSRYzd1elWOuFbAPoBGgeiLmwzBxbDQ0VKDGEnbNrKHtiXzGAUbKSkhr0VdbZc7IgA+Gfan8Ft6hJIndaGmiBXkoC2A8F9IMq0H5dgM82mi9NJFuY/8uRWM8ZhXx0u5AOspA81go4AFDoDZvMsDbdUrvffEhqBna0QpkrmzHlRsewv9DztIXLw48hBYXWcWtK4VzW9F3ZC04VKQW2JhKKFnd5D8OwQ2oCQKMxbm1/VwdidxlfzoTiOT4hWGWGOl45PeVXL7pn5bn+Ib2woB27joaUA+5yuvXu2/B5HIbPD/Mzgfn7lDWbt5Kl75yHMZ1SRSlKwiW2JtJ1G7rH0+00SGOgn6jwkz0eHAtqLY4uuAAAIABJREFUgYi3X0mrjrXwGqr1wOSeZ/MTXg2sIxcskQ7VQTSvah96kOHtyX7UCpCcF6YW3HNCND6sJkuLG0/pdQPySA2Fr8W4wLKSzlGPR3gM1DLl26Rt21Eei7SiOzxhT+ItpWDFcnHMNKQhOi41L8vHpC3xnnqXJd64Kr4ENhkpmc8YT8ALC9rTKOy0F+UmiVcMkgaZGwBT3DY5ZSG0yMeRxMsU/kaNAfdflIbTukOBSIk7l6KNPlaDHmvR1cwZppSByQIiQan24JZZXS6VPhM1HD/ynGWJrwXmGi+YchzEiiGn3DQCf1ZTxtI6nJJnqbaP1YBuirdU/nFyvK7q25cOcpFv5Er1vxy/KSUzw0JVeuPwftzZIDH9jQTttEYvg3WuIafOp/lGUTAH4sealAHVsenXuHfmu3xL1r3LSIztVndHJl1qURrPgSmvzvUUhGVANHQ21VPZO5KPE9OYubic+7eqH6ihZRwDCCkyKdgOyo+0XVkzVsb23VS6Yy0xARKr+BhPCd+TfTh2SmYRjjLjaAgoZVkRh02ly/9S5BddDfmtoTBtb3ykvKBjZV1KsZLSKu3TSHrrtA78AzoKz+OPpRcOtH0hZdE9RajUWAuSlTyOZ964/FaePkg/x3PZmuFAWduRDT9SPqEmS+nXpMjbaMRghfdMaJ+pfx6FFdMoaN41HoSLELyLzptHUwHJ/J4DfkjjIQUaczwNw/lw1gccei5trSvj6km5gZziXb65KUd1LvF0vDFhJOtUepYD/hplQCIJ4GoUtRqFuFZpTnkIUl6gUgmDdMIM0fB0bdg4vSkezBcKtMPC1bmV/buyRnpxFCoUvH+Z7/lDEepIs79xXgHp9xQPg+NE+7k7X77KuACi6XNiLORR+9W2o3mbVL/5/hILpCn1NqUs4/OAIInGW8pjnuXqawpxdd30tflp5jLiV3QGimOFgljLzxJ85xTQuX1TohSoeiNlyN8YGqP8jVEkUtauHLeGZ5J3Ydjc9MgcutSgnT4O04yi0tyr3EnL4Fir/eQaOy2o4jDDzl1LYR5e2x+rvdVbmry+0qKegGFO/4wdZJRwqVRjyz1Gccv1kSkacw3gjRnkontv4LYL9B/3bAxNcYcDCwET+9Rao9emozVNM6/DJTISVX4CceU3RklVMre8U0A/1Q/HAnap7STrNBxLJLuHfPnn9M7lglg+F93XFWFS5ZOwYso4duocMyYSIfy6G+65NV+qc7vUoC2RUmED5Wg4dxhqQ0trnCXS1oxUincudpew4mFDN04+D1mjm1O+3KDNeS9MWGC33WK/3+Pk5JpdBTxDgKnwuMhanmsopfiV0k9p68+FoopIWVF1O+nrKTcXH7Cn0mfP5+ZDq8dR9Ml5W4yUMRriKhxY2xjK21lehJFKGsXheebqIiVPqM0C13DGGq0zVJT964V3vhXpVeyVS+WxhLs85jfZJwtrPVx9mDmrJLlXFqQHHr8R3eXSg/bQJV4+mH3KAK5xH011q7Jc4DXQIGX2PsyvbnAsK5yB4YBNDXKJ+r7HT37yE1y7dg0nJ9coRpLPrHsqY84H/pOKNospJ8CW6lcxH2MBS3y+pEVZkedUACqB9BzibWeu1wCawjy/xFv8nX4DMDdLFZMbGgJLzOFL6eXCUB6avA7RuxIPXPYl53c1v2QobQCRccJSj8KyPeCB4pHiM+QtHktSGcf04dFtM1E3VIA7ltkphBPkyaUH7ZBC94mhMhhI8Usu4bGu0xzlrbmB3h7kSa6ksKNyz8ESVl5Yf7ELnw8oype8BCm6du0abt68iaZpWNy80hNaiWDz20OAFoVsph5SrmzRQh05PTKFUnnU9Tm2chkI10lp+rBtxvsx/ScMF77POLbQ/RnLae9CrizSs8H0QoV7MSig/cq3BLobIjKxDa/wglP5KhlYVS45W8uKpaYgSqP5CsqwDKGbORPTKtJTlQVqExms+e88zyZ+dbYsjqQshLKO85T7ncsnjjfVMzLG4h+MwRmrRF8w0M4dtlByVZJ2WAbs1PMacCiTBt2Mo51AoOfpW3i07uyACtOidObylPodatb8vYJGfMOPp0ePHqFtWyjB75Oy0gNAQKZbF7wAUn6p38/VrR1RbDUcDgc0TVM+VEQhqHknDpSOKi2Clci6oXyhbJUqH8dBZ9B8w8NB4vTod86jIE39GCVNOzCkrDWAlheLysDZ1Z7r2HKR5GNwmJimtIb1pFXP0kuUR3w6lrhs4uOAWjmliEjgPo0G7lqhDb3BMGy/kC+qtjg+l3slaqK6yPM+l7gVT0pKSbaUwF5612c05wAOMvSCgbYkIIaa2FihXGqgmvSkBpStSd5pZUskl1atFp2z2KZYkUN3ucg+AHuPMLtYIAXQtcpT8J5prDVDNeX2ex5U66LTWqPve/R9b+9gLhNPKchH+S9UR41KmIVg9cItd165sa4mxJeoqJRF4K0Af548InYj63tg3bJnKXW99ExKMxm5/GoEWZWB6r9g+UkAmaKxVmRpfDRNg74fblEdyk8J8InfNC/hGJWNkRhcS+mknuXmywO5JY2ZQXoTlIaUbKjoVC8MaNcK2nw4Gt6hBKt1qy5BuYUcNaIntM7T6fs4OfFEB/enASU3f5SrmlplqTZOrAAkMChLXxZY58JQHRivxNC9OTLnoE0UAKUv9mz11LxiSSEb8KS4SCelsE4pvYh2VbB2bkK4XwTJc7lTerqNnQC2qfyPUQJqrVBZuRvHX8owKQF3Kaxhppx3SSbnaMrYfGFAm1NYyXyog9Qz6xbLATMNhnDQPw/BngdsOJ7kjl07CBX7k/MqlTt+JAFnjsa6rWviuHAgq/D5tp3IywSFkrvgiMz8/9w685ZKrRwppVkSvimAnlQWeDehG+EjyjKVBkrFRWdock2/GWEhF3OZM84qrX5uZUtxvZIKILtg0CuzY/rP2Lqaq9BwZZE8ZVPym0IvJGiHDWrBN5oP5Z8pCqySCS7jpWlK+mlL2AM2DzMUqHKeYf36ugp4zPTBlFtLonhut2awTrc/yhTXaer9ReQbW5Bxu84d/KWy5eJYFXdSvpKHyV8ASb/jSK4HY8n5W+JD8g5IHoApaZfJL9ZKF6WsrVykFyXgJONxG4ZJ8RbKFE7W1gIvs9ZmJXzKChbXRkRTMDEfkpyJ448dI1JfukgacY3O5aHSgJUaM51GOi2psWvyL5Hk0pPSl11/4zTBOF3+LFUv4XNfT1WKDerraqyFGrTrYI59eSDN1d2S6afSlebg8lMKaSVD6gsXQaVyBOFU2toe/C1Y9+TlyHoQFslJIq9MF0MqBSOi6S/yBjyHaQ/p99R28GlQWUIDQ+u00irlO6c/pPrp4Hkhiylrc+bSC2FpV1WCFIZZZKHOqoJFDqn0U89TysBca72OD9nGHCuQ+YBIl4fym045sBm7MCxVC897gZnjYUS+JUsl1vJT+Ul9Nmd9S1YDD+nGR5RvLSBI8SSBm7KGcvxzqz6++nIKrxLPqTqf05NkHocpD/AhUTdhGuP3vY8dFzmFpqafShZr2upOW988vVQe8fuUdT1FwTFp5etOqo+xc/9j6dKD9pRCDQSa/SRXm6nMdIMsATAlvvjvXOPm3VDTtd983It170y2vhew2sfSEl6V3LvY6ispkkVKzBu4PuP3R5n6HCPMlEp2jeHcpaysURgJ0MUsAeTml5ewNpMgNLUJst6Q6emYZ8ukk6MauTSWpgIn5yPloawFxy9zumtJuvSgvSzRcZrjrNJ4UI9tjFIeUzvNxVqW5VnjybiSqM8qME+5WhHWx/OY65vSrpKHoyaN2nnS5HmIinxNoc+plG/wTNf1/aT1OsJK5sWgrxclBFNEh6+MjreAYp8GGMPZ8+rfOQ/JlHTmxKlZ71JLtd6eBHfJ8Ln596WUoUsP2qawAFUUPQPAnktx/ElcKQvXP84DlKThXQTVW975hRnhu/hJyk2VC1NP55sn+Jff+s+90OUMEH9zhBr7zoX530TK+T/cuyoviVRr0aNCkDGUXaxmu68uKBB1qsWLQ1ZiTYiVcB+7OlyGlPtfuz6VlEMSWAmppd0yY9rWjXLIcjqTUjGfcsc/tKfFZjMAbvirAf+5yuclB20Ns1vSOsl0DFoE2E0QR6mGxedajg6eh8SX7Odb6SK03Bq3qATYadKosZZtymFMzZWUcWXtmy0+vvn9UXG+oq/oK/qKXhwazpdzD8hFe/wuOWhPIRnYTOXF89JcO2IpVFhuKet9bLzSu9pnY3iozz8/N9foNe48/Q727VN8fvVHs/L+ir6ir+grusyk+hVufP4tXH32uvkdGFr5g1ti63qOrL7koJ2+4k965ivFn/S1CBeXyP2asrbnzTnRN6PYmN9lK/3ocBv/xl/+Qzy59v/i//qt/3RS3l/RV/QVfUUvAq33N/Hd/+e/Q6Nj2AwXkk6Rw2PiXHLQHkce0Mqrsb9MIM5tVaDv6f1/yygjYdp/k2YPv6Kv6Cv6ir48kqzq1CK6KQD/QoB2btWgdusmcvPVy/JRs9pZIq4wlFwlOeVijHt8Dp81eQLAjbOv4w//v/8hkRh9qMEztioJ2h1tSEfQEv+Ufyp55VdGj236Wr0lLoNjcEKecdJ2gbIKFmf5d5orczYvrewSJKUAre2tVSwcgKqlDMASRfD58mUQ1G7Bi2HeEp9ae6ayi61q1lRKfLr/NZMajemDLJGm5K3ja6QkniJ+uiKDtuI0oKFs5w/5HIQF/MlyM9pSwa4M4vUutIHWGoOjwTX1TTl3/mp47WsUK1ioSHkGCQTjUUeFdrezau0mSrVNjaIqGzDmVgRQLqf1GkpLF/pEZZq4J7w23gsB2kAOfPKW9fj0QorDTN+kX362BA1X2OdXvktbFMYupFj313D3i38ty0+JuEKUoiXn8msOMpHSTyleOXKCgtIW3juJq3wY1cQxHXMiNqQ8NzmiPeJL9UelFBPi0XMhb/4u3gpXW79TzlAItt4BABqPwVYJbJDRNyq2DAXjCEBnnsYpAQFAxWVP3U0ty73JU2QAGg5+QhtorWNuPUAmjaph2Tj10IFiWhOnlB71vYbYs6BNS5pJaaPoqcNQ0nnXGYhjXeW14V8Y0JYoXOG8nOC+SNd5Ke2xe/lS/NcMojj+nL3nOaFVw8ucOp8KOrl4cxeOBOG1752+p+qgy2rtQZosbh11a25LD+2ECj6Qbv85yumgLxTe1zwfo1QV7x8vxC/xI1FOboh7ckcYHCFvpJA0Sb5jHi7qUBSlyPp3b1HwhWRJaz3sLBjWo+RqTvFqvE4ajfZjhIZRA694xBnnFpFFXEefMh+kDEvPUsp1rRx7IUC7piAlAB7TkceCT216c4RCuDc9fD7GwsoBqFRXcwVZTfiL2BZRqvMpXpYp+QOk3XOnLIWBd/Upf8WfBm9nxf53qU/iYyzlFLx8HuFO7bmWcClciWrSMVXP+3067iR5RI1dUQVDoJLe8Z6Uj19L1fH4oivk6yMG/QGQuSTLwFzrhXOH4mjPa1zvXP/IyaE8cA95H1OGKeMCeAFAe6DpMeIDowRc9RZ1XQXOsrwqw6QaXgLVUvoUh6wSKY3h4OLu2WWE//PwbIwdDBepPAApd7ga2CiGDQZ4Kf5VDIvjqFa7r2kryaKAvvg6Xd4bJnvr5pQjcPOOjDus5/BdjcUd8zAl/xIg5UBI+l3j2atVFsXnyrZkUF8wLviEgZNSKpamVL3E70t06UEbqLEeG/tpH2TrXQNKGaFnTZpcO02t2DFhcx0/7SoMhUysNZrv5Q4i5cdCIafRXyTlBlCe52E6PI70LvU7R2MHtwdov9BOQaFn7rbUsZkE5hTOr7aZRoGykEhqTj9XUbehBV6SI3WO8lHiabwwNmPKF8e7UhVTdqWUglEjjWf339D1HYeVyFuG49p9DHhry2PoAY/rzjYslVGxSJQXC+qjavbb1HOYTb6NpPaU5SK98/wbi17wJLK2CTyNjDPqn9p35iFvVCLBk8AppdTEVGqrFwK0UzQEmExY7S0cQLkVkErT97SWPdblfJGuVzN4uQVsfvv0iOc6gZX3UOgA+HO8pyy2krZ9EZRWdPz7UnxOS2jfHaXt/osNaeXAjeXMAkZCqsaLyfMKUxyQVCNT60ErOCGpraCWgLu5IMAeSxxqFFsQ6BeOaeb9iCLr8v3GfGROmQE27Y5oLC4P3l2wxIx9H4hZ86DXvs4GemQE/gxD4QA7AXIl7yKNA1m2KbfoT4Gtd9DalMoGbzwX/n/JM6L7qKZ1+N7m2Sf4ztFUb8jlBm1VA25p4JZiRvaOC+c7VR6ApwLBHBItmUw4pXyJaucFa4F9SZpqzY35ngPwGvCWFsOMpVze3lAhgK5PM7cgJyayBLJupQmUrUNnlLEwE7Nfug8OrKI4gJYeDuMqheQdLRTWJKcnAbZjp7LdcvVUVJg1AZKspKeU92zfjbVF1u+njC0Ky4E75o3kX6Ma2UsQuZdifSNmW1Cjh88Us8pzc/gZj1/ttN7lBu0Kqh7LKuGYiuIvaQnm3CVz5zVq49Skt4QlWavMLDW9MKeNauPG87Vz0hMHrOLv83xctPdmzgxIWnCmw5oIz8/SXhL058xVS+lIHr2l5lZjC3VuGkulz8F3Kh/ib9KClZrXOAmSxrECAnRPKelLtekLA9qjCl30BSoRrCmfJamU3hQrsC5NOe2pnWfsfG/svlqiXqdYy5eFlrLUtY5d6In8KtLigWuqcey0Aj1LewSQFaw1fTU3dVMDglq0nSxvAphK6fGkvWUd51NHF7kQagotBdhzlfV6PvxUTDaPam6EuPG00QjtoOQhq2n/Fwa0nWZmfzdBxSX9WEGInGKf6lQXPQebn1MeRyGvRiLyZ7HLOJeOxOMUwP+yQXUKvzV1M9UjsohQzoCdjsI9j/UDAx6E/jPFYzFl7NUtvPRmUVxfLp0xSiqL6uSU8u9c/iPG3FRaymsmzSFfRJ5jxkRd2NAdXuuinpW3oPfl5EQqrVq+XgjQ1pABN6yQjBtWj7Q8Kt/PsfyWAus0D8OBtsS8WE2apcMuxpa31vXOny8lBEvzeaV42fQ0ALdgECAhU0xTR78RPK4C68H7Ga7T3BTIVADn6Yx1oWbLbuu51z20In5sXPe6PDZ9WwjCF97iA0tv4DFZYNyPqZuasStZzyXFLMdLqi9M4T9ONz19ResHzHKzOD9SoAbPBH5q+XQLLQUv45gy1dALAdqxIU2GhkoFKMQfnf1zdpnXxh3rcqJO/mVbv5eZSou7lnL5u7hBEtMVjdQajTH8pBbQLEEXpWBJlhSQB0VtAgJO6LNDPjBPXJAdL3lD8kAznS6ivZawRpeUM5T2uDRNa9CW4FLacxQIdUHTqxK9GKDNR5ICcsPqIirtoudl56RRmx7vlFPLIw3IsRrzUu0zJ525guXSKj2VbI31XExJq5bGTNOUeEgtVCrzKM9rx2km6y3ghStQXjHTJrECHzKV5kFLYZ4HDfNX4DVj3hF4xtYsD1OfR6yg+bU8s+20Yt7xc6VqDxaeT5cbtKOxpBVAJ8oOHYPLanVA2ep6HnRpASKiJYHgslDOzXuReY2li+BsrBdHIi5M5ffLC9cSKShoFc6XxdzF0BOvCxmAk/Ll0PDATca2pjeZhqqROUsoOGOpBFb5/OWpuzDoOJd5PCabpgk8iFT/GOSR7mmScifNg0+Z2rkIutygbUnBnFJER9GxjXGGNPupdfAuNY+Tm4eLny01/3wRlLcmeAXR77RVsTQtNQ1wUVTKo1Z4SIM5TFu6lUsNmsDEKc87ygyV+bwomupKrdU2alfnSm0wKL9T/LU38SJApa/m1ivttvQYMNCDqs6NPP5E677YHuMsZj+epXhTPGp1YFxH6Tlz8viJkQb8WDdFVS9Q3BPr0vKHqjhLnL4gUefMZK/KmaVnspbbYgm61KCtuFzTsPMGXLD5gR8ecGA14wwQx99zz3LPx5AoRDJh5/GgBt/l6H19irN5SsdNuSGnuv1yVvJc1/qU+TUzpr3k8FHLQnz4MPtzNkl5jl0MxtOR2kJrjUYpcWtOPL/o5ogLvKhIcPLx5uKQTs8P3tBhGgTS/H5ppWIZI+QNb5kPyg2NTjj3P5dWeRFfCz9+dZWbmfNW40nKKQP8t9zWJdmSSJcWc9kgDfyJgoMU4r7mUo6hlnjx89u5NQ/SUTjZmfGJi86myLZLDdq1NKj6S2YNc7qohWB5F97lIr7wQxrsPJz0vYYuovzT0zQWUc67E683SIV7HpRauzBnoQ5Ptyatmnnc4XvZ1Tqsv4H/9DmQP8R1jsD2cQEO2HPKs7Q1TTRH4XbeDQ6eE4ZB0gu2gDch7Fe+Ty25BkqiSw/axQl+coPzRQ9Iz2LkKnJqJees89jVVJPH0hZtITcsPeBr6niJOdOAD2a5+q08Q6c0IJRWqIKho3oecX5yc8BzaY7AKHkkasEmNSVF79w40OUwKZ7isTRGCeA3KnMQDSPAusTH12OSLzUMUzMFI1m2OsFb2iUt8zeXSsBc8ngNFET3265e8j+rKefp8WGAktwrT3tx71k6udhzNLf+Lz1oDynTECzI1IpZyhKe4mafCtZzQD4Hukt0tKmCXqIkIKlQaeP7mN1YkrJ38XR4DkCC1Wl1QNp33nMwt889T2u8FixTAj1wZeph2KGgHDaJJPAV09RrlMNsnY1QoKrzUEPsGWuN+jEQPM3mn8tjytzrHK9XLA+06ws6UJIah9cp86uO0mWvl0cGE9JRtPY8jlWap4zbSw/afB6QKCgoTYOo6Y07x11F8aaCq5QWD18CzjkuZIly2v3Y9Gt4W9K74Y3tCBDjsrjnFCmeWS0vPRkFBomgvK7HDvY5FvUwTigwa4FkjsdA6+FRkyllkYR3DECp8ZH1fNmFZRSrsemLyoXA2xTyced7UkIwKYeN66TGEo/zuUjybRGiouwjqyfuqQn7C/U9uGc8jsijVf5TfChlr9jNeGYCD9NMuvSgXUNOCEdadvxdIinsokAyA8zHNvI0YAW4lvhlz4WPcacF72Chl6wZHjYy1UpGSq4GqurX8WD+y7l4x+STU+hSz+M+IbuCVbCAqkYhqAGDOI3cvH2uDHE6sTD2L4bq1yBteO8L/cl5sr5U4FWKP3CjVqQBjDEcuCJgd9ckphRiQBxLNYCfK3tOLrq+hnBaU4PAMlR4aj07pXFgKywZf8B7wl3nwJjSTBDPf1p7e7r8oB1UhAp/CuUdA1ovkkvy4ojpurGgSXS0xXJexEq0z+HFmAKM1kuub/LG0PadSt19zHDiVk2NuxKQBV0KYKU53BRw5gBd+h7sfrpAGlgb2o/n0ty1ZkJ7rEs5yxOWsH9tWhlriiuVyyrGwxKQRRmNCEb1ynAczqWQCZ8zHgbKTcTdQLxP6JexIhX2GZW0nCe3C2noBcV1qXa//KDNSDQSgGA+MrVApRYg5oDTEu6PGoGbezaeytbe0oBdo4mPzZdf8KDZ/yYheq4CTd48TK0urpMXgzoSDVlZGRKFfM/7q5/y8eeBlC1Q6XkNjbEASoI5/i3yVbCLY8Dm1LDtU1OEYaBeaZ9DkJYx99JpJOpLKqvW2gv3iHj4lLVXIxOM8ajc9yg0z3GQ9hhFKGVVS5btFCPK1xVYu5Tzr0nXlbU3dv2Yckthc/P1KT5KaZbohQFtucAA2VPBOqTKRl1qjmFpqtFS5yoXPg3Z1qhREpbQHJe0tvkKcogrT53tbSMAUHbONLA86wdxzI+K06qIF7jgVBjGseReqaw2Ma0+MegCOW/AWEoLsWG+Yyn2GIymVJyJfCUBbUQaWTdtkJd7Owj3vKe5crKhdh59TF5jgHZJqqnf+vabVgcvAGjnKt1WYGYRwBhg/rIBvCQgc4A9dVog5xKvTWfsYqD4/RJueD2wYmRwC2fQfNCQSYgHadTwxnB3dJtoFnuQ/SCt9Pwa/12Tr+QeLymHc8HB5OvbQbL4ROEXzEob4Kq5X5xoOA+uol5Dp6VF6Wq4xa4a6XrRrD573hlc6jYPN5drFzFRYSC1rEzDNoj6P2c+jIlB/3f1yBXaMAkpl6SyF42/rDs94sz0DSE8Z9nWc9BPaW45xa/m/cy3b1yPuWFTUkYC/jJhUhZ6zXi65KCtkLuhJZ7nCmIOGiIv0JYA7FIaS7i4a11OuU4Txu/ds5J2mEpzbF2mwqdcvVVpZHMUU8hESr8r1v1AUBe4iOu0Nm5UNVpr8UrUi1JEa+dA+973ryEv8vWIcRpc6DZQ4JOdIa6MVyAaEPAPFSeTvnIpU7a9kfhovNgHGBA7FlkZoDRawKXmlccQxHk+OTLBc+ODwg3Hqn/kYU1B2xO/vCEUnn0RQ2viuQXGXmn0kIEoAD5bl7GSrKCCE8ioTigqpdH3Ouwj4O0Y5qnMFwqEHAX9qjRVlEtnhIVd60G45KBdRznBNNbNl1vwc1E8lsJMsUIvwvU/BkRr0qkt15R5n4tM58uinHJK76Xnz4NS7tGxfOSUzJzwr8037gO1lpONHefm5pBl0U0KgDf7yoqF9yAQv8Fb0aqeR2T9G2M1DShh/nXviJJKGavDsSWS5tBTdBEyZIk0JeOyRC80aMcVyJ/H3+OKzlmsNQszci7mOQCdoyWAuNYKnupul95NFeApy3tKHVw0iIXpL68YOEuscoHPZVivwa3sWoot72AMWvxL0ZwFReU45o8bqd5ZnksrtNyrFI8qjka6dFg8b4UXQlb0oSRg61BBSaajgSZ6lTvjPU4v1ZYpz+FckBW9jBPSnDM2Lzloaxj3bSwQvXZrym4dO4KQ50JuKWsgB2zxu7J7ennKKRS18eLnY1ZE5ngYo9DkPB5T6/Ai6j7sW7Z/LphNyaKM+1p8XeFFktTPOeDu93u0bYu2bQfxjLsyTCdH/IKRGsVa4rXWrR+GU+LXsZSzsn09mpDLUJyODj4lHYgbNTk+XYoJ9/dgegDa9BGOAAAgAElEQVRDeSvKxuizlL9EKcX2snjZeP+SjMkSXXLQloA4FuBp4IyfpbSvmrwlXnI0xVVUSzz+WFezxKPkFqtNJ6X4lNIr8f1lW4ljKWjTC2Rdqpc5HoileeHPlVJYrVaT+lIgxFy1+kNg4rFcK8zHUry3X4FZ3Lpu3LgwQvgcpeSYSSN9PKl5lson4pc91zpWQOcBXY2S5HJic/qNBjCiL9fkU1uOL2ssjaFLDtoSSPKj+dKeiWEjadfZszlGFnqcfw1w1zR8zgKf40aOBVluAM5xF42Jmxc+5bBTni81/z6efN+cnZKgfec08iU8Ebn4OZBMKcTS4jgWAjmr0immtGCNWeW5abFcPx89H8n94YM6GTF2MoCdU0AkZbf03lyJWTAMNLsn3Pws9qk4n1I5Us8G8WiqIZoJyaUjfX8eQBvL01TZSjzNkb2XHLQBoLFjRRaGBri5azKuMK51LudSHWOhT0l/atxavoZ1FNJYb0CN1RM/lwT6VIv/8hD1wfDp83JTP8884v6U87bU8DemDJKnqSRAS8/kd3y6w1ijvXX/NoJrn7u3RcWHlyGI49NS/GWS15RS1QfyMn6vbB6x+ZID5xLAiPIRadd7HE7B7gooNH+ssMZtX+v1W5KWMnxSColElx60SyCknQIcAndIsoU9xnpbWiiOBdspHWOsYjE2j5IbrcZ9+ryJex+WHMzeKoSTwi+ewjGOihZURR8f64qVBHYcd44g5eTygAdWfx4AmagGcoZwPCxrH0FZylFdZ8GXvYZBaBEs7dYo0ksSVmQNYA/CJFgbeEn0VFNqCNYSLdEPiv1JKECNl1WSRTX8XnrQzlHO3c1d6D5MGSxSrrextJTAngJwU/OeIuxS7trLCNgxTfUkSOlIQmvu2oVcfped6vpSnTJtoG5avxwTLummZvhsLGHLd+Axl9okflYG2il7zX3aea9D0B81y0vbPdnKhxPjVFCgvAplEUF+nP6RnOpYYlyMcWe7fL36M+CxJu2xYV5o0DbEW5wDNYJn7teEinsRhCQQam4jYwZpjAsTrjGA1kx+RO2hG7+cJ6mJj+W9np5PO8amg3eXjxV+UxWoKVSKJbk7s2Er+AgFOwMNSdj7hIOHzhs9hsFKIkvQL4QzeTQqxhkt+IIjXn0KF0JhVmmv48AtzlivBRo+G0ltSJ8mvD2sxRnxDNK0NnPXNLUwss1Slr3r+4q8HL5f6aB9zO+UP9aHIuUj7G88KaPIUV4qaISxXs4xY/dvAGgDIaDQPKnfj1grLGvd4lPmrJecq+XWquQmVK7jUoeSO4MPF9Kw86gMmMYA3sOLBgVof1qRUm06qkhUtlI4gasLns7IhPT/uyh1g1nKs+/7wmKuYRyXa2bhE6cq606FQilHmukt2fIqXjMZT4a2gp/l3yvmFmUgUqrd0ngevOcyxC3eiutY4F0Pf3pn+0VRPJ7D8U/z5Vr7RWjaPnfKD2NRqqsevvj+REr/naBOaTtP7cJFC8k4i1NK+v+397Wh1y1Xfb91njSxTUuiRkLwhibSS0JaNKYSEyrFKm1vRNIv+ZBQqKWBUEhBoSC5CC394IdSqLVgpaGmfpHE1tY2BGlMo1AomBg1xrx49VoDuUG9tvgCFaS5Z/XDnpc1M2tm1sze+7z8n/17+D/nnL1n1qx5W69z9lFkHxHhDP/Et2hpMedq2n+7PotMyL2jvAsGQHYnLMPO3t4qHfcAlHacsAg9NJTUGrSEemiFZ1oHYdYql2pIT1HWM20NGy0kvoriNkIUDGe0Hks7i9FDMqMHpHrtlhGOOj97Hs6yCoU9D+ZMQ2OJkpfhSMKWZxcuOWbSM1zjcMT0YXmYzOs16WmvsSe0uRk5XNVDLwoQDbj6V+FyPkfWx5bzv5bW9hL0wiCa88T2wMxkjCoc7Z41T9xayDm9Wqi9K0SkIjtRiH/Ftm9LYazZQES1rzRREB6y7CV52xq78sLRR1RjP+JCWOsox/Re0ljXAmnCsjrog3SRK8HtFHYN/hBamh9f2iaKXn/4TIuvXAkwTmOrddeSuxIPwNOWyBXD5Taxt+DWhMG3CMWPwi+S2YMcZZ0oGHxYKj2cAhBdfn56aKUweqdT1XGjMnTXo6XxdA2syY3PtQflByP8T9lEnoBsvLOx9+q8mu/s8lF6br26vUjOCGppCmvKQ1+/y9fUisieku1IA8Hpa5NvxaOWKZJtEOmmbUVZ4pWyTF+4EUgoudhDeQxhIpJj9doXWdjGY5jTHvPk9jrZO4pWSH3vvOyW4UOPJTcWvWsvOHxQR/6K0vVH3zYGRWixGhav4bIe82z4f42BsQa1w0hyV4dr3sDU7hVneOMaLPL4txTFqMiumdRINMAdZS7nU4bD1bAz4ve4427V29t7HNshdk7e+1y2ZdgIWFJ3Rv5raUjteuK8+bEnJwV5rF0ND0Rps5io9oxpAmnL8MbW924BI3m1dDNHe30hsU8/R8evV74W8bB6XwgnfNz7Bu1e/i1QNHqKFmNvTZ7UhEGB5H9dQLbGnowWxKBFAqrscT3qFdkb87prRkxtTYzMW/jRT9GXE526a6JOlpHGKPqKJgwzLe43u9ByzVtuKexLRmnScR6urNKx7sfe9dJAIlCwhOzREg0PRmnLvo4e8NnqUFitjVtQyikPMvjVXiSjAr7scxQyp5MS4nTQBYCp6YtBC9Fa0yE1I3FrAbcF7UsJ3bDv/Gf/H/lMpP+saW7Er+V4Bc1pub33Xc0L1OSJttM0hR3KDyi/2J6uD1pKNvHxOU1lSXo5i73IFMnvRq1AHIeeIbqWfvtaD2qKILdEV7bhcfcH0bbE7CDKAwT5YYJZr2dtLjznbcHJ/VHyV/MsrdGB0iCQf5cLpa2FNdxtD4tfD/fAo4f3DTl7P07IHurcE/n+JyKnVWzttqIEsQ29nhy5kYgCZ0S3itaMlm3Vv9R6XqOwPagx32ujrrftaVPbcxhdOH4z+I20ht5ajEYDetfb9OICKsOzXTaqbWmhXkCfpyKvZhr79Up+VPiM5HPrtAnIDttZQ9dboBaq3YrmVlB5I6tqW5DwJNzZGr9bjEuNdk1WUc0FNqxvS0SqoNrMA6d0YxjX5RsY4PPZecsxmlGjUecn5pb9ut9i/VgiWb36Zf6/r2M0uVWbG6LybEWNl1r9Fm5baXPakbUWiiagW3mou/FUsoWXh6ZdKaWmfxCB3XgZHZPWJutb0P3w/QxG1krX4wn/iXBtdnyHXKGq7PY0+lHALr9dnvNbliEmLIxfKVDCKAWiUDVByfAkj+b9TiKcLOeL/RClgj1fQ/l5ZfJ0fCfz5hIjBGX/svSCpyOnVD5fnPwaFGX9hxMo2JkkaMuiPuyt/RpXQtO96enR1hmRnnKuGduyXMtoW/jTDSlpbLQMoF5YnbicVimZ5boewW0rbYHapG4Vepkp0/KcLsFXhwKyHY50e0eBQtS2mkfHaDTE3MsrWYXqlsaGrV4qNL1gLWowFWU1Uvno77q+wqvBK5DC3ETcVtKcswUCjycinBnQT1yn3l1kpx156K39mKNc6p5dW96YySnW5uZE+VruGIbOoCavaVkoSW2dRQ4EiWXfx8eIlqZ8nrduUQbnOdVMWXpzyjC1M5HS3n7QPOGactbpyDmK/bDmvQN/bpw9t/JoYG1wrPvhbpS2htZE5e/3bP826dZsvLytrdsdR88iltdmeWyFtSz8aKDsTaveVtGb9SF2DgbCHiHvaqsr25F7XfNSluvje7+nDGL4eJxXjda19pgmK2fWZCuiMzLHRRTCsBZbSri2v2s0uRHV6qUkLIZDrz/aHes83KXS7k2KHDTrBsoX8BqvzgpLm70w7fYe+db0Hy7Y+SR76L1dxl2EQ4HrKpE14OqHnRqh8nJ4JeCRkYeWd9bLkV8ClvVwa6nDlsPWy1f3YFHe5rMNMo8gXHhrGk7itpU22ZSnzz3kIdUtQ9Sz1mitrtV6a93fY+PM0FyTYqijvYj9/N6K8NgCBHRDy7U+d9fTZRzq3VD1XAjBwx79xahum2gP20xzMwpa80atyqilFFret0V+tupbkXuno3Xya7XyFqdHixxo491T5lrbboXGlIoSabDitpU2txcbMJAXG1zso0p1tFwLvU26t6Jaa02vq8+V9ylGaffGNC9nQ/n0JWtEROUh0xJF6iLxkrMGWBoyaA1dladbRVMghwN+cxq7H5IVXnXwmjKjPCkfo2ZbpR4ukeaTSvN8Phf3a7xs2ccRWtY9XD/bEFMseaSzpxdG54OofGSqxpMVt620UZ8cizfbQs/62jvXN8Pv+vuyTFy81eTOBnxZectz2Mu1eZqj6Q4rUjr5OfFe+Q5t5MqgYmCy3mZoi1NlA8mjcd9svf4tnqS1jrdJckPG31CpNZRNuCXrEqJ35NIg0hYSakyUTfnWDMSa0B8dA/uBqzbtllNUU9atnPKMUs+NBoujZlWwdTqpYh9xyvLy2tjIiJglV/9wwuMCWn6iFxJpfe5Bs772Ch236liUk14mFy/yVSrskl7+fjQ0P+sFyzOWvUXc8+a3tNxHsKb+mhycOkeNdgAM/U73XrD0UaZCtIiJ/wxaIhCmcRPjdc7zjr5dd8n/lnchU/qtrDaK9nIeWhEBi1ExytfatKXmEdfo+zJtpZl+08CaDtDaya/l/Hb71S2V4vq7dgLWBdMS6Pl9Ocmz7c4K7JpSnBXgEXmdOSv4VjAazt7SsNgLe0d0NOQK8NZRCF8S80eiP/IBQvIvA2d/2rVi5xCBQMv3mZN/upetQRPul4ZFzs3S7WFN/62Rxq371huvnjHRpI3UlaLsWg1342kDc5Nt8cj2whqlYfX8ago/LqZxT116NtY2Lffa0D38LaIbs0JyJjpjDVteymiojYXG5zV4GTEeVE9H3gfCd6kJUsnnLnTmNZpaL2NW4dMV7L9aSDa/tsbBmYlUaXRrXueMbOuVn805a3Rm2q7R1NrLS1hl/l0pbStyYXkrXpXElkJT3xBaEEXzIfrQ8nK1ttf1Kw/hL3ntFpmLzm0llywvzginKUZM89g+FxCoDeb0ZL1R5AaZRXEX/PHyXyH6vP4Mutqt1+QEH8RZAffTlRzJJHqefFMskk2tB3tGfpcnncVogA+Drl0JtTD1mshJbU7zdIQsQ7Q85CYWRmEM5XRG1lgzDaLwmt/vjcVJsBukDcVPMQKzPJgm70NNt9TuW3puHZ+7UtqjHp4UCLXBnW37EspiJOxi4c+Su7K2tz1im3LzVEt3lOOod9vzXPIwFhx38oeltjDErELHBqGNKu3k71vXatAUxsyabaE4/KP0i4o3vrJKMHt1/chPtlFZvTggqHj0RBROaLBT+o/cq8XwsayDPcLsmnLWynCwppd9StlS09aDNZXVOujVq2dFbkB5Y49omU4/xy8I3mtGTM6L1ndSrs/O310pbWBcmIxCOwy0d5sWnnpttLzhGb6sm2YWtnFtK+49ofIWNvR+2FYQb6s4ffk1wkfznLTDPRr2UlKqgQf9azo5Z/JzVGTxXvDQK6yPeshyf28R1l0HYcoShwN71dITIfigLC3cTPZ/i2jFLGIEx467OYjmw2m1ex7+JKBWV9IYtWA1urcCC1+1PmkY8fAfEmS/62vNTuchQlPYowbi2vHZYi/mRqk/SR/mnuJcxxCnZsgtdQM9r0w5M0Kova5qvK3p157I5els+zUahbzGEtVimk3ylcjX0RbyfYhG1m+GrW8372mPCABLSFSz7C3t7A6qCIVWlQ15rm2+vcbF5sn3N8BWIX7ZX59/DLGytCTk1grlLoRZz8yjtkeshl9u9HplV+Twrr2fqhDZ6YbCYRdSieuh8lOVzDhDhEAD9czTFt/nXjMHo9AiG5H1dgi7NYfuWEHX8FfrGvqfr7Mk5hbto6mo15pxtoTjW/nupoFr5OvmlbYGywGz0bB272BB79oMlt+wPYEpbvKcn1a7I7mfW0QzX7Z8Qk1xa2mMFl0LijHXNhExzj6HdwWMCRxuC0JD1Mna/mwqak39KRClPy3ZSCd5xUTuV9pqnrYrttCWtKQiryxlv95H5ZWERR5q5a3X6+Uy2cPletvKEPEetm/RG9blWQfxvfsGWso3+UzhP5XGyH6wpoF6uHmlnVv3tRBT65p1cC7pJXhfrdWUJtTWGhFr6s96r6NoKZOakWJNnVh49OHNeEHk1tz1IIhR29JzqPXjGqmZntDdep/U2rNECyx0Ax0q50y2vSjs/KEX/YhfWt/pad9Ww9ttjWOt714O1qKGawyinjEX6Mv7HO/5umuVVBq+dg9DkdEvF51M51aLjun9q322QK6pmfNDMwazRzenTUQfIKLnieiz4tq/IKJfJ6LPENFPE9HLxb2niehZInqGiP62uP6Uu/YsEb1vhMlWjrq2aPdQ2LnxMAufn7GEVZm5eBawv669t9DzqBlArbr539YoafeVsRVy3Wh9D9exbIyTa514+R1nx2HB1pbjcomzE1r/t1LAo2tqBkkO2Yi0r/UyQQ6Ifwbi6UNamF0UTS++Zp30jNMt1k/t/EthCEheGn2t0cjL1fZlLATAedgnMTe57K69WpHykeoYTd9ofe3RXwPLQbQfB/BUdu1jAP4KM38jgN8A8LRj5g0A3gngL7s6/4aIHhHRIwA/AuBtAN4A4F2u7BD28EKsCr4l7EcwwmluvQP2TSBpzBgxt4BCLnS85g1bDg1T/neh8VOFpORvElus4XvFPgYRue/yEs44La9y4fK2h52k0jifzzifz7sY0TWeQ/uI+2ExdMflTC7TaoYvEQUD+sQI6Y2k/cwAlXz0/nJ+RsZjBFKOtNCj3w2PM/P/IKLXZNd+Vnz8BQDvcO//DoAPMfOfAvhtInoWwJvdvWeZ+X8BABF9yJX9fK99Vz7nKVwf9aS3wipvivr8+PuzB33yxSijA7cusFP+xqMaa3JG5MNrXPLh/18T2lqDyI/M7um4hNW/Njd3TUiDuHWtVtdDqBb4efGZ7MXjjuVqo9Rrd20OWmtvTX1mdhZ1DE/32tPKnM9nk6IMXrik2WkrN/BbY6zJyhGY2xKGHLj8zr6s38IWOe1/AOAn3fuvx6LEPZ5z1wDgS9n1b92g7YA8PFR0PDlbEL2o8CmLfibBWULy5XvfTlFXVKT0P9E2XLYsExiNMHDSF4I7reqtNh/Mzbpb8LqhcA35K/9+8TX8u2r80YB5Iyzf0sv8hPSX20hxpDh5MIq47O7lD9pYA+k1uCuc3udgJOgCJBW0XB3iUlhofZDXvFHYplVLQ/lr1zJkWgjCPuzJS0VqsFjmnKpqLzPK0UdWxgZtffToWKOVOe2CXvjsc/+6py8dhdGQ8tbG4JpI3RbO4ahBWMMqpU1EPwDgKwB+Yg2djOZ7ALwHAF75yldOT1zhWZapyOQzxaVXlCP4+mITCqVYVbjhulQVthBJoJF5x+yYk+KAFONAE9b1cOs4vBHjFUhm82zU3lAyQbSVfvb3l3FfhMxZKSHbrClsStqx9yk3oPL3moeQcJXcK40+S7uagGc+Q3/kbR8Wr2AvtDyi5Drr+5PBpYyo0J3po1fQ0hrSf89pnfFQ480anm4Z9D2jrPXIk60U1Ci2MMZmvG1fz/PQpZFHDgbGYlppE9HfB/DdAL6TI3dfBvBqUewJdw2N6wmY+f0A3g8Ar3/d66q91nIYsyHkkfzLTN2kHuDcYGP5Fv0gF8Y96VUKVdHQnOmRLQ0EG9oh42UjYa2MXNWv3Fv1ijQ+2MO6ZtveSW4Y7Dn+NQE126bVYzTT69zfY3y0qESlJHyUxVa+j17EYyRtYi3bKzerAEfqzXrOe0Rcary3DPIRPqZMbCJ6CsD3A3g7M/+JuPVhAO8kopcQ0WsBPAngkwB+EcCTRPRaInoxlsNqHzY1xiIM7KzmE8WfxAseHyPcl9ejR1j0wdrX5H3+eRwi/l6ZpyIkXqMUJtu+QDYFwblyaZTidnEdr7AGIsKjR48A9IXHFrlnjU7PCNii/UvD75883VArB8S9dLnwPov/L5tW2KutLcfQQmOLtlqRiuVvHe3evpnhv+tpE9EHAXw7gFcQ0XMA/imW0+IvAfAxx9QvMPM/ZObPEdF/wHLA7CsA3svMLzg6/wjARwE8AvABZv6chcGgfCl+VsPRLIJPHCdD/WGBhpc843XbIRXseNs+NB75l3WjpykF8Uwex9S/3CMSr9cU77d8OEoLgad8WtZE3drT6NcUdlrGxr/Oz1idvRTG8qzwMixu4XavNRM9LtlnsTcrAXMrbcv9SxoDebTTMq5b8Tcb0vZ1NX7YRUSt6+JSY205Pf4u5fKPNcr/IIAfVK7/DICfGeLOoRcyq4WuGzx2F5Vsw4cv51EK2mXrckyuVnKaZYZVRBIyJ4kmHtNlHTst/xp5bCuSEVgFaO1AVI1OMGSYg/Ezg7WCfU6YcvJaW/+1kJy6rm7YuLEg8M+LN0QgvACO0TW0p1hLI8h7G3Hp8r4LX2cQ/G9/hSAVose4tt3WurAqNVm2Nj6WNq08WqHVGx2z1j6oteePJsxiD0V+809Es1qUo7BO+GjuWi9XmTjOXvOqftO54+uFgq1c17zsOm/p/Zowb216lpEQiuXXIOSgzeiHspjnIgGXU2ytDT6/+fvzDuSjMiJs9hyf1rojphCJYzBO8E8yG/fstu+DUNgAQMAj5ErwGgZg3zBvRWt8/Zaynlk7o32QPFpSSy2DvsXXyL7TjB1LnVHctNLudWd9frlNeysLeA1YUYIyPD76IyMFfSWcZa1nW/Tbo7ZZW4KDXfpkhqstvaBRI7B5+GGITouvLGSzcVt7eBun7jc25rDFuhWmdhoYzzxfa7s1JTNyAKzmqWrXRsZglKeaY6Dt3Vr0QzMqfP54xChr8ZrcG1wSI7J0Zm/czU9zAqnA097XymvXR8Mqe6C5Ua3lLnjwIy8b25aP9xunlyOdn7pwy+exNhbhgMxSaUowbznOPWMj3u8LwG1wubznJuC4zkaxlUyYwUxKYu2am9nXo/Q1JQtsN9aXOBMh6W/Rxp5r6aY9bQnNQ1ljEdageURb5DFNFmDejhr6lreX8PhaBWnh81LQ+tu6liq4upAI87oJl5eEnqfOP1vmbXR+R72oS6LMJNn7tvc6b31/WeNBvr/mWYM95NxahTuSwqzhkutWi6Zs3f7dKG0bZADUsHGghNlI0KAYbJM/97bLhqJ0osP/SjdiD7dYDD6slObZWmGyciPqgWdLqKzPm+0AjHuuV/wefFJ2uQcgfQoaR87PFVbm5tqHtP064mQe2zRtXnZSY5NQnPajNPnnMSO51V4vr9os475Okq5/n/6w8UhUKsi8ubgnGl4jAOZ4uGwWfrysBgUDeIHcO5ZtcyLTZg2UEJ1S5EA+R1srpWQs4HeSvoemD7YJ0bqkztx5iFNO1wej0zSSlCmC6kWMrbtQ2rU8oLbB4yKq5+lCWXc73+jVdjrz0cpT9fKwmgKuNbftsvBqS3qq9rzQVotUH7uBfKtyAEmObTLsjiRRtgaUqIVFidThD9OlP/TYy+ndLurRjEtjjcG6KOyU2kjEKfeiihER9K3nPqTCtq6L/IFG4UN2vSbPLAq3NS69nHmLVgtSYQfTTHR2dN9o43wGwn5n9z6Jkfg6oV1PQ8pI+X5sLCRvozLmtpX2RGh6ZBEy1Q+0pJXsbdfCQRavUuaGe3lsy7hoY1HWyxSau3Zp1Ptt4IX9S0qj6+mx2JsKPzVjsQ8pNZf3NQF5zXDotdDzsqcP/mU2RS8ltSb0usc5kjGaDDqvN6PMqbsaF5X1O0NTMwJkcOd0OlW9/5x+b2zd9g/pz7wf8XNq4PkITWn46e1YMBqtuG2ljTlhxsw4nYz1nIVVK53aUJeBlhfJ4e9tK+x7C33egNpbKfWEV/S6B2hWvJ8abY0b8hb85e2gzeHTKBbYDMayvOUgUBByqV1kVmAzc7F3SHiWXuL/iXTenjn+XtkhWrFSUT+EximVz6VibcvIGqwyaRmfs0ifyIUnXyvPaG84ERb5kuPmlXYLmxxSQH2js/hbi164LabRr+1xsf5xkK1bOrQ0gplNNNPGaPl7Hc8atLBgLdx6Ur+DX/4K25lF6ESFNwzaxZZwaVQUtzn2cUyiLvFnOlxCZmPFnUey5HvpAW+xXhnIfoWPwxkDi/HXSlW26pR8u/MKSnUihj/n4Y1zSa+HWRlz10q7Bi1EXRug5YBZXOxho1KqvkZoWnhbkx/eipe0vmIFDngvLexviHhG17ezNrqg0lxb/0aUxho2Rsax2CM9y5nH2siLSc9OLvbaY1AvNR+WQ3CxsIsX5rxReoi2rOgUvE8xVcqGq6flQ1nOPxcxhpXzOVP7IeVs5exQ+EW2yrDX0k7lQUOplLW0oMJe5iWnr6kxaY0QrV0/D1Jpz4Cz1y20lfWQgT90kV/T4X97GesZDG1pyRl3b5MW5kLrlirhIJAlUlG5FSMdZYE9vO51+fL7wGzIVRsPjYp6EC2rSoXmaHhboqQ34KVg3zvaYTmHUUDZozXFWCUhDJZWxDE5KyC8m5hCysowcDI4JuwOa9btsmWmT4TEhOpFLlvnR1r1xu4vnnYtvz1K34q7VdqWsHcoi7gom0p0Qn5K68mSP5kJ7ZQIDyxX7p1EmT7UpjZYW5t4qEFg1u4LD6nzVbWY067klSY6PavQ71VR14TTmnB/97AgnKdV3i2ulrZnm3YSjl9IWqsPo9bPNbnsZiIgOT01Qd/tCW1c8jM3ch8kMszYteqhNQAcFl0Z7tba1fqxFfIDaz40zs7AG6U1i7tS2roVKRM7cilzWaYyrqp1bwh1WO6PhOys+3eh6UMz42FHDWExmr/pui103voDEvJo6zlo8HE5WNq/ZrhcS830ysmycl+cz1bD0hgBGdjfaQH98hapoRbWyhgL3ZoxqkUO1HqqyCVVYSc885wxl/Aho2cNY9FiAGMAOi8AABm/SURBVCq1MSRfCiMByXtPr3forPXZirt6jOko/GD796fTKVyzKl3rvTU5ald6sJ624Gy/IzxKdx29PjZRlL3ICzPOfEZ9o9o2vCqgbgg+6nM+nzdX7nnY0bKPJG5pvAov24Bb4j8/JTvLW76e5Zy2xkXKVatMHeEplzlElx9/q1GajJkhWrp2rO7K09bByUuwdphTa48Z5QOdSmW0jHn0APzJ1exLB4unoJymTGll4buK9zGGlkfI8F9N0Lzw2UNW7McuCV6MLbq5UPIyPynbafYxbG7DWBIIxCeUPyVKOCHOp+c33CXZeS3X3sqv+X5o/KSvVizc6F4qJW/qmcI5LAsrPAGMvMehcdH2Kphz3nQjVA89VoxI8j3mrApnb9vJkBh1iv83CqciiOSt6AHO5sRD+k3SdQ2eOHQn4Mxn5aErJS9FG35XhHmhbtc1r1L2M8pHJ0OQy9GlCfmsjHM2N0I1LoeDXd+W5e149iJe9juoAF3mnZLJkmcX4p5lAGeFhh+juDbtclamUmcPEd+/0q5szloYTx8gea0ccO1AhaTVo29T1tlTlpoTKRVZXtYe1FMPRPG2YcFmCC3jpXZPlPIU0jYadJM2/cZkFJomEYobeagWrzS/YouxKE/hGiEwCS4MAS8l2/ujQ3Xivr4OksxYpWlNXauhTOse0i7kbHUUdjflIKy7eI5Df8oe53UynE6N4Cp5Xgd4a9AK9RZCzsLLirEb6zB3Ys9IQnJua22JsVfS4K4IB1kgm6RYwHRWIB2LUna1T66jes2Cu1La1tCDL9sPZS4zWz28dKX87iysHn+zvGKl9+jP8mXDdp5i4mFzzpfuLZS8lKGwWYyOyhbGRG8tNHNxmVvdO8Fbw0iEZ2tYBWXvd7nrDaxr11KOhXdfa3+LNEZNyczMy/ZzOU+PmRODQBvzmdPnebn00Jquu2aMortS2hpailweImhQgFfcCx0grnyd/hJO2g5b0dM8/trG63n1uaFq8WZz7JeD4ux1rp0QpvKhLkrHRxub2uYePdNAqM9Rjde90TrhvJWhktJohxFr99L7Y+txTai6Tjj9OCLwR9dN0qYgKU/Y73GW4RaQ8MHpdS/ntf04YixZ564VLdTeF/rDYCTUcPdKW8OYskg3v89TWGiMWl5VT7hD2x42d+U90ZU6MyUxf3hC9r9Fw9Y/GZ7VOR3izQu7iocSeVte5eNxa5tUg+wWYYniLP018DiwoWfPLWh09jG65rzzPi2jhzrSJuvhdL1o3eDJy/lwcOHJKyFgFrHbRI6wLDr2hcVaXlu2MWtI1tZMby3V1q2m3EjW0ULgG0QCwuedHI/ZfDbwAJS2FgKXyf6RvNqSdikXcz20PoZis2iu7AQC3USGlYrM7GEI4RFNmvRBE7N81urb5kpT2HAba0woxOswf4ciZ2/Mms/z0HJ+pOHY9uwvgf3arMzfaprjyPdCoSTYbgqeMx7YPUqwOMDk5Qyc0Sb846DAGcVPa57PZ7C2RmOVhNktIgm9cye9qMyWEZnS8JFlAJnr3749e39q5Vq57l5dDXevtGvIN2FPIVBY8P2tWrPwBpgT7+Xl9mboMIX8hLun6etrIZvmuIhbiYrZwQvL52lko3hVV6tTteK9yOR23mm5BtQm3aKwVZlbkKtveOuG7q/zRsheGb/UyFxzysOmsOcjBWnEzIJe6sOktiv2fP4952TvaYfhnJUQftcZmYzIlJNPqUWPMGOroSi0fV8LDYe2VniGFiTnJtCPgFRvmZV3ex/0rvUja7aIQy2y18JdKu3aArLmDkYWnqX89EK2pK5qIXUlVJZY2nMcNfgA7F7N2HhoxkR9U3gJthGMRpPEuFWv89yiM+s52HPBqJbb7yxCH731vkd7VdqZt3y9cVnWTy8dU1MAs57iSFprtK1VIMTfRSBdGvT2ASlbUjvHkj937xby+zevtFsWnqZQ5bXaYYCtrcYRQyBwtDIc3uLDRwKYbVajtU1ZrS78T9U28s3f64dCHdH7UUJmBk8hlk8t+uiFoHlyeM7jtRoC/jnG9fI9obh2Tc94VWW5PMyfWpWtMOsee7POZ6cubNtU9qBWvhfhUIkJmufKeq3yVBnj2t6SCmuNYtojCicRnBQS0mAwPF6kEvN7yOdkP0U9GkkDbl1pi9y0vhjsCknLIdjZ8KeMa63mFfLGlQLsbnjvuEO1uemzpgkx19Nk00fWGuVqfa4LjzTMVSPYOzpTyzfG9qLijv/bNkAwarJrcY71B0Gkrdbhg+9z4Ow9Je/3svRryi1tT3VPlLleXKH8snXLzZ+ZSNuQId+6DKlSE/+na6G1dnuzM2tEyJGfTyHofFTbzNZBGMs8b1YQ9wTM3CRrRQv5J+NmJWtvvVjaeYSlPV6Ne4Fuqz4Zyy24baUNAtGj5HNy1318JDKGfkGdi2frKNR7i90Jdrl9l7FdWjnJdjkqYGb/6ANyNDI+hKWo9csKn89dBkIKFdEUy2eUe2u9SbXyOY5Esxw3eiPHCDAL8YREobjL+zZCS/snLE9ICz82UaW9ZBuJCMRxRutdqClfHbFPnHkOOZ190d4T5VPY5LrP7rjXcs3k3vwabzhpUey/GXqSlzj6nk9kIdVyDTTFstWDJTem2bUTn5anncH3qVxTW45loBH0Z5QxXrZFJe5/r5OWH/hwpSzrVa6o4hxApQ5DyLDJLnK2VgIZKg8WjjRCCe+2/ToaKbhtpS3GqpdzK+6zfdHWPAs1JO//d8IqOekZ3eboTBcKO7iaoRwpi9QcTkvK6XVCk2JM6mueik9M5b2cPdI6kdSi7JN9kbZzv1KUjIECL+TqO/9aKO4krwdOAvSBTjFXuaI1hD1kjQvnzcz7RL1aphJYLG5NOfs0idbPWhpsKwydIyAUfUuke+7xhjf17wz3eJDlWcoKcW+5rq8pk2zsIO7l1LOWJ92ZpeL2USoS1rhxzjLlmZuqhVIN91NeRpCUF6wSZUaED1d2h4xQ/MRc3kaLn8xY6eG2lXYFvTDXqkm01vECiZbfjaXAl7tLcmGVKPgfsBhLQajb+rV8SeHDcVo+LUlDCrbkon3VitahQqta7OUDfXg1jqnOcz6uuvLpMNPh8ZLQwq1r+ajlqmfLte7Ph9PLcy7Wfo+Gl/M6au5UKSf5Sldku89Ww6BVfvGt2w8CKc9u9OeiFd7Pd51fi/nz5GcO2lmgZntsNdGScVueQ7l5pV0XsHXFfW78lvS2hyTOYBDOInjEiJ5p8Ncai6o8CDXmkY0aL8XIsOfUhfSL8Nbg4xybRbm7p1shvpqA20JoL/QFn9678GWcR1GMqBJJo8r1a8PnJa2HmKbbMdLJFeUsX+U8lr/XXTVgFcWttVnbwyPrT+bVq+uaRRCuYmzXwuMtPocR5EIdxbj5he9YGzGwgnJ2jpD/6lvKT5uXrQ1eeY6pjdLIqn1Waw/yffNKW6K3uYkITKxah3k5T0+bmN4W1KxUZoRcjyyjbU55qCMqBUPDJSfir43GaIg/nuTDLnhn6LbmOw/l9VDzMBZafpxSoUje1lACEQVnk+MneanxuhuCNugU24i/GUPLZgDMRd80xZzvz1r90Zx5rf2YqknL94wGjdZqcCpVcr41ZX2WeltEIS38FdcYAGWRBaq7DjOGaLU8K7Ks7UTHekjXzl64+d/Ttkwyg3F2/0LY2kh7PBNaoZXRiTkaLgSBBxGFX90Z44MAnLB8vcpo5eef5YKslhrHmgVby8dpBkHurczSj7SiMeWF6AnAIy9OR5oSQu8GHOwEzTELfN8a1314w3ktjdb13YQxA2B3GJLTdtL1byc5vDfcv5P7U785Qe664PEM9yOxJMthauHL/ecDfd5g7nVHOkK9cspVAG7MKJMtPnpANl1xifTWzXvarYMVi4Xlg9Te46rTkRPrFWa05NCsX7Tt/+fynoe0oGt9yg+G9UHw34XW2pRtF/fZHRESUQBiqfxYvPgygrlNZLnsqR4irFn2dZLbbxTiuImBilFFxRvP0CamYD13uD0CdUOkYGteZr2kcnzae61GtxfNsfLZgirMi6hyJ8yabMY+WqkmDeFQbQhepfz4vLrnPT3kvk5I9MLKfi/2DKseqpE2pYw3HsRPschSpvZGYVljN6+05YYazd+aN9nA+KfKkHDmc5evluExA2vITBVuzIuSIxLmq7IoOduE+elI5GPR5VrQSzWDdSxyIRLqm2r36NIUIRb/S1wqsr0X/Cyl6YPtOrXGI7HUbeWg888t5T2T9hlRlCGykdjWpWe/pPFkqN4YYVPaV2Ul6ravGr5O2nB1A5HtF39PzuVpjNGURkOCd9vXaO/pcd+20m54sdWCCjSlnx6eWGcdygUTna++9zAnBOOm6NFoLvSlQHYBIUQa1LiyGdahbSlfLI9bcrCXvDHDMpe7jA+VIfH8rPJ9YJnAXIhbvDNNcW8heEdptBS+V9x7oJKCLvnI+0OxTOR9/3VTU8r5eSWPWoqthpjenFsHs3LZgttW2gK1xUwGpZtvRO81hLC6EtkZDtn5PAzREja6kBKyCplw2A0IYSaS4bakqhd8rnD0u1ShIQ+dLOOZDiiFn7NM845+aGoetNqHLCWBzsbUoAW5/BYNUcgOLyljvZvt0B8wF20YrdukK/4Hlnm0ipbRMH4e3+nR3Kqudq8ZthbK339u1UuutQxA4S8kT1rzBoYwouThVrnP2g3YEcPDNoOAsvfeuEv2cNGIUjkykDgISVuZXMsPCvYMnNB0hW7JpuJVZ05M/DCveFtRAIvMuW2lbViTUsiaSIrCJ8SJJf/GiGLzBys4PUFuyZV1OLYzZUXcJZ6Z7LZU6IsiO59sGzqNote8dPtA+6+onUQ1/5ATAKD02GoTwQbJr2Xv6x63KnUqrcmyjxrl5jEfrWnQDK+R39PpNOQdUPa6tue5ogC5p9Kx96yXMx5n6AI+oaVc145d+YNZy/eD871uNE64DH0HGtDPuyxGP4M5PpdLmLyZ9tgO8YE4+bWMPSzPpQifGUluW/KcPCUy7NnUiC0fZtIOMffC3qoxRVjWTGhT9NaxuKwdMdael3PcY2clRRjaALpG3Va4baUNy+ZIvaNuDqmRzxgRgPnCyr1Fed+fEJ/HdhvUQqmwYr2nXEq2tF6Flt8ZPClwqmG7vPGeh0yVfih1dIWoCbXU8491KCmZsrHNd0o1T8RSvgaNpRmjINTIU0Z5ezM0gYTRJIJUq5sJ08KQDHafIhsoRpqip9sZE0696NybrrWVl4nktA7Oy4Tq+stJVpsVD5NyF4unenmDhaOBEhVi6TV7vlqY3TPScIrjLwv4NVCO9Ol08rMfe1Axwi6Fm1fafaSW2xqszRvmObRtvKA+jT2tOgQrtf2VmpmuWsKq7qnGfXTaT8Jl2GjMON2sbUu739daeNDMTqdPs+tx9BCOdq16+KlBq2dIxWiQn9vUcM6xJjcpc5x74JL5YM3R0D5bUV1VIZInP5ZtW9J7szLVoh2YOT6LAanXHJ3rklLBr2Bt1jC///A4LN7DFjTmPR813CbC4usU97YhMHuzcvV5YamEjqQArXop24ZH4xX/9bWyPcljcv3CwxnHab5+K586q+R7h3g02tY24lmIPljkM3NlbFEoITyulMnHTXrY40aIG2/L+HJ9mfXymMn9DdeqdTxXtdHKiSdRsOVCmAvYvNSWQWiCD/gl0Z8l/Cdb9/cI6dzL9tSxFBGY/CxEwUoW7dFotnDzSruVMgyHnnrRKtYPa605JaqF2UbohLLVcBup14dyi9MGg1jIvG6cAjWu89PlU2z6eEAHwfunIBDiXESDIY4zA921shZ15VKuk573sLWxWRMW+rkDyXu/vXSN1NdL0nal/ZwXkpOct8k5Xd++H2O9bQtYtJv/8FZO099OBX6/3Xwt7BFmnVUOsZL8oChnXs4HnRH3elEtQTTsFvG330/O+jaEkx/1BtK5k+Vzla1lYaRyzhV//n6Nks5x40pbfzIPAHHIgcB4oUtJs3zW5hZVj3PAw5biK+bO0pDfpRGXcna9IYB7lqU1gaHOh99oypD4LFM85KLjjHKemnzsOPatcRrB7KGXmgE7WnfkXoOgylOhxFHuBr0f/liTM+lYXpPldIO4gDcG0Vm/UgF1kMuM3PMPv+28wxq0GmBppZQT+d7PgfReiZX8dhVWyWCHtV/aHvBhcqA0nmRUaKY9Cz9WOjettDWrNb2/LJBcYNQEiFZuBGrIVfKjGAUqHZV2eleruqc1GlvW263xk1ibMuwEGU0gtb6kk79PDwilr/JT9ICi4pZRjEXg8phs2CCcbWpmUnmPHkDLsdc6GlbctHg8Le9+KUZyg2Tead2IqNGzICrqdl3tmeEm+jUFusJe19ZDa41YDn7FvdePHnh5XPvtBy2svBgp2xgouSxKeWsjRjqEd40yTJ6OpysdiI/v/Z5O0XDTStsC/9WM5NrKRaAJH1tYcLDtpGi6W/dW0EnLnVB9ntsrr081KiktCvY83+fCE5M3LjeUd4mtwnYz0HLPEjL8HOc0NwpRneNV/Qlbcrsx0dIjhQLfrLWImXGoxTlrc5RVTkLS9UZ0mWcy5Bp8WTxXbR4SgwdLhC8Yh9QySi8XGb17pa2N1ai3U7MKZ7ymnredKJOdMMJ33nPKBGDvgFBr86TKPhO0Sdit/M7q+PC4QHnmZatft2mMz6jRNRtKz6MUM7DWawmvnnDbIpS/FgwAmbKTyo1oMfry352tGyPtyI+ZL2FQWFZs7UDYVimTEeSH8or23f60Oi9KC24P+v3O8o5oc/ssfr6vNJllMjwEd4x0LFRPvhPhWBPllbh/pc3LwMrDRxasFZhWnM/n0J57s2t70xBsbTUmNYGQh9H3wL0417NjLcd2TV7t0p51Dc0zEU1DuM9/7lFtqbC3Wmi5IbKWzq0hi6sVkPJ7zzU57IjVIj+0H589HulWNq0GIvp9AP8XwP++Ni9XwCtw9PtxwtHvxwtHvx8vjPb7LzLz12k3blppAwARfYqZv+XafFwaR78fLxz9frxw9Pvxwpb9Xvt8zQMHDhw4cODAhXAo7QMHDhw4cOBOcA9K+/3XZuBKOPr9eOHo9+OFo9+PFzbr983ntA8cOHDgwIEDC+7B0z5w4MCBAwcO4IaVNhE9RUTPENGzRPS+a/OzJYjoA0T0PBF9Vlz7GiL6GBH9pnv9anediOhfu3H4DBG96XqcrwMRvZqIfp6IPk9EnyOi73XXH3TfieiriOiTRPSrrt//zF1/LRF9wvXvJ4noxe76S9znZ93911yT/7UgokdE9CtE9BH3+cH3m4i+SES/RkSfJqJPuWsPep0DABG9nIh+ioh+nYi+QERvfej9JqLXuXn2f39MRN+3V79vUmkT0SMAPwLgbQDeAOBdRPSG63K1KX4cwFPZtfcB+DgzPwng4+4zsIzBk+7vPQB+9EI87oGvAPjHzPwGAG8B8F43rw+9738K4DuY+ZsAvBHAU0T0FgD/HMAPMfNfAvAHAN7tyr8bwB+46z/kyt0zvhfAF8Tnx6Xff4OZ3yi+6vPQ1zkA/DCA/8bMrwfwTVjm/UH3m5mfcfP8RgB/FcCfAPhp7NVv/yi7W/oD8FYAHxWfnwbw9LX52riPrwHwWfH5GQCvcu9fBeAZ9/7fAniXVu7e/wD8VwB/83HqO4A/B+CXAXwrloctvMhdD2sewEcBvNW9f5ErR9fmfbK/TziB9R0APoLlgViPQ7+/COAV2bUHvc4BvAzAb+dz9tD7nfX1bwH4n3v2+yY9bQBfD+BL4vNz7tpDxiuZ+Xfc+98F8Er3/kGOhQt9fjOAT+Ax6LsLEX8awPMAPgbgtwD8ITN/xRWRfQv9dvf/CMDXXpbjzfCvAHw/4pPBvxaPR78ZwM8S0S8R0XvctYe+zl8L4PcB/HuXDvl3RPRSPPx+S7wTwAfd+136fatK+7EGL+bXgz3WT0R/HsB/AvB9zPzH8t5D7Tszv8BL+OwJAG8G8Pors7Q7iOi7ATzPzL90bV6ugG9j5jdhCYW+l4j+urz5QNf5iwC8CcCPMvM3Y3kEdXIe6YH2GwDgzma8HcB/zO9t2e9bVdpfBvBq8fkJd+0h4/eI6FUA4F6fd9cf1FgQ0Z/BorB/gpn/s7v8WPQdAJj5DwH8PJaw8MuJyP9oj+xb6Le7/zIA/+fCrG6Bvwbg7UT0RQAfwhIi/2E8/H6Dmb/sXp/Hkt98Mx7+On8OwHPM/An3+aewKPGH3m+PtwH4ZWb+Pfd5l37fqtL+RQBPulOmL8YScvjwlXnaGx8G8D3u/fdgyff663/PnTh8C4A/EiGXuwIREYAfA/AFZv6X4taD7jsRfR0Rvdy9/7NY8vhfwKK83+GK5f324/EOAD/nLPW7AjM/zcxPMPNrsOzhn2Pmv4sH3m8ieikR/QX/Hkue87N44OucmX8XwJeI6HXu0ncC+DweeL8F3oUYGgf26ve1E/eNhP53AfgNLLm/H7g2Pxv37YMAfgfA/8Ninb4bS+7u4wB+E8B/B/A1rixhOUn/WwB+DcC3XJv/Ff3+Niwhos8A+LT7+66H3ncA3wjgV1y/Pwvgn7jr3wDgkwCexRJSe4m7/lXu87Pu/jdcuw8bjMG3A/jI49Bv179fdX+f8/Lroa9z15c3AviUW+v/BcBXPyb9fimWqNDLxLVd+n08Ee3AgQMHDhy4E9xqePzAgQMHDhw4kOFQ2gcOHDhw4MCd4FDaBw4cOHDgwJ3gUNoHDhw4cODAneBQ2gcOHDhw4MCd4FDaBw4cOHDgwJ3gUNoHDhw4cODAneBQ2gcOHDhw4MCd4P8DNp1tYrrwlG4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x1224 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dhHNprHQwQP"
      },
      "source": [
        "# 8. Zip  & Download Inference Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnuQmDhRGbX"
      },
      "source": [
        "%cd /content/dataset/models\r\n",
        "!zip -r inference_graph.zip inference_graph\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.download(\"inference_graph.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aphTNb9XSHgC"
      },
      "source": [
        "___\r\n",
        "# Source :\r\n",
        "- https://muchamadsyaiffudin.medium.com/object-detection-with-custom-dataset-faster-rcnn-on-google-colab-33b373a625eb\r\n",
        "- https://colab.research.google.com/drive/1skc-BJ6HzuaIRbi3diP86lRnCTcNCond?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfa2ew_pRdZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYlGooKpxSe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e21a8d1b-bf16-44c7-e446-5be487a46fdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/models/research/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/models/research/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkIgy06m_FRG"
      },
      "source": [
        "**RUN WEBCAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxXfkQv_BS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6607d02e-4328-4123-ba12-5a298a662b6a"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "#if tf.__version__ < '1.4.0':\n",
        "#  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
        "  \n",
        "  \n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/dataset/models/inference_graph' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/dataset/data/', 'object-detection.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "     \n",
        "    \n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "    # Run inference\n",
        "    output_dict = sess.run(tensor_dict,\n",
        "                            feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "    output_dict['detection_classes'] = output_dict[\n",
        "        'detection_classes'][0].astype(np.uint8)\n",
        "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "    if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOF45NDg__G6"
      },
      "source": [
        "    import cv2\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "        ops = tf.get_default_graph().get_operations()\n",
        "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "        tensor_dict = {}\n",
        "        for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "          ]:\n",
        "            tensor_name = key + ':0'\n",
        "            if tensor_name in all_tensor_names:\n",
        "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "        while True:\n",
        "            ret, image_np = cap.read()\n",
        "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            # Actual detection.\n",
        "            output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "            # Visualization of the results of a detection.\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "              image_np,\n",
        "              output_dict['detection_boxes'],\n",
        "              output_dict['detection_classes'],\n",
        "              output_dict['detection_scores'],\n",
        "              category_index,\n",
        "              instance_masks=output_dict.get('detection_masks'),\n",
        "              use_normalized_coordinates=True,\n",
        "              line_thickness=8)\n",
        "            cv2.imshow('object detection', cv2.resize(image_np, (800,600)))\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                cap.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}