{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster R-CNN Training using Custom Dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6baQ8wWMPkfO"
      },
      "source": [
        "# Faster R-CNN Training using Tensorflow\r\n",
        "___\r\n",
        "\r\n",
        "### Before started!\r\n",
        "- navigate to `Runtime` menu, and choose `change runtime type`,\r\n",
        "- then, change `hardware acceleration` to `GPU`\r\n",
        "- click `connect` button in top-right colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOpn4IebMl6p"
      },
      "source": [
        "# 1. Install Library\n",
        "### 1.A. Install Tensorflow 1.15 & OpenCV 4.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvLlklwNhg_"
      },
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmTVmjYeY4lU"
      },
      "source": [
        "!pip install opencv-python==4.4.0.46\r\n",
        "!pip install opencv-contrib-python==4.4.0.46"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLBq4481GWAD"
      },
      "source": [
        "### 1.B. Install Other Library & Clone Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGqlSTLuxld"
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython tf_slim\n",
        "!pip install -q pycocotools\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_drTO_gGeYP"
      },
      "source": [
        "### 1.C. Build Tensorflow Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCdUXiMQ-OBX"
      },
      "source": [
        "%cd /content/models/research\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += \":/content/models\"\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append(\"/content/models\")\r\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiXiLQumY-nz"
      },
      "source": [
        "# 2. Prepare Dataset\r\n",
        "### 2.A Upload and extract dataset.\r\n",
        "- upload `dataset.zip` using this script,\r\n",
        "- `dataset.zip` is created by running `dataset_builder.ipynb` from this repository ([ObjectDetection-Tensorflow](https://github.com/Muhammad-Yunus/ObjectDetection-Tensorflow)) in your local computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THhnes1ckVA5"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files\n",
        "from os import path\n",
        "\n",
        "print(\"Upload `dataset.zip` to colab :\")\n",
        "uploaded = files.upload()\n",
        "  \n",
        "for fileName, data in uploaded.items():\n",
        "  with open('dataset.zip', 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved dataset (.zip) file ' + fileName)\n",
        "\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKqIKqOc7bzs"
      },
      "source": [
        "### 2.B. Prepare Dataset \r\n",
        "- Convert XML PASCAL VOC to CSV\r\n",
        "- Create TF_Record from generated CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yre-rvSJ83bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31afd446-d68c-4221-f58b-7a2526327fca"
      },
      "source": [
        "%cd /content/dataset\n",
        "\n",
        "!python xml_to_csv.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHhmA2KNNUGl"
      },
      "source": [
        "- edit `class_text_to_int()` function in `generated_tfrecord.py` with label and index label we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeqgzNhluaC"
      },
      "source": [
        "%cd /content/dataset\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=data/train.record --image_dir=images/train\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=data/test.record --image_dir=images/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyO_oSKdhsG"
      },
      "source": [
        "# 3. Download pretrained model\n",
        "\n",
        "- Pretrained model (Tensorflow 1 Model Zoo) : [[tensorflow github](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZJly9QBTS1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce798192-1430-4efb-8c37-4c763d926090"
      },
      "source": [
        "%cd /content/dataset\n",
        "%rm -rf models\n",
        "\n",
        "%mkdir models\n",
        "%mkdir models/inference_graph"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUDk1gLQsWOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f575140-94a4-4a0b-924b-aef5be240771"
      },
      "source": [
        "%cd /content/dataset/models\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "MODEL = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'faster_rcnn_inception_v2'\n",
        "\n",
        "with urllib.request.urlopen(DOWNLOAD_BASE+MODEL_FILE) as response, open(MODEL_FILE, 'wb') as out_file:\n",
        "  shutil.copyfileobj(response, out_file)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QydCLoLFIWLN"
      },
      "source": [
        "# 4. Copy & Edit Config File\r\n",
        "- copy config model to `data/` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UVdm_SRi-SwV",
        "outputId": "a6379d5e-5ecc-4624-e641-c8229b38d267"
      },
      "source": [
        "CONFIG_NAME = \"faster_rcnn_inception_v2_coco.config\"\r\n",
        "shutil.copy(\r\n",
        "    \"/content/models/research/object_detection/samples/configs/\" + CONFIG_NAME, \r\n",
        "    \"/content/dataset/data/\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/dataset/data/faster_rcnn_inception_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSdT5sLCMyeI"
      },
      "source": [
        "- open & edit config file in `/content/dataset/data/faster_rcnn_inception_v2_coco.config`, \r\n",
        "\r\n",
        "- navigate to line 10, change  `model`>`faster_rcnn`>`num_classes` to number of class on uploaded dataset (e.g/ 2).\r\n",
        "- navigate to line 107,\r\n",
        "```\r\n",
        "fine_tune_checkpoint: \"/Path to the pre-trained models/model.ckpt\"\r\n",
        "```\r\n",
        "- change to \r\n",
        "```\r\n",
        "/content/dataset/models/faster_rcnn_inception_v2/model.ckpt\r\n",
        "```\r\n",
        "- navigate to line 113, change `train_config`>`num_steps` to number of training step (e.g/ 2000)\r\n",
        "- navigate to line 120,\r\n",
        "```\r\n",
        "train_input_reader: {\r\n",
        "  tf_record_input_reader {\r\n",
        "  input_path: \"/Path to the tfrecord/train.record\"\r\n",
        "  }\r\n",
        "  label_map_path: \"/Path to label map/object-detection.pbtxt\"\r\n",
        "}\r\n",
        "```\r\n",
        "- change `input_path` to,\r\n",
        "```\r\n",
        "/content/dataset/data/train.record\r\n",
        "```\r\n",
        "- change `label_map_path` to,\r\n",
        "```\r\n",
        "/content/dataset/data/object-detection.pbtxt\r\n",
        "```\r\n",
        "\r\n",
        "- navigate to line 134,\r\n",
        "```\r\n",
        "eval_input_reader: {\r\n",
        "tf_record_input_reader {\r\n",
        "input_path: \"/Path to the tfrecord/test.record\"\r\n",
        "}\r\n",
        "label_map_path: \"/Path to label map/object-detection.pbtxt\"\r\n",
        "}\r\n",
        "```\r\n",
        "- change `input_path` to,\r\n",
        "```\r\n",
        "/content/dataset/data/test.record\r\n",
        "```\r\n",
        "- change `label_map_path` to,\r\n",
        "```\r\n",
        "/content/dataset/data/object-detection.pbtxt\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAYXLhS2uZ9X"
      },
      "source": [
        "# 5. Train model\n",
        "Make and set train directory num_train_steps and num_eval_steps values to change train and eval steps in training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF7VAuMY_9aK"
      },
      "source": [
        "!cp /content/models/research/object_detection/legacy/train.py /content/models/research/object_detection"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aFmHc6wcR0Y"
      },
      "source": [
        "%cd /content/models/research/object_detection/\n",
        "%rm -rf training/*\n",
        "\n",
        "!python train.py \\\n",
        "  --logtostderr \\\n",
        "  --train_dir=training/ \\\n",
        "  --pipeline_config_path=/content/dataset/data/faster_rcnn_inception_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaxwL13IdftO"
      },
      "source": [
        "# 5. Tensorboard Training Visualisation + Ngrok\r\n",
        "- **TensorBoard** is a tool for providing the `measurements` and `visualizations` needed during the machine learning workflow. It enables `tracking` experiment `metrics` like `loss` and `accuracy`, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\r\n",
        "- **ngrok** is secure `introspectable tunnels` to `localhost` webhook development tool and debugging tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w5x4EJQbM59"
      },
      "source": [
        "%cd /content/models/research/object_detection/training/\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F36HIisRcClB"
      },
      "source": [
        "LOG_DIR = '/content/models/research/object_detection/training/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFxPaub4A_GB"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTQxZXmZcNtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a13f4b-f332-4feb-c55a-c4f93067c92b"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://b4f9d7cbe24c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCrPTr-4u0dw"
      },
      "source": [
        "- close ngrok - tensorboard for training log visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q92w-ApwtOUp",
        "outputId": "9997c4ba-e44d-41b1-ad7d-c6ae01901115"
      },
      "source": [
        "!ps aux | grep ngrok"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root        4478  0.8  0.2 122768 29960 ?        Sl   00:53   0:00 ./ngrok http 6006\n",
            "root        4534  0.0  0.0  39204  6436 ?        S    00:54   0:00 /bin/bash -c ps aux | grep ngrok\n",
            "root        4536  0.0  0.0  38576  5596 ?        S    00:54   0:00 grep ngrok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI4i5_gBtRse"
      },
      "source": [
        "!kill -9 4478  #<---ngrok tensorboard train pid--->"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hb9qzlQiffl"
      },
      "source": [
        "#. 6 Tensor Board Eval Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwbTu781iovB",
        "outputId": "5745f0e8-788a-40d8-b605-e3a949fcdd88"
      },
      "source": [
        "%cd /content/models/research/object_detection/\r\n",
        "!cp /content/models/research/object_detection/legacy/eval.py /content/models/research/object_detection"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y0IF7uxjWak"
      },
      "source": [
        "!pip install lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEo3knlvu8c5"
      },
      "source": [
        "- run evaluation metric (`eval.py`) to find **mAP** of object detection model,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4EcgSMaimLv"
      },
      "source": [
        "%rm -rf eval/*\r\n",
        "\r\n",
        "!python eval.py \\\r\n",
        "  --logtostderr \\\r\n",
        "  --pipeline_config_path=/content/dataset/data/faster_rcnn_inception_v2_coco.config \\\r\n",
        "  --checkpoint_dir=training/ \\\r\n",
        "  --eval_dir=eval/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOkQx0Au53T3"
      },
      "source": [
        "%cd /content/models/research/object_detection/training/\r\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_WNzm0Dk35k"
      },
      "source": [
        "LOG_DIR = '/content/models/research/object_detection/eval/'\r\n",
        "get_ipython().system_raw(\r\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6007 &'\r\n",
        "    .format(LOG_DIR)\r\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugDZQ69Ql_Tj"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6007 &')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiEgBV-omCz0",
        "outputId": "b7f483ac-4cd4-4403-e476-82186a8995c6"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\r\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://a5e52255d1e4.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJCB5NKK4Nb"
      },
      "source": [
        "# 7. Export trained model\n",
        "\n",
        "Export trained model with highest step number in filename.\n",
        "- change `model.ckpt-xxxxx` with `xxxxx` is number of step in trainingphase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNlbs1R-B2q"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "%rm -rf inference_graph/*\n",
        "\n",
        "!python export_inference_graph.py \\\n",
        "  --input_type image_tensor \\\n",
        "  --pipeline_config_path /content/dataset/data/faster_rcnn_inception_v2_coco.config \\\n",
        "  --trained_checkpoint_prefix /content/models/research/object_detection/training/model.ckpt-120000 \\\n",
        "  --output_directory /content/dataset/models/inference_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YAGmBifasRy"
      },
      "source": [
        "# 8. Generate OpenCV DNN Config for Inference\r\n",
        "- generate `faster_rcnn_inception_v2_custom_dataset.pbtxt` for OpenCV DNN inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKsDngRZas5S"
      },
      "source": [
        "%cd /content\r\n",
        "!python dataset/cvdnn_config_generator/tf_text_graph_faster_rcnn.py \\\r\n",
        "    --input dataset/models/inference_graph/frozen_inference_graph.pb \\\r\n",
        "    --output dataset/models/inference_graph/faster_rcnn_inception_v2_custom_dataset.pbtxt \\\r\n",
        "    --config dataset/models/inference_graph/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk7O6XltU2si"
      },
      "source": [
        "# 9. Test Model (Inferencing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvwN58CCcA3j"
      },
      "source": [
        "- upload arial font (`arial.ttf`) from cloned repo ([ObjectDetection-Tensorflow](https://github.com/Muhammad-Yunus/ObjectDetection-Tensorflow)) using script below,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrZQ_i-Ebc4-"
      },
      "source": [
        "uploaded = files.upload()\r\n",
        "  \r\n",
        "for name, data in uploaded.items():\r\n",
        "  with open('/content/models/research/object_detection/utils/arial.ttf', 'wb') as f:\r\n",
        "    f.write(data)\r\n",
        "    f.close()\r\n",
        "    print('saved file ' + name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG98BJDOdmny"
      },
      "source": [
        "- open `/content/models/research/object_detection/utils/visualization_utils.py` and navigate to line `212`, change *font size* to a proper value (e.g/ 50).\r\n",
        "    ```\r\n",
        "    try:\r\n",
        "      font = ImageFont.truetype('arial.ttf', 50)\r\n",
        "    except IOError:\r\n",
        "      font = ImageFont.load_default()\r\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llq00Y-zQbAk"
      },
      "source": [
        "- Upload image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI8Ya_6GE9ll"
      },
      "source": [
        "%cd /content\n",
        "# upload image from local computer to colab\n",
        "\n",
        "from google.colab import files\n",
        "from os import path\n",
        "\n",
        "uploaded = files.upload()\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open('image1.jpg', 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUiDDKD-Qj6I"
      },
      "source": [
        "- predict on `image1.jpg`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUy6KXMToLVc"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "# [NOTE!] this sample implementation using Tensorflow ver 1.14\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils import label_map_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from utils import visualization_utils as vis_util\n",
        "import importlib\n",
        "importlib.reload(vis_util)\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/dataset/models/inference_graph' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/dataset/data', 'object-detection.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 2 #[TODO!] change to number of training class\n",
        "\n",
        "TEST_IMAGE_PATHS = [ os.path.join('/content/', 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
        "\n",
        "IMAGE_SIZE = (8, 17)\n",
        "\n",
        "# load frozen inference graph\n",
        "frcnn_graph = tf.Graph()\n",
        "with frcnn_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "# load label map\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "# PIL image to numpy array converter\n",
        "def PIL_to_numpy(image):\n",
        "  (w, h) = image.size\n",
        "\n",
        "  return np.array(image.getdata()).reshape((h, w, 3)).astype(np.uint8)\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "          \n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        \n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        \n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "                                      'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "# -------------- main block --------------\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  # read image using PIL\n",
        "  image = Image.open(image_path)\n",
        "  image_np = PIL_to_numpy(image)\n",
        "\n",
        "  # predict image\n",
        "  output_dict = run_inference_for_single_image(image_np, frcnn_graph)\n",
        "\n",
        "  # draw bousing box using `vis_util`\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  \n",
        "  # show image\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dhHNprHQwQP"
      },
      "source": [
        "# 10. Zip  & Download Inference Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnuQmDhRGbX"
      },
      "source": [
        "%cd /content/dataset/models\r\n",
        "!zip -r inference_graph.zip inference_graph/frozen_inference_graph.pb inference_graph/faster_rcnn_inception_v2_custom_dataset.pbtxt\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.download(\"inference_graph.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aphTNb9XSHgC"
      },
      "source": [
        "___\r\n",
        "# Source :\r\n",
        "- https://muchamadsyaiffudin.medium.com/object-detection-with-custom-dataset-faster-rcnn-on-google-colab-33b373a625eb\r\n",
        "- https://colab.research.google.com/drive/1skc-BJ6HzuaIRbi3diP86lRnCTcNCond?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfa2ew_pRdZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}